import json
from dojo.models import Finding


class HarborVulnerabilityParser(object):

    """
    Read JSON data from Harbor compatible format and import it to DefectDojo
    """

    def __init__(self, filename, test):

        self.items = []
        if filename is None:
            return

        tree = filename.read()
        try:
            data = json.loads(str(tree, "utf-8"))
        except:
            data = json.loads(tree)

        # When doing dictionary, we can detect duplications
        dupes = dict()

        # To be compatible with update in version
        try:
            vulnerability = data[next(iter(data.keys()))]["vulnerabilities"]
        except (KeyError, StopIteration):
            return

        # Early exit if empty
        if vulnerability is None:
            return

        for item in vulnerability:
            # Default = empty string
            title = ""
            sev = ""
            findingdetail = ""
            mitigation = ""
            impact = ""
            references = ""
            static_finding = True

            # Trying to add all possible details
            title = "{} - {} ({})".format(item["id"], item["package"], item["version"])
            sev = transpose_severity(item["severity"])
            findingdetail += item["description"]

            if item["fix_version"]:
                mitigation += "Upgrade {} to version {}\n\n".format(
                    item["package"], item["version"]
                )

            if len(item["links"]) > 0:
                for l in item["links"]:
                    references += "{}\n".format(l)
                mitigation += "Reference: {}".format(item["links"][0])

            dupe_key = title

            if dupe_key in dupes:
                find = dupes[dupe_key]
            else:
                dupes[dupe_key] = True

                find = Finding(
                    title=title,
                    test=test,
                    active=False,
                    verified=False,
                    description=findingdetail,
                    severity=sev,
                    numerical_severity=Finding.get_numerical_severity(sev),
                    mitigation=mitigation,
                    impact=impact,
                    references=references,
                    file_path=filename,
                    url="N/A",
                    static_finding=True,
                )

                dupes[dupe_key] = find
                findingdetail = ""

        self.items = list(dupes.values())


def transpose_severity(severity):
    if (severity == "Negligible") or (severity == "Unknown"):
        return "Informational"
    else:
        return severity.title()
