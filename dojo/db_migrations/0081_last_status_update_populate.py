# Generated by Django 2.2.17 on 2021-02-27 17:14
from django.db import migrations
from django.utils import timezone
from django.db import connection
import logging
logger = logging.getLogger(__name__)


def populate_last_status_update(apps, schema_editor):
    # We can't import the models directly as it may be a newer
    # version than this migration expects. We use the historical version.

    now = timezone.now()
    Finding = apps.get_model('dojo', 'Finding')
    findings = Finding.objects.order_by('id').only('id', 'is_Mitigated', 'mitigated', 'last_reviewed', 'last_status_update')

    # use filter to make count fast on mysql
    total_count = Finding.objects.filter(id__gt=0).count()
    logger.info('Setting last_status_update timestamp on %s findings to be initially equal to last_reviewed timestamp (may take a while)', total_count)

    # some dude in switzerland says he has 500k findings and the migration needed to be optimized to not take 1,5 hours to run
    # using paging (LIMIT/OFFSET) is very slow, the higher the page number, the longer the query takes
    # so we use a 'seek' method
    with connection.cursor() as cursor:
        cursor.execute("UPDATE dojo_finding SET mitigated = CASE WHEN last_reviewed is not NULL THEN last_reviewed ELSE %s END WHERE is_Mitigated = 1 AND mitigated IS NULL", [now])
        row = cursor.fetchone()

        logger.debug(connection.queries[-1])

        cursor.execute("UPDATE dojo_finding SET last_status_update = CASE WHEN last_reviewed is not NULL THEN last_reviewed ELSE mitigated END WHERE (last_reviewed IS NOT NULL or (is_Mitigated = 1 AND mitigated IS NOT NULL))")
        row = cursor.fetchone()

        logger.debug(connection.queries[-1])


class Migration(migrations.Migration):

    dependencies = [
        ('dojo', '0080_last_status_update'),
    ]

    operations = [
        migrations.RunPython(populate_last_status_update, migrations.RunPython.noop),
    ]
