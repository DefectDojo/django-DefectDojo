[{"content":"There are no special instructions for upgrading to 2.41.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":0,"permalink":"/en/open_source/upgrading/2.41/","summary":"There are no special instructions for upgrading to 2.41.x. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.41.x"},{"content":"With the upgrade to Django 5.1.x, Posgres 12 will no longer be supported. Please make plans to upgrade to a later version of Postrges before upgrading to version 2.40.0 of DefectDojo. To determine which version of Postgres to target, please refer to the end of life version schedule\nCheck the Release Notes for the contents of the release.\n","date":"0001-01-01","id":1,"permalink":"/en/open_source/upgrading/2.40/","summary":"With the upgrade to Django 5.1.x, Posgres 12 will no longer be supported. Please make plans to upgrade to a later version of Postrges before upgrading to version 2.","tags":[],"title":"Upgrading to DefectDojo Version 2.40.x"},{"content":"There are no special instructions for upgrading to 2.39.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":2,"permalink":"/en/open_source/upgrading/2.39/","summary":"There are no special instructions for upgrading to 2.39.x. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.39.x"},{"content":"Breaking Change\nPrevious HELM values.yaml file was not following the official HELM best practicies on key naming - https://helm.sh/docs/chart_best_practices/values/#naming-conventions\nThe following snake_case keys are replaced with camelCase keys in the values.yaml:\nsite_url is replaced with siteUrl\ncelery.worker.app_settings block is replaced with celery.worker.appSettings. In this block:\npool_type is replaced with poolType autoscale_min is replaced with autoscaleMin autoscale_max is replaced with autoscaleMax prefetch_multiplier is replaced with prefetchMultiplier django.uwsgi.app_settings block is changed to django.uwsgi.appSettings. In this block:\nmax_fd is changed to maxFd django.uwsgi.enable_debug is changed to django.uwsgi.enableDebug\nThere are no other special instructions for upgrading to 2.38.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":3,"permalink":"/en/open_source/upgrading/2.38/","summary":"Breaking Change\nPrevious HELM values.yaml file was not following the official HELM best practicies on key naming - https://helm.sh/docs/chart_best_practices/values/#naming-conventions\nThe following snake_case keys are replaced with camelCase keys in the values.","tags":[],"title":"Upgrading to DefectDojo Version 2.38.x"},{"content":"Breaking Change\nSupport for MySQL and RabbitMQ was previously deprecated see discussion post here) and is now being removed\nMySQL and RabbitMQ have been removed from the following places:\nDocker Compose files Helm Chart Unit/Integration CI/CD Tests There are no other special instructions for upgrading to 2.37.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":4,"permalink":"/en/open_source/upgrading/2.37/","summary":"Breaking Change\nSupport for MySQL and RabbitMQ was previously deprecated see discussion post here) and is now being removed\nMySQL and RabbitMQ have been removed from the following places:","tags":[],"title":"Upgrading to DefectDojo Version 2.37.x"},{"content":"Previous HELM deployments (HELM chart \u0026lt;=1.6.136, DefectDojo \u0026lt;=2.35.4) used a pinned version of PostgreSQL in versions 11.x. These are incompatible with Django in version 4.2 (used from DefectDojo version 3.36.0; HELM chart 1.6.137). Because of this, it is necessary to upgrade PostgreSQL to version 12.x or higher. DefectDojo in version 3.36.1 (HELM chart 1.6.138) uses this new version of PostgreSQL.\nUnfortunately, an upgrade of PostgreSQL is not enough because PostgreSQL does not support automatic migration of data structures in the filesystem. Because of this, migration is needed. There are different ways (many of them similar to migration between different database backends (e.g. from MySQL to PostgreSQL)). Please find inspiration and the best fitting way for you in:\nhttps://github.com/DefectDojo/django-DefectDojo/discussions/9480 https://owasp.slack.com/archives/C2P5BA8MN/p1717610931766739?thread_ts=1717587117.831149\u0026amp;cid=C2P5BA8MN https://dev.to/jkostolansky/how-to-upgrade-postgresql-from-11-to-12-2la6 There are no other special instructions for upgrading to 2.36.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":5,"permalink":"/en/open_source/upgrading/2.36/","summary":"Previous HELM deployments (HELM chart \u0026lt;=1.6.136, DefectDojo \u0026lt;=2.35.4) used a pinned version of PostgreSQL in versions 11.x. These are incompatible with Django in version 4.","tags":[],"title":"Upgrading to DefectDojo Version 2.36.x"},{"content":"From 2.35.0, DefectDojo will perform an integrity check of the settings.dist.py file to ensure it has not been modified. If the user changed this file (in the past or even now) the DefectDojo instance will not start until those changes have been reverted. Any customization of variables needs to be done via environmental variables or in \u0026rsquo;local_settings.py\u0026rsquo;. For more information check Configuration documentation page.\nThere are no other special instructions for upgrading to 2.35.x. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":6,"permalink":"/en/open_source/upgrading/2.35/","summary":"From 2.35.0, DefectDojo will perform an integrity check of the settings.dist.py file to ensure it has not been modified. If the user changed this file (in the past or even now) the DefectDojo instance will not start until those changes have been reverted.","tags":[],"title":"Upgrading to DefectDojo Version 2.35.x"},{"content":"Breaking Change\nAWS_Scout2 has been removed. This parser was already disactivated by default in releases \u0026gt;= 2.3.1. and has been replaced with ScoutSuite (https://github.com/nccgroup/ScoutSuite) upstream. Please switch to ScoutSuite now if you haven\u0026rsquo;t done it yet. For all other changes, check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":7,"permalink":"/en/open_source/upgrading/2.34/","summary":"Breaking Change\nAWS_Scout2 has been removed. This parser was already disactivated by default in releases \u0026gt;= 2.3.1. and has been replaced with ScoutSuite (https://github.","tags":[],"title":"Upgrading to DefectDojo Version 2.34.x"},{"content":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\nAcunetix and Acunetix360 were merged to Acunetix. There is a migration process built into the upgrade that will automatically convert existing Acunetix360 findings into Acunetix findings. Breaking Change\nIf there is any use of the above mentioned Acunetix360 parser in an automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated accordingly. For all other changes, check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":8,"permalink":"/en/open_source/upgrading/2.33/","summary":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\nAcunetix and Acunetix360 were merged to Acunetix.","tags":[],"title":"Upgrading to DefectDojo Version 2.33.x"},{"content":"There are no special instructions for upgrading to 2.32.x. Check the Release Notes for the contents of the release.\nRemoval\nThe OpenAPI 2.0 Swagger API documentation was removed in favor of the existing OpenAPI 3.0 API documentation page.\nNote: The API has not changed in any way and behaves the same between OAPI2 and OAPI3\n","date":"0001-01-01","id":9,"permalink":"/en/open_source/upgrading/2.32/","summary":"There are no special instructions for upgrading to 2.32.x. Check the Release Notes for the contents of the release.\nRemoval","tags":[],"title":"Upgrading to DefectDojo Version 2.32.x"},{"content":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\nOpenVAS XML and OpenVAS CSV were merged to OpenVAS Parser. There is a migration process built into the upgrade that will automatically convert existing OpenVAS XML and OpenVAS CSV findings into OpenVAS Parser findings. Clair Scan and Clair Klar Scan were merged to Clair Scan. There is a migration process built into the upgrade that will automatically convert existing Clair Klar Scan findings to Clair Scan findings. Whitesource has been renamed to Mend. There is a migration process built into the upgrade that will automatically convert existing Whitesource findings and tests into Mend findings and tests Breaking Change\nIf there is any use of the above mentioned parsers in automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated accordingly. For all other changes, check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":10,"permalink":"/en/open_source/upgrading/2.31/","summary":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\nOpenVAS XML and OpenVAS CSV were merged to OpenVAS Parser.","tags":[],"title":"Upgrading to DefectDojo Version 2.31.x"},{"content":"There are instructions for upgrading to 2.30.0 if you disabled enable_auditlog before (read below). Check the Release Notes for the contents of the release.\nBreaking Change\nParameter enable_auditlog is not possible to set through System settings anymore. If you set this parameter or you need to change it to False (to disable audit logging), set environmental variable DD_ENABLE_AUDITLOG to False.\nIf you are using docker compose, another EnvVar should be added to the docker-compose.yml file in all the containers ran by the django image. This should do the trick\nDD_ENABLE_AUDITLOG: ${DD_ENABLE_AUDITLOG:-False}\rSomewhere in the environment blocks for the uwsgi, celerybeat, celeryworker, and init containers.\n","date":"0001-01-01","id":11,"permalink":"/en/open_source/upgrading/2.30/","summary":"There are instructions for upgrading to 2.30.0 if you disabled enable_auditlog before (read below). Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.30.x"},{"content":"There are no special instructions for upgrading to 2.29.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":12,"permalink":"/en/open_source/upgrading/2.29/","summary":"There are no special instructions for upgrading to 2.29.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.29.x"},{"content":"There are no special instructions for upgrading to 2.28.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":13,"permalink":"/en/open_source/upgrading/2.28/","summary":"There are no special instructions for upgrading to 2.28.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.28.x"},{"content":"There are no special instructions for upgrading to 2.27.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":14,"permalink":"/en/open_source/upgrading/2.27/","summary":"There are no special instructions for upgrading to 2.27.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.27.x"},{"content":"There are no special instructions for upgrading to 2.26.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":15,"permalink":"/en/open_source/upgrading/2.26/","summary":"There are no special instructions for upgrading to 2.26.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.26.x"},{"content":"There are no special instructions for upgrading to 2.25.0. Check the Release Notes for the contents of the release.\nA few query parameters related to filtering object via API related to a products tags have been renamed to be more consistent with the other \u0026ldquo;related object tags\u0026rdquo;:\nBreaking Change\nEngagement product__tags__name -\u0026gt; product__tags not_product__tags__name -\u0026gt; not_product__tags Test engagement__product__tags__name -\u0026gt; engagement__product__tags not_engagement__product__tags__name -\u0026gt; not_engagement__product__tags Finding test__engagement__product__tags__name -\u0026gt; test__engagement__product__tags not_test__engagement__product__tags__name -\u0026gt; not_test__engagement__product__tags Deprecation\nThe OpenAPI 2.0 Swagger API documentation is being deprecated in favor of the existing OpenAPI 3.0 API documentation page. The OpenAPI 2.0 Swagger API documentation page is slated for removal in version 2.30.0\nNote: The API has not changed in any way and behaves the same between OAPI2 and OAPI3\nFor all other changes, check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":16,"permalink":"/en/open_source/upgrading/2.25/","summary":"There are no special instructions for upgrading to 2.25.0. Check the Release Notes for the contents of the release.\nA few query parameters related to filtering object via API related to a products tags have been renamed to be more consistent with the other \u0026ldquo;related object tags\u0026rdquo;:","tags":[],"title":"Upgrading to DefectDojo Version 2.25.x"},{"content":"There are no special instructions for upgrading to 2.24.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":17,"permalink":"/en/open_source/upgrading/2.24/","summary":"There are no special instructions for upgrading to 2.24.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.24.x"},{"content":"There is a migration from the legacy Nessus and Nessus WAS parsers to a single Tenable parser. The updated Tenable parser simply merges existing support for Nessus and Nessus WAS without introducing new functionality that could create instability\nThere is a migration process built into the upgrade that will automatically convert exiting Nessus and Nessus WAS findings and tests into Tenable findings and tests\nBreaking Change\nIf there is any use of the Nessus or Nessus WAS in automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated to Tenable Scan The default containerized database will now be PostgreSQL rather than MySQL due to the use of case insensitivity on fields by default It is recommended to update the database character set and collation to use UTF encoding If your deployment uses the MySQL containerized database, please see the following updates to run DefectDojo: Use of the helper script \u0026ldquo;dc-up\u0026rdquo;: ./dc-up.sh mysql-rabbitmq or ./dc-up.sh mysql-redis Use of the helper script \u0026ldquo;dc-up-d\u0026rdquo;: ./dc-up-d.sh mysql-rabbitmq or ./dc-up-d.sh mysql-redis Use of Docker Compose directly: docker compose --profile mysql-rabbitmq --env-file ./docker/environments/mysql-rabbitmq.env up or docker compose --profile mysql-redis --env-file ./docker/environments/mysql-redis.env up For all other changes, check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":18,"permalink":"/en/open_source/upgrading/2.23/","summary":"There is a migration from the legacy Nessus and Nessus WAS parsers to a single Tenable parser. The updated Tenable parser simply merges existing support for Nessus and Nessus WAS without introducing new functionality that could create instability","tags":[],"title":"Upgrading to DefectDojo Version 2.23.x"},{"content":"There are no special instructions for upgrading to 2.22.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":19,"permalink":"/en/open_source/upgrading/2.22/","summary":"There are no special instructions for upgrading to 2.22.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.22.x"},{"content":"There are no special instructions for upgrading to 2.21.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":20,"permalink":"/en/open_source/upgrading/2.21/","summary":"There are no special instructions for upgrading to 2.21.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.21.x"},{"content":"There are no special instructions for upgrading to 2.20.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":21,"permalink":"/en/open_source/upgrading/2.20/","summary":"There are no special instructions for upgrading to 2.20.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.20.x"},{"content":"There are new docker images based on alpine with fewer third party dependencies. Related to the new images the current docker files had to be renamed and have a \u0026ldquo;-debian\u0026rdquo; or the new images a \u0026ldquo;-alpine\u0026rdquo; at the end. Furthermore there are new docker tags [DefectdojoVersion]-[OS]. For example 2.19.0-alpine or 2.19.0-debian. The currend tags (latest and [DefectdojoVersion]) are still based on the \u0026ldquo;old\u0026rdquo; images. Be aware that the new alpine images are not heavily tested and may contain bugs.\nBreaking Change\nIn version 2.19.3, the GitHub OAuth integration has been removed to prevent configurations that may allow more access than intended.\nDefectDojo Security Advisory: Severity Medium | Potential GitHub Authentication Misconfiguration\n","date":"0001-01-01","id":22,"permalink":"/en/open_source/upgrading/2.19/","summary":"There are new docker images based on alpine with fewer third party dependencies. Related to the new images the current docker files had to be renamed and have a \u0026ldquo;-debian\u0026rdquo; or the new images a \u0026ldquo;-alpine\u0026rdquo; at the end.","tags":[],"title":"Upgrading to DefectDojo Version 2.19.x"},{"content":"Upgrade instructions for helm chart with rabbitMQ enabled: The rabbitMQ uses a statefulset by default. Before upgrading the helm chart we have to ensure that all queues are empty:\nkubectl exec -i \u0026lt;name_of_the_rabbitmq_pod\u0026gt; -- rabbitmqctl list_queues\rNext step is to delete rabbitMQ pvc:\nkubectl delete pvc -l app.kubernetes.io/name=rabbitmq\rLast step is to perform the upgrade.\nFor more information: https://artifacthub.io/packages/helm/bitnami/rabbitmq/11.2.0\n","date":"0001-01-01","id":23,"permalink":"/en/open_source/upgrading/2.18/","summary":"Upgrade instructions for helm chart with rabbitMQ enabled: The rabbitMQ uses a statefulset by default. Before upgrading the helm chart we have to ensure that all queues are empty:","tags":[],"title":"Upgrading to DefectDojo Version 2.18.x"},{"content":"There are no special instructions for upgrading to 2.17.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":24,"permalink":"/en/open_source/upgrading/2.17/","summary":"There are no special instructions for upgrading to 2.17.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.17.x"},{"content":"There are no special instructions for upgrading to 2.16.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":25,"permalink":"/en/open_source/upgrading/2.16/","summary":"There are no special instructions for upgrading to 2.16.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.16.x"},{"content":"There are no special instructions for upgrading to 2.15.0. Check the Release Notes for the contents of the release.\n","date":"0001-01-01","id":26,"permalink":"/en/open_source/upgrading/2.15/","summary":"There are no special instructions for upgrading to 2.15.0. Check the Release Notes for the contents of the release.","tags":[],"title":"Upgrading to DefectDojo Version 2.15.x"},{"content":"The last release implemented the search for vulnerability ids, but the search database was not initialized. To populate the database table of the vulnerability ids, execute this django command from the defect dojo installation directory or from a shell of the Docker container or Kubernetes pod:\n./manage.py migrate_cve\nAdditionally this requires a one-time rebuild of the Django-Watson search index. Execute this django command from the defect dojo installation directory or from a shell of the Docker container or Kubernetes pod:\n./manage.py buildwatson\nFurther changes:\nLegacy authorization for changing configurations based on staff users has been removed.\n","date":"0001-01-01","id":27,"permalink":"/en/open_source/upgrading/2.13/","summary":"The last release implemented the search for vulnerability ids, but the search database was not initialized. To populate the database table of the vulnerability ids, execute this django command from the defect dojo installation directory or from a shell of the Docker container or Kubernetes pod:","tags":[],"title":"Upgrading to DefectDojo Version 2.13.x"},{"content":"Breaking change for search: The field cve has been removed from the search index for Findings and the Vulnerability Ids have been added to the search index. With this the syntax to search explicitly for vulnerability ids have been changed from cve: to vulnerability_id:, e.g. vulnerability_id:CVE-2020-27619.\nUpgrade instructions for helm chart with postgres enabled: The postgres database uses a statefulset by default. Before upgrading the helm chart we have to delete the statefullset and ensure that the pvc is reused, to keep the data. For more information: https://docs.bitnami.com/kubernetes/infrastructure/postgresql/administration/upgrade/ .\nhelm repo update helm dependency update ./helm/defectdojo # obtain name oft the postgres pvc export POSTGRESQL_PVC=$(kubectl get pvc -l app.kubernetes.io/instance=defectdojo,role=primary -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) # delete postgres statefulset kubectl delete statefulsets.apps defectdojo-postgresql --namespace default --cascade=orphan # upgrade helm upgrade \\ defectdojo \\ ./helm/defectdojo/ \\ --set primary.persistence.existingClaim=$POSTGRESQL_PVC \\ ... # add your custom settings\r","date":"0001-01-01","id":28,"permalink":"/en/open_source/upgrading/2.12/","summary":"Breaking change for search: The field cve has been removed from the search index for Findings and the Vulnerability Ids have been added to the search index.","tags":[],"title":"Upgrading to DefectDojo Version 2.12.x"},{"content":"Breaking change for Findings: The field cve will be replaced by a list of Vulnerability Ids, which can store references to security advisories associated with this finding. These can be Common Vulnerabilities and Exposures (CVE) or from other sources, eg. GitHub Security Advisories. Although the field does still exist in the code, the API and the UI have already been changed to use the list of Vulnerability Ids. Other areas like hash code calculation, search and parsers will be migrated step by step in later stages.\nThis change also causes an API change for the endpoint /engagements/{id}/accept_risks/.\n","date":"0001-01-01","id":29,"permalink":"/en/open_source/upgrading/2.10/","summary":"Breaking change for Findings: The field cve will be replaced by a list of Vulnerability Ids, which can store references to security advisories associated with this finding.","tags":[],"title":"Upgrading to DefectDojo Version 2.10.x"},{"content":"Breaking change for APIv2: configuration_url was removed from API endpoint /api/v2/tool_configurations/ due to redundancy.\n","date":"0001-01-01","id":30,"permalink":"/en/open_source/upgrading/2.9/","summary":"Breaking change for APIv2: configuration_url was removed from API endpoint /api/v2/tool_configurations/ due to redundancy.","tags":[],"title":"Upgrading to DefectDojo Version 2.9.x"},{"content":"Breaking change for Docker Compose: Starting DefectDojo with Docker Compose now supports 2 databases (MySQL and PostgreSQL) and 2 celery brokers (RabbitMQ and Redis). To make this possible, docker-compose needs to be started with the parameters --profile and --env-file. You can get more information in Setup via Docker Compose - Profiles. The profile mysql-rabbitmq provides the same configuration as in previous releases. With this the prerequisites have changed as well: Docker requires at least version 19.03.0 and Docker Compose 1.28.0.\nBreaking change for Helm Chart: In one of the last releases we upgraded the redis dependency in our helm chart without renaming keys in our helm chart. We fixed this bug with this release, but you may want to check if all redis values are correct (Pull Request).\nThe flexible permissions for the configuration of DefectDojo are now active by default. With this, the flag Staff for users is not relevant and not visible anymore. The old behaviour can still be activated by setting the parameter FEATURE_CONFIGURATION_AUTHORIZATION to False. If you haven\u0026rsquo;t done so with the previous release, you can still run a migration script with ./manage.py migrate_staff_users. This script:\ncreates a group for all staff users, sets all configuration permissions that staff users had and sets the global Owner role, if AUTHORIZATION_STAFF_OVERRIDE is set to True. ","date":"0001-01-01","id":31,"permalink":"/en/open_source/upgrading/2.8/","summary":"Breaking change for Docker Compose: Starting DefectDojo with Docker Compose now supports 2 databases (MySQL and PostgreSQL) and 2 celery brokers (RabbitMQ and Redis).","tags":[],"title":"Upgrading to DefectDojo Version 2.8.x"},{"content":"This release is a breaking change regarding the Choctaw Hog parser. As the maintainers of this project unified multiple parsers under the RustyHog parser, we now support the parsing of Choctaw Hog JSON output files through the Rusty Hog parser. Furthermore, we also support Gottingen Hog and Essex Hog JSON output files with the RustyHog parser.\nThere is another breaking change regarding the import of SSLyze scans. The parser has been renamed from SSLyze 3 Scan (JSON) to SSLyze Scan (JSON). The data in the database is fixed by the initializer, but it may break scripted API calls.\nRelease 2.7.0 contains a beta functionality to make permissions for the configuration of DefectDojo more flexible. When the settings parameter FEATURE_CONFIGURATION_AUTHORIZATION is set to True, many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their Superuser or Staff status, see Configuration Permissions.\nThe functionality using the flag AUTHORIZATION_STAFF_OVERRIDE has been removed. The same result can be achieved with giving the staff users a global Owner role.\nTo support the transition for these 2 changes, you can run a migration script with ./manage.py migrate_staff_users. This script:\ncreates a group for all staff users, sets all configuration permissions that staff users had and sets the global Owner role, if AUTHORIZATION_STAFF_OVERRIDE is set to True. ","date":"0001-01-01","id":32,"permalink":"/en/open_source/upgrading/2.7/","summary":"This release is a breaking change regarding the Choctaw Hog parser. As the maintainers of this project unified multiple parsers under the RustyHog parser, we now support the parsing of Choctaw Hog JSON output files through the Rusty Hog parser.","tags":[],"title":"Upgrading to DefectDojo Version 2.7.x"},{"content":"There are no special instructions for upgrading to 2.6.0. Check the Release Notes for the contents of the release.\nPlease consult the security advisories GHSA-f82x-m585-gj24 (moderate) and GHSA-v7fv-g69g-x7p2 (high) to see what security issues were fixed in this release. These will be published and become visible at January 18th, 2022.\n","date":"0001-01-01","id":33,"permalink":"/en/open_source/upgrading/2.6/","summary":"There are no special instructions for upgrading to 2.6.0. Check the Release Notes for the contents of the release.\nPlease consult the security advisories GHSA-f82x-m585-gj24 (moderate) and GHSA-v7fv-g69g-x7p2 (high) to see what security issues were fixed in this release.","tags":[],"title":"Upgrading to DefectDojo Version 2.6.x"},{"content":"Legacy authorization has been completely removed with version 2.5.0. This includes removal of the migration of users to the new authorization as described in https://documentation.defectdojo.com/getting_started/upgrading/#authorization. If you are still using the legacy authorization, you should run the migration with ./manage.py migrate_authorization_v2 before upgrading to version 2.5.0\nThis release introduces the \u0026ldquo;Forgot password\u0026rdquo; functionality (DD_FORGOT_PASSWORD: default True). The function allows sending an e-mail with the reset password link. Missing configuration or misconfiguration of SMTP (DD_EMAIL_URL) could raise an error (HTTP-500). Check and test (for example by resetting your own password) if you configured SMTP correctly. If you want to avoid HTTP-500 and you don\u0026rsquo;t want to set up SMTP, you can just simply switch off the \u0026ldquo;Forgot password\u0026rdquo; functionality (DD_FORGOT_PASSWORD=False).\nRelease renamed system setting mail_notifications_from to email_from. This value will not be used only for sending notifications but also for sending the reset password emails. It is highly recommended to check the content of this value if you are satisfied. If you installed DefectDojo earlier, you can expect \u0026quot;from@example.com\u0026quot; there. A fresh installation will use \u0026quot;no-reply@example.com\u0026quot;\nThis release updates our helm dependencies. There is a breaking change if you are using the mysql database from the helm chart because we replaced the deprecated chart from the stable repo with a chart from bitnami. If you have persistance enabled, ensure to backup your data before upgrading. All data get lost when replacing the mysql chart during the upgrade. For data migration take a look at the mysql backup and restore process.\nFurthermore we updated our kubernetes version. Current tests run on 1.18.16 and 1.22.0.\n","date":"0001-01-01","id":34,"permalink":"/en/open_source/upgrading/2.5/","summary":"Legacy authorization has been completely removed with version 2.5.0. This includes removal of the migration of users to the new authorization as described in https://documentation.","tags":[],"title":"Upgrading to DefectDojo Version 2.5.x"},{"content":"This releases fixes a High severity vulnerability for which the details will be disclosed on November 16th in GHSA-fwg9-752c-qh8w\nThere is a breaking change in the API for importing and re-importings scans with SonarQube API and Cobalt.io API. The scan configurations have been unified and are set now with the attribute api_scan_configuration. The existing configurations for SonarQube API and Cobalt.io API have been migrated.\nAt the request of pyup.io, we had to remove the parser for Safety scans.\n","date":"0001-01-01","id":35,"permalink":"/en/open_source/upgrading/2.4/","summary":"This releases fixes a High severity vulnerability for which the details will be disclosed on November 16th in GHSA-fwg9-752c-qh8w\nThere is a breaking change in the API for importing and re-importings scans with SonarQube API and Cobalt.","tags":[],"title":"Upgrading to DefectDojo Version 2.4.x (Security Release)"},{"content":"There are no special instructions for upgrading to 2.3.0. In 2.3.0 we changed the default password hashing algorithm to Argon2 (from PBKDF2). When logging in, exising hashes get replaced by an Argon2 hash. If you want to rehash password without users having to login, please see the Django password management docs. The previous password hashing algorithm (PBKDF2) was not unsafe, but we wanted to follow the OWASP guidelines.\n","date":"0001-01-01","id":36,"permalink":"/en/open_source/upgrading/2.3/","summary":"There are no special instructions for upgrading to 2.3.0. In 2.3.0 we changed the default password hashing algorithm to Argon2 (from PBKDF2).","tags":[],"title":"Upgrading to DefectDojo Version 2.3.x"},{"content":"Upgrade to 2.0.0 contained migration of endpoints. Some parts of migration haven\u0026rsquo;t been done properly. This deficiency may manifest as a doubled slash in endpoint URLs (like http://foo.bar:8080//test) or as a problem with deduplication of the same endpoints. The mentioned bug was fixed in 2.2.0 and if you have seen these kinds of problems, just rerun \u0026ldquo;Endpoint migration\u0026rdquo; as it is written in Upgrading to DefectDojo Version 2.0.x..\n","date":"0001-01-01","id":37,"permalink":"/en/open_source/upgrading/2.2/","summary":"Upgrade to 2.0.0 contained migration of endpoints. Some parts of migration haven\u0026rsquo;t been done properly. This deficiency may manifest as a doubled slash in endpoint URLs (like http://foo.","tags":[],"title":"Upgrading to DefectDojo Version 2.2.x"},{"content":"Follow the usual steps to upgrade as described above.\nBEFORE UPGRADING\nIf you are using SAML2 checkout the new documentaion and update you settings following the migration section. We replaced django-saml2-auth with djangosaml2. AFTER UPGRADING\nUsual migration process (python manage.py migrate) try to migrate all endpoints to new format and merge duplicates. All broken endpoints (which weren\u0026rsquo;t possible to migrate) have red flag ðŸš© in standard list of endpoints. Check if all your endpoints was migrated successfully, go to: https:///endpoint/migrate. Alternatively, this can be run as management command: docker-compose exec uwsgi ./manage.py endpoint_migration --dry-run When all endpoint will be fixed (there is not broken endpoint), press \u0026ldquo;Run migration\u0026rdquo; in https:///endpoint/migrate Or, you can run management command: docker-compose exec uwsgi ./manage.py endpoint_migration Details about endpoint migration / improvements in https://github.com/DefectDojo/django-DefectDojo/pull/4473 We decided to name this version 2.0.0 because we did some big cleanups in this release:\nRemove API v1 (#4413)\nRemove setup.bash installation method (#4417)\nRename Finding.is_Mitigated field to Finding.is_mitigated (#3854)\nRemove everything related to the old tagging library (#4419)\nRemove S0/S1/S2../S5 severity display option (#4415)\nRefactor EndPoint handling/formatting (#4473)\nUpgrade to Django 3.x (#3632)\nPDF Reports removed (#4418)\nHashcode calculation logic has changed. To update existing findings run:\n./manage.py dedupe --hash_code_only.\nIf you\u0026rsquo;re using docker:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only.\nThis can take a while depending on your instance size.\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/2.0.0 Endpoints The usual migration process (python manage.py migrate) tries to migrate all endpoints to new format and merge duplicates. All broken endpoints (which weren\u0026rsquo;t possible to migrate) have a red flag ðŸš© in the standard list of endpoints. Check if all your endpoints were migrated successfully, go to: https:///endpoint/migrate. Alternatively, this can be run as management command: docker-compose exec uwsgi ./manage.py endpoint_migration --dry-run When all endpoint are fixed (there is not broken endpoint), press \u0026ldquo;Run migration\u0026rdquo; in https:///endpoint/migrate Or, you can run management command: docker-compose exec uwsgi ./manage.py endpoint_migration Details about endpoint migration / improvements in https://github.com/DefectDojo/django-DefectDojo/pull/4473 Authorization The new authorization system for Products and Product Types based on roles is the default now. The fields for authorized users are not available anymore, but you can assign roles as described in Permissions. Users are migrated automatically, so that their permissions are as close as possible to the previous authorization:\nSuperusers will still have all permissions on Products and Product Types, so they must not be changed. Staff users have had all permissions for all product types and products, so they will be get a global role as Owner. Product_Members and Product Type_Members will be added for authorized users according to the settings for the previous authorization: The Reader role is set as the default. If AUTHORIZED_USERS_ALLOW_STAFF is True, the user will get the Owner role for the respective Product or Product Type. If AUTHORIZED_USERS_ALLOW_CHANGE or AUTHORIZED_USERS_ALLOW_DELETE is True, the user will get the Writer role for the respective Product or Product Type. The new authorization is active for both UI and API. Permissions set via authorized users or via the Django Admin interface are no longer taken into account.\nPlease review the roles for your users after the upgrade to avoid an unintended permissions creep.\n","date":"0001-01-01","id":38,"permalink":"/en/open_source/upgrading/2.0/","summary":"Follow the usual steps to upgrade as described above.\nBEFORE UPGRADING\nIf you are using SAML2 checkout the new documentaion and update you settings following the migration section.","tags":[],"title":"Upgrading to DefectDojo Version 2.0.x"},{"content":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.15.0\nIf you have made changes to JIRA templates or the template config in the JIRA Project config for instances/products/engagements: The jira template settings introduced in 1.13 have been changed. You now have to select a subfolder instead of a sinlge template file. If you have chosen a non-default template here, you have to reapply that to all products / engagements. Also you have to move your custom templates into the correct subfolder in dojo/templates/issue-trackers/.\nHashcode calculation logic has changed in #4134, #4308 and #4310 to update existing findings run:\n./manage.py dedupe --hash_code_only\nIf you\u0026rsquo;re using docker:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only\nThis can take a while depending on your instance size.\n","date":"0001-01-01","id":39,"permalink":"/en/open_source/upgrading/1.15/","summary":"See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.15.0\nIf you have made changes to JIRA templates or the template config in the JIRA Project config for instances/products/engagements: The jira template settings introduced in 1.","tags":[],"title":"Upgrading to DefectDojo Version 1.15.x"},{"content":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.14.0 Note that the below fields are now optional without default value. They will not be filled anymore with values such as \u0026ldquo;No references given\u0026rdquo; when found empty while saving the findings\nmitigation references impact url ","date":"0001-01-01","id":40,"permalink":"/en/open_source/upgrading/1.14/","summary":"See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.14.0 Note that the below fields are now optional without default value. They will not be filled anymore with values such as \u0026ldquo;No references given\u0026rdquo; when found empty while saving the findings","tags":[],"title":"Upgrading to DefectDojo Version 1.14.x"},{"content":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.13.0\nHashcode settings affecting deduplication have changed, to update existing findings run:\n./manage.py dedupe\nIf you\u0026rsquo;re using docker:\ndocker-compose exec uwsgi ./manage.py dedupe This can take a while depeneding on your instance size. It might possible that new duplicates are detected among existing findings, so make a backup before running!\n","date":"0001-01-01","id":41,"permalink":"/en/open_source/upgrading/1.13/","summary":"See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.13.0\nHashcode settings affecting deduplication have changed, to update existing findings run:\n./manage.py dedupe\nIf you\u0026rsquo;re using docker:","tags":[],"title":"Upgrading to DefectDojo Version 1.13.x"},{"content":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.0 1.12.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.1 ","date":"0001-01-01","id":42,"permalink":"/en/open_source/upgrading/1.12/","summary":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.0 1.12.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.1 ","tags":[],"title":"Upgrading to DefectDojo Version 1.12.x"},{"content":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.0 1.11.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.1 ","date":"0001-01-01","id":43,"permalink":"/en/open_source/upgrading/1.11/","summary":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.0 1.11.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.1 ","tags":[],"title":"Upgrading to DefectDojo Version 1.11.x"},{"content":"1.10.4 is a security release\nSee the security advisory: https://github.com/DefectDojo/django-DefectDojo/security/advisories/GHSA-96vq-gqr9-vf2c See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.10.4 Version 1.10.4 replaces 1.10.3 as the latter contained an incomplete fix What's New:\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases DefectDojo now provides a settings.py file out-of-the-box. Custom settings need to go into local\\_settings.py. See https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.py and https://github.com/DefectDojo/django-DefectDojo/blob/master/docker/extra_settings/README.md A quickfix is to rename your own / customized settings.py or settings.dist.py to local\\_settings.py. Details of that PR: https://github.com/DefectDojo/django-DefectDojo/pull/3136 Major JIRA integration refactoring, for which you should at least use 1.10.1 and not 1.10.0 for many bug fixes. Breaking changes\nKubernetes/Helm users: we have moved away from the \u0026quot;stable\u0026quot; repository to \u0026quot;bitnami\u0026quot; in this release. The bitnami postgresql chart required us to add a new key to the postgresql secret, which will give you the error postgresql-postgres-password is missing if you have createPostgresqlSecret: false. In 1.10.1, a fix was also included to allow your existing postgresqlPassword to be reused properly.\nIncluding in 1.10.1 were a couple fixes related to a rabbitMQ upgrade. The path to access password, erlangCookie and existingPasswordSecret changed from rabbitmq to auth. Furthermore, as rabbitMQ is deployed as a StatefulSet, an in-place upgrade is not possible and an error will likely be thrown such as Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden. After ensuring your rabbitMQ celery queue is empty, you will then want to delete your rabbitMQ StatefulSet and PVC to allow them to get re-created, or fully delete and recreate defectdojo.\n","date":"0001-01-01","id":44,"permalink":"/en/open_source/upgrading/1.10/","summary":"1.10.4 is a security release\nSee the security advisory: https://github.com/DefectDojo/django-DefectDojo/security/advisories/GHSA-96vq-gqr9-vf2c See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.10.4 Version 1.10.4 replaces 1.10.3 as the latter contained an incomplete fix What's New:","tags":[],"title":"Upgrading to DefectDojo Version 1.10.x"},{"content":"This is a security release\nSee the security advisory See release notes What's New:\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases NOTE:\nWhen upgrading from before 1.9.2, a corrective script may need to be ran\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\nSearch index tweaking index rebuild after upgrade: This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson]\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\n","date":"0001-01-01","id":45,"permalink":"/en/open_source/upgrading/1.9.3/","summary":"This is a security release\nSee the security advisory See release notes What's New:\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases NOTE:\nWhen upgrading from before 1.","tags":[],"title":"Upgrading to DefectDojo Version 1.9.3"},{"content":"What's New:\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases Improved search, which requires an index rebuild (https://github.com/DefectDojo/django-DefectDojo/pull/2861) This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\nNOTE: As a result of a breaking bug revolving around Endpoint_status objects, a corrective script will need to be ran after every dynamic scan imported through either API version.\nThe script can be found here\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\n","date":"0001-01-01","id":46,"permalink":"/en/open_source/upgrading/1.8.0/","summary":"What's New:\nSee release notes: https://github.com/DefectDojo/django-DefectDojo/releases Improved search, which requires an index rebuild (https://github.com/DefectDojo/django-DefectDojo/pull/2861) This requires a (one-time) rebuild of the Django-Watson search index.","tags":[],"title":"Upgrading to DefectDojo Version 1.8.0"},{"content":"What's New:\nUpdated search, you can now search for CVE-XXXX-YYYY Updated search index, fields added to index: 'id', 'title', 'cve', 'url', 'severity', 'description', 'mitigation', 'impact', 'steps_to_reproduce', 'severity_justification', 'references', 'sourcefilepath', 'sourcefile', 'hash_code', 'file_path', 'component_name', 'component_version', 'unique_id_from_tool' This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson dojo.Finding\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson dojo.Finding\nUpgrading to DefectDojo Version 1.5.0 What's New:\nUpdated UI with a new DefectDojo logo, default colors and CSS. Updated Product views with tabs for Product Overview, Metrics, Engagements, Endpoints, Benchmarks (ASVS), and Settings to make it easier to navigate and manage your products. New Product Information fields: Regulations, Criticality, Platform, Lifecycle, Origin, User Records, Revenue, External Audience, Internet Accessible Languages pie chart on product overview, only supported through the API and Django admin, integrates with cloc analyzer New Engagement type of CI/CD to support continual testing Engagement shortcuts and ability to import findings and auto-create an engagement Engagement labels for overdue, no tests and findings New Contextual menus throughout DefectDojo and shortcuts to new findings and critical findings Ability to merge a finding into a parent finding and either inactivate or delete the merged findings. Report improvements and styling adjustment with the default option of HTML reports SLA for remediation of severities based on finding criticality, for example critical findings remediated within 7 days. Configurable in System Settings. Engagement Auto-Close Days in System Settings. Automatically close an engagement if open past the end date. Ability to apply remediation advice based on CWE. For example XSS can be configured as a template so that it's consistent across all findings. Enabled in system settings. Finding confidence field supported from scanners. First implementation in the Burp importer. Goast importer for static analysis of Golang products Celery status check on System Settings Beta rules framework release for modifying findings on the fly DefectDojo 2.0 API with Swagger support Created and Modified fields on all major tables Various bug fixes reported on Github Upgrading to 1.5.0 requirements:\nBack up your database first, ideally take the backup from production and test the upgrade on a staging server.\nEdit the settings.py file which can be found in django-DefectDojo/dojo/settings/settings.py. Copy in the rest framework configuration after the CSRF_COOKIE_SECURE = True:\nREST_FRAMEWORK = { 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.TokenAuthentication', 'rest_framework.authentication.BasicAuthentication', ), 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.DjangoModelPermissions', ), 'DEFAULT_RENDERER_CLASSES': ( 'rest_framework.renderers.JSONRenderer', ), 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination', 'PAGE_SIZE': 25 } Navigate to: LOGIN_EXEMPT_URLS and add the following after r'^%sfinding/image/(?P\u0026lt;token\u0026gt;[^/]+)$' % URL_PREFIX:\nr'^%sfinding/image/(?P\u0026lt;token\u0026gt;[^/]+)$' % URL_PREFIX, r'^%sapi/v2/' % URL_PREFIX, Navigate to: INSTALLED_APPS and add the following after: 'multiselectfield',:\n'multiselectfield', 'rest_framework', 'rest_framework.authtoken', 'rest_framework_swagger', 'dbbackup', Navigate to: CELERY_TASK_IGNORE_RESULT = True and add the following after CELERY_TASK_IGNORE_RESULT line:\nCELERY_RESULT_BACKEND = 'db+sqlite:///dojo.celeryresults.sqlite' Save your modified settings file. For reference the modified file should look like the new 1.5.0 [settings](https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.dist.py) file, minus the environmental configurations. As an alternative this file can be used and the enviromental configurations from you environment can be copied into this file.\nActivate your virtual environment and then upgrade the requirements: pip install -r requirements.txt --upgrade\nUpgrade the database:\n./manage.py makemigrations ./manage.py migrate Collect the static files (Javascript, Images, CSS):\n./manage.py collectstatic --noinput Complete\n","date":"0001-01-01","id":47,"permalink":"/en/open_source/upgrading/1.7.0/","summary":"What's New:\nUpdated search, you can now search for CVE-XXXX-YYYY Updated search index, fields added to index: 'id', 'title', 'cve', 'url', 'severity', 'description', 'mitigation', 'impact', 'steps_to_reproduce', 'severity_justification', 'references', 'sourcefilepath', 'sourcefile', 'hash_code', 'file_path', 'component_name', 'component_version', 'unique_id_from_tool' This requires a (one-time) rebuild of the Django-Watson search index.","tags":[],"title":"Upgrading to DefectDojo Version 1.7.0"},{"content":"What's New:\nNew importers for Contrast, Nikto and TruffleHog (finding secrets in git repos). Improved merging of findings for dynamic and static importers Markdown support for findings HTML report improvements including support of Markdown. System settings Celery status page to assist in debugging if Celery is functional. Upgrading to 1.3.1 requires:\npip install markdown pip install pandas ./manage.py makemigrations ./manage.py migrate ./manage.py collectstatic --noinput Complete ","date":"0001-01-01","id":48,"permalink":"/en/open_source/upgrading/1.3.1/","summary":"What's New:\nNew importers for Contrast, Nikto and TruffleHog (finding secrets in git repos). Improved merging of findings for dynamic and static importers Markdown support for findings HTML report improvements including support of Markdown.","tags":[],"title":"Upgrading to DefectDojo Version 1.3.1"},{"content":"What's New: New feature: Benchmarks (OWASP ASVS)\nUpgrading to 1.2.9 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/benchmark_type.json ./manage.py loaddata dojo/fixtures/benchmark_category.json ./manage.py loaddata dojo/fixtures/benchmark_requirement.json ./manage.py collectstatic --noinput Complete ","date":"0001-01-01","id":49,"permalink":"/en/open_source/upgrading/1.2.9/","summary":"What's New: New feature: Benchmarks (OWASP ASVS)\nUpgrading to 1.2.9 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/benchmark_type.json ./manage.py loaddata dojo/fixtures/benchmark_category.","tags":[],"title":"Upgrading to DefectDojo Version 1.2.9"},{"content":"New feature: Product Grading (Overall Product Health) Upgrading to 1.2.8 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py system_settings ./manage.py collectstatic --noinput pip install asteval pip install --upgrade celery Complete ","date":"0001-01-01","id":50,"permalink":"/en/open_source/upgrading/1.2.8/","summary":"New feature: Product Grading (Overall Product Health) Upgrading to 1.2.8 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py system_settings ./manage.py collectstatic --noinput pip install asteval pip install --upgrade celery Complete ","tags":[],"title":"Upgrading to DefectDojo Version 1.2.8"},{"content":"Upgrading to 1.2.4 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/objects_review.json ","date":"0001-01-01","id":51,"permalink":"/en/open_source/upgrading/1.2.4/","summary":"Upgrading to 1.2.4 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/objects_review.json ","tags":[],"title":"Upgrading to DefectDojo Version 1.2.4"},{"content":"Upgrading to 1.2.3 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/language_type.json Currently languages and technologies can be updated via the API or in the admin section of Django. ","date":"0001-01-01","id":52,"permalink":"/en/open_source/upgrading/1.2.3/","summary":"Upgrading to 1.2.3 requires:\n./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/language_type.json Currently languages and technologies can be updated via the API or in the admin section of Django.","tags":[],"title":"Upgrading to DefectDojo Version 1.2.3"},{"content":"Upgrading to 1.2.2 requires:\nCopying settings.py to the settings/ folder. If you have supervisor scripts change DJANGO_SETTINGS_MODULE=dojo.settings.settings ","date":"0001-01-01","id":53,"permalink":"/en/open_source/upgrading/1.2.2/","summary":"Upgrading to 1.2.2 requires:\nCopying settings.py to the settings/ folder. If you have supervisor scripts change DJANGO_SETTINGS_MODULE=dojo.settings.settings ","tags":[],"title":"Upgrading to DefectDojo Version 1.2.2"},{"content":"","date":"2023-09-07","id":54,"permalink":"/en/connecting_your_tools/import_scan_files/","summary":"","tags":[],"title":"Import Scans"},{"content":"","date":"2021-02-02","id":55,"permalink":"/en/about_defectdojo/","summary":"","tags":[],"title":"About DefectDojo"},{"content":"\rWhat is DefectDojo? DefectDojo is a DevSecOps platform. DefectDojo streamlines DevSecOps by serving as an aggregator and single pane of glass for your security tools. DefectDojo has smart features to enhance and tune the results from your security tools including the ability to merge findings, remember false positives, and distill duplicates. DefectDojo also integrates with JIRA, provides metrics / reports, and can also be used for traditional pen test management.\nWhat does DefectDojo do? While automation and efficiency are the ultimate end goals, DefectDojo is a bug tracker at its core for vulnerabilities. Taking advantage of DefectDojo\u0026rsquo;s Product:Engagement model, enables traceability among multiple projects / test cycles, and allows for fine-grained reporting.\nHow does DefectDojo work? Installation covers how to install and configure DefectDojo. New User Checklist covers how to use DefectDojo to manage vulnerabilities. We support a large amount of integrations to help fit DefectDojo in your DevSecOps program. Where to find DefectDojo? The open-source edition is available on GitHub.\nA running example is available on our demo server, using the credentials admin / 1Defectdojo@demo#appsec. Note: The demo server is refreshed regularly and provisioned with some sample data.\nDefectDojo Pro DefectDojo Inc. hosts a commercial edition of this software, which includes:\nadditional features, smart features and UI improvements cloud hosting, with regular backups, updates and maintenance premium support and implementation guidance For more information, please visit defectdojo.com.\nDefectDojo Inc. maintains this documentation to support both the Community and Pro editions of DefectDojo.\nFollow DefectDojo Inc. on LinkedIn for updates. To get in touch with us, please reach out to info@defectdojo.com\n","date":"2021-02-02","id":56,"permalink":"/en/about_defectdojo/about_docs/","summary":"What is DefectDojo? DefectDojo is a DevSecOps platform. DefectDojo streamlines DevSecOps by serving as an aggregator and single pane of glass for your security tools.","tags":[],"title":"About Our Documentation"},{"content":"{{ readFile \u0026ldquo;/docs/assets/svgs/DD-Architecture.svg\u0026rdquo; | safeHTML }}\nNGINX The webserver NGINX delivers all static content, e.g. images, JavaScript files or CSS files.\nuWSGI uWSGI is the application server that runs the DefectDojo platform, written in Python/Django, to serve all dynamic content.\nMessage Broker The application server sends tasks to a Message Broker for asynchronous execution. Currently, only Redis is supported as a broker.\nCelery Worker Tasks like deduplication or the JIRA synchronization are performed asynchronously in the background by the Celery Worker.\nCelery Beat In order to identify and notify users about things like upcoming engagements, DefectDojo runs scheduled tasks. These tasks are scheduled and run using Celery Beat.\nInitializer The Initializer setups / maintains the database and syncs / runs migrations after version upgrades. It shuts itself down after all tasks are performed.\nDatabase The Database stores all the application data of DefectDojo. Currently only PostgreSQL is supported.\n","date":"0001-01-01","id":57,"permalink":"/en/open_source/installation/architecture/","summary":"{{ readFile \u0026ldquo;/docs/assets/svgs/DD-Architecture.svg\u0026rdquo; | safeHTML }}\nNGINX The webserver NGINX delivers all static content, e.g. images, JavaScript files or CSS files.","tags":[],"title":"Architecture"},{"content":"{{ readFile \u0026ldquo;/docs/assets/svgs/DD-Hierarchy.svg\u0026rdquo; | safeHTML }}\nProduct Type Product types represent the top level model, these can be business unit divisions, different offices or locations, development teams, or any other logical way of distinguishing \u0026ldquo;types\u0026rdquo; of products.\nExamples: IAM Team Internal / 3rd Party Main company / Acquisition San Francisco / New York offices Product This is the name of any project, program, or product that you are currently testing.\nExamples: Wordpress Internal wiki Slack Engagement Engagements are moments in time when testing is taking place. They are associated with a name for easy reference, a time line, a lead (the user account of the main person conducting the testing), a test strategy, and a status. Engagement consists of two types: Interactive and CI/CD. An interactive engagement is typically an engagement conducted by an engineer, where findings are usually uploaded by the engineer. A CI/CD engagement, as it\u0026rsquo;s name suggests, is for automated integration with a CI/CD pipeline.\nExamples: Beta Quarterly PCI Scan Release Version X Test Tests are a grouping of activities conducted by engineers to attempt to discover flaws in a product. Tests are bundled within engagements, have a start and end date and are defined by a test type.\nExamples: Burp Scan from Oct. 29, 2015 to Oct. 29, 2015 Nessus Scan from Oct. 31, 2015 to Oct. 31, 2015 API Test from Oct. 15, 2015 to Oct. 20, 2015 Finding A finding represents a flaw discovered while testing. It can be categorized with severities of Critical, High, Medium, Low, and Informational (Info).\nExamples: OpenSSL \u0026lsquo;ChangeCipherSpec\u0026rsquo; MiTM Potential Vulnerability Web Application Potentially Vulnerable to Clickjacking Web Browser XSS Protection Not Enabled Endpoint Endpoints represent testable systems defined by their IP address or Fully Qualified Domain Name.\nExamples: https://www.example.com https://www.example.com:8080/products 192.168.0.36 ","date":"0001-01-01","id":58,"permalink":"/en/open_source/archived_docs/usage/models/","summary":"{{ readFile \u0026ldquo;/docs/assets/svgs/DD-Hierarchy.svg\u0026rdquo; | safeHTML }}\nProduct Type Product types represent the top level model, these can be business unit divisions, different offices or locations, development teams, or any other logical way of distinguishing \u0026ldquo;types\u0026rdquo; of products.","tags":[],"title":"Core data classes"},{"content":"Event HTTP header X-DefectDojo-Event: product_type_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34;, \u0026#34;user\u0026#34;: null }\r","date":"0001-01-01","id":59,"permalink":"/en/open_source/notification_webhooks/product_type_added/","summary":"Event HTTP header X-DefectDojo-Event: product_type_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34;, \u0026#34;user\u0026#34;: null }\r","tags":[],"title":"Event: product_type_added"},{"content":"","date":"0001-01-01","id":60,"permalink":"/en/connecting_your_tools/parsers/file/","summary":"","tags":[],"title":"Files"},{"content":"Import The importers analyze each report and create new Findings for each item reported. DefectDojo collapses duplicate Findings by capturing the individual hosts vulnerable.\nThis approach will create a new Test for each upload. This can result in a lot of findings. If deduplication is enabled, new Findings that are identical to existing Findings get marked as a duplicate.\nReimport Additionally, DefectDojo allows for re-imports of previously uploaded reports. This greatly reduces the amount of findings as no duplicates are created for findings that already exist.\nDefectDojo will attempt to capture the deltas between the original and new import and automatically add or mitigate findings as appropriate.\nThis behaviour can be controled via the closed_old_findings parameter on the reupload form.\nThe history of a test will be shown with the delta\u0026rsquo;s for each reimported scan report. Clicking on a reimport changset will show the affected findings, as well as a status history per finding. Triage-less scanners Some scanners might not include triage information in their reports (e.g. tfsec). They simply scan code or dependencies, flag issues, and return everything. Removing some findings requires you to add comments in your code perhaps, but there is no simple way to filter out findings from the reports.\nThat is why DefectDojo also includes a \u0026ldquo;Do not reactivate\u0026rdquo; checkbox in uploading reports (also in the reimport API), so you can persist the triages that have been done in Defectdojo without reactivating Findings on every upload.\nFor context, see #6892\nAPI This section focuses on Import and Reimport via the API. Please see the full documentation details of all API Endpoints for more details. Reimport is actually the easiest way to get started as it will create any entities on the fly if needed and it will automatically detect if it is a first time upload or a re-upload.\nImport Importing via the API is performed via the import-scan endpoint.\nAs described in the Core Data Classes, a test gets created inside an Engagement, inside a Product, inside a Product Type.\nAn import can be performed by specifying the names of these entities in the API request:\n{ \u0026#34;minimum_severity\u0026#34;: \u0026#39;Info\u0026#39;, \u0026#34;active\u0026#34;: True, \u0026#34;verified\u0026#34;: True, \u0026#34;scan_type\u0026#34;: \u0026#39;ZAP Scan\u0026#39;, \u0026#34;test_title\u0026#34;: \u0026#39;Manual ZAP Scan by John\u0026#39;, \u0026#34;product_type_name\u0026#34;: \u0026#39;Good Products\u0026#39;, \u0026#34;product_name\u0026#34;: \u0026#39;My little product\u0026#39;, \u0026#34;engagement_name\u0026#34;: \u0026#39;Important import\u0026#39;, \u0026#34;auto_create_context\u0026#34;: True, }\rWhen auto_create_context is True, the product, engagement, and environment will be created if needed. Make sure your user has sufficient permissions to do this.\nA classic way of importing a scan is by specifying the ID of the engagement instead:\n{ \u0026#34;minimum_severity\u0026#34;: \u0026#39;Info\u0026#39;, \u0026#34;active\u0026#34;: True, \u0026#34;verified\u0026#34;: True, \u0026#34;scan_type\u0026#34;: \u0026#39;ZAP Scan\u0026#39;, \u0026#34;test_title\u0026#34;: \u0026#39;Manual ZAP Scan by John\u0026#39;, \u0026#34;engagement\u0026#34;: 123, }\rReimport ReImporting via the API is performed via the reimport-scan endpoint.\nA reimport can be performed by specifying the names of these entities in the API request:\n{ \u0026#34;minimum_severity\u0026#34;: \u0026#39;Info\u0026#39;, \u0026#34;active\u0026#34;: True, \u0026#34;verified\u0026#34;: True, \u0026#34;scan_type\u0026#34;: \u0026#39;ZAP Scan\u0026#39;, \u0026#34;test_title\u0026#34;: \u0026#39;Manual ZAP Scan by John\u0026#39;, \u0026#34;product_type_name\u0026#34;: \u0026#39;Good Products\u0026#39;, \u0026#34;product_name\u0026#34;: \u0026#39;My little product\u0026#39;, \u0026#34;engagement_name\u0026#34;: \u0026#39;Important import\u0026#39;, \u0026#34;auto_create_context\u0026#34;: True, \u0026#34;do_not_reactivate\u0026#34;: False, }\rWhen auto_create_context is True, the product and engagement will be created if needed. Make sure your user has sufficient permissions to do this.\nWhen do_not_reactivate is True, the importing/reimporting will ignore uploaded active findings and not reactivate previously closed findings, while still creating new findings if there are new ones. You will get a note on the finding to explain that it was not reactivated for that reason.\nA reimport will automatically select the latest test inside the provided engagement that satisifes the provided scan_type and (optionally) provided test_title.\nIf no existing Test is found, the reimport endpoint will use the import function to import the provided report into a new Test. This means a (CI/CD) script using the API doesn\u0026rsquo;t need to know if a Test already exists, or if it is a first time upload for this Product / Engagement.\nA classic way of reimporting a scan is by specifying the ID of the test instead:\n{ \u0026#34;minimum_severity\u0026#34;: \u0026#39;Info\u0026#39;, \u0026#34;active\u0026#34;: True, \u0026#34;verified\u0026#34;: True, \u0026#34;scan_type\u0026#34;: \u0026#39;ZAP Scan\u0026#39;, \u0026#34;test\u0026#34;: 123, }\rUsing the Scan Completion Date (API: scan_date) field DefectDojo offers a plethora of supported scanner reports, but not all of them contain the information most important to a user. The scan_date field is a flexible smart feature that allows users to set the completion date of the a given scan report, and have it propagate down to all the findings imported. This field is not mandatory, but the default value for this field is the date of import (whenever the request is processed and a successful response is returned).\nHere are the following use cases for using this field:\nThe report does not set the date, and scan_date is not set at import Finding date will be the default value of scan_date The report sets the date, and the scan_date is not set at import Finding date will be whatever the report sets The report does not set the date, and the scan_date is set at import Finding date will be whatever the user set for scan_date The report sets the date, and the scan_date is set at import Finding date will be whatever the user set for scan_date ","date":"0001-01-01","id":61,"permalink":"/en/open_source/archived_docs/importing/","summary":"Import The importers analyze each report and create new Findings for each item reported. DefectDojo collapses duplicate Findings by capturing the individual hosts vulnerable.","tags":[],"title":"Importing"},{"content":"","date":"0001-01-01","id":62,"permalink":"/en/open_source/installation/","summary":"","tags":[],"title":"Installation \u0026 Configuration"},{"content":"Use this template as part of writing a new parser.\nCopy this .md file and add it to docs/integrations/parsers/file in the GitHub repository Update the title to match the name of your new parser Fill out all sections listed below File Types Specify all file types accepted by your parser. Include a process for creating the acceptable file from the related security tool.\nSample Scan Data / Unit Tests Add a link to the relevant unit tests or sample scan data folder in the GitHub repository.\nLink To Tool A link to the scanner itself - (e.g. GitHub or appropriate vendor link)\n","date":"0001-01-01","id":63,"permalink":"/en/open_source/contributing/parser-documentation-template/","summary":"Use this template as part of writing a new parser.\nCopy this .md file and add it to docs/integrations/parsers/file in the GitHub repository Update the title to match the name of your new parser Fill out all sections listed below File Types Specify all file types accepted by your parser.","tags":[],"title":"Parser Documentation Template"},{"content":"All commands assume that you\u0026rsquo;re located at the root of the django-DefectDojo cloned repo.\nPre-requisites You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally. Checkout dev and make sure you\u0026rsquo;re up to date with the latest changes. It\u0026rsquo;s advised that you create a dedicated branch for your development, such as git checkout -b parser-name. It is easiest to use the docker compose deployment as it has hot-reload capbility for uWSGI. Set up your environment to use the dev environment:\n$ docker/setEnv.sh dev\nPlease have a look at DOCKER.md for more details.\nDocker images You will want to build your docker images locally, and eventually pass in your local user\u0026rsquo;s uid to be able to write to the image (handy for database migration files). Assuming your user\u0026rsquo;s uid is 1000, then:\n$ docker compose build --build-arg uid=1000 Which files do you need to modify? File Purpose dojo/tools/\u0026lt;parser_dir\u0026gt;/__init__.py Empty file for class initialization dojo/tools/\u0026lt;parser_dir\u0026gt;/parser.py The meat. This is where you write your actual parser. The class name must be the Python module name without underscores plus Parser. Example: When the name of the Python module is dependency_check, the class name shall be DependencyCheckParser unittests/scans/\u0026lt;parser_dir\u0026gt;/{many_vulns,no_vuln,one_vuln}.json Sample files containing meaningful data for unit tests. The minimal set. unittests/tools/test_\u0026lt;parser_name\u0026gt;_parser.py Unit tests of the parser. dojo/settings/settings.dist.py If you want to use a modern hashcode based deduplication algorithm doc/content/en/integrations/parsers/\u0026lt;file/api\u0026gt;/\u0026lt;parser_file\u0026gt;.md Documentation, what kind of file format is required and how it should be obtained Factory contract Parsers are loaded dynamicaly with a factory pattern. To have your parser loaded and works correctly, you need to implement the contract.\nyour parser MUST be in a sub-module of module dojo.tools ex: dojo.tools.my_tool.parser module your parser MUST be a class in this sub-module. ex: dojo.tools.my_tool.parser.MyToolParser The name of this class MUST be the Python module name without underscores and with Parser suffix. ex: dojo.tools.my_tool.parser.MyToolParser This class MUST have an empty constructor or no constructor This class MUST implement 3 methods: def get_scan_types(self) This function return a list of all the scan_type supported by your parser. This identifiers are used internally. Your parser can support more than one scan_type. For example some parsers use different identifier to modify the behavior of the parser (aggregate, filter, etc\u0026hellip;) def get_label_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (short label) def get_description_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (long description) def get_findings(self, file, test) This function return a list of findings If your parser have more than 1 scan_type (for detailled mode) you MUST implement def set_mode(self, mode) method Example:\nclass MyToolParser(object): def get_scan_types(self): return [\u0026#34;My Tool Scan\u0026#34;, \u0026#34;My Tool Scan detailed\u0026#34;] def get_label_for_scan_types(self, scan_type): if scan_type == \u0026#34;My Tool Scan\u0026#34;: return \u0026#34;My Tool XML Scan aggregated by ...\u0026#34; else: return \u0026#34;My Tool XML Scan\u0026#34; def get_description_for_scan_types(self, scan_type): return \u0026#34;Aggregates findings per cwe, title, description, file_path. SonarQube output file can be imported in HTML format. Generate with https://github.com/soprasteria/sonar-report version \u0026gt;= 1.1.0\u0026#34; def requires_file(self, scan_type): return False # mode: # None (default): aggregates vulnerabilites per sink filename (legacy behavior) # \u0026#39;detailed\u0026#39; : No aggregation mode = None def set_mode(self, mode): self.mode = mode def get_findings(self, file, test): \u0026lt;...\u0026gt;\rAPI Parsers DefectDojo has a limited number of API parsers. While we won\u0026rsquo;t remove these connectors, adding API connectors has been problematic and thus we cannot accept new API parsers / connectors from the community at this time for supportability reasonsing. To maintain a high quality API connector, it is necessary to have a license to the tool. To get that license requires partnership with the author or vendor. We\u0026rsquo;re close to announcing a new program to help address this and bring API connectors to DefectDojo.\nTemplate Generator Use the template parser to quickly generate the files required. To get started you will need to install cookiecutter.\n$ pip install cookiecutter Then generate your scanner parser from the root of django-DefectDojo:\n$ cookiecutter https://github.com/DefectDojo/cookiecutter-scanner-parser Read more on the template configuration variables.\nThings to pay attention to Here is a list of considerations that will make the parser robust for both common cases and edge cases.\nDo not parse URLs by hand We use 2 modules to handle endpoints:\nhyperlink dojo.models with a specific class to handle processing around URLs to create endpoints Endpoint. All the existing parser use the same code to parse URL and create endpoints. Using Endpoint.from_uri() is the best way to create endpoints. If you really need to parse an URL, use hyperlink module.\nGood example:\nif \u0026#34;url\u0026#34; in item: endpoint = Endpoint.from_uri(item[\u0026#34;url\u0026#34;]) finding.unsaved_endpoints = [endpoint]\rVery bad example:\nu = urlparse(item[\u0026#34;url\u0026#34;]) endpoint = Endpoint(host=u.host) finding.unsaved_endpoints = [endpoint]\rUse the right libraries to parse information Various file formats are handled through libraries. In order to keep DefectDojo slim and also don\u0026rsquo;t extend the attack surface, keep the number of libraries used minimal and take other parsers as an example.\ndefusedXML in favour of lxml As xml is by default an unsecure format, the information parsed from various xml output has to be parsed in a secure way. Within an evaluation, we determined that defusedXML is the library which we will use in the future to parse xml files in parsers as this library is rated more secure. Thus, we will only accept PRs with the defusedxml library.\nNot all attributes are mandatory Parsers may have many fields, out of which many of them may be optional. It better to not set attribute if you don\u0026rsquo;t have data instead of filling with values like NA, No data etc\u0026hellip;\nCheck class dojo.models.Finding\nData could be missing in the source report Always make sure you include checks to avoid potential KeyError errors (e.g. field does not exist), for those fields you are not absolutely certain will always be in file that will get uploaded. These translate to 500 error, and do not look good.\nGood example:\nif \u0026#34;mykey\u0026#34; in data: finding.cwe = data[\u0026#34;mykey\u0026#34;]\rDo not parse CVSS by hand (vector, score or severity) Data can have CVSS vectors or scores. Don\u0026rsquo;t write your own CVSS score algorithm. For parser, we rely on module cvss.\nIt\u0026rsquo;s easy to use and will make the parser aligned with the rest of the code.\nExample of use:\nfrom cvss.cvss3 import CVSS3 import cvss.parser vectors = cvss.parser.parse_cvss_from_text(\u0026#34;CVSS:3.0/S:C/C:H/I:H/A:N/AV:P/AC:H/PR:H/UI:R/E:H/RL:O/RC:R/CR:H/IR:X/AR:X/MAC:H/MPR:X/MUI:X/MC:L/MA:X\u0026#34;) if len(vectors) \u0026gt; 0 and type(vectors[0]) == CVSS3: print(vectors[0].severities()) # this is the 3 severities cvssv3 = vectors[0].clean_vector() severity = vectors[0].severities()[0] vectors[0].compute_base_score() cvssv3_score = vectors[0].scores()[0] print(severity) print(cvssv3_score)\rGood example:\nvectors = cvss.parser.parse_cvss_from_text(item[\u0026#39;cvss_vect\u0026#39;]) if len(vectors) \u0026gt; 0 and type(vectors[0]) == CVSS3: finding.cvss = vectors[0].clean_vector() finding.severity = vectors[0].severities()[0] # if your tool does generate severity\rBad example (DIY):\ndef get_severity(self, cvss, cvss_version=\u0026#34;2.0\u0026#34;): cvss = float(cvss) cvss_version = float(cvss_version[:1]) # If CVSS Version 3 and above if cvss_version \u0026gt;= 3: if cvss \u0026gt; 0 and cvss \u0026lt; 4: return \u0026#34;Low\u0026#34; elif cvss \u0026gt;= 4 and cvss \u0026lt; 7: return \u0026#34;Medium\u0026#34; elif cvss \u0026gt;= 7 and cvss \u0026lt; 9: return \u0026#34;High\u0026#34; elif cvss \u0026gt;= 9: return \u0026#34;Critical\u0026#34; else: return \u0026#34;Informational\u0026#34; # If CVSS Version prior to 3 else: if cvss \u0026gt; 0 and cvss \u0026lt; 4: return \u0026#34;Low\u0026#34; elif cvss \u0026gt;= 4 and cvss \u0026lt; 7: return \u0026#34;Medium\u0026#34; elif cvss \u0026gt;= 7 and cvss \u0026lt;= 10: return \u0026#34;High\u0026#34; else: return \u0026#34;Informational\u0026#34;\rDeduplication algorithm By default a new parser uses the \u0026rsquo;legacy\u0026rsquo; deduplication algorithm documented at https://documentation.defectdojo.com/usage/features/#deduplication-algorithms\nPlease use a pre-defined deduplication algorithm where applicable.\nUnit tests Each parser must have unit tests, at least to test for 0 vuln, 1 vuln and many vulns. You can take a look at how other parsers have them for starters. The more quality tests, the better.\nIt\u0026rsquo;s important to add checks on attributes of findings. For ex:\nwith self.subTest(i=0): finding = findings[0] self.assertEqual(\u0026#34;test title\u0026#34;, finding.title) self.assertEqual(True, finding.active) self.assertEqual(True, finding.verified) self.assertEqual(False, finding.duplicate) self.assertIn(finding.severity, Finding.SEVERITIES) self.assertEqual(\u0026#34;CVE-2020-36234\u0026#34;, finding.vulnerability_ids[0]) self.assertEqual(261, finding.cwe) self.assertEqual(\u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, finding.cvssv3) self.assertIn(\u0026#34;security\u0026#34;, finding.tags) self.assertIn(\u0026#34;network\u0026#34;, finding.tags) self.assertEqual(\u0026#34;3287f2d0-554f-491b-8516-3c349ead8ee5\u0026#34;, finding.unique_id_from_tool) self.assertEqual(\u0026#34;TEST1\u0026#34;, finding.vuln_id_from_tool)\rUse with to open example files In order to make certain that file handles are closed properly, please use the with pattern to open files. Instead of:\ntestfile = open(\u0026#34;path_to_file.json\u0026#34;) ... testfile.close()\ruse:\nwith open(\u0026#34;path_to_file.json\u0026#34;) as testfile: ...\rThis ensures the file is closed at the end of the with statement, even if an exception occurs somewhere in the block.\nTest database To test your unit tests locally, you first need to grant some rights. Get your MySQL root password from the docker compose logs, login as root and issue the following commands:\nMYSQL\u0026gt; grant all privileges on test_defectdojo.* to defectdojo@\u0026#39;%\u0026#39;; MYSQL\u0026gt; flush privileges; Run your tests This local command will launch the unit test for your new parser\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py test unittests.tools.\u0026lt;your_unittest_py_file\u0026gt;.\u0026lt;main_class_name\u0026gt; -v2\u0026#39; or like this:\n$ ./dc-unittest.sh --test-case unittests.tools.\u0026lt;your_unittest_py_file\u0026gt;.\u0026lt;main_class_name\u0026gt; Example for the blackduck hub parser:\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py test unittests.tools.test_blackduck_csv_parser.TestBlackduckHubParser -v2\u0026#39; or like this:\n$ ./dc-unittest.sh --test-case unittests.tools.test_blackduck_csv_parser.TestBlackduckHubParser If you want to run all unit tests, simply run $ docker-compose exec uwsgi bash -c 'python manage.py test unittests -v2'\nEndpoint validation Some types of parsers create a list of endpoints that are vulnerable (they are stored in finding.unsaved_endpoints). DefectDojo requires storing endpoints in a specific format (which follow RFCs). Endpoints that do not follow this format can be stored but they will be marked as broken (red flag ðŸš©in UI). To be sure your parse store endpoints in the correct format run the .clean() function for all endpoints in unit tests\nfindings = parser.get_findings(testfile, Test()) for finding in findings: for endpoint in finding.unsaved_endpoints: endpoint.clean()\rTests API Parsers Not only parser but also importer should be tested. patch method from unittest.mock is usualy usefull for simulating API responses. It is highly recommeded to use it.\nOther files that could be involved Change to the model In the event where you\u0026rsquo;d have to change the model, e.g. to increase a database column size to accomodate a longer string of data to be saved\nChange what you need in dojo/models.py\nCreate a new migration file in dojo/db_migrations by running and including as part of your PR\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py makemigrations -v2\u0026#39; Accept a different type of file to upload If you want to be able to accept a new type of file for your parser, take a look at dojo/forms.py around line 436 (at the time of this writing) or locate the 2 places (for import and re-import) where you find the string attrs={\u0026quot;accept\u0026quot;:.\nFormats currently accepted: .xml, .csv, .nessus, .json, .html, .js, .zip.\nA need for more than just the parser.py Of course, nothing prevents you from having more files than the parser.py file. It\u0026rsquo;s python :-)\nPull request examples If you want to take a look at previous parsers that are now part of DefectDojo, take a look at https://github.com/DefectDojo/django-DefectDojo/pulls?q=is%3Apr+sort%3Aupdated-desc+label%3A%22Import+Scans%22+is%3Aclosed\nUpdate the import page documentation Please add a new .md file in [docs/content/en/integrations/parsers] with the details of your new parser. Include the following content headings:\nAcceptable File Type(s) - please include how to generate this type of file from the related tool, as some tools have multiple methods or require specific commands. An example unit test block, if applicable. A link to the relevant unit tests folder so that users can quickly navigate there from Documentation. A link to the scanner itself - (e.g. GitHub or vendor link) Here is an example of a completed Parser documentation page: https://defectdojo.github.io/django-DefectDojo/integrations/parsers/file/awssecurityhub/\n","date":"0001-01-01","id":64,"permalink":"/en/open_source/contributing/how-to-write-a-parser/","summary":"All commands assume that you\u0026rsquo;re located at the root of the django-DefectDojo cloned repo.\nPre-requisites You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally.","tags":[],"title":"Parsers"},{"content":"","date":"0001-01-01","id":65,"permalink":"/en/connecting_your_tools/parsers/","summary":"","tags":[],"title":"Supported Reports"},{"content":"","date":"2023-09-07","id":66,"permalink":"/en/cloud_management/","summary":"","tags":[],"title":"DefectDojo Cloud Manager"},{"content":"DefectDojo allows users to build sophisticated API integrations, and gives users full control over how their vulnerability data is organized.\nBut everyone needs a starting point, and that\u0026rsquo;s where Connectors come in. Connectors are designed to get your security tools connected and importing data to DefectDojo as quickly as possible.\nWe currently support Connectors for the following tools, with more on the way:\nAWS Security Hub BurpSuite Checkmarx ONE Dependency-Track Probely Semgrep SonarQube Snyk Tenable These Connectors provide an API-speed integration with DefectDojo, and can be used to automatically ingest and organize vulnerability data from the tool.\nConnectors Quick-Start If you\u0026rsquo;re using DefectDojo\u0026rsquo;s Auto-Map settings, you can have your first Connector up and running in no time.\nSet up a Connector from a supported tool. Discover your tool\u0026rsquo;s data hierarchy. Sync the vulnerabilities found with your tool into DefectDojo. That\u0026rsquo;s all, really! And remember, even if you create your Connector the \u0026rsquo;easy\u0026rsquo; way, you can easily change the way things are set up later, without losing any of your work.\nHow Connectors Work As long as you have the API key from the tool you\u0026rsquo;re trying to connect, a connector can be added in just a few minutes. Once the connection is working, DefectDojo will Discover your tool\u0026rsquo;s environment to see how you\u0026rsquo;re organizing your scan data.\nLet\u0026rsquo;s say you have a BurpSuite tool, which is set up to scan five different repositories for vulnerabilities. Your Connector will take note of this organizational structure and set up Records to help you translate those separate repositories into DefectDojo\u0026rsquo;s Product / Engagement / Test hierarchy. If you have \u0026lsquo;Auto-Map Records\u0026rsquo; enabled, DefectDojo will learn and copy that structure automatically.\nOnce your Record mappings are set up, DefectDojo will start importing scan data on a regular basis. You\u0026rsquo;ll be kept up to date on any new vulnerabilities detected by the tool, and you can start working with existing vulnerabilities immediately, using DefectDojo\u0026rsquo;s Findings system.\nWhen you\u0026rsquo;re ready to add more tools to DefectDojo, you can easily rearrange your import mappings to something else. Multiple tools can be set up to import vulnerabilities to the same destination, and you can always reorganize your setup for a better fit without losing any work.\nMy Connector isn\u0026rsquo;t supported Fortunately, DefectDojo can still handle manual import for a wide range of security tools. Please see our Supported Tool List, as well as our guide to Importing data.\nNext Steps Check out the Connectors page by switching to DefectDojo\u0026rsquo;s Beta UI. Follow our guide to create your first Connector. Check out the process of Discovering \u0026amp; Mapping your security tools and see how they can be configured to import data. ","date":"2023-09-07","id":67,"permalink":"/en/connecting_your_tools/connectors/","summary":"DefectDojo allows users to build sophisticated API integrations, and gives users full control over how their vulnerability data is organized.","tags":[],"title":"Set Up API Connectors"},{"content":"","date":"2023-09-07","id":68,"permalink":"/en/user_management/","summary":"","tags":[],"title":"Set User Permissions"},{"content":"All parsers that use API pull have common basic configuration steps, but with different values.\nFollow these steps to set up API importing:\nConfigure the API authentication details by navigating to Configuration -\u0026gt; Tool Configuration -\u0026gt; Add Tool Configuration. Enter a Name, selecting the related Tool Type and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your credentials to the proper fields based on definitions below.\nIn the Product settings select Add API Scan Configuration and select the previously added Tool Configuration. Provide values based on definitions below.\nAfter this is done, you can import the findings on the Product page through Findings -\u0026gt; Import Scan Results. As the Scan type, select the related type, the API scan configuration from the last step, and click Import.\n","date":"0001-01-01","id":69,"permalink":"/en/connecting_your_tools/parsers/api/","summary":"All parsers that use API pull have common basic configuration steps, but with different values.\nFollow these steps to set up API importing:","tags":[],"title":"API Pull"},{"content":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/doc/ and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.\nThe documentation is generated using drf-spectacular at /api/v2/oa3/swagger-ui/, and is interactive. On the top of API v2 docs is a link that generates an OpenAPI v3 spec.\nTo interact with the documentation, a valid Authorization header value is needed. Visit the /api/key-v2 view to generate your API Key (Token \u0026lt;api_key\u0026gt;) and copy the header value provided.\nEach section allows you to make calls to the API and view the Request URL, Response Body, Response Code and Response Headers.\nIf you\u0026rsquo;re logged in to the Defect Dojo web UI, you do not need to provide the authorization token.\nAuthentication The API uses header authentication with API key. The format of the header should be: :\nAuthorization: Token \u0026lt;api.key\u0026gt; For example: :\nAuthorization: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff Alternative authentication method If you use an alternative authentication method for users, you may want to disable DefectDojo API tokens because it could bypass your authentication concept. Using of DefectDojo API tokens can be disabled by specifying the environment variable DD_API_TOKENS_ENABLED to False. Or only api/v2/api-token-auth/ endpoint can be disabled by setting DD_API_TOKEN_AUTH_ENDPOINT_ENABLED to False.\nSample Code Here are some simple python examples and their results produced against the /users endpoint: :\nimport requests url = \u0026#39;http://127.0.0.1:8000/api/v2/users\u0026#39; headers = {\u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Token c8572a5adf107a693aa6c72584da31f4d1f1dcff\u0026#39;} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\u0026#34;\u0026#39;{key}\u0026#39;: \u0026#39;{value}\u0026#39;\u0026#34;) print(\u0026#39;------------------\u0026#39;) This code will return the list of all the users defined in DefectDojo. The json object result looks like : :\n[ { \u0026#34;first_name\u0026#34;: \u0026#34;Tyagi\u0026#34;, \u0026#34;id\u0026#34;: 22, \u0026#34;last_login\u0026#34;: \u0026#34;2019-06-18T08:05:51.925743\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Paz\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;dev7958\u0026#34; }, { \u0026#34;first_name\u0026#34;: \u0026#34;saurabh\u0026#34;, \u0026#34;id\u0026#34;: 31, \u0026#34;last_login\u0026#34;: \u0026#34;2019-06-06T11:44:32.533035\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;saurabh.paz\u0026#34; } ] Here is another example against the /users endpoint, this time we will filter the results to include only the users whose user name includes jay:\nimport requests url = \u0026#39;http://127.0.0.1:8000/api/v2/users/?username__contains=jay\u0026#39; headers = {\u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Token c8572a5adf107a693aa6c72584da31f4d1f1dcff\u0026#39;} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\u0026#34;\u0026#39;{key}\u0026#39;: \u0026#39;{value}\u0026#39;\u0026#34;) print(\u0026#39;------------------\u0026#39;) The json object result is: :\n[ { \u0026#34;first_name\u0026#34;: \u0026#34;Jay\u0026#34;, \u0026#34;id\u0026#34;: 22, \u0026#34;last_login\u0026#34;: \u0026#34;2015-10-28T08:05:51.925743\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Paz\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;jay7958\u0026#34; }, { \u0026#34;first_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;id\u0026#34;: 31, \u0026#34;last_login\u0026#34;: \u0026#34;2015-10-13T11:44:32.533035\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;jay.paz\u0026#34; } ] See Django Rest Framework's documentation on interacting with an API for additional examples and tips.\nManually calling the API Tools like Postman can be used for testing the API.\nExample for importing a scan result:\nVerb: POST\nURI: http://localhost:8080/api/v2/import-scan/\nHeaders tab:\nadd the authentication header Key: Authorization Value: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff Body tab\nselect \u0026quot;form-data\u0026quot;, click \u0026quot;bulk edit\u0026quot;. Example for a ZAP scan: engagement:3 verified:true active:true lead:1 tags:test scan_type:ZAP Scan minimum_severity:Info skip_duplicates:true close_old_findings:false Body tab\nClick \u0026quot;Key-value\u0026quot; edit Add a \u0026quot;file\u0026quot; parameter of type \u0026quot;file\u0026quot;. This will trigger multi-part form data for sending the file content Browse for the file to upload Click send\nClients / API Wrappers Wrapper Status Notes Specific python wrapper working (2021-01-21) API Wrapper including scripts for continous CI/CD uploading. Is lagging behind a bit on latest API features as we plan to revamp the API wrapper Openapi python wrapper proof of concept only where we found out the the OpenAPI spec is not perfect yet Java library working (2021-08-30) Created by the kind people of SecureCodeBox Image using the Java library working (2021-08-30) .Net/C# library working (2021-06-08) dd-import working (2021-08-24) dd-import is not directly an API wrapper. It offers some convenience functions to make it easier to import findings and language data from CI/CD pipelines. Some of the api wrappers contain quite a bit of logic to ease scanning and importing in CI/CD environments. We are in the process of simplifying this by making the DefectDojo API smarter (so api wrappers / script can be dumber).\n","date":"0001-01-01","id":70,"permalink":"/en/api/api-v2-docs/","summary":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/doc/ and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.","tags":[],"title":"DefectDojo API v2"},{"content":"The documentation is built with Hugo and uses the theme Docsy. Static files for the webside are build with github actions and are publish in the gh-pages branch.\nHow to run a local preview Install Hugo. Make sure you have installed the extended version with Sass/SCSS support. Please note there are various Linux packages available on Hugo GitHub\nInstall JavaScript packages\nTo build or update your site\u0026rsquo;s CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default, npm installs tools under the directory where you run npm install:\ncd docs npm install Clone the DefectDojo git repository with the option --recurse-submodules. If you have already cloned the repository, make sure that you have checked out out the Docsy theme or use git submodule to check it out:\ncd docs/themes/docsy git submodule update --init --recursive Switch to the docs folder and start the hugo server with hot reloading hugo server -D --config config.dev.toml\nVisit http://localhost:1313/django-DefectDojo/dev.\nSee also the Docsy installation procedures for reference.\n","date":"0001-01-01","id":71,"permalink":"/en/open_source/contributing/documentation/","summary":"The documentation is built with Hugo and uses the theme Docsy. Static files for the webside are build with github actions and are publish in the gh-pages branch.","tags":[],"title":"Documentation"},{"content":"Event HTTP header X-DefectDojo-Event: product_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34;, \u0026#34;user\u0026#34;: null }\r","date":"0001-01-01","id":72,"permalink":"/en/open_source/notification_webhooks/product_added/","summary":"Event HTTP header X-DefectDojo-Event: product_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34;, \u0026#34;user\u0026#34;: null }\r","tags":[],"title":"Event: product_added"},{"content":"Tags In DefectDojo, tags are a first class citizen and are recognized as the facilitators of organization within each level of the data model. Tags are ideal for grouping objects in a manner that can be filtered out into smaller, more digestible chunks.\nHere is an example with a product with two tags and four findings each with a single tag\nFormat of tag Tags can be formatted in any of the following ways:\nStringWithNoSpaces string-with-hyphens string_with_underscores colons:acceptable \u0026ldquo;quoted string with spaces\u0026rdquo; \u0026ldquo;quoted,comma,tag\u0026rdquo; \u0026ldquo;quoted with spaces, and also commas!\u0026rdquo; Adding and Removing Tags can be managed in the following ways\nCreating or Editing new objects\nWhen a new object is created or edited through the UI or API, there is a field for specifying the tags to be set on a given object. This field is a multiselect field that also has auto completion to make searching and adding existing tags a breeze. Here is what the field looks like on the product from the screenshot in the previous section:\nImport and Reimport\nTags can also be applied to a given test at the time of import or reimport. This is a very handy use case when importing via the API with automation as it provides an opportunity to append automation run details and tool information that may not be captured in the test or finding object directly.\nThe field looks and behaves exactly as it does on a given object\nBulk Edit Menu (Findings only)\nWhen needing to update many findings with the same set of tags, the bulk edit menu can be used to ease the burden.\nIn the following example, lets say I want to update the tags of the two findings with the tag \u0026ldquo;tag-group-alpha\u0026rdquo; to be a new tag list like this [\u0026ldquo;tag-group-charlie\u0026rdquo;, \u0026ldquo;tag-group-delta\u0026rdquo;]. First I would select the tags to be updated:\nOnce a finding is selected, a new button appears with the name \u0026ldquo;Bulk Edit\u0026rdquo;. Clicking this button produces a dropdown menu with many options, but the focus is just on tags for now. Update the field to have the desired tag list as follows, and click submit\nThe tags on the selected Findings will be updated to whatever was specified in the tags field within the bulk edit menu\nFiltering Tags can be filtered in many ways through both the UI and the API. For example, here is a snippet of the Finding filters:\nThere are ten fields related to tags:\nTags: filter on any tags that are attached to a given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;B\u0026rdquo; Finding Will not be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;F\u0026rdquo; Not Tags: filter on any tags that are not attached to a given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;F\u0026rdquo; Finding Will not be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;B\u0026rdquo; Tag Name Contains: filter on any tags that contain part or all of the query in the given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;et\u0026rdquo; (part of \u0026ldquo;Beta\u0026rdquo;) Finding Will not be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;meg\u0026rdquo; (part of \u0026ldquo;Omega\u0026rdquo;) Not Tags: filter on any tags that do not contain part or all of the query in the given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;meg\u0026rdquo; (part of \u0026ldquo;Omega\u0026rdquo;) Finding Will not be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;et\u0026rdquo; (part of \u0026ldquo;Beta\u0026rdquo;) For the other six tag filters, they follow the same rules as \u0026ldquo;Tags\u0026rdquo; and \u0026ldquo;Not Tags\u0026rdquo; as above, but at different levels in the data model:\nTags (Test): filter on any tags that are attached to the Test of a given Finding is part of Not Tags (Test): filter on any tags that are not attached to the Test of a given Finding is part of Tags (Engagement): filter on any tags that are attached to the Engagement of a given Finding is part of Not Tags (Engagement): filter on any tags that are not attached to the Engagement of a given Finding is part of Tags (Product): filter on any tags that are attached to the Product of a given Finding is part of Not Tags (Product): filter on any tags that are not attached to the Product of a given Finding is part of Tag Inheritance When enabled, tags applied to a given product will automatically be applied to all objects under products in the data model.\nConfiguration Tag Inheritance can be enabled at the following scope levels:\nGlobal Scope Every product system wide will begin applying tags to all children objects This is set within the System Settings Product Scope Only the selected product will begin applying tags to all children objects This is set at the product creation/edit page Behaviors Tags can be added and removed to other objects the same as when tag inheritance is disabled. The only exception to that rule being inherited tags as they cannot be removed from an object. See the following example of adding a tag \u0026ldquo;test_only_tag\u0026rdquo; to the Test object and a tag \u0026ldquo;engagement_only_tag\u0026rdquo; to the Engagement.\nWhen updates are made to the tag list on a product, the same changes are made to all objects within the product asynchronously. The duration of this task directly correlates to the number the objects contained within a finding. If the results are not observed within a reasonable time period, consult the celery worker logs to identify where any problems might have arisen.\nRisk Acceptance Findings cannot always be remediated or addressed for various reasons. A finding 'status' can be change to 'accepted' by doing the following: Findings are accepted in the engagement view. To locate the engagement from the finding click the link to engagement as shown below.\nThen, in the engagement view click the plus icon in the 'Risk Acceptance' box and fill in the details to support the risk acceptance.\nThe engagement view is now updated with the risk.\nThe finding status changes to 'Accepted' with a link to the risk acceptance.\nDeduplication Deduplication is a feature that when enabled will compare findings to automatically identify duplicates. When deduplication is enabled, a list of deduplicated findings is added to the engagement view. The following image illustrates the option deduplication on engagement and deduplication on product level:\nUpon saving a finding, DefectDojo will look at the other findings in the product or the engagement (depending on the configuration) to find duplicates\nWhen a duplicate is found:\nThe newly imported finding takes status: inactive, duplicate An \u0026quot;Original\u0026quot; link is displayed after the finding status, leading to the original finding There are two ways to use the deduplication:\nDeduplicate vulnerabilities in the same build/release. The vulnerabilities may be found by the same scanner (same scanner deduplication) or by different scanners (cross-scanner deduplication). this helps analysis and assessment of the technical debt, especially if using many different scanners; although detecting duplicates across scanners is not trivial as it requires a certain standardization. Track unique vulnerabilities across builds/releases so that DefectDojo knows when it finds a vulnerability that has seen it before. this allows you keep information attached to a given finding in a unique place: all further duplicate findings will point to the original one.\nDeduplication configuration Global configuration The deduplication can be activated in \u0026quot;System Settings\u0026quot; by ticking \u0026quot;Deduplicate findings\u0026quot;.\nAn option to delete duplicates can be found in the same menu, and the maximum number of duplicates to keep for the same finding can be configured.\nEngagement configuration When creating or editing an engagement, the \u0026quot;Deduplication within engagement only\u0026quot; checkbox can be ticked.\nIf activated: Findings are only deduplicated within the same engagement. Findings present in different engagements cannot be duplicates Otherwise: Findings are deduplicated across the whole product Note that currently deduplication does not occur across different products.\nDeduplication algorithms The behavior of the deduplication can be configured for each parser in settings.dist.py (or settings.py after install) by configuring the DEDUPLICATION_ALGORITHM_PER_PARSER variable, or via the env variable (useful for Kubernetes deployments) DD_DEDUPLICATION_ALGORITHM_PER_PARSER with a JSON string like\n{\u0026#34;ScannerName\u0026#34;:\u0026#34;algorithm\u0026#34;}\rThe environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe available algorithms are:\nDEDUPE_ALGO_UNIQUE_ID_FROM_TOOL (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: unique_id_from_tool) The deduplication occurs based on finding.unique_id_from_tool which is a unique technical id existing in the source tool. Few scanners populate this field currently. If you want to use this algorithm, you may need to update the scanner code beforehand. Advantages: If your source tool has a reliable means of tracking a unique vulnerability across scans, this configuration will allow defectDojo to use this ability. Drawbacks: Using this algorithm will not allow cross-scanner deduplication as other tools will have a different technical id. When the tool evolves, it may change the way the unique id is generated. In that case you won't be able to recognise that findings found in previous scans are actually the same as the new findings. DEDUPE_ALGO_HASH_CODE (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: hash_code) The deduplication occurs based on finding.hash_code. The hash_code itself is configurable for each scanner in parameter HASHCODE_FIELDS_PER_SCANNER. DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: unique_id_from_tool_or_hash_code) A finding is a duplicate with another if they have the same unique_id_from_tool OR the same hash_code. Allows to use both a technical deduplication (based on unique_id_from_tool) for a reliable same-parser deduplication and a functional one (based on hash_code configured on CWE+severity+file_path for example) for cross-parser deduplication DEDUPE_ALGO_LEGACY (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: legacy) This is algorithm that was in place before the configuration per parser was made possible, and also the default one for backward compatibility reasons. Legacy algorithm basically deduplicates based on: For static scanner: ['title', 'cwe', 'line', 'file_path', 'description'] For dynamic scanner: ['title', 'cwe', 'line', 'file_path', 'description', 'endpoints'] Note that there are some subtleties that may give unexpected results. Switch dojo.specific-loggers.deduplication to debug in settings.py to get more info in case of trouble.\nHash_code computation configuration The hash_code computation can be configured for each parser using the parameter HASHCODE_FIELDS_PER_SCANNER in settings.dist.py, or via the env variable (useful for Kubernetes deployments) DD_HASHCODE_FIELDS_PER_SCANNER with a JSON string like\n{\u0026#34;ScannerName\u0026#34;:[\u0026#34;field1\u0026#34;, \u0026#34;field2\u0026#34;]}\rThe environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe parameter HASHCODE_ALLOWED_FIELDS list the fields from finding table that were tested and are known to be working when used as a hash_code. Don't hesitate to enrich this list when required (the code is generic and allows adding new fields by configuration only)\nNote that endpoints isn't a field from finding table but rather a meta value that will trigger a computation based on all the endpoints.\nWhen populating HASHCODE_FIELDS_PER_SCANNER, please respect the order of declaration of the fields: use the same order as in HASHCODE_ALLOWED_FIELDS: that will allow cross-scanner deduplication to function because the hash_code is computed as a sha-256 of concatenated values of the configured fields.\nTips:\nIt's advised to use fields that are standardized for a reliable deduplication, especially if aiming at cross-scanner deduplication. For example title and description tend to change when the tools evolve and don't allow cross-scanner deduplication\nGood candidates are cwe or cve Adding the severity will make sure the deduplication won't be to aggressive (there are several families of XSS and sql injection for example, with various severities but the same cwe). Adding the file_path or endpoints is advised too. The parameter HASHCODE_ALLOWS_NULL_CWE will allow switching to legacy algorithm when a null cwe is found for a given finding: this is to avoid getting many duplicates when the tool fails to give a cwe while we are expecting it.\nHashcode generation / regeneration When you change the hashcode configuration, it is needed to regenerated the hashcodes for all findings, or at least those findings found by scanners for which the configuration was updated.\nThis is sometimes also needed after an upgrade to a new DefectDojo version, for example when we made changes to the hashcode configuration or calculation logic. We will mention this in the upgrade notes.\nTo regenerate the hashcodes, use the dedupe management command:\ndocker compose exec uwsgi ./manage.py dedupe --hash_code_only This will only regenerated the hashcodes, but will not run any deduplication logic on existing findings. If you want to run deduplication again on existing findings to make sure any duplicates found by the new hashcode config are marked as such, run:\ndocker compose exec uwsgi ./manage.py dedupe The deduplication part of this command will run the deduplication for each finding in a celery task. If you want to run the deduplication in the foreground process, use:\ndocker compose exec uwsgi ./manage.py dedupe --dedupe_sync Please note the deduplication process is resource intensive and can take a long time to complete (estimated ~7500 findings per minute when run in the foreground)\nDebugging deduplication There is a specific logger that can be activated in order to have details about the deduplication process : switch dojo.specific-loggers.deduplication to debug in settings.dist.py.\nDeduplication - APIv2 parameters close_old_findings : if true, findings that are not duplicates and that were in the previous scan of the same type (example ZAP) for the same engagement (or product in case of \u0026quot;close_old_findings_product_scope\u0026quot;) and that are not present in the new scan are closed (Inactive, Verified, Mitigated). close_old_findings_product_scope : if true, close_old_findings applies to all findings of the same type in the product. Note that \u0026quot;Deduplication on engagement\u0026quot; is no longer used to determine the scope of close_old_findings. Deduplication / Similar findings Similar Findings Visualization:\nSimilar Findings While viewing a finding, similar findings within the same product are listed along with buttons to mark one finding a duplicate of the other. Clicking the \u0026quot;Use as original\u0026quot; button on a similar finding will mark that finding as the original while marking the viewed finding as a duplicate. Clicking the \u0026quot;Mark as duplicate\u0026quot; button on a similar finding will mark that finding as a duplicate of the viewed finding. If a similar finding is already marked as a duplicate, then a \u0026quot;Reset duplicate status\u0026quot; button is shown instead which will remove the duplicate status on that finding along with marking it active again. Service Level Agreement (SLA) DefectDojo allows you to maintain your security SLAs and automatically remind teams whenever a SLA is about to get breached, or is breached.\nTo apply SLAs to Findings, open the System Settings page and check \u0026lsquo;Enable Finding SLAs\u0026rsquo;.\nYou will then need to create one or more SLA Configurations, from the SLA Configuration menu (your-defectdojo.com/sla_config).\nSLA notification configuration There are 3 variables in the system settings that can be set for notifications of SLA breaches. By default notifications are disabled. You can either choose to notify about breaches for findings that are only in \u0026lsquo;Active\u0026rsquo; or for any findings across the instance that are in Active, Verified. Furthermore, it is possible choose to only consider findings that have a JIRA issue linked to them.\nThere are 2 variables in the settings.py file that you can configure, to act on the global behavior.\nSLA_NOTIFY_PRE_BREACH = 3 SLA_NOTIFY_POST_BREACH = 7 The SLA_NOTIFY_PRE_BREACH is expressed in days. Whenever a finding's \u0026quot;SLA countdown\u0026quot; (time to remediate) drops to this number, a notification would be sent everyday, as scheduled by the crontab in settings.py, until the day it breaches.\nThe SLA_NOTIFY_POST_BREACH lets you define in days how long you want to be kept notified about findings that have breached the SLA. Passed that number, notifications will cease.\nBe mindful of performance if you choose to have SLA notifications on non-verified findings, especially if you import a lot of findings through CI in 'active' state.\nWhat notification channels for SLA notifications? You will notice that an extra SLA breach option is now present on the Notification page and also in the Product view.\nSLA notification with JIRA You can choose to also send SLA notification as JIRA comments, if your product is configured with JIRA. You can enable this at the Product level in the Product specific JIRA settings.\nThe Product level JIRA notification configuration takes precendence over the global JIRA notification configuration.\nWhen is the SLA notification job run? The default setup will trigger the SLA notification code at 7:30am on a daily basis, as defined in the settings.py file. You can of course modify this schedule to your context.\n\u0026#39;compute-sla-age-and-notify\u0026#39;: { \u0026#39;task\u0026#39;: \u0026#39;dojo.tasks.async_sla_compute_and_notify\u0026#39;, \u0026#39;schedule\u0026#39;: crontab(hour=7, minute=30), } The celery containers are the ones concerned with this configuration. If you suspect things are not working as expected, make sure they have the latest version of your settings.py file.\nYou can of course change this default by modifying that stanza.\nLaunching from the CLI You can also invoke the SLAÂ notification function from the CLI. For example, if run from docker compose:\n$ docker compose exec uwsgi /bin/bash -c \u0026#39;python manage.py sla_notifications\u0026#39; Reports Instant reports Instant reports can be generated for:\nProduct types Products Engagements Tests List of Findings Endpoints Filtering is available on all report generation views to aid in focusing the report for the appropriate need.\nCustom reports Custom reports, generated with the Report Builder, allow you to select specific components to be added to the report. These include:\nCover Page Table of Contents WYSIWYG Content Findings Vulnerable Endpoints Page Breaks DefectDojo\u0026rsquo;s reports can be generated in HTML.\nMetrics DefectDojo provides a number of metrics visualization in order to help with reporting, awareness and to be able to quickly communicate a products/product type's security stance.\nThe following metric views are provided:\nProduct Type Metrics This view provides graphs displaying Open Bug Count by Month, Accepted Bug Count by Month, Open Bug Count by Week, Accepted Bug Count by Week as well as tabular data on Top 10 Products by bug severity, Detail Breakdown of all reported findings, Opened Findings, Accepted Findings, Closed Findings, Trending Open Bug Count, Trending Accepted Bug Count, and Age of Issues. Product Type Counts This view provides tabular data of Total Current Security Bug Count, Total Security Bugs Opened In Period, Total Security Bugs Closed In Period, Trending Total Bug Count By Month, Top 10 By Bug Severity, and Open Findings. This view works great for communication with stakeholders as it is a snapshot in time of the product. Product Tag Counts Same as above, but for a group of products sharing a tag. Simple Metrics Provides tabular data for all Product Types. The data displayed in this view is the total number of S0, S1, S2, S3, S4, Opened This Month, and Closed This Month. Engineer Metrics Provides graphs displaying information about a tester's activity. Metrics Dashboard Provides a full screen, auto scroll view with many metrics in graph format. This view is great for large displays or \u0026quot;Dashboards.\u0026quot; Users DefectDojo users inherit from django.contrib.auth.models.User.\nA username, first name, last name, and email address can be associated with each user. Additionally the following attributes describe the type of users:\nActive Designates whether this user should be treated as active and can login to DefectDojo. Unselect this instead of deleting accounts. Superuser status Designates that this user can configure the system and has all permissions for objects without explicitly assigning them. A superuser may force a password reset for any user at any given time. This can be set when creating a new user, or when editing an existing one, requiring the user to change their password upon their next login.\nDefectDojo enforces the following password rules for all users:\nMust meet a length requirement of 9 characters Must be unique (not commonly used) Must contain one of each of the following: a number (0-9), uppercase letter (A-Z), lowercase letter (a-z), and symbol ()[]{}|~!@#$%^\u0026amp;*_-+=;:`\u0026rsquo;\u0026quot;,\u0026lt;\u0026gt;./? Calendar The calendar view provides a look at all the engagements and tests occurring during the month d, week or day displayed. Each entry is a direct link to the respective engagement or test view page.\nBenchmarks DefectDojo utilizes the OWASP ASVS Benchmarks to benchmark a product to ensure the product meets your application technical security controls. Benchmarks can be defined per the organizations policy for secure development and multiple benchmarks can be applied to a product.\nBenchmarks are available from the Product view. To view the configured benchmarks select the dropdown menu from the right hand drop down menu. You will find the selection near the bottom of the menu entitled: 'OWASP ASVS v.3.1'.\nIn the Benchmarks view for each product, the default level is ASVS Level\nOn the top right hand side the drop down can be changed to the desired ASVS level (Level 1, Level 2 or Level 3). The publish checkbox will display the ASVS score on the product page and in the future this will be applied to reporting. On the left hand side the ASVS score is displayed with the desired score, the % of benchmarks passed to achieve the score and the total enabled benchmarks for that AVSV level.\nAdditional benchmarks can be added/updated in the Django admin site. In a future release this will be brought out to the UI.\nEndpoint Meta Importer For heavy infrastructure scanning organizations, endpoints need to be as flexible as possible to get the most of DefectDojo. This flexibility comes in the form of Tags and custom fields. Tags allow users to filter, sort, and report objects in ways the base object is not totally proficient in doing.\nEndpoint Meta Importer provides a means to apply arbitrary tags and custom fields to endpoints in mass via a CSV file. Tags and customs fields are stored in the format of column:row.\nHere is a very simple example with only two columns:\nhostname | team | public_facing ------------------------------------------------------------------ sheets.google.com | data analytics | yes docs.google.com | language processing | yes feedback.internal.google.com | human resources | no\rThe three endpoints hosts will be used to find existing endpoints with matching hosts, or create new endpoints, and then apply meta as follows:\nsheets.google.com (endpoint) -\u0026gt; [ team:data analytics, public_facing:yes ] (tags) docs.google.com (endpoint) -\u0026gt; [ team:language processing, public_facing:yes ] (tags) feedback.internal.google.com (endpoint) -\u0026gt; [ team:human resources, public_facing:no ] (tags)\rEndpoint Meta Importer can be found in the Endpoint tab when viewing a Product\nNote: The field \u0026ldquo;hostname\u0026rdquo; is required as it is used to query/create endpoints.\nFindings Image Upload You can add images (.png, .jpeg, .gif) to your findings. In order to achieve this, you have to click on \u0026ldquo;Manage Files\u0026rdquo; within the finding: There, you can upload a png file to attach it to a finding: The following picture shows the result: ","date":"0001-01-01","id":73,"permalink":"/en/open_source/archived_docs/usage/features/","summary":"Tags In DefectDojo, tags are a first class citizen and are recognized as the facilitators of organization within each level of the data model.","tags":[],"title":"Features"},{"content":"Recommended Options Docker Compose See instructions in DOCKER.md\nSaaS (Includes Support \u0026amp; Supports the Project) SaaS link\nAWS AMI (Supports the Project) Marketplace link, and complete walkthrough\nOptions for the brave (not officially supported) Kubernetes See instructions in KUBERNETES.md\nLocal install with godojo See instructions in README.md in the godojo repository\nCustomizing of settings See Configuration\n","date":"0001-01-01","id":74,"permalink":"/en/open_source/installation/installation/","summary":"Recommended Options Docker Compose See instructions in DOCKER.md\nSaaS (Includes Support \u0026amp; Supports the Project) SaaS link\nAWS AMI (Supports the Project) Marketplace link, and complete walkthrough","tags":[],"title":"Installation"},{"content":"Here\u0026rsquo;s a quick reference you can use to ensure successful implementation - from a blank canvas to a fully functional app.\nThe Basics Start by importing a file using the UI. This is generally the quickest way to see how your data fits into the DefectDojo model. (note: OS users will need to set up a Product Type and Product before they can import data)\nNow that you have data in DefectDojo, learn more about how to organize it with the Product Hierarchy Overview. The Product Hierarchy creates a working inventory of your apps, which helps you divide your data up into logical categories. These categories can be used to apply access control rules, or to segement your reports to the correct team.\nTry creating a Report to summarize the data you\u0026rsquo;ve imported. Reports can be used to quickly share Findings with stakeholders such as Product Owners.\nThis is the essence of DefectDojo - import security data, organize it, and present it to the folks who need to know.\nAll of these features can be automated, and because DefectDojo can handle over 190 tools (at time of writing) you should be all set to create a functional security inventory of your entire organizational output.\nOther guides Does your organization use Jira? Learn how to use our Jira integration to create Jira tickets from the data you ingest. Are you expecting to share DefectDojo with many users in your organization? Check out our guides to user management and set up role-based access control (RBAC). Ready to dive into automation? Learn how to use the DefectDojo API to automatically import new data, and build a robust CI / CD pipeline. ","date":"0001-01-01","id":75,"permalink":"/en/about_defectdojo/new_user_checklist/","summary":"Here\u0026rsquo;s a quick reference you can use to ensure successful implementation - from a blank canvas to a fully functional app.","tags":[],"title":"New User Checklist"},{"content":"Product Health Grading Within DefectDojo\u0026rsquo;s system settings, you have the opportunity to enable a grading system for your products. For that you have to enable (\u0026ldquo;Enable Product Grading\u0026rdquo;). Then, the products are graded with the following possible grades:\nGrade A Grade B Grade C Grade D Grade F The best grade is A going down to the worst grade F. By default the grades stick to the achieved percentage mentioned in grade converation here.\nCalculation of the grades The code that performs the grade calculations can be found here.\nThe highest health score is 100 and it decreases based on the number of findings for each severity (critical, high, medium, low) within the product. In the following code snippet you can see the rules. Note that the following abbreviations were used:\ncrit: amount of critical findings within the product high: amount of high findings within the product med: amount of medium findings within the product low: amount of low findings within the product health=100 if crit \u0026gt; 0: health = 40 health = health - ((crit - 1) * 5) if high \u0026gt; 0: if health == 100: health = 60 health = health - ((high - 1) * 3) if med \u0026gt; 0: if health == 100: health = 80 health = health - ((med - 1) * 2) if low \u0026gt; 0: if health == 100: health = 95 health = health - low if health \u0026lt; 5: health = 5 return health\r","date":"0001-01-01","id":76,"permalink":"/en/open_source/archived_docs/usage/productgrading/","summary":"Product Health Grading Within DefectDojo\u0026rsquo;s system settings, you have the opportunity to enable a grading system for your products. For that you have to enable (\u0026ldquo;Enable Product Grading\u0026rdquo;).","tags":[],"title":"Product Health Grading"},{"content":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.\nUsing docker images provided in DockerHub If you're using latest, then you need to pre pull the latest from DockerHub to update.\nThe generic upgrade method for docker compose are as follows:\nPull the latest version\ndocker pull defectdojo/defectdojo-django:latest docker pull defectdojo/defectdojo-nginx:latest\rIf you would like to use a version other than the latest, specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2 docker pull defectdojo/defectdojo-nginx:1.10.2\rIf you would like to use alpine based images, you specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2-alpine docker pull defectdojo/defectdojo-nginx:1.10.2-alpine\rGo to the directory where your docker-compose.yml file lives\nStop DefectDojo: ./dc-stop.sh\nRe-start DefectDojo, allowing for container recreation: ./dc-up-d.sh\nDatabase migrations will be run automatically by the initializer. Check the output via docker compose logs initializer or relevant k8s command\nIf you have the initializer disabled (or if you want to be on the safe side), run the migration command: docker compose exec uwsgi /bin/bash -c \u0026quot;python manage.py migrate\u0026quot;\nBuilding your local images If you build your images locally and do not use the ones from DockerHub, the instructions are the same, with the caveat that you must build your images first.\nPull the latest DefectDojo changes\ngit fetch git pull git merge origin/master\rThen replace the first step of the above generic upgrade method for docker compose with: docker compose build\ngodojo installations If you have installed DefectDojo on \u0026ldquo;iron\u0026rdquo; and wish to upgrade the installation, please see the instructions in the repo.\nUpgrade notes for each release ","date":"0001-01-01","id":77,"permalink":"/en/open_source/upgrading/","summary":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.","tags":[],"title":"Upgrading"},{"content":"","date":"0001-01-01","id":78,"permalink":"/en/open_source/archived_docs/usage/","summary":"","tags":[],"title":"Usage"},{"content":"","date":"2023-09-07","id":79,"permalink":"/en/connecting_your_tools/","summary":"","tags":[],"title":"Connect Your Tools"},{"content":"Auth0 In the same way as with other identity providers, it\u0026rsquo;s now possible to leverage Auth0 to authenticate users on DefectDojo.\nInside your Auth0 dashboard create a new application (Applications / Create Application / Single Page Web Application).\nOn the new application set the following fields:\nName: \u0026ldquo;Defectdojo\u0026rdquo; Allowed Callback URLs: https://the_hostname_you_have_dojo_deployed:your_server_port/complete/auth0/ Copy the following info from the application:\nDomain Client ID Client Secret Now, edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_AUTH0_OAUTH2_ENABLED=True DD_SOCIAL_AUTH_AUTH0_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_AUTH0_SECRET=(str,\u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_AUTH0_DOMAIN=(str, \u0026#39;**YOUR_AUTH0_DOMAIN_FROM_STEP_ABOVE**\u0026#39;), Restart DefectDojo, and you should now see a Login with Auth0 button on the login page.\nGoogle New to DefectDojo, a Google account can now be used for Authentication, Authorization, and a DefectDojo user. Upon login with a Google account, a new user will be created if one does not already exist. The criteria for determining whether a user exists is based on the users username. In the event a new user is created, the username is that of the Google address without the domain. Once created, the user creation process will not happen again as the user is recalled by its username, and logged in. In order to make the magic happen, a Google authentication server needs to be created. Closely follow the steps below to guarantee success.\nNavigate to the following address and either create a new account, or login with an existing one: Google Developers Console\nOnce logged in, find the key shaped button labeled Credentials on the left side of the screen. Click Create Credentials, and choose OAuth Client ID:\nSelect Web Applications, and provide a descriptive name for the client.\nAdd the pictured URLs in the Authorized Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access.\nOnce all URLs are added, finish by clicking Create\nNow with the authentication client created, the Client ID and Client Secret Key need to be copied over to the settings. Click the newly created client and copy the values:\nEdit the settings (see Configuration with the following information:\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_GOOGLE_OAUTH2_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET=(str, \u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), To authorize users you will need to set the following:\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS = [\u0026#39;example.com\u0026#39;, \u0026#39;example.org\u0026#39;] or\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS = [\u0026#39;\u0026lt;email@example.com\u0026gt;\u0026#39;] OKTA In a similar fashion to that of Google, using OKTA as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\nNavigate to the following address and either create a new account, or login with an existing one: OKTA Account Creation\nOnce logged in, enter the Applications and click Add Application:\nSelect Web Applications.\nAdd the pictured URLs in the Login Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access. Check the Implicit box as well.\nOnce all URLs are added, finish by clicking Done.\nReturn to the Dashboard to find the Org-URL. Note this value as it will be important in the settings file.\nNow, with the authentication client created, the Client ID and Client Secret Key need to be copied over to the settings. Click the newly created client and copy the values:\nEdit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_OKTA_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_OKTA_OAUTH2_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_OKTA_OAUTH2_SECRET=(str, \u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_OKTA_OAUTH2_API_URL=(str, \u0026#39;https://{your-org-url}/oauth2\u0026#39;), If during the login process you get the following error: The \u0026lsquo;redirect_uri\u0026rsquo; parameter must be an absolute URI that is whitelisted in the client app settings. and the redirect_uri HTTP GET parameter starts with http:// instead of https:// you need to add SOCIAL_AUTH_REDIRECT_IS_HTTPS = True in the settings.\nAzure Active Directory Azure AD Configuration You can now use your corporate Azure Active Directory to authenticate users to Defect Dojo. Users will be using your corporate Azure AD account (A.K.A. Office 365 identity) to authenticate via OAuth, and all the conditional access rules and benefits from Azure Active Directory will also apply to the Defect Dojo Authentication. Once the user signs in, it will try to match the UPN of the user to an existing e-mail from a user in Defect Dojo, and if no match is found, a new user will be created in Defect Dojo, associated with the unique id/value of the user provided by your Azure AD tenant. Then, you can assign roles to this user, such as \u0026lsquo;superuser\u0026rsquo;.\nNavigate to the following address and follow instructions to create a new app registration\nhttps://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app Once you register an app, take note of the following information:\nApplication (client) ID Directory (tenant) ID Under Certificates \u0026amp; Secrets, create a new Client Secret Under Authentication \u0026gt; Redirect URIs, add a WEB type of uri where the redirect points to\nhttp://localhost:8080/complete/azuread-tenant-oauth2/ OR https://the_hostname_you_have_dojo_deployed:your_server_port/complete/azuread-tenant-oauth2/ Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_KEY=(str, \u0026#39;YOUR_APPLICATION_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_SECRET=(str, \u0026#39;YOUR_CLIENT_SECRET_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_TENANT_ID=(str, \u0026#39;YOUR_DIRECTORY_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_ENABLED = True Restart your Dojo, and you should now see a Login with Azure AD button on the login page which should magically work\nAutomatic Import of User-Groups To import groups from Azure AD users, the following environment variable needs to be set:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS=True This will ensure the user is added to all the groups found in the Azure AD Token. Any missing groups will be created in DefectDojo (unless filtered). This group synchronization allows for product access via groups to limit the products a user can interact with.\nThe Azure AD token returned by Azure will also need to be configured to include group IDs. Without this step, the token will not contain any notion of a group, and the mapping process will report that the current user is not a member of any groups. To update the the format of the token, add a group claim that applies to whatever group type you are using. If unsure of what type that is, select All Groups. Do not activate Emit groups as role claims within the Azure AD \u0026ldquo;Token configuration\u0026rdquo; page.\nApplication API permissions need to be updated with the Group.Read.All permission so that groups can be read on behalf of the user that has successfully signed in.\nTo limit the amount of groups imported from Azure AD, a regular expression can be used as the following:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GROUPS_FILTER=\u0026#39;^team-.*\u0026#39; # or \u0026#39;teamA|teamB|groupC\u0026#39; Automatic Cleanup of User-Groups To prevent authorization creep, old Azure AD groups a user is not having anymore can be deleted with the following environment parameter:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS=True When a user is removed from a given group in Azure AD, they will also be removed from the corresponding group in DefectDojo. If there is a group in DefectDojo, that no longer has any members, it will be left as is for record purposes.\nGitlab In a similar fashion to that of Google and OKTA, using Gitlab as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\nNavigate to your Gitlab settings page and got to the Applications section\nhttps://gitlab.com/profile/applications OR https://the_hostname_you_have_gitlab_deployed:your_gitlab_port/profile/applications Choose a name for your application\nFor the Redirect URI, enter the DefectDojo URL with the following format\nhttps://the_hostname_you_have_dojo_deployed:your_server_port/complete/gitlab/ Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_GITLAB_KEY=(str, \u0026#39;YOUR_APPLICATION_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_GITLAB_SECRET=(str, \u0026#39;YOUR_SECRET_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_GITLAB_API_URL=(str, \u0026#39;https://gitlab.com\u0026#39;), DD_SOCIAL_AUTH_GITLAB_OAUTH2_ENABLED = True Additionally, if you want to import your Gitlab projects as DefectDojo products, add the following line to your settings:\nDD_SOCIAL_AUTH_GITLAB_PROJECT_AUTO_IMPORT = True Important: if you enable this setting on already working instance with gitlab integrations, it will require new grant \u0026ldquo;read_repository\u0026rdquo; by user\nRestart DefectDojo, and you should now see a Login with Gitlab button on the login page.\nKeycloak There is also an option to use Keycloak as OAuth2 provider in order to authenticate users to Defect Dojo, also by using the social-auth plugin.\nHere are suggestion on how to configure Keycloak and DefectDojo:\nConfigure Keycloak (assuming you already have an existing realm, otherwise create one)\nNavigate to your keycloak realm and add a new client of type openid-connect. Choose a name for the client id and use this value below for DD_SOCIAL_AUTH_KEYCLOAK_KEY). In the client settings: Set access type to confidential Under valid Redirect URIs, add the URI to your defect dojo installation, e.g. \u0026lsquo;https://\u0026lt;YOUR_DD_HOST\u0026gt;/*\u0026rsquo; Under web origins, add the same (or \u0026lsquo;+\u0026rsquo;) Under Fine grained openID connect configuration -\u0026gt; user info signed response algorithm: set to RS256 Under Fine grained openID connect configuration -\u0026gt; request object signature algorithm: set to RS256 -\u0026gt; save these settings in keycloak (hit save button) Under Scope -\u0026gt; Full Scope Allowed set to off Under mappers -\u0026gt; add a custom mapper here: Name: aud Mapper type: audience Included audience: select your client/client-id here Add ID to token: off Add access to token: on Under credentials: copy the secret (and use as DD_SOCIAL_AUTH_KEYCLOAK_SECRET below) In your realm settings -\u0026gt; keys: copy the \u0026ldquo;Public key\u0026rdquo; (signing key) (use for DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY below) In your realm settings -\u0026gt; general -\u0026gt; endpoints: look into openId endpoint configuration and look up your authorization and token endpoint (use them below) Configure Defect Dojo Edit the settings (see Configuration) with the following information:\nDD_SESSION_COOKIE_SECURE=True, DD_CSRF_COOKIE_SECURE=True, DD_SECURE_SSL_REDIRECT=True, DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY=(str, \u0026#39;\u0026lt;your realm public key\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_KEY=(str, \u0026#39;\u0026lt;your client id\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_SECRET=(str, \u0026#39;\u0026lt;your keycloak client credentials secret\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL=(str, \u0026#39;\u0026lt;your authorization endpoint\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL=(str, \u0026#39;\u0026lt;your token endpoint\u0026gt;\u0026#39;) or, alternatively, for helm configuration, add this to the extraConfig section:\nDD_SESSION_COOKIE_SECURE: \u0026#39;True\u0026#39; DD_CSRF_COOKIE_SECURE: \u0026#39;True\u0026#39; DD_SECURE_SSL_REDIRECT: \u0026#39;True\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED: \u0026#39;True\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY: \u0026#39;\u0026lt;your realm public key\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_KEY: \u0026#39;\u0026lt;your client id\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_SECRET: \u0026#39;\u0026lt;your keycloak client credentials secret\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL: \u0026#39;\u0026lt;your authorization endpoint\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL: \u0026#39;\u0026lt;your token endpoint\u0026gt;\u0026#39;\rOptionally, you can set DD_SOCIAL_AUTH_KEYCLOAK_LOGIN_BUTTON_TEXT in order to customize the login button\u0026rsquo;s text caption.\nGitHub Enterprise Navigate to your GitHub Enterprise Server and follow instructions to create a new OAuth App https://docs.github.com/en/enterprise-server/developers/apps/building-oauth-apps/creating-an-oauth-app Choose a name for your application For the Redirect URI, enter the DefectDojo URL with the following format https://the_hostname_you_have_dojo_deployed:your_server_port/complete/github-enterprise/ Edit the settings (see Configuration) with the following information: DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_KEY=(str, \u0026#39;GitHub Enterprise OAuth App Client ID\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_SECRET=(str, \u0026#39;GitHub Enterprise OAuth App Client Secret\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_URL=(str, \u0026#39;https://github.\u0026lt;your_company\u0026gt;.com/\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_API_URL=(str, \u0026#39;https://github.\u0026lt;your_company\u0026gt;.com/api/v3/\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_OAUTH2_ENABLED = True, Restart DefectDojo, and you should now see a Login with GitHub Enterprise button on the login page. SAML 2.0 In a similar direction to OAuth, this SAML addition provides a more secure perogative to SSO. For definitions of terms used and more information, see the plugin plugin homepage.\nNavigate to your SAML IdP and find your metadata\nEdit the settings (see Configuration) with the following information:\nDD_SAML2_ENABLED=(bool, **True**), # SAML Login Button Text DD_SAML2_LOGIN_BUTTON_TEXT=(str, \u0026#39;Login with SAML\u0026#39;), # If the metadata can be accessed from a url, try the DD_SAML2_METADATA_AUTO_CONF_URL=(str, \u0026#39;\u0026lt;https://your_IdP.com/metadata.xml\u0026gt;\u0026#39;), # Otherwise, downlaod a copy of the metadata into an xml file, and # list the path in DD_SAML2_METADATA_LOCAL_FILE_PATH DD_SAML2_METADATA_LOCAL_FILE_PATH=(str, \u0026#39;/path/to/your/metadata.xml\u0026#39;), # Fill in DD_SAML2_ATTRIBUTES_MAP to corresponding SAML2 userprofile attributes provided by your IdP DD_SAML2_ATTRIBUTES_MAP=(dict, { # format: SAML attrib:django_user_model \u0026#39;Email\u0026#39;: \u0026#39;email\u0026#39;, \u0026#39;UserName\u0026#39;: \u0026#39;username\u0026#39;, \u0026#39;Firstname\u0026#39;: \u0026#39;first_name\u0026#39;, \u0026#39;Lastname\u0026#39;: \u0026#39;last_name\u0026#39; }), # May configure the optional fields NOTE: DD_SAML2_ATTRIBUTES_MAP in k8s can be referenced as extraConfig (e.g. DD_SAML2_ATTRIBUTES_MAP: 'Email'='email', 'Username'='username'...)\nNOTE: DD_SITE_URL might also need to be set depending on the choices you make with the metadata.xml provider. (File versus URL).\nCheckout the SAML section in dojo/dojo/settings/settings.dist.py and verfiy if it fits your requirement. If you need help, take a look at the plugin documentation.\nRestart DefectDojo, and you should now see a Login with SAML button (default setting of DD_SAML2_LOGIN_BUTTON_TEXT) on the login page.\nNOTE: In the case when IDP is configured to use self signed (private) certificate, than CA needs to be specified by define environments variable REQUESTS_CA_BUNDLE that points to the path of private CA certificate.\nAdvanced Configuration The https://github.com/IdentityPython/djangosaml2 plugin has a lot of options. For details take a look at the plugin documentation. All default options in DefectDojo can overwritten in the local_settings.py. If you want to change the organization name, you can add the following lines:\nif SAML2_ENABLED: SAML_CONFIG[\u0026#39;contact_person\u0026#39;] = [{ \u0026#39;given_name\u0026#39;: \u0026#39;Extra\u0026#39;, \u0026#39;sur_name\u0026#39;: \u0026#39;Example\u0026#39;, \u0026#39;company\u0026#39;: \u0026#39;DefectDojo\u0026#39;, \u0026#39;email_address\u0026#39;: \u0026#39;dummy@defectdojo.com\u0026#39;, \u0026#39;contact_type\u0026#39;: \u0026#39;technical\u0026#39; }] SAML_CONFIG[\u0026#39;organization\u0026#39;] = { \u0026#39;name\u0026#39;: [(\u0026#39;DefectDojo\u0026#39;, \u0026#39;en\u0026#39;)], \u0026#39;display_name\u0026#39;: [(\u0026#39;DefectDojo\u0026#39;, \u0026#39;en\u0026#39;)], }, Migration from django-saml2-auth Up to relase 1.15.0 the SAML integration was based on https://github.com/fangli/django-saml2-auth. Which the switch to djangosaml2 some parameters has changed:\nDD_SAML2_ASSERTION_URL: not necessary any more - automatically generated DD_SAML2_DEFAULT_NEXT_URL: not necessary any more - default forwarding from defectdojo is used DD_SAML2_NEW_USER_PROFILE: not possible any more - default profile is used, see User Permissions DD_SAML2_ATTRIBUTES_MAP: Syntax has changed DD_SAML2_CREATE_USER: Default value changed to False, to avoid security breaches RemoteUser This implementation is suitable if the DefectDojo instance is placed behind HTTP Authentication Proxy. Dojo expects that the proxy will perform authentication and pass HTTP requests to the Dojo instance with filled HTTP headers. The proxy should check if an attacker is not trying to add a malicious HTTP header and bypass authentication.\nValues which need to be set:\nDD_AUTH_REMOTEUSER_ENABLED - Needs to be set to True DD_AUTH_REMOTEUSER_USERNAME_HEADER - Name of the header which contains the username DD_AUTH_REMOTEUSER_EMAIL_HEADER(optional) - Name of the header which contains the email DD_AUTH_REMOTEUSER_FIRSTNAME_HEADER(optional) - Name of the header which contains the first name DD_AUTH_REMOTEUSER_LASTNAME_HEADER(optional) - Name of the header which contains the last name DD_AUTH_REMOTEUSER_GROUPS_HEADER(optional) - Name of the header which contains the comma-separated list of groups; user will be assigned to these groups (missing groups will be created) DD_AUTH_REMOTEUSER_GROUPS_CLEANUP(optional) - Same as [#automatic-import-of-user-groups](AzureAD implementation) DD_AUTH_REMOTEUSER_TRUSTED_PROXY - Comma separated list of proxies; Simple IP and CIDR formats are supported DD_AUTH_REMOTEUSER_LOGIN_ONLY(optional) - Check Django documentation WARNING: There is possible spoofing of headers (for all DD_AUTH_REMOTEUSER_xxx_HEADER values). Read Warning in Django documentation\nUser Permissions When a new user is created via the social-auth, only the default permissions are active. This means that the newly created user does not have access to add, edit, nor delete anything within DefectDojo. There are two parameters in the System Settings to influence the permissions for newly created users:\nDefault group When both the parameters Default group and Default group role are set, the new user will be a member of the given group with the given role, which will give him the respective permissions.\nGroups from Identity Providers Some Identity Providers are able to send list of groups to which should user belongs. This functionality is implemented only for Identity Providers mentioned below. For all others, we will be more than happy for contribution (hint: functions assign_user_to_groups and cleanup_old_groups_for_user from dojo/pipeline.py might be useful).\nAzure: Check DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS and DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS RemoteUser: Check DD_AUTH_REMOTEUSER_GROUPS_HEADER and DD_AUTH_REMOTEUSER_GROUPS_CLEANUP Login speed-up You can bypass the login form if you are only using SSO/Social authentication for login in by enabling these two environment variables:\nDD_SOCIAL_LOGIN_AUTO_REDIRECT: \u0026#34;true\u0026#34; DD_SOCIAL_AUTH_SHOW_LOGIN_FORM: \u0026#34;false\u0026#34;\rLogin form fallback If you are using \u0026ldquo;login speed-up\u0026rdquo;, it can be useful to be able to login by the standard way, for example when an admin user needs to log in because of a change of some settings or permissions. This feature is accessible by a visiting the URL \u0026lt;DD_HOST\u0026gt;/login?force_login_form.\nOther Providers In an effort to accommodate as much generality as possible, it was decided to implement OAuth2 with the social-auth ecosystem as it has a library of compatible providers with documentation of implementation. Conveniently, each provider has an identical procedure of managing the authenticated responses and authorizing access within a given application. The only difficulty is creating a new authentication client with a given OAuth2 provider.\n","date":"0001-01-01","id":80,"permalink":"/en/open_source/archived_docs/integrations/social-authentication/","summary":"Auth0 In the same way as with other identity providers, it\u0026rsquo;s now possible to leverage Auth0 to authenticate users on DefectDojo.","tags":[],"title":"Authentication via OAuth2/SAML2"},{"content":"Regular releases The DefectDojo team aims to maintain the following cadence:\nMinor releases: at least once a month on the first Monday of the month. Patch/Bugfix: releases every week on Monday. Security releases: will be performed outside of our regular cadence depending on severity. GitHub Actions are the source of truth. The releases are semi-automated. The steps for a regular release are:\nCreate the release branch from dev or bugfix and prepare a PR against master (details) \u0026ndash;\u0026gt; A maintainer verifies and manually merges the PR Tag, issue draft release and docker build+push (details) \u0026ndash;\u0026gt; A maintainer massages the release-drafter notes and publishes the release A PR to merge master back to dev and bugfix is created to re-align the branches (details) Security releases PRs that relate to security issues are done through security advisories which provide a way to work privately on code without prematurely disclosing vulnerabilities.\nRelease and hotfix model Diagrams created with plantUML. Find a web-based editor for PlantUML at https://www.planttext.com.\nDocumentation A dev version of the documentation built from the dev branch is available at DefectDojo Documentation - dev branch.\n``` @startuml participant \u0026ldquo;Dev Branch\u0026rdquo; as dev #LightBlue participant \u0026ldquo;BugFix Branch\u0026rdquo; as bugfix #LightGreen participant \u0026ldquo;Release Branch\u0026rdquo; as release #LightGoldenRodYellow participant \u0026ldquo;Master Branch\u0026rdquo; as master #LightSalmon\n== Minor Release (Monthly) ==\ndev -\u0026gt; release: Create branch \u0026ldquo;release/2.x.0\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.0\\n - Push 2.x.0 to DockerHub master \u0026ndash;\u0026gt; bugfix: Merge master into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master back into dev\n== Patch/BugFix Release (Weekly) ==\nbugfix -\u0026gt; release: Create branch \u0026ldquo;release/2.x.y\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master -\u0026gt; bugfix: Merge master back into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master into dev to realign\n== Security Release (As Needed) ==\nmaster -\u0026gt; release: Create branch \u0026ldquo;release/2.x.y\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master \u0026ndash;\u0026gt; bugfix: Merge master into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master into dev to realign\n@enduml\n\u0026lt;/div\u0026gt;\r","date":"0001-01-01","id":81,"permalink":"/en/open_source/contributing/branching-model/","summary":"Regular releases The DefectDojo team aims to maintain the following cadence:\nMinor releases: at least once a month on the first Monday of the month.","tags":[],"title":"Branching model"},{"content":"dojo/settings/settings.dist.py The main settings are stored in dojo/settings/settings.dist.py. It is great to use this file as a reference for what can be configured, but it shouldn't be edited directly, because changes will be overwritten when updating DefectDojo. There are several methods to change the default settings:\nEnvironment variables Most parameters can be set by environment variables.\nWhen you deploy DefectDojo via Docker Compose, you can set environment variables in docker-compose.yml. Be aware you have to set the variables for three services: uwsgi, celerybeat and celeryworker.\nWhen you deploy DefectDojo in a Kubernetes cluster, you can set environment variables as extraConfigs and extraSecrets in helm/defectdojo/values.yaml.\nEnvironment file (not with Docker Compose or Kubernetes) settings.dist.py reads environment variables from a file whose name is specified in the environment variable DD_ENV_PATH. If this variable is not set, the default .env.prod is used. The file must be located in the dojo/settings directory.\nAn example can be found in template_env.\nlocal_settings.py (not with Kubernetes) local_settings.py can contain more complex customizations such as adding MIDDLEWARE or INSTALLED_APP entries. This file is processed after settings.dist.py is processed, so you can modify settings delivered by DefectDojo out of the box. The file must be located in the dojo/settings directory. Environment variables in this file must not have the DD_ prefix. If the file is missing feel free to create it. Do not edit settings.dist.py directly.\nAn example can be found in dojo/settings/template-local_settings.\nIn Docker Compose release mode, files in docker/extra_settings/ (relative to the file docker-compose.yml) will be copied into dojo/settings/ in the docker container on startup.\nConfiguration in the UI Users with the superuser status can configure more options via the UI under Configuration / System Settings.\n","date":"0001-01-01","id":82,"permalink":"/en/open_source/installation/configuration/","summary":"dojo/settings/settings.dist.py The main settings are stored in dojo/settings/settings.dist.py. It is great to use this file as a reference for what can be configured, but it shouldn't be edited directly, because changes will be overwritten when updating DefectDojo.","tags":[],"title":"Configuration"},{"content":"For DefectDojo Pro users, DefectDojo\u0026rsquo;s Support team can be contacted in a variety of ways.\nContacting Support via Email Customers / Pro Users can always email our team directly at support at defectdojo dot com\r.\nContacting Support through the DefectDojo app You can contact us through the DefectDojo App:\nby opening Cloud Manager \u0026gt; Contact Support from the left sidebar**,** or through {your-instance}.defectdojo.com/cloud_portal/support. Contact Support through the DefectDojo Cloud Portal You can also contact our support team through your Cloud Portal:\nby clicking on Contact Us (on the left sidebar) or via https://cloud.defectdojo.com/resources/contact. ","date":"0001-01-01","id":83,"permalink":"/en/about_defectdojo/contact_defectdojo_support/","summary":"For DefectDojo Pro users, DefectDojo\u0026rsquo;s Support team can be contacted in a variety of ways.\nContacting Support via Email Customers / Pro Users can always email our team directly at support at defectdojo dot com\r.","tags":[],"title":"Contact DefectDojo Support"},{"content":"Event HTTP header X-DefectDojo-Event: engagement_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engagement\u0026#34;: { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;notif eng\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34; }, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34;, \u0026#34;user\u0026#34;: null }\r","date":"0001-01-01","id":84,"permalink":"/en/open_source/notification_webhooks/engagement_added/","summary":"Event HTTP header X-DefectDojo-Event: engagement_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engagement\u0026#34;: { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;notif eng\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34; }, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34;, \u0026#34;user\u0026#34;: null }\r","tags":[],"title":"Event: engagement_added"},{"content":"","date":"0001-01-01","id":85,"permalink":"/en/open_source/archived_docs/integrations/","summary":"","tags":[],"title":"Integrations"},{"content":"System-wide permissions Administrators (aka superusers) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. Staff users can add Product Types, and have access to data according to their role in a Product or Product Type. Regular users have limited functionality available. They cannot add Product Types but have access to data according to their role in a Product or Product Type Product and Product Type permissions Users can be assigned as members to Products and Product Types, giving them one out of five predefined roles. The role defines what kind of access a user has to functions for interacting with data of that Product or Product Type:\nProduct / Product Type roles:\nReader Writer Maintainer Owner API Importer Add Product Type 1) 1) View Product Type x x x x x Remove yourself as a member x x x x Manage Product Type members x x Edit Product Type x x Add Product x x Add Product Type member as Owner x Delete Product Type x View Product x x x x x Remove yourself as a member x x x x Manage Product members x x Edit Product x x Add Product member as Owner x Delete Product x View Engagement x x x x x Add Engagement x x x x Edit Engagement x x x x Risk Acceptance x x x Delete Engagement x x View Test x x x x x Add Test x x x Edit Test x x x x Delete Test x x View Finding x x x x x Add Finding x x x Edit Finding x x x (Re-)Import Scan Result x x x x Delete Finding x x View Finding Group x x x x x Add Finding Group x x x Edit Finding Group x x x Delete Finding Group x x x View Endpoint x x x x x Add Endpoint x x x Edit Endpoint x x x Delete Endpoint x x Edit Benchmark x x x Delete Benchmark x x View Components x x x x x View Note History x x x x Add Note x x x x Edit Note (x) 2) x x x Delete Note (x) 2) (x) 2) x x 1) Every superuser can add Product Types. Regular users are not allowed to add Product Types, unless they are a Global Owner or Maintainer.\n2) Every user is allowed to edit and delete his own notes.\nThe role of a user within a Product Type is inherited by all Products of that Product Type, unless the user is explicitly defined as a member of a Product with a different role. In that case, if a user doesn\u0026rsquo;t have a certain right for the Product Type, it is then checked if he has the right for the Product.\nA Product Type needs to have at least one owner. The last owner cannot be removed.\nGlobal permissions Users can be assigned a global role in the Edit User dialog. A global role gives a user access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nA use case for a global role could be the Chief Information Security Officer of a company who needs an overview of all systems. If he gets the global role Reader, he can see the findings for all products and also all metrics.\nSince global roles give users access to all data, only superusers are allowed to edit it.\nGroups If you have a number of users who should all have the same permissions for some Products or Product Types, you can put them together in a group. The group defines the roles for Products and Product Types that are applied to all members of the group.\nThe membership of a group itself has a role that determines what permissions the member has to manage the group:\nReader Maintainer Owner Add Group 1) View Group x x x Remove yourself as a member x x x Manage Group members x x Edit Group x x Add Group member as Owner x Delete Group x 1) Every superuser can add groups. Regular users are not allowed to add groups.\nThe permissions to manage the roles of Products and Product types for a group is defined by the role of the user in the respective Product or Product Type.\nGroups can have a global role too. This global role gives all members of the group access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nConfiguration permissions Many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their superuser status:\n3 configurations can still only be changed by superusers:\nSystem settings Notifications on system level Configuration permissions for users and groups These configuration settings are a powerful tool and should be used with great care.\n","date":"0001-01-01","id":86,"permalink":"/en/open_source/archived_docs/usage/permissions/","summary":"System-wide permissions Administrators (aka superusers) have no limitations in the system. They can change all settings, manage users and have read / write access to all data.","tags":[],"title":"Permissions"},{"content":"Questionnaires Questionnaires provide a means for collecting information from developers and respective stakeholders. DefectDojo includes functionality to create new questionnaires with custom questions, open questionnaires to receive responses for certain time periods from insiders or outsiders, and connect questionnaires with new or existing engagements.\nCreating a New Questionnaire To access, create, or modify new/existing questionnaires, navigate to the All Questionnaires dashboard from the sidebar.\nOn the questionnaire dashboard, all existing questionnaires are displayed. To quickly find a questionnaire, the filters may be used to search for snippets within the questionnaire name and/or description, as well as by active/inactive status.\nWhen questionnaires are open for responses, they will be displayed in the General Questionnaires block towards the bottom of the page.\nTo begin the process of creating a new questionnaire, select the Create Questionnaire button located in the top right of the questionnaire dashboard.\nQuestionnaires have a name and description, as well as an activity status, which are initially set on questionnaire creation, but can be modified in the future if necessary. Once these fields are filled in appropriately, the user can create the questionnaire without any questions (by selecting Create Questionnaire), or with questions (by selecting Create Questionnaire and Add Questions).\nTo add questions to a questionnaire, select the dropdown titled Select as many Questions as applicable, which will open all of the existing questions within DefectDojo. Once the desired questions are selected from the list, the dropdown can be closed, and the Update Questionnaire Questions can be selected to save the newly created questionnaire.\nNote: New questions may also be added at the time of questionnaire creation by selecting the plus located next to the questions dropdown.\nCreating New Questions The questions dashboard displays all of the questions that may exist as part of questionnaires within DefectDojo. Similar to questionnaires, to quickly find a question, the filters may be used to search for optional status, or snippets within the question name and/or description. Two types of questions exist within DefectDojo questionnaires: Text Questions and Multiple Choice Questions. To add a new question, select the Create Question button located in the top right of the questions dashboard.\nAdding Text Questions To add a text question (open-ended), fill out the add question form, where:\nType - The type of question being created, in this case Text. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Question Text - The text that is displayed to prompt a user for their answer (e.g. What is your favorite color?). Adding Multiple Choice Questions Similar to the process of adding a text question, choice questions (non-open-ended) allow the user to pick from a given list of choices. To add a choice question, fill out the add question form, where:\nType - The type of question being created, in this case Choice. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Multichoice - When the multichoice box is checked, multiple choices from the list of choices may be selected by the user. Answer Choices - The possible answer choices that may be selected by a user. Publishing a Questionnaire Once a questionnaire has been successfully created, it can be published to accept responses. To publish a questionnaire, select the plus located to the right of General Questionnaires.\nThis will prompt for a specific questionnaire to be selected, as well as a date the questionnaire response window should close. The response window sets a due date for recipients. Once these two options have been selected, publish the questionnaire by selecting Add Questionnaire.\nOnce a questionnaire is published, a link to share it can be retrieved by selecting the Share Questionnaire action. To ensure the newly created questionnaire has been constructed as expected, open the share link and view the newly created questionnaire.\nUnassigned Questionnaires When a questionnaire\u0026rsquo;s response window has closed, all of the responses will be saved, and the questionnaire will be listed as an Unassigned Answered Engagement Questionnaire on the DefectDojo dashboard.\nThere are three actions that may be taken when a questionnaire\u0026rsquo;s response window has closed: View Responses, Create Engagement, and Assign User.\nView Questionnaire Responses To view the questionnaire responses, select the View Responses action. All of the responses from the questionnaire will be displayed.\nCreate an Engagement From a Questionnaire To link the questionnaire to a product via an engagement, select the Create Engagement action. Once a product is selected from the dropdown, select Create Engagement. This will link the questionnaire results with a new engagement under the selected product, which can then be given specific details similar to other engagements in DefectDojo, such as Description, Version, Status, Tags, etc.\nTo view a questionnaire at the engagement level, navigate to the engagement linked with the desired questionnaire. Expand the Additional Features menu to reveal a Questionnaires dropdown, which will contain all of the linked questionnaires.\nAssign a Questionnaire to a User To assign a questionnaire to a user, select the Assign User action. This will prompt for a user to be selected from the dropdown of available users. Once a user is selected, assign the questionnaire to the specified user by selecting Assign Questionnaire.\nCreating Questionnaires From Engagements While questionnaires are commonly created from the questionnaire dashboard, they can also be created at the engagement level. To create a new questionnaire from within an engagement, expand the Additional Features dropdown to reveal the Questionnaires dropdown. In the right side header of the Questionnaires dropdown, select the plus to link a new questionnaire.\nOnce prompted, select a questionnaire from the available surveys list to link it with the engagement. If the user wishes to leave a response at the time of linking the questionnaire with the engagement, the Add Questionnaire and Repond option may be selected. To simply link the questionnaire with the engagement, select Add Questionnaire.\nAnonymous Questionnaires Questionnaires, by default, are only accessible by DefectDojo users. To allow outside responses to DefectDojo questionnaires, ensure the Allow Anonymous Survey Reponses option within the System Settings is selected. To share a questionnaire with anonymous users, use the questionnaire\u0026rsquo;s Share Link.\n","date":"0001-01-01","id":87,"permalink":"/en/open_source/archived_docs/usage/questionnaires/","summary":"Questionnaires Questionnaires provide a means for collecting information from developers and respective stakeholders. DefectDojo includes functionality to create new questionnaires with custom questions, open questionnaires to receive responses for certain time periods from insiders or outsiders, and connect questionnaires with new or existing engagements.","tags":[],"title":"Questionnaires"},{"content":"","date":"2023-09-07","id":88,"permalink":"/en/jira_integration/","summary":"","tags":[],"title":"Connect To Jira"},{"content":"You can find further information in the contributing guidelines.\n","date":"0001-01-01","id":89,"permalink":"/en/open_source/contributing/","summary":"You can find further information in the contributing guidelines.","tags":[],"title":"Contributing"},{"content":"Event HTTP header X-DefectDojo-Event: test_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engagement\u0026#34;: { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;notif eng\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34; }, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;test\u0026#34;: { \u0026#34;id\u0026#34;: 90, \u0026#34;title\u0026#34;: \u0026#34;notif test\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34;, \u0026#34;user\u0026#34;: null }\r","date":"0001-01-01","id":90,"permalink":"/en/open_source/notification_webhooks/test_added/","summary":"Event HTTP header X-DefectDojo-Event: test_added\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engagement\u0026#34;: { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;notif eng\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34; }, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;test\u0026#34;: { \u0026#34;id\u0026#34;: 90, \u0026#34;title\u0026#34;: \u0026#34;notif test\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34;, \u0026#34;user\u0026#34;: null }\r","tags":[],"title":"Event: test_added"},{"content":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.\nWhen he is asked to audit an application, Bill registers a new Product in DefectDojo, and creates a new Engagement. Here he sets some basic information, like how long he expects the Engagement will take, who will be leading the testing (himself), what Product he will be working on, and what tests he will be doing.\nNext, he can add a Test to the Engagement, or upload a Nessus scan and start picking out the real vulnerabilities from the false positives (Nessus scan Findings are imported as inactive by default).\nWithin the Test section, Bill can add Findings for any issues that he has uncovered during his audit. He can assign a severity to the Findings, describe replication steps, mitigation strategies, and impact on the system. This will come in handy when he wants to generate a report to send to the development team responsible for this Product, or his manager.\nOnce Bill has completed his Engagement, he can close the Engagement on the main Engagement page. He can then view the results of his Tests, and generate a report to send to the development team.\nIf Bill hears back from the development team that they won't be able to fix the issue for a while, he can make a note of this on the Engagement page. Bill will also receive Alerts for any bugs that persist longer than they are supposed to based on their severity.\nExample 2 - John the QE manager John wants to keep tabs on what his team members are up to, and find issues that are taking a long time to get fixed. He creates his own DefectDojo account with superuser privileges so that he can view other team members' metrics.\nTo get a better idea of what his team members are currently working on, he can start by checking the Calendar. This will show him any active Engagements that his team is involved in, based on the dates assigned to those Engagements.\nHe can view metrics for a Product Type, such as \u0026quot;Third Party Apps\u0026quot; to track his team's activity and follow up with Product teams who have long-lived bugs. He can also look at all the Findings for which there is a Risk Acceptance associated, and ensure that the proper documentation or timeline has been provided for the Findings in question.\nIf he wants to check on a particular team member's progress, he can look at the Engineer Metrics dashboard under \u0026quot;Additional Metrics\u0026quot; for that user.\n","date":"0001-01-01","id":91,"permalink":"/en/open_source/archived_docs/usage/workflows/","summary":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.","tags":[],"title":"Example workflows"},{"content":"DefectDojo's JIRA integration is bidirectional. You may push findings to JIRA and share comments. If an issue is closed in JIRA it will automatically be closed in Dojo.\nNOTE: These steps will configure the necessary webhook in JIRA and add JIRA integration into DefectDojo. This isn't sufficient by itself, you will need to configure products and findings to push to JIRA. On a product's settings page you will need to define a:\nProject Key (and this project must exist in JIRA) JIRA Configuration (select the JIRA configuration that you create in the steps below) Component (can be left blank) Then elect (via tickbox) whether you want to 'Push all issues', 'Enable engagement epic mapping' and/or 'Push notes'. Then click on 'Submit'.\nIf creating a Finding, ensure to tick 'Push to jira' if desired.\nEnabling the Webhook Visit https://\u0026lt;YOUR JIRA URL\u0026gt;/plugins/servlet/webhooks Click 'Create a Webhook' For the field labeled 'URL' enter: https://\u0026lt;YOUR DOJO DOMAIN\u0026gt;/jira/webhook/\u0026lt;YOUR GENERATED WEBHOOK SECRET\u0026gt; This value can be found under Defect Dojo System settings Under 'Comments' enable 'Created'. Under Issue enable 'Updated'. Configurations in Dojo Navigate to the System Settings from the menu on the left side or by directly visiting \u0026lt;your url\u0026gt;/system_settings. Enable 'Enable JIRA integration' and click submit. For the webhook created in Enabling the Webhook, enable 'Enable JIRA web hook' and click submit. Adding JIRA to Dojo Click 'JIRA' from the left hand menu.\nSelect 'Add Configuration' from the drop-down.\nFor JIRA Server:\nEnter the Username \u0026amp; Password. A Username and JIRA Personal Access Token will not necessarily work.\nFor JIRA Cloud:\nEnter Email Address \u0026amp; API token for Jira\nTo obtain the 'open status key' and 'closed status key' visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions?expand=transitions.fields\nThe 'id' for 'Todo' should be filled in as the 'open status key'\nThe 'id' for 'Done' should be filled in as the 'closed status key'\nTo obtain 'epic name id': If you have admin access to JIRA:\nvisit: https://\u0026lt;YOUR JIRA URL\u0026gt;/secure/admin/ViewCustomFields.jspa Click on the cog next to 'Epic Name' and select view. The numeric value for 'epic name id' will be displayed in the URL Note: dojojira uses the same celery functionality as reports. Make sure the celery runner is setup correctly as described: https://documentation.defectdojo.com/basics/features/#reports Or\nlogin to JIRA visit https://yourjiraurl/rest/api/2/field and use control+F or grep to search for 'Epic Name' it should look something like this: { \u0026ldquo;id\u0026rdquo;:\u0026ldquo;customfield_122\u0026rdquo;, \u0026ldquo;key\u0026rdquo;:\u0026ldquo;customfield_122\u0026rdquo;, \u0026ldquo;name\u0026rdquo;:\u0026ldquo;Epic Name\u0026rdquo;, \u0026ldquo;custom\u0026rdquo;:true, \u0026ldquo;orderable\u0026rdquo;:true, \u0026ldquo;navigable\u0026rdquo;:true, \u0026ldquo;searchable\u0026rdquo;:true, \u0026ldquo;clauseNames\u0026rdquo;:\u0026ldquo;cf[122]\u0026rdquo;, \u0026ldquo;Epic Name\u0026rdquo;], \u0026ldquo;schema\u0026rdquo;:{\u0026ldquo;type\u0026rdquo;:\u0026ldquo;string\u0026rdquo;,\u0026ldquo;custom\u0026rdquo;:\u0026ldquo;com.pyxis.greenhopper.jira:gh-epic-label\u0026rdquo;,\u0026ldquo;customId\u0026rdquo;:122} }\nIn the above example 122 is the number needed\nCustomize JIRA issue description By default Defect Dojo uses the dojo/templates/issue-trackers/jira_full/jira-description.tpl template to render the description of the \u0026rsquo;to be\u0026rsquo; created JIRA issue. This file can be modified to your needs, rebuild all containers afterwards. There\u0026rsquo;s also a more limited template available, which can be chosen when configuring a JIRA Instance or JIRA Project for a Product or Engagement:\nAny folder added to dojo/templates/issue-trackers/ will be added to the dropdown (after rebuilding/restarting the containers).\nEngagement Epic Mapping If creating an Engagement, ensure to tick \u0026lsquo;Enable engagement epic mapping\u0026rsquo; if desired. This can also be done after engagement creation on the edit engagement page. This will create an \u0026lsquo;Epic\u0026rsquo; type issue within Jira. All findings in the engagement pushed to Jira will have a link to this Epic issue. If Epic Mapping was enabled after associated findings have already been pushed to Jira, simply pushing them again will link the Jira issue to the Epic issue.\nPushing findings Findings can be pushed to Jira in a number of ways:\nWhen importing scanner reports, select \u0026lsquo;Push to JIRA\u0026rsquo; to push every single finding in the report to Jira When creating a new finding, select \u0026lsquo;Push to JIRA\u0026rsquo; and submit. This will create the finding in DefectDojo and Jira simultaneously If a finding already exist, visit the edit finding page and find the \u0026lsquo;Push to JIRA\u0026rsquo; tick box at the bottom When viewing a list of findings, select each relevant tick boxes to the left of the finding, and click the \u0026lsquo;Bulk Edit\u0026rsquo; button at the top. find \u0026lsquo;Push to JIRA\u0026rsquo; at the bottom of the menu Status Sync DefectDojo will try to keep the status in sync with the status in JIRA using the Close and Reopen transition IDs configured for each JIRA instance. This will only work if your workflow in JIRA allows the Close transition to be performed from every status a JIRA issue can be in.\nKnown Issues The Risk Acceptance feature in DefectDojo will (for that reason) not (yet) try to sync statuses. A comment will be pushed to JIRA if a finding is risk accepted or unaccepted. Contributions are welcome to enhance the integration.\nStatus reconciliation Sometimes JIRA is down, or Defect Dojo is down, or there was bug in a webhook. In this case JIRA can become out of sync with Defect Dojo. If this is the case for lots of issues, manual reconciliation might not be feasible. For this scenario there is the management command \u0026lsquo;jira_status_reconciliation\u0026rsquo;.\nusage: manage.py jira_status_reconciliation [-h] [--mode MODE] [--product PRODUCT] [--engagement ENGAGEMENT] [--dryrun] [--version] [-v {0,1,2,3}] Reconcile finding status with JIRA issue status, stdout will contain semicolon seperated CSV results. Risk Accepted findings are skipped. Findings created before 1.14.0 are skipped. optional arguments: -h, --help show this help message and exit --mode MODE - reconcile: (default)reconcile any differences in status between Defect Dojo and JIRA, will look at the latest status change timestamp in both systems to determine which one is the correct status - push_status_to_jira: update JIRA status for all JIRA issues connected to a Defect Dojo finding (will not push summary/description, only status) - import_status_from_jira: update Defect Dojo finding status from JIRA --product PRODUCT Only process findings in this product (name) --engagement ENGAGEMENT Only process findings in this product (name) --dryrun Only print actions to be performed, but make no modifications. -v {0,1,2,3}, --verbosity {0,1,2,3} Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output This can be executed from the uwsgi docker container using:\n$ docker compose exec uwsgi /bin/bash -c \u0026#39;python manage.py jira_status_reconciliation\u0026#39; DEBUG output can be obtains via -v 3, but only after increasing the logging to DEBUG level in your settings.dist.py or local_settings.py file\n$ docker compose exec uwsgi /bin/bash -c \u0026#39;python manage.py jira_status_reconciliation -v 3\u0026#39; At the end of the command a semicolon seperated CSV summary will be printed. This can be captured by redirecting stdout to a file:\n$ docker compose exec uwsgi /bin/bash -c \u0026#39;python manage.py jira_status_reconciliation \u0026gt; jira_reconciliation.csv\u0026#39; Troubleshooting JIRA integration JIRA actions are typically performed in the celery background process. Errors are logged as alerts/notifications to be seen on the top right of the DefectDojo UI and in stdout of the celery workers.\n","date":"0001-01-01","id":92,"permalink":"/en/open_source/archived_docs/jira/","summary":"DefectDojo's JIRA integration is bidirectional. You may push findings to JIRA and share comments. If an issue is closed in JIRA it will automatically be closed in Dojo.","tags":[],"title":"JIRA integration"},{"content":"Filter String Matching Optimization IN the UI, many of the filters for a given object will also query related objects for an easy visual match of an item to filter on. For instances with many objects, this could lead to a considerable performance hit. To alleviate this constriction, enable the \u0026ldquo;Filter String Matching Optimization\u0026rdquo; setting in the System Settings to change many filters to only search on names, rather than the objects themselves. This change will save many large queries, and will improve the performance of UI based interactions.\nAsynchronous Import DefectDojo offers an experimental feature to aynschronously import security reports. This feature works in most use cases, but struggles when doing things such as pushing to Jira during the import process. Because Endpoints are still being processed and created even after the import procedure is completed, pushing Findings to Jira can result in incomplete Jira tickets. It is advised to wait until after import has been completed (reaches 100%).\nTo enable this feature, set ASYNC_FINDING_IMPORT to True in local_settings.py\nAsynchronous Delete For larger instances, deleting an object can take minutes for all related objects to be expanded into memory, rendered on the page, and then removing all objects from the database. To combat this issue, two settings can be set in local_settings.py:\nASYNC_OBJECT_DELETE Deleting an object asynchronously changes the way an object is deleted under the hood. By removing the need to expand into memory, a lot of time (and memory) can be saved by offloading the lookups and removals onto celery processes. This process works by starting at the bottom of a given object, and walking the tree upwards rather than downwards. This way, objects can be seperated into buckets, and then deleted.\nDELETE_PREVIEW Previewing all the objects to be deleted takes almost as much time as deleting the objects itself. This is a safety feature intended to warn users of what they are about to delete, as well as educating users of how the delete functionality works by cascade deleting all related objects. With this feature enabled, the user will only see the following text in the delete preview (without any database lookups)\nPreviewing the relationships has been disabled.\n","date":"0001-01-01","id":93,"permalink":"/en/open_source/performance/","summary":"Filter String Matching Optimization IN the UI, many of the filters for a given object will also query related objects for an easy visual match of an item to filter on.","tags":[],"title":"Performance Enhancements"},{"content":"If your team requires an on-premise DefectDojo installation, please connect with our Sales team by emailing -\u0026gt; info at defectdojo dot com\r. This trial setup process only applies to DefectDojo Cloud users.\nAll DefectDojo plans include a free 2-week trial, which you can use to evaluate our software. DefectDojo Trial instances are fully-featured and can be immediately converted to our team into paid instances - no need to set everything up again, or reupload any data when your trial period ends.\nRequesting your Trial In order to sign up for the trial, you\u0026rsquo;ll need to complete the process at https://www.defectdojo.com/pricing.\nAt the end of this process, you\u0026rsquo;ll be put in touch with our Sales team, who will follow up to receive your billing information, and authorize and set up your company\u0026rsquo;s trial instance.\nStep 1: Select a Plan DefectDojo offers 4 plan tiers: Entry, Team, Business and Enterprise. For more information on these plan tiers, see https://www.defectdojo.com/pricing.\nStep 2: Enter your Company Information \u0026amp; create your Domain Enter your company\u0026rsquo;s Name and the Server Label you want to use with DefectDojo. You will then have a custom domain created for your DefectDojo instance on our servers.\nNormally, DefectDojo will name your domain according to your Company Name., but if you select \u0026ldquo;Use Server Label in Domain\u0026rdquo;, DefectDojo will instead label your domain according to the Server Label you chose. This approach may be preferred if you plan to use multiple DefectDojo instances (such as a Production instance and a Test instance, for example). Please contact our Sales team -\u0026gt; info at defectdojo dot com\rif you require multiple instances.\nStep 3: Select a Server Location Select a Server Location from the drop-down menu. We recommend selecting a server that is geographically closest to the main DefectDojo team to reduce server latency.\nStep 4: Configure your Firewall Rules Enter the IP address ranges, subnet mask and labels that you want to allow to access DefectDojo. Additional IP addresses and rules can be added or changed by your team after your instance is up and running.\nIf you want to use external services with DefectDojo (GitHub or JIRA), check the appropriate boxes listed under Select External Services.\nStep 4: Confirm your Plan type and Billing Frequency Before you complete the process, please confirm the plan you want to use along with your billing frequency - monthly or annually.\nStep 5: Review and Submit your Request We\u0026rsquo;ll prompt you to look over your request one more time. Once submitted, only Firewall rules can be changed by your team without assistance from Support. To contact Support, please email support at defectdojo dot com\ror follow the instructions in this article.\nAfter reviewing and accepting DefectDojo\u0026rsquo;s License and Support Agreement, you can click Proceed To Checkout, or Meet The Creators.\nProceed To Checkout will take you to a Stripe page where you can enter your billing information. If you do not wish to enter your billing info at this time, you can click Meet The Creators - our Sales team will be in touch to set up your trial. Once your trial has been approved Our Support team will send you a Welcome email with links to access your DefectDojo instance. You can always reach out to support at defectdojo dot com\rfor product assistance once your trial begins.\n","date":"0001-01-01","id":94,"permalink":"/en/about_defectdojo/request_a_trial/","summary":"If your team requires an on-premise DefectDojo installation, please connect with our Sales team by emailing -\u0026gt; info at defectdojo dot com\r.","tags":[],"title":"Request a Trial"},{"content":"Production use with docker compose The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.\nAlthough Docker Compose is one of the supported installation methods to deploy a containerized DefectDojo in a production environment, the docker-compose.yml file is not intended for production use without first customizing it to your particular situation.\nSee Running with Docker Compose for more information how to run DefectDojo with Docker Compose.\nDatabase performance and backup It is recommended to use a dedicated database server and not the preconfigured PostgreSQL database. This will improve the performance of DefectDojo.\nIn both cases (dedicated DB or containerized), if you are self-hosting, it is recommended that you implement and create periodic backups of your data.\nBackup of Media files Media files for uploaded files, including threat models and risk acceptance, are stored in a docker volume. This volume needs to be backed up regularly.\nInstance size Please read the paragraphs below about key processes tweaks.\nWith a separate database, the minimum recommendations are:\n2 vCPUs 8 GB of RAM 10 GB of disk space (remember, your database is not here -- so what you have for your O/S should do). You could allocate a different disk than your OS's for potential performance improvements. uWSGI By default (except in ptvsd mode for debug purposes), uWSGI will handle 4 concurrent connections.\nBased on your resource settings, you can tweak:\nDD_UWSGI_NUM_OF_PROCESSES for the number of spawned processes. (default 2) DD_UWSGI_NUM_OF_THREADS for the number of threads in these processes. (default 2) For example, you may have 4 processes with 6 threads each, yielding 24 concurrent connections.\nCelery worker By default, a single mono-process celery worker is spawned. When storing a large amount of findings, leveraging async functions (like deduplication), or both. Eventually, it is important to adjust these parameters to prevent resource starvation.\nThe following variables can be changed to increase worker performance, while keeping a single celery container.\nDD_CELERY_WORKER_POOL_TYPE will let you switch to prefork. (default solo) When you enable prefork, the variables below have to be used. see the Dockerfile.django-* for in-file references.\nDD_CELERY_WORKER_AUTOSCALE_MIN defaults to 2. DD_CELERY_WORKER_AUTOSCALE_MAX defaults to 8. DD_CELERY_WORKER_CONCURRENCY defaults to 8. DD_CELERY_WORKER_PREFETCH_MULTIPLIER defaults to 128. You can execute the following command to see the configuration:\ndocker compose exec celerybeat bash -c \u0026quot;celery -A dojo inspect stats\u0026quot; and see what is in effect.\nAsynchronous Import Please note: Asynchronous Import is currently an experimental feature. Please exercise caution with this method as results may be inconsistent.\nImport and Re-Import can also be configured to handle uploads asynchronously to aid in processing especially large scans. It works by batching Findings and Endpoints by a configurable amount. Each batch will be be processed in separate celery tasks.\nThe following variables impact async imports.\nDD_ASYNC_FINDING_IMPORT defaults to False DD_ASYNC_FINDING_IMPORT_CHUNK_SIZE defaults to 100 When using asynchronous imports with dynamic scanners, Endpoints will continue to \u0026ldquo;trickle\u0026rdquo; in even after the import has returned a successful response. This is because processing continues to occur after the Findings have already been imported.\nTo determine if an import has been fully completed, please see the progress bar in the appropriate test.\n","date":"0001-01-01","id":95,"permalink":"/en/open_source/installation/running-in-production/","summary":"Production use with docker compose The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.","tags":[],"title":"Running in production"},{"content":"Event scan_added_empty describes a situation when reimport did not affect the existing test (no finding has been created or closed).\nEvent HTTP header for scan_added X-DefectDojo-Event: scan_added\rEvent HTTP header for scan_added_empty X-DefectDojo-Event: scan_added_empty\rEvent HTTP body { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engagement\u0026#34;: { \u0026#34;id\u0026#34;: 7, \u0026#34;name\u0026#34;: \u0026#34;notif eng\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/engagements/7/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/engagement/7\u0026#34; }, \u0026#34;finding_count\u0026#34;: 4, \u0026#34;findings\u0026#34;: { \u0026#34;mitigated\u0026#34;: [ { \u0026#34;id\u0026#34;: 233, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Mitigated Finding\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/findings/233/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/finding/233\u0026#34; } ], \u0026#34;new\u0026#34;: [ { \u0026#34;id\u0026#34;: 232, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;New Finding\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/findings/232/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/finding/232\u0026#34; } ], \u0026#34;reactivated\u0026#34;: [ { \u0026#34;id\u0026#34;: 234, \u0026#34;severity\u0026#34;: \u0026#34;Low\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Reactivated Finding\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/findings/234/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/finding/234\u0026#34; } ], \u0026#34;untouched\u0026#34;: [ { \u0026#34;id\u0026#34;: 235, \u0026#34;severity\u0026#34;: \u0026#34;Info\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Untouched Finding\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/findings/235/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/finding/235\u0026#34; } ] }, \u0026#34;product\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/products/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/4\u0026#34; }, \u0026#34;product_type\u0026#34;: { \u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;notif prod type\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/product_types/4/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/product/type/4\u0026#34; }, \u0026#34;test\u0026#34;: { \u0026#34;id\u0026#34;: 90, \u0026#34;title\u0026#34;: \u0026#34;notif test\u0026#34;, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34; }, \u0026#34;url_api\u0026#34;: \u0026#34;http://localhost:8080/api/v2/tests/90/\u0026#34;, \u0026#34;url_ui\u0026#34;: \u0026#34;http://localhost:8080/test/90\u0026#34;, \u0026#34;user\u0026#34;: null }\r","date":"0001-01-01","id":96,"permalink":"/en/open_source/notification_webhooks/scan_added/","summary":"Event scan_added_empty describes a situation when reimport did not affect the existing test (no finding has been created or closed).","tags":[],"title":"Event: scan_added and scan_added_empty"},{"content":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool. If the repository of the source code is specified in the Engagement, DefectDojo will present the filepath as a link and the user can navigate directly to the location of the vulnerability.\nSetting the repository in the Engagement and Test Engagement While editing the Engagement, users can set the URL of the specific SCM repo. For Interactive Engagement it needs to be the URL including the branch:\nfor GitHub - like https://github.com/DefectDojo/django-DefectDojo/tree/dev for GitLab - like https://gitlab.com/gitlab-org/gitlab/-/tree/master for public BitBucket - like (like git clone url) for standalone/onpremise BitBucket https://bb.example.com/scm/some-project/some-repo.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url) For CI/CD Engagement, where user could set commit hash, branch/tag and code line it should look like examples below:\nfor GitHub - like https://github.com/DefectDojo/django-DefectDojo for GitLab - like https://gitlab.com/gitlab-org/gitlab for public BitBucket, Gitea and Codeberg - like https://bitbucket.org/some-user/some-project.git (like git clone url) for standalone/onpremise BitBucket https://bb.example.com/scm/some-project.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url) If user does not set commit hash or branch/tag in appropriate fields of CI/CD Engagement edit form, the URL should look like in Interactive Engagement edit form.\nSCM navigation URL is composed from Repo URL using SCM Type. Github/Gitlab SCM type is default, but user could set certain SCM type in Product custom field \u0026ldquo;scm-type\u0026rdquo;.\nProduct custom fields:\nProduct SCM type add:\nPossible SCM types could be \u0026lsquo;github\u0026rsquo;, \u0026lsquo;gitlab\u0026rsquo;, \u0026lsquo;bitbucket\u0026rsquo;, \u0026lsquo;bitbucket-standalone\u0026rsquo;, \u0026lsquo;gitea\u0026rsquo;, \u0026lsquo;codeberg\u0026rsquo; or nothing (for default github).\nLink in Finding When viewing a finding, the location will be presented as a link, if the repository of the source code has been set in the Engagement:\nClicking on this link will open a new tab in the browser, with the source file of the vulnerability at the corresponding line number:\n","date":"0001-01-01","id":97,"permalink":"/en/open_source/archived_docs/integrations/source-code-repositories/","summary":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool.","tags":[],"title":"Source code repositories"},{"content":"Demo Try out the demo sever at demo.defectdojo.org\nLog in with admin / 1Defectdojo@demo#appsec. Please note that the demo is publicly accessable and regularly reset. Do not put sensitive data in the demo.\n","date":"0001-01-01","id":98,"permalink":"/en/open_source/installation/demo/","summary":"Demo Try out the demo sever at demo.defectdojo.org\nLog in with admin / 1Defectdojo@demo#appsec. Please note that the demo is publicly accessable and regularly reset.","tags":[],"title":"Demo"},{"content":"Notifications DefectDojo can inform you of different events in a variety of ways. You can be notified about things like an upcoming engagement, when someone mentions you in a comment, a scheduled report has finished generating, and more.\nThe following notification methods currently exist:\nEmail Slack Microsoft Teams Webhooks Alerts within DefectDojo (default) You can set these notifications on a global scope (if you have administrator rights) or on a personal scope. For instance, an administrator might want notifications of all upcoming engagements sent to a certain Slack channel, whereas an individual user wants email notifications to be sent to the user's specified email address when a report has finished generating.\nUsers can define notifications on a product level as well, and these settings will be applied only for selected products.\nIn order to identify and notify you about things like upcoming engagements, DefectDojo runs scheduled tasks for this purpose. These tasks are scheduled and run using Celery beat, so this needs to run for those notifications to work.\nDefectDojo allows template to be used, administrator can use this feature to define which notification should be received by newly created users.\nSlack Basic Integration This method will allow DefectDojo to send Global notifications to a Slack channel. It can also send Personal notifications to an individual user\u0026rsquo;s Slackbot.\nTo configure Slack messaging, you will first need to create a new Slack app at https://api.slack.com/apps.\nThis app can be created from scratch, or from a JSON manifest which includes all necessary scopes and bot functionality. This manifest can be copied and pasted into the Slack App wizard when you select \u0026lsquo;Build From Manifest\u0026rsquo;.\nJSON Manifest { \u0026#34;_metadata\u0026#34;: { \u0026#34;major_version\u0026#34;: 1, \u0026#34;minor_version\u0026#34;: 1 }, \u0026#34;display_information\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;DefectDojo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Notifications from DefectDojo\u0026#34;, \u0026#34;background_color\u0026#34;: \u0026#34;#0000AA\u0026#34; }, \u0026#34;features\u0026#34;: { \u0026#34;bot_user\u0026#34;: { \u0026#34;display_name\u0026#34;: \u0026#34;DefectDojo Notifications\u0026#34; } }, \u0026#34;oauth_config\u0026#34;: { \u0026#34;scopes\u0026#34;: { \u0026#34;bot\u0026#34;: [ \u0026#34;chat:write\u0026#34;, \u0026#34;chat:write.customize\u0026#34;, \u0026#34;chat:write.public\u0026#34;, \u0026#34;incoming-webhook\u0026#34;, \u0026#34;users:read\u0026#34;, \u0026#34;users:read.email\u0026#34; ] }, \u0026#34;redirect_urls\u0026#34;: [ \u0026#34;https://slack.com/oauth/v2/authorize\u0026#34; ] } }\rChoose the channel where you want to post Global notifications during the \u0026lsquo;Create From Manifest\u0026rsquo; process. Personal notifications will appear in a user\u0026rsquo;s Slackbot if they have their Slack Email Address specified on their user profile.\nScopes The following scopes have to be granted to your Slack App. If the App was created from the JSON Manifest above, these permission scopes will already be set correctly.\nToken The Slack Bot Token needs to be pasted in the DefectDojo System Settings, nested underneath the \u0026lsquo;Enable slack notifications\u0026rsquo; checkbox. This token can be found in the Features / OAuth \u0026amp; Permissions section on the Slack App settings.\nExamples of Slack notifications Microsoft Teams Microsoft Teams does not provide an easy way to send messages to a personal channel. Therefore, DefectDojo can only send system scope notifications to Microsoft Teams.\nTo activate notifications to Microsoft Teams, you have to:\nConfigure an Incoming Webhook in a Teams channel and copy the URL of the webhook to the clipboard Activate Enable Microsoft Teams notifications in the System Settings Paste the URL of the Incoming Webhook into the field Msteams url Specific overrides System notification settings (scope: system) describe the sending of notifications to superadmins. User notification settings (scope: personal) describe sending notifications to the specific user.\nHowever, there is a specific use-case when the user decides to disable notifications (to decrease noise) but the system setting is used to override this behavior. These overrides apply only to user_mentioned and review_requested by default.\nThe scope of this setting is customizable (see environmental variable DD_NOTIFICATIONS_SYSTEM_LEVEL_TRUMP).\nFor more information about this behavior see the related pull request #9699\nWebhooks (experimental) DefectDojo also supports webhooks that follow the same events as other notifications (you can be notified in the same situations). Details about setup are described in related page.\n","date":"0001-01-01","id":99,"permalink":"/en/open_source/archived_docs/notifications/","summary":"Notifications DefectDojo can inform you of different events in a variety of ways. You can be notified about things like an upcoming engagement, when someone mentions you in a comment, a scheduled report has finished generating, and more.","tags":[],"title":"Notifications"},{"content":"","date":"2023-09-07","id":100,"permalink":"/en/dashboard/","summary":"","tags":[],"title":"Set Up Your Dashboard"},{"content":"Webhooks are HTTP requests coming from the DefectDojo instance towards a user-defined webserver which expects this kind of incoming traffic.\nTransition graph: It is not unusual that in some cases a webhook can not be delivered. It is usually connected to network issues, server misconfiguration, or running upgrades on the server. DefectDojo needs to react to these outages. It might temporarily or permanently disable related endpoints. The following graph shows how it might change the status of the webhook definition based on HTTP responses (or manual user interaction).\nflowchart TD START{{Endpoint created}} ALL{All states} STATUS_ACTIVE([STATUS_ACTIVE]) STATUS_INACTIVE_TMP STATUS_INACTIVE_PERMANENT STATUS_ACTIVE_TMP([STATUS_ACTIVE_TMP]) END{{Endpoint removed}} START ==\u003e STATUS_ACTIVE STATUS_ACTIVE --HTTP 200 or 201 --\u003e STATUS_ACTIVE STATUS_ACTIVE --HTTP 5xx or HTTP 429 or Timeout--\u003e STATUS_INACTIVE_TMP STATUS_ACTIVE --Any HTTP 4xx response\nor any other HTTP response\nor non-HTTP error--\u003e STATUS_INACTIVE_PERMANENT STATUS_INACTIVE_TMP -.After 60s.-\u003e STATUS_ACTIVE_TMP STATUS_ACTIVE_TMP --HTTP 5xx or HTTP 429 or Timeout within 24h\nfrom the first error--\u003eSTATUS_INACTIVE_TMP STATUS_ACTIVE_TMP -.After 24h.-\u003e STATUS_ACTIVE STATUS_ACTIVE_TMP --HTTP 200 or 201 --\u003e STATUS_ACTIVE_TMP STATUS_ACTIVE_TMP --HTTP 5xx or HTTP 429 or Timeout within 24h from the first error\nor any other HTTP response or error--\u003e STATUS_INACTIVE_PERMANENT ALL ==Activation by user==\u003e STATUS_ACTIVE ALL ==Deactivation by user==\u003e STATUS_INACTIVE_PERMANENT ALL ==Removal of endpoint by user==\u003e END\rNotes:\nTransitions: bold: manual changes by user dotted: automated by celery others: based on responses on webhooks Nodes: Stadium-shaped: Active - following webhook can be sent Rectangles: Inactive - performing of webhook will fail (and not retried) Hexagonal: Initial and final states Rhombus: All states (meta node to make the graph more readable) Body and Headers The body of each request is JSON which contains data about related events like names and IDs of affected elements. Examples of bodies are on pages related to each event (see below).\nEach request contains the following headers. They might be useful for better handling of events by the server receiving them.\nUser-Agent: DefectDojo-\u0026lt;version of DD\u0026gt; X-DefectDojo-Event: \u0026lt;name of the event\u0026gt; X-DefectDojo-Instance: \u0026lt;Base URL for DD instance\u0026gt;\rDisclaimer This functionality is new and in experimental mode. This means functionality might generate breaking changes in following DefectDojo releases and might not be considered final.\nHowever, the community is open to feedback to make this functionality better and get it stable as soon as possible.\nRoadmap There are a couple of known issues that are expected to be resolved as soon as core functionality is considered ready.\nSupport events - Not only adding products, product types, engagements, tests, or upload of new scans but also events around SLA User webhook - right now only admins can define webhooks; in the future, users will also be able to define their own Improvement in UI - add filtering and pagination of webhook endpoints Events ","date":"0001-01-01","id":101,"permalink":"/en/open_source/notification_webhooks/","summary":"Webhooks are HTTP requests coming from the DefectDojo instance towards a user-defined webserver which expects this kind of incoming traffic.","tags":[],"title":"Notification Webhooks (experimental)"},{"content":"","date":"2023-09-07","id":102,"permalink":"/en/notifications/","summary":"","tags":[],"title":"Set Up Notifications"},{"content":"","date":"2021-02-02","id":103,"permalink":"/en/working_with_findings/","summary":"","tags":[],"title":"Working With Findings"},{"content":"Please note - the Google Sheets feature has been deprecated as of DefectDojo version 2.21.0 - these documents are for reference only.\nWith the Google Sheets sync feature, DefectDojo allow the users to export all the finding details of each test into a separate Google Spreadsheet. Users can review and edit finding details via Google Spreadsheets. Also, they can add new notes to findings and edit existing notes using the Google Spreadsheet. After reviewing and updating the finding details in the Google Spreadsheet, the user can import (sync) all the changes done via the Google Spreadsheet into DefectDojo database.\nConfiguration Creating a project and a Service Account\nGo to the Service Accounts page. Create a new project for DefectDojo and select it. Click +CREATE SERVICE ACCOUNT, enter a name and description for the service account. You can use the default service account ID, or choose a different, unique one. When done click Create. The Service account permissions (optional) section that follows is not required. Click Continue. On the Grant users access to this service account screen, scroll down to the Create key section. Click +Create key. In the side panel that appears, select the format for your key as JSON Click Create. Your new public/private key pair is generated and downloaded to your machine. Enabling the required APIs\nGo to the Google API Console. From the projects list, select the project created for DefectDojo. If the APIs \u0026amp; services page isn't already open, open the console left side menu and select APIs \u0026amp; services, and then select Library. Google Sheets API and Google Drive API should be enabled. Click the API you want to enable. If you need help finding the API, use the search field. Click ENABLE. Configurations in DefectDojo\nClick 'Configuration' from the left hand menu.\nClick 'Google Sheets Sync'.\nFill the form.\nUpload the downloaded json file into the Upload Credentials file field.\nDrive Folder Id:\nCreate a folder inside the Google drive of the same Gmail account used to create the service account.\nGet the client_email from the downloaded json file and share the created drive folder with client_email giving edit access.\nExtract the folder id from the URL and insert it as the Drive Folder Id:\nTick the Enable Service check box. (Optional as this has no impact on the configuration, but you must set it to true inorder to use the feature. Service can be enabled or disabled at any point after the configuration using this check box)\nFor each field in the finding table there are two related entries in the form:\nIn the drop down, select Hide if the column needs to be hidden in the Google Sheet, else select any other option based on the length of the entry that goes under the column. If the column needs to be protected in the Google Sheet, tick the check box. Otherwise leave it unchecked. Click 'Submit'.\nAdmin has the privilege to revoke the access given to DefectDojo to access Google Sheets and Google Drive data by simply clicking the Revoke Access button.\nUsing Google Sheets Sync Feature Before a user can export a test to a Google Spreadsheet, admin must Configure Google Sheets Sync and Enable sync feature.Depending on whether a Google Spreadsheet exists for the test or not, the User interface displayed will be different.\nIf a Google Spreadsheet does not exist for the Test:\nIf a Google Spreadsheet is already created for the Test:\nAfter creating a Google Spreadsheet, users can review and edit Finding details using the Google Sheet. If any change is done in the Google Sheet users can click the Sync Google Sheet button to get those changes into DefectDojo.\n","date":"0001-01-01","id":104,"permalink":"/en/open_source/archived_docs/google-sheets-sync/","summary":"Please note - the Google Sheets feature has been deprecated as of DefectDojo version 2.21.0 - these documents are for reference only.","tags":[],"title":"Google Sheets synchronisation"},{"content":"","date":"2023-09-07","id":105,"permalink":"/en/pro_reports/","summary":"","tags":[],"title":"Create A Report"},{"content":"Please note: The DefectDojo Burp Plugin has been sunset and is no longer a supported feature.\nBurp is still a supported tool, and all the results from it can be imported into DefectDojo. Burp can produce XML reports and these can be uploaded to DefectDojo using the graphical user interface or the API. Our documentation at https://documentation.defectdojo.com/integrations/parsers/file/burp/ describes this usage.\nThis is Burp Plugin to export findings directly to DefectDojo.\nInstallation In order for the plugin to work , you will need to have Jython set up in Burp Suite Pro . To use this plugin before it appears in the BApp Store you will need to do the following :\nGo to Extender and select the Extensions tab Click on Add , select Extension Type: to be Python and select the DefectDojoPlugin.py Usage ","date":"0001-01-01","id":106,"permalink":"/en/open_source/archived_docs/burp-plugin/","summary":"Please note: The DefectDojo Burp Plugin has been sunset and is no longer a supported feature.\nBurp is still a supported tool, and all the results from it can be imported into DefectDojo.","tags":[],"title":"Defect Dojo Burp plugin"},{"content":"Import of languages for a project You can import JSON reports generated by the cloc tool via the API:\nWhen importing a file, all language information for the respective project will be deleted first and then populated with the content of the file. Please make sure to use the --json parameter when invoking the cloc command, to get the correct file format.\nDisplay The results of the import are shown on the left side of the product details page.\nThe colors are defined by entries in the table Language_Type, which has been prepopulated with data from GitHub.\nImport of language types GitHub updates its language colors from time to time, when new languages emerge. The management command\n./manage.py import_github_languages\nreads data from a JSON file hosted in https://github.com/ozh/github-colors to add new languages and update colors.\n","date":"0001-01-01","id":107,"permalink":"/en/open_source/languages/","summary":"Import of languages for a project You can import JSON reports generated by the cloc tool via the API:\nWhen importing a file, all language information for the respective project will be deleted first and then populated with the content of the file.","tags":[],"title":"Languages and lines of code"},{"content":"DefectDojo has protection against brute force attacks through rate limiting\nConfiguration For further information, please visit the package documentation Django Ratelimit\nEnable Rate Limiting To enable and configure rate limiting, edit the settings (see Configuration and edit/replace the following information:\nDD_RATE_LIMITER_ENABLED=(bool, True), DD_RATE_LIMITER_RATE=(str, \u0026#39;5/m\u0026#39;), DD_RATE_LIMITER_BLOCK=(bool, True), DD_RATE_LIMITER_ACCOUNT_LOCKOUT=(bool, True), Rate Limit The frequency at which the request will be limited can be set to\nseconds - 1s minutes - 5m hours - 100h days - 2400d Extended configuration can be found here\nBlock Requests By default, rate limiting is set to record offenses, but does not actually block requests and enforce the limit.\nSetting DD_RATE_LIMITER_BLOCK will block all incoming requests at the configured frequncy once that frequency has been exceeded.\nAccount Lockout In the event of a brute force attack, a users credentials could potentially be comprimised.\nIn an attempt to circumvent that event, setting DD_RATE_LIMITER_ACCOUNT_LOCKOUT will force a user to reset their password upon the next attempted login.\nMulti-Process Behavior When using configurations with multiple uwsgi processes, the rate limiting package uses the default cache that is memory based and local to a process.\nExtra Configuation For further information, please visit the package documentation Django Ratelimit\n","date":"0001-01-01","id":108,"permalink":"/en/open_source/rate_limiting/","summary":"DefectDojo has protection against brute force attacks through rate limiting\nConfiguration For further information, please visit the package documentation Django Ratelimit","tags":[],"title":"Rate Limiting"},{"content":"Export Findings Pages that show a list of findings or a list of engagements have a CSV and Excel Export functionality in the top right dropdown menu.\nThe list of engagements can be exported as CSV/Excel.\n","date":"0001-01-01","id":109,"permalink":"/en/open_source/exporting/","summary":"Export Findings Pages that show a list of findings or a list of engagements have a CSV and Excel Export functionality in the top right dropdown menu.","tags":[],"title":"Exporting"},{"content":"","date":"2023-09-07","id":110,"permalink":"/en/api/","summary":"","tags":[],"title":"API Documentation"},{"content":"","date":"2023-09-07","id":111,"permalink":"/en/changelog/","summary":"","tags":[],"title":"Changelog"},{"content":"","date":"2023-09-07","id":112,"permalink":"/en/open_source/archived_docs/","summary":"","tags":[],"title":"Archived Documentation"},{"content":"","date":"2023-09-07","id":113,"permalink":"/en/open_source/","summary":"","tags":[],"title":"Open Source DefectDojo"},{"content":"","date":"2023-09-07","id":114,"permalink":"/","summary":"","tags":[],"title":"DefectDojo Documentation"},{"content":"","date":"2021-02-02","id":115,"permalink":"/en/working_with_findings/finding_deduplication/","summary":"","tags":[],"title":"Finding Deduplication"},{"content":"","date":"2021-02-02","id":116,"permalink":"/en/working_with_findings/findings_workflows/","summary":"","tags":[],"title":"Findings Workflows"},{"content":"","date":"2021-02-02","id":117,"permalink":"/en/","summary":"","tags":[],"title":"Index"},{"content":"","date":"2021-02-02","id":118,"permalink":"/en/working_with_findings/organizing_engagements_tests/","summary":"","tags":[],"title":"Organizing Engagements and Tests"},{"content":"Once you have a Connector set up, you can start making decisions about how data will flow from the tool into DefectDojo. This is managed through the Discovery process.\nYou can manage all of these processes from the Manage Records \u0026amp; Operations page. From the API Connectors page, click the drop-down menu on the Connector you wish to work with, and select Manage Records \u0026amp; Operations.\nCreating New Records The first step a DefectDojo Connector needs to take is to Discover your tool\u0026rsquo;s environment to see how you\u0026rsquo;re organizing your scan data.\nLet\u0026rsquo;s say you have a BurpSuite tool, which is set up to scan five different repositories for vulnerabilities. Your Connector will take note of this organizational structure and set up Records to help you translate those separate repositories into DefectDojos Product/Engagement/Test hierarchy.\nEach time your Connector runs a Discover operation, it will look for new Vendor-Equivalent-Products (VEPs). DefectDojo looks at the way the Vendor tool is set up and will create Records of VEPs based on how your tool is organized.\nRun Discover Manually Discover operations will automatically run on a regular basis, but they can also be run manually. If you\u0026rsquo;re setting up this Connector for the first time, you can click the Discover button next to the Unmapped Records header. After you refresh the page, you will see your initial list of Records.\nNext Steps: Learn how to manage the Records discovered by a Connector, and start importing data. If your Records have already been mapped (such as through Auto-Map Records), learn how to import data via Sync operations. ","date":"0001-01-01","id":119,"permalink":"/en/connecting_your_tools/connectors/operations_discover/","summary":"Once you have a Connector set up, you can start making decisions about how data will flow from the tool into DefectDojo.","tags":[],"title":"'Discover' Operations"},{"content":"The primary â€˜Jobâ€™ of a DefectDojo Connector is to import data from a security tool, and this process is handled by the Sync Operation.\nOn a daily basis, DefectDojo will look at each Mapped Record for new scan data. DefectDojo will then run a Reimport, which compares the state of each scan.\nThe Sync Process Where is my vulnerability data stored? DefectDojo will create an Engagement nested under the Product specified in the Record Mapping. This Engagement will be called Global Connectors. The Global Connectors Engagement will track each separate Connection associated with the Product as a Test. On this sync, and each subsequent sync, the Test will store each vulnerability found by the tool as a Finding. How Sync handles new vulnerability data Whenever Sync runs, it will compare the latest scan data against the existing list of Findings for changes.\nIf there are new Findings detected, they will be added to the Test as new Findings. If there are any Findings which arenâ€™t detected in the latest scan, they will be marked as Inactive in the Test. To learn more about Products, Engagements, Tests and Findings, see our Core Data Classes Overview.\nRunning Sync Manually To have DefectDojo run a Sync operation off-schedule:\nNavigate to the Manage Records \u0026amp; Operations page for the connector you want to use. From the API Connectors page, click the drop-down menu on the Connector you wish to work with, and select Manage Records \u0026amp; Operations.\nâ€‹ From this page, click the Sync button. This button is located next to the Mapped Records header. Next Steps Learn how to set up the flow of data into DefectDojo through a Discover operation. Adjust the schedule of your Sync and Discover operations by Editing a Connector. Learn about Engagements, Tests and Findings with our guide to Core Data Classes. ","date":"0001-01-01","id":120,"permalink":"/en/connecting_your_tools/connectors/operations_sync/","summary":"The primary â€˜Jobâ€™ of a DefectDojo Connector is to import data from a security tool, and this process is handled by the Sync Operation.","tags":[],"title":"'Sync' Operations"},{"content":"Dashboard Tiles are customizable sets of filters for your DefectDojo instance, which can be added to your ðŸ  Home dashboard. Tiles are designed to provide relevant information and speed up navigation within DefectDojo.\nTiles can:\nAct as shortcuts for particular sets of Findings, Products, or other objects Visualize relevant metrics related to your Product Provide alerts on particular activity, track SLA Violations, failing imports or new Critical Findings Tile Components Each Tile contains four main components:\n1. A customizable icon. You can choose an icon and color for the Tile. If you wish, you can also have an iconâ€™s color dynamically change from Green -\u0026gt; Yellow -\u0026gt; Red based on a value range. 2. A count of each object that meets the Tileâ€™s filter conditions. For example, a Findings Tile will count the number of Findings filtered by the Tile. 3. A customizable Header which can be set to describe the function of the tile. 4. A customizable Footer which brings you to the related list of objects. For example, a Findings Tileâ€™s footer will bring you to a list of Findings filtered by the Tile.\nTypes of Dashboard Tiles There are eight Tiles which you can choose from. These Tiles are explained in more detail below, along with examples of usage.\nProduct Tile Engagement Tile Test Tile Endpoint Tile SLA Violation Tile Scan Time Violation Tile Product Grade Tile Product, Engagement or Test Tile These Tiles allow you to quickly select a list of Products, Engagements or Tests based on the filter parameters you set. You can use this tile for ease in navigation.\nThe number on the tile represents the count of objects (Products, Engagement or Tests) contained within the tileâ€™s filter parameters. Clicking the footer will take you to a filtered list of those objects.\nExample: Monitoring Engagements In Progress If you want to create a list of your In-Progress Engagements in DefectDojo, you can set up an Engagement tile which filters for that condition.\nCreate an Engagement tile, and from the Tile Filters set Engagement Status to In Progress. To make sure your Tile is accurately labeled, set the Header of your tile to â€˜Engagements In Progressâ€™. You could also create Engagement tiles for one or more other states, such as Blocked or Completed.\nFinding Tiles Finding tiles provide a count of Findings based on the filter parameters you set. As with other tiles, clicking the Footer will take you to a list of the Findings set by the tile.\nUsing filter parameters you can track Findings in a particular state or time period.\nExample: Monitoring Critical Findings If you wanted to be able to quickly access all of your Critical Findings in DefectDojo, you could do this by creating a tile.\nCreate a Finding tile, and from the Tile Filters set Severity to Critical. To make sure your Tile is accurately labeled, set the Header of the tile to â€˜Critical Findingsâ€™. You can add additional filter parameters to make this tile more functional for your use-case. For example, if you wanted this tile to only track Open Findings (and ignore any Mitigated Findings) you could set the Active filter to Yes.\nEndpoint Tiles If you need to keep track of particular Endpoints, you can set up a Tile to quickly navigate to a filtered list. This tile can be set up to filter by Host, Product, Tags or other parameters that are relevant to the Endpoints you want to track.\nClicking the footer on this tile brings us to a filtered list of Endpoints which displays their status. DefectDojo will only create and track Endpoints with related vulnerabilities, so this will not include any Endpoints which have no vulnerabilities reported.\nExample: Monitor All Endpoints With Same Host If you wanted to use Endpoints to look at vulnerabilities on a certain part of your architecture, regardless of the associated Product, you could use an Endpoint Tile to filter for a particular URL. From there, you could see all Findings associated with that part of your network.\nCreate an Endpoint tile. For this example, we are setting the Host Contains field to â€˜centralaction-itemsâ€™, as that string is part of many Endpoint URLs in our infrastructure.â€‹ Set your Header to a title which describes the intended function of your tile. In this example, we used â€˜Host: centralaction-itemsâ€™. SLA Violation Tile This Tile counts Findings which are at risk of violating SLA. It can be set to track all Products, or specific Products chosen from a list.\nExample: Findings Approaching SLA Violation If you want to create a filter for Findings which are within 7 days of SLA expiration, you can set up your filter parameters to track this. When setting the Filter parameters for the SLA Violation tile, set â€˜Days Before Expirationâ€™ to 7. Select either All Products, or a list of specific Products.\nSet the Header to describe the filter youâ€™re applying, for example â€˜SLA Violation - 3 Days Or Lessâ€™.\nClicking on the footer will bring you to a list of these Findings for you to address. This tile only tracks Active Findings, but will also track Findings with an expired SLA.\nScan Time Violation Tile This Tile is used to track specific Products to ensure that new scan data is being added on a regular basis.\nIf there are particular Products which youâ€™re scanning on a regular interval, you can use this tile to ensure your tools and imports are running as expected.\nThis Tile will return a count and related list of Products which have not had new scan data added in the interval youâ€™ve defined.\nExample: Automation Tracking If you have scanning tools set to run on a weekly basis, you can use this tile to make sure those automated processes are working correctly.\nFrom the Tile filters, select the target Products where the scan data will be imported via automation. Set the Days Since Last Scan field to â€˜Past Weekâ€™. Set a descriptive name in the Header which communicates the interval youâ€™re testing. If you have multiple scanning intervals that you want to monitor, you can set up multiple tiles to track each one.\nProduct Grade Title This Tile compares the Product Grade of all Products on your instance, so that you can track any Products which do not meet your grading standard.\nThis tile uses a comparison operator (\u0026lt;, =, \u0026lt;=, \u0026gt;=) to track Products which equal, exceed or fail to meet the Product Grade which you want to monitor.\nFor more information on how Product Grades are calculated, see our article on Product Health Grading.\nExample: Track Failing Products If you want to quickly access Products in your instance which do not meet your Grading standard, you can set up a Tile which handles that calculation. The Grading standard used in this example is â€˜Less Than Câ€™: we want our tile to flag any Products with a Grade of D or lower.\nCreate a Product Grade Tile. From the Filters list, set the Grade which you consider â€˜failingâ€™. In this case weâ€™ll select C. In the Filters list, set a Comparison Operator to determine the logic used in counting your failing Products. In this case, weâ€™ll select â€˜Less Thanâ€™. As with other Product related Tiles, you can set the Tile to look at All Products in your instance, or only a specific list of Products.\nNext Steps: Learn how to Add, Edit or Delete your Dashboard Tiles. For more detailed descriptions of Tile Filters, see our Tile Filter Index. ","date":"0001-01-01","id":121,"permalink":"/en/dashboard/about-custom-dashboard-tiles/","summary":"Dashboard Tiles are customizable sets of filters for your DefectDojo instance, which can be added to your ðŸ  Home dashboard. Tiles are designed to provide relevant information and speed up navigation within DefectDojo.","tags":[],"title":"About Custom Dashboard Tiles"},{"content":"DefectDojo is designed to ingest bulk reports from tools, creating one or more Findings based on the content of the report. When using DefectDojo, youâ€™ll most likely be ingesting reports from the same tool on a regular basis, which means that duplicate Findings are highly likely.\nThis is where Deduplication comes in, a Smart feature which you can set up to automatically manage duplicate Findings.\nHow DefectDojo handles duplicates First, you import Test 1. Your report contains a vulnerability which is recorded as Finding A. Later, you import Test 2 which contains the same vulnerability. This will be recorded as Finding B, and Finding B will be marked as a duplicate of Finding A. Later still, you import Test 3 which also contains that vulnerability. This will be recorded as Finding C, which will be marked as a duplicate of Finding A. By creating and marking Duplicates in this way, DefectDojo ensures that all the work for the â€˜originalâ€™ vulnerability is centralized on the original Finding page, without creating separate contexts, or giving your team the impression that there are multiple separate vulnerabilities which need to be addressed.\nBy default, these Tests would need to be nested under the same Product for Deduplication to be applied. If you wish, you can further limit the Deduplication scope to a single Engagement.\nDuplicate Findings are set as Inactive by default. This does not mean the Duplicate Finding itself is Inactive. Rather, this is so that your team only has a single active Finding to work on and remediate, with the implication being that once the original Finding is Mitigated, the Duplicates will also be Mitigated.\nDeduplication vs Reimport Deduplication and Reimport are similar processes but they have a key difference:\nWhen you Reimport to a Test, the Reimport process looks at incoming Findings, filters and discards any matches. Those matches will never be created as Findings or Finding Duplicates. Deduplication is applied \u0026lsquo;passively\u0026rsquo; on Findings that have already been created. It will identify duplicates in scope and label them, but it will not delete or discard the Finding unless \u0026lsquo;Delete Deduplicate Findings\u0026rsquo; is enabled. The \u0026lsquo;reimport\u0026rsquo; action of discarding a Finding always happens before deduplication; DefectDojo cannot deduplicate Findings that are never created as a result of Reimport\u0026rsquo;s filtering. When are duplicates appropriate? Duplicates are useful when youâ€™re dealing with shared, but discrete Testing contexts. For example, if your Product is uploading Test results for two different repositories, which need to be compared, itâ€™s useful to know which vulnerabilities are shared across those repositories.\nHowever, if DefectDojo is creating excess duplicates, this can also be a sign that you need to adjust your import processes.\nWhat do my duplicates indicate? The same vulnerability, but found in a different context: this is the appropriate way to use Duplicate Findings. If you have many components which are affected by the same vulnerability, you would likely want to know which components are affected to understand the scope of the problem.\nâ€‹ The same vulnerability, found in the same context: better options exist for this case. If the Duplicate Finding does not give you any new context on the vulnerability, or if you find yourself frequently ignoring or deleting your duplicate Findings, this is a sign that your process can be improved. For example, Reimport allows you to effectively manage incoming reports from a CI/CD pipeline. Rather than create a completely new Finding object for each duplicate, Reimport will make a note of the incoming duplicate without creating the Duplicate Finding at all. Next Steps: Enable and configure Deduplication from the System Settings page. Brush up on DefectDojoâ€™s Product and Engagement data models to make sure that your environment is optimized for deduplication. Learn how to manage excess duplicates with the Delete Deduplicate Findings option. ","date":"0001-01-01","id":122,"permalink":"/en/working_with_findings/finding_deduplication/about-deduplication/","summary":"DefectDojo is designed to ingest bulk reports from tools, creating one or more Findings based on the content of the report.","tags":[],"title":"About Deduplication"},{"content":"DefectDojoâ€™s Alerts system keeps you up to date with all Product or system activity.\nThe Alerts List The Alerts List is always visible in the top-right hand corner of DefectDojo, and contains a compact list of notifications. Clicking on each Alert will take you directly to the relevant page in DefectDojo.\nYou can open your Alerts List by clicking on the ðŸ””â–¼ icon on the top right hand corner:\n#\nTo see all of your notifications, along with additional detail, you can click the See All Alerts \u0026gt; button, which will open the Alerts Page.\nYou can also Clear All Alerts \u0026gt; from the Alerts List.\nThe Alerts Page The Alerts Page stores all of your Alerts in DefectDojo with additional detail. On this page, you can read descriptions of each Alert in DefectDojo, and remove them from the Alerts queue once you no longer need them.\nTo remove one or more Alerts from the Alerts Page, check the empty box next to it, and then click the Remove selected button in the bottom-right corner of the Page.\nNotes On Alerts Reading an Alert, or opening the Alerts Page will not remove any Alerts from the count next to the bell icon. This is so that you can easily access past alerts to use them as reminders or a personal activity log. Using the Clear All Alerts \u0026gt; function in the Alerts Menu will also completely clear the Alerts Page, so use this feature with care. Removing an Alertonly affects your own Alerts List - it will not affect any other userâ€™s Alerts. Removing an Alert does not remove any import history or activity logs from DefectDojo. ","date":"0001-01-01","id":123,"permalink":"/en/notifications/about-in-app-alerts/","summary":"DefectDojoâ€™s Alerts system keeps you up to date with all Product or system activity.\nThe Alerts List The Alerts List is always visible in the top-right hand corner of DefectDojo, and contains a compact list of notifications.","tags":[],"title":"About In-App Alerts"},{"content":"DefectDojo keeps you up to date in a variety of ways. Notifications can be sent for upcoming Engagements, user Mentions, SLA expiry, and other events in the software.\nThis article contains an overview of notifications at both System-wide and Personal levels.\nNotification Types DefectDojo handles notifications in two different ways::\nSystem-Wide Notifications are sent to all users. Personal Notifications are set by individual users, and will be received in addition to any System-Wide Notifications. In both cases, Role-Based Access Control rules apply, so users will not receive activity notifications for Products or Product Types (or their related objects) which they donâ€™t have access to.\nNotification Delivery Methods There are four delivery methods for DefectDojo notifications:\nDefectDojo can share ðŸ”” Alerts, stored as a list in the DefectDojo interface DefectDojo can send notifications to an Email address DefectDojo can send notifications to Slack, in either a shared or individual channel DefectDojo can also send notifications to Microsoft Teams in a shared channel Notifications can be sent to multiple destinations simultaneously.\nReceiving Slack and Teams notifications will require you to have a working integration. For more info, see our articles:\nSlack Integration Teams Integration Next Steps:\nLearn more about DefectDojo\u0026rsquo;s internal ðŸ”” Alerts Set up a Slack integration for DefectDojo Set up a Teams integration for DefectDojo ","date":"0001-01-01","id":124,"permalink":"/en/notifications/about-notifications/","summary":"DefectDojo keeps you up to date in a variety of ways. Notifications can be sent for upcoming Engagements, user Mentions, SLA expiry, and other events in the software.","tags":[],"title":"About Notifications"},{"content":"If you have a team of users working in DefectDojo, it\u0026rsquo;s important to set up Role-Based Access Control (RBAC) appropriately so that users can only access specific data. Security data is highly sensitive, and DefectDojo\u0026rsquo;s options for access control allow you to be specific about each team memberâ€™s access to information.\nTypes of Permissions DefectDojo manages four different kinds of permissions:\nUsers can be assigned as Members to Products or Product Types. A Product Membership comes with a Role which allows your users to view and interact with Data Types (Product Types, Products, Engagements, Tests and Findings) in DefectDojo. Users can have multiple Product or Product Type memberships, with different levels of access.\nâ€‹ Users can also have Configuration Permissions assigned, which allow them to access configuration pages in DefectDojo. Configuration Permissions are not related to Products or Product Types, and are not associated with Roles.\nâ€‹ Users can be assigned Global Roles, which give them a standardized level of access to all Products and Product Types.\nâ€‹ Users can be set up as Superusers: administrator level roles which give them control and access to all DefectDojo data and configuration. Each of these Permission types can also be assigned to User Group. If you have a large number of users in DefectDojo, such as a dedicated testing team for a particular Product, Groups allow you to set up and maintain permissions quickly.\nProduct/Product Type Membership \u0026amp; Roles When users are assigned as members to a Product or Product Type, they also receive a role which controls how they interact with the associated Finding data.\nRole Summaries Users can be assigned a role of Reader, Writer, Maintainer, Owner or API Importer, either globally or within a Product / Product Type.\nâ€˜Underlying dataâ€™ refers to all Products, Engagements, Tests, Findings or Endpoints nested under a Product, or Product Type.\nReader Users can view underlying data on any Product or Product Type they are assigned to, and add comments. They cannot edit, add or otherwise modify any of the underlying data, but they can export Reports and add Notes to data.\nâ€‹ Writer Users have all Reader abilities, plus the ability to Add or Edit Engagements, Tests and Findings. They cannot add new Products, and they cannot Delete any underlying data.\nâ€‹ Maintainer Users have all Writer abilities, plus the ability to edit Product or Product Types. They can add new Members with Roles to the Product or Product Type, and they can also Delete Engagements, Tests, and Findings.\nâ€‹ Owner Users have the greatest amount of control over a Product or Product Type. They can designate other Owners, and can also Delete the Products or Product Types theyâ€™re assigned to.\nâ€‹ API Importer Users have limited abilities. This Role allows limited API access without exposing the majority of the API endpoints, so is useful for automation or users who are meant to be â€˜externalâ€™ to DefectDojo. They can view underlying data, Add / Edit Engagements, and Import Scan Data. For detailed information on Roles, please see our Role Permission Chart.\nGlobal Roles Users with Global Roles can view and interact with any Data Type (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on their assigned Role.\nGroup Memberships User Groups can be added as Members of a Product or Product Type. Users who are part of the Group will inherit access to all associated Products or Product Types, and will inherit the Role assigned to the Group.\nUsers with multiple roles If a User is assigned as a member of a Product, they are not granted any associated Product Type permissions by default.\nA User\u0026rsquo;s Product Role always supersedes their \u0026lsquo;default\u0026rsquo; Product Type Role.\nâ€‹\nA User\u0026rsquo;s Product / Product Type Role always supersedes their Global Role within the underlying Product or Product Type. For example, if a User has a Product Type Role of Reader, but is also assigned as an Owner on a Product nested under that Product Type, they will have additional Owner permissions added for that Product only.\nâ€‹\nRoles cannot take away permissions, they can only add additional ones. For example, If a User has a Product Type Role or Global Role of Owner, assigning them a Reader role on a particular Product will not take away their Owner permissions on that Product.\nâ€‹\nSuperuser status always supersedes any Roles assigned.\nSuperusers Superusers (Admins) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. They can also change access rules for all users in DefectDojo. Superusers will also receive notifications for all system issues and alerts.\nBy default, the first account created on a new DefectDojo instance will have Superuser permissions. That user will be able to edit permissions for all subsequent DefectDojo users. Only an existing Superuser can add another superuser, or add a Global Role to a user.\nConfiguration Permissions Configuration Permissions, although similar, are not related to Products or Roles. They must be assigned separately from Roles. Regular users do not have any Configuration Permissions by default, and assigning these configuration permissions should be done carefully.\nUsers can have Configuration Permissions assigned in different ways:\nUsers can be assigned Configuration Permissions directly. Specific permissions can be configured directly on a User page.\nâ€‹ User Groups can be assigned Configuration Permissions. As with Roles, specific Configuration Permissions can be added to Groups, which will give all Group members these permissions. Superusers have all Configuration Permissions, so they do not have a Configuration Permission section on their User page.\nGroup Configuration Permissions If users are part of a Group, they also have Group Configuration Permissions which control their level of access to a Groupâ€™s configuration. Group Permissions do not correspond to the Groupâ€™s Product or Product Type membership.\nIf users create a new Group, they will be given the Owner role of the new Group by default.\nFor more information on Configuration Permissions, see our Configuration Permissions Chart.\n","date":"0001-01-01","id":125,"permalink":"/en/user_management/about-permissions--roles/","summary":"If you have a team of users working in DefectDojo, it\u0026rsquo;s important to set up Role-Based Access Control (RBAC) appropriately so that users can only access specific data.","tags":[],"title":"About Permissions \u0026 Roles"},{"content":"This parser imports the Acunetix Scanner with xml output or Acunetix 360 Scanner with JSON output.\nSample Scan Data Sample Acunetix Scanner scans can be found here.\n","date":"0001-01-01","id":126,"permalink":"/en/connecting_your_tools/parsers/file/acunetix/","summary":"This parser imports the Acunetix Scanner with xml output or Acunetix 360 Scanner with JSON output.\nSample Scan Data Sample Acunetix Scanner scans can be found here.","tags":[],"title":"Acunetix Scanner"},{"content":"If you haven\u0026rsquo;t already set up DefectDojo\u0026rsquo;s Jira Configuration, you\u0026rsquo;ll need to start by linking one or more Jira instances to DefectDojo.\nâ€‹\nSee this guide for more information: https://support.defectdojo.com/en/articles/8766815-connect-defectdojo-to-jira\nOnce a Jira configuration is connected to a Product, Jira and the Product will communicate to do the following:\nUse DefectDojo Findings to create Jira Issues, which automatically contain all relevant Finding information and links Bidirectional Sync, allowing for status updates and comments to be created on both the Jira and DefectDojo side. Adding a Jira Configuration to a Product Each Product in DefectDojo has its own settings which govern how Findings are converted to JIRA Issues. From here, you can decide the associated JIRA Project and set the default behaviour for creating Issues, Epics, Labels and other JIRA metadata.\nIn the UI, you can find this page by clicking the \u0026quot; ðŸ“ Edit\u0026quot; button under Settings on the Product page (defectdojo.com/product/{id}) - see below.\nâ€‹ You can link to a Product Settings page directly via **yourcompany.**defectdojo.com/product/{id}/settings.â€‹ List of Jira Settings Jira settings are located near the bottom of the Product Settings page.\nJira Instance If you have multiple instances of Jira set up, for separate products or teams within your organization, you can indicate which Jira Project you want DefectDojo to create Issues in. Select a Project from the drop-down menu.\nIf this menu doesn\u0026rsquo;t list any Jira instances, confirm that those Projects are connected in your global Jira Configuration for DefectDojo - yourcompany.defectdojo.com/jira.\nProject key This is the Jira Key that you want to use for DefectDojo-related Issues. You can set this Key to whatever you prefer for identifying DefectDojo Issues (e.g. if you set this key to â€œDEFâ€ then Jira issues will be keyed as DEF-1, DEF-2.. etc).\nIssue template Here you can determine how much DefectDojo metadata you want to send to Jira. Select one of two options:\njira_full: Issues will track all of the parameters from DefectDojo - a full Description, CVE, Severity, etc. Useful if you need complete Finding context in Jira (for example, if someone is working on this Issue who doesn\u0026rsquo;t have access to DefectDojo).\nHere is an example of a jira_full Issue:\nâ€‹ Jira_limited: Issues will only track the DefectDojo link, the Product/Engagement/Test links, the Reporter and Environment fields. All other fields are tracked in DefectDojo only. Useful if you don\u0026rsquo;t require full Finding context in Jira (for example, if someone is working on this Issue who mainly works in DefectDojo, and doesn\u0026rsquo;t need the full picture in JIRA as well.)\nâ€‹\nâ€‹**Here is an example of a jira_limited Issue:**â€‹ Component If you manage your Jira project using Components, you can assign the appropriate Component for DefectDojo here.\nCustom fields\nIf you donâ€™t need to use Custom Fields with DefectDojo issues, you can leave this field as â€˜nullâ€™.\nHowever, if your Jira Project Settings require you to use Custom Fields on new Issues, you will need to hard-code these mappings.\nJira Cloud now allows you to create a default Custom Field value directly in-app. See Atlassian\u0026rsquo;s documentation on Custom Fields for more information on how to configure this.\nNote that DefectDojo cannot send any Issue-specific metadata as Custom Fields, only a default value. This section should only be set up if your JIRA Project requires that these Custom Fields exist in every Issue in your project.\nFollow this guide to get started working with Custom Fields.\nJira labels\nSelect the relevant labels that you want the Issue to be created with in Jira, e.g. DefectDojo, YourProductName..\nDefault assignee The name of the default assignee in Jira. If left blank, DefectDojo will follow the default behaviour in your Jira Project when creating Issues.\nCheckbox options Add vulnerability Id as a Jira label This allows you to add the Vulnerability ID data as a Jira Label automatically. Vulnerability IDs are added to Findings from individual security tools - these may be Common Vulnerabilities and Exposures (CVE) IDs or a different format, specific to the tool reporting the Finding.\nEnable engagement epic mapping In DefectDojo, Engagements represent a collection of work. Each Engagement contains one or more tests, which contain one or more Findings which need to be mitigated. Epics in Jira work in a similar way, and this checkbox allows you to push Engagements to Jira as Epics.\nAn Engagement in DefectDojo - note the three findings listed at the bottom.\nâ€‹ How the same Engagement becomes an Epic when pushed to JIRA - the Engagement\u0026rsquo;s Findings are also pushed, and live inside the Engagement as Child Issues. Push All Issues If checked, DefectDojo will automatically push any Active and Verified Findings to Jira as Issues. If left unchecked, all Findings will need to be pushed to Jira manually.\nPush notes If enabled, Jira comments will populate on the associated Finding in DefectDojo, under Notes on the issue(screenshot), and vice versa; Notes on Findings will be added to the associated Jira Issue as Comments.\nSend SLA notifications as comment? If enabled, any Issue which breaches DefectDojoâ€™s Service Level Agreement rules will have comments added to the Jira issue indicating this. These comments will be posted daily until the Issue is resolved.\nService Level Agreements can be configured under Configuration \u0026gt; SLA Configuration in DefectDojo and assigned to each Product.\nSend Risk Acceptance expiration notifications as comment? If enabled, any Issue where the associated DefectDojo Risk Acceptance expires will have a comment added to the Jira issue indicating this. These comments will be posted daily until the Issue is resolved.\nTesting \u0026amp; Troubleshooting the Jira integration Test 1: Do Findings successfully push to Jira? In order to test that the Jira integration is working properly, you can add a new blank Finding to the Product associated with Jira in DefectDojo. Product \u0026gt; Findings \u0026gt; Add New Finding.\nAdd whatever title severity and description you wish, and then click â€œFinishedâ€. The Finding should appear as an Issue in Jira with all of the relevant metadata.\nIf Jira Issues are not being created correctly, check your Notifications for error codes.\nConfirm that the Jira User associated with DefectDojo\u0026rsquo;s Jira Configuration has permission to create and update issues on that particular Jira Project. Test 2: Jira Webhooks send and receive updates from DefectDojo In order to test the Jira webhooks, add a Note to a Finding which also exists in JIRA as an Issue (for example, the test issue in the section above).\nIf the webhooks are configured correctly, you should see the Note in Jira as a Comment on the issue.\nIf this doesnâ€™t work correctly, it could be due to a Firewall issue on your Jira instance blocking the Webhook.\nDefectDojo\u0026rsquo;s Firewall Rules include a checkbox for Jira Cloud, which needs to be enabled before DefectDojo can receive Webhook messages from Jira. Next Steps Learn how to create Jira Issues from your Product with this guide.\n","date":"0001-01-01","id":127,"permalink":"/en/jira_integration/add-a-connected-jira-project-to-a-product/","summary":"If you haven\u0026rsquo;t already set up DefectDojo\u0026rsquo;s Jira Configuration, you\u0026rsquo;ll need to start by linking one or more Jira instances to DefectDojo.","tags":[],"title":"Add a Connected Jira Project to a Product"},{"content":"The process for adding and configuring a connector is similar, regardless of the tool youâ€™re trying to connect. However, certain tools may require you to create API keys or complete additional steps.\nBefore you begin this process, we recommend checking our tool-specific reference to find the API resources for the tool you\u0026rsquo;re trying to connect.\nIf you haven\u0026rsquo;t already, start by switching to the Beta UI in DefectDojo. From the left-side menu, click on the API Connectors menu item. This is nested under the Import header.\nâ€‹ 3. Choose a new Connector you want to add to DefectDojo in Available Connections, and click the Add Configuration underneath the tool.\nâ€‹\nYou can also edit an existing Connection under the Configured Connections header. Click Manage Configuration \u0026gt; Edit Configuration for the Configured Connection you want to Edit.\nâ€‹\n4. You will need an accessible URL Location for the tool, along with an API Secret key. The location of the API key will depend on the tool you are trying to configure. See our Tool-Specific Reference for more details.\nâ€‹ 5. Set a Label for this connection to help you identify it in DefectDojo.\nâ€‹ 6. Schedule the Connectorâ€™s automatic Discovery and Synchronization activities. These can be changed later.\nâ€‹ 7. Select whether you wish to Enable Auto-Mapping. Enable Auto-Mapping will create a new Product in DefectDojo to store the data from this connector. Auto-Mapping can be turned on or off at any time.\nâ€‹ 8. Click Submit.\nNext Steps Now that you\u0026rsquo;ve added a connector, you can confirm everything is set up correctly by running a Discover operation. ","date":"0001-01-01","id":128,"permalink":"/en/connecting_your_tools/connectors/add_edit_connectors/","summary":"The process for adding and configuring a connector is similar, regardless of the tool youâ€™re trying to connect. However, certain tools may require you to create API keys or complete additional steps.","tags":[],"title":"Add or Edit a Connector"},{"content":"When a Test is created in DefectDojo (either in advance or by importing a scan file), the Test can be extended with new Finding data.\nFor example, letâ€™s say you have a CI/CD pipeline, which is designed to send a new report to DefectDojo every day. Rather than create a new Test or Engagement for each â€˜runâ€™ of the pipeline, you could have each report flow into the same Test using Reimport.\nReimport: Process Summary Reimporting data does not replace any old data in the Test, instead, it compares the incoming scan file with the existing scan data in a test to make informed decisions:\nBased on the latest file, which vulnerabilities are still present? Which vulnerabilities are no longer present? Which vulnerabilities have been previously solved, but have since been reintroduced? The Test will track and separate each scan version via Import History, so that you can check the Finding changes in your Test over time.\nReimport Logic: Create, Ignore, Close or Reopen When using Reimport, DefectDojo will compare the incoming scan data with the existing scan data, and then apply changes to the Findings contained within your Test as follows:\nCreate Findings Any vulnerabilities which were not contained in the previous import will be added to the Test automatically as new Findings.\nIgnore existing Findings If any incoming Findings match Findings that already exist, the incoming Findings will be discarded rather than recorded as Duplicates. These Findings have been recorded already - no need to add a new Finding object. The Test page will show these Findings as Left Untouched.\nClose Findings If there are any Findings that already exist in the Test but which are not present in the incoming report, you can choose to automatically set those Findings to Inactive and Mitigated (on the assumption that those vulnerabilities have been resolved since the previous import). The Test page will show these Findings as Closed.\nIf you donâ€™t want any Findings to be closed, you can disable this behavior on Reimport:\nUncheck the Close Old Findings checkbox if using the UI Set close_old_findings to False if using the API Reopen Findings If there are any Closed Findings which appear again in a Reimport, they will automatically be Reopened. The assumption is that these vulnerabilities have occurred again, despite previous mitigation. The Test page will track these Findings as Reactivated. If youâ€™re using a triage-less scanner, or you donâ€™t otherwise want Closed Findings to reactivate, you can disable this behavior on Reimport:\nSet do_not_reactivate to True if using the API Check the Do Not Reactivate checkbox if using the UI Opening the Reimport form The Re-Import Findings form can be accessed on any Test page, under the âš™ï¸Gear drop-down menu.\n##\nThe Re-import Findings Form will not allow you to import a different scan type, or change the destination of the Findings youâ€™re trying to upload. If youâ€™re trying to do one of those things, youâ€™ll need to use the Import Scan Form.\nWorking with Import History Import History for a given test is listed under the Test Overview header on the Test page.\nThis table shows each Import or Reimport as a single line with a Timestamp, along with Branch Tag, Build ID, Commit Hash and Version columns if those were specified.\nActions This header indicates the actions taken by an Import/Reimport.\n# created indicates the number of new Findings created at the time of Import/Reimport # closed shows the number of Findings that were closed by a Reimport (due to not existing in the incoming report). # left untouched shows the count of Open Findings which were unchanged by a Reimport (because they also existed in the incoming report). # reactivated shows any Closed Findings which were reopened by an incoming Reimport. Reimport via API - special note Note that the /reimport API endpoint can both extend an existing Test (apply the method in this article) or create a new Test with new data - an initial call to /import, or setting up a Test in advance is not required.\n","date":"0001-01-01","id":129,"permalink":"/en/connecting_your_tools/import_scan_files/using_reimport/","summary":"When a Test is created in DefectDojo (either in advance or by importing a scan file), the Test can be extended with new Finding data.","tags":[],"title":"Adding new Findings to a Test via Reimport"},{"content":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample Anchore Enterprise Policy Check scans can be found here.\n","date":"0001-01-01","id":130,"permalink":"/en/connecting_your_tools/parsers/file/anchore_enterprise/","summary":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample Anchore Enterprise Policy Check scans can be found here.","tags":[],"title":"Anchore Enterprise Policy Check"},{"content":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON files are created using the Grype CLI, using the \u0026lsquo;-o json\u0026rsquo; option. See: https://github.com/anchore/grype\nExample: grype yourApp/example-page -o json \u0026gt; example_vulns.json\nAcceptable JSON Format All properties are expected as strings and are required by the parser.\n{ \u0026#34;matches\u0026#34;: [ { \u0026#34;vulnerability\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;example-id\u0026#34;, \u0026#34;dataSource\u0026#34;: \u0026#34;https://example.org/.../example-id\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;exampleName\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;exampleSeverity\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;https://example.org/.../example-id\u0026#34;, ... ], \u0026#34;cvss\u0026#34;: [], \u0026#34;fix\u0026#34;: { \u0026#34;versions\u0026#34;: [], \u0026#34;state\u0026#34;: \u0026#34;not-fixed\u0026#34; }, \u0026#34;advisories\u0026#34;: [] }, \u0026#34;relatedVulnerabilities\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;first-related-example-id\u0026#34;, \u0026#34;dataSource\u0026#34;: \u0026#34;https://example.org/.../related-example-id\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;first-related-exampleName\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;first-related-exampleSeverity\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;https://example.org/.../related-example-id\u0026#34;, ... ], \u0026#34;description\u0026#34;: \u0026#34;first-example-description\u0026#34;, \u0026#34;cvss\u0026#34;: [ { \u0026#34;version\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;vector\u0026#34;: \u0026#34;AV:L/AC:L/Au:N/C:N/I:P/A:N\u0026#34;, \u0026#34;metrics\u0026#34;: { \u0026#34;baseScore\u0026#34;: 2.1, \u0026#34;exploitabilityScore\u0026#34;: 3.9, \u0026#34;impactScore\u0026#34;: 2.9 }, \u0026#34;vendorMetadata\u0026#34;: {} } ] }, ... ], \u0026#34;matchDetails\u0026#34;: [ { \u0026#34;matcher\u0026#34;: \u0026#34;example-matcher\u0026#34;, \u0026#34;searchedBy\u0026#34;: { \u0026#34;distro\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;example-distrotype\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;namespace\u0026#34;: \u0026#34;exampleName\u0026#34;, \u0026#34;package\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;example-package\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.17-3+deb10u3\u0026#34; } }, \u0026#34;found\u0026#34;: { \u0026#34;versionConstraint\u0026#34;: \u0026#34;none (deb)\u0026#34; } } ], \u0026#34;artifact\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;example-artifact\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;example-artifact-version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;example-type\u0026#34;, \u0026#34;locations\u0026#34;: [ { \u0026#34;path\u0026#34;: \u0026#34;.../examplePath/\u0026#34;, \u0026#34;layerID\u0026#34;: \u0026#34;exampleLayerID\u0026#34; }, { \u0026#34;path\u0026#34;: \u0026#34;.../examplePath-2/\u0026#34;, \u0026#34;layerID\u0026#34;: \u0026#34;exampleLayerID\u0026#34; }, ... ], \u0026#34;language\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;licenses\u0026#34;: [ \u0026#34;GPL-2\u0026#34; ], \u0026#34;cpes\u0026#34;: [ \u0026#34;example-cpe\u0026#34;, ... ], \u0026#34;purl\u0026#34;: \u0026#34;pkg:deb/debian/libgssapi-krb5-2@1.17-3+deb10u3?arch=amd64\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;Source\u0026#34;: \u0026#34;krb5\u0026#34; } } }, ... ], \u0026#34;source\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, \u0026#34;target\u0026#34;: { \u0026#34;userInput\u0026#34;: \u0026#34;vulnerable-image:latest\u0026#34;, \u0026#34;imageID\u0026#34;: \u0026#34;sha256:ce9898fd214aef9c994a42624b09056bdce3ff4a8e3f68dc242d967b80fcbeee\u0026#34;, \u0026#34;manifestDigest\u0026#34;: \u0026#34;sha256:9d8825ab20ac86b40eb71495bece1608a302fb180384740697a28c2b0a5a0fc6\u0026#34;, \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.distribution.manifest.v2+json\u0026#34;, \u0026#34;tags\u0026#34;: [ \u0026#34;vulnerable-image:latest\u0026#34; ], \u0026#34;imageSize\u0026#34;: 707381791, \u0026#34;layers\u0026#34;: [ { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.image.rootfs.diff.tar.gzip\u0026#34;, \u0026#34;digest\u0026#34;: \u0026#34;sha256:d000633a56813933cb0ac5ee3246cf7a4c0205db6290018a169d7cb096581046\u0026#34;, \u0026#34;size\u0026#34;: 69238554 }, ... ], \u0026#34;manifest\u0026#34;: \u0026#34;exampleManifestString==\u0026#34;, \u0026#34;config\u0026#34;: \u0026#34;exampleConfigString\u0026#34;, \u0026#34;repoDigests\u0026#34;: [] } }, \u0026#34;distro\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;debian\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;idLike\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;descriptor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;grype\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.28.0\u0026#34;, \u0026#34;configuration\u0026#34;: { \u0026#34;configPath\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;output-template-file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;quiet\u0026#34;: false, \u0026#34;check-for-app-update\u0026#34;: true, \u0026#34;only-fixed\u0026#34;: false, \u0026#34;scope\u0026#34;: \u0026#34;Squashed\u0026#34;, \u0026#34;log\u0026#34;: { \u0026#34;structured\u0026#34;: false, \u0026#34;level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;file\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;db\u0026#34;: { \u0026#34;cache-dir\u0026#34;: \u0026#34;/home/user/.cache/grype/db\u0026#34;, \u0026#34;update-url\u0026#34;: \u0026#34;https://toolbox-data.anchore.io/grype/databases/listing.json\u0026#34;, \u0026#34;ca-cert\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;auto-update\u0026#34;: true, \u0026#34;validate-by-hash-on-start\u0026#34;: false }, \u0026#34;dev\u0026#34;: { \u0026#34;profile-cpu\u0026#34;: false, \u0026#34;profile-mem\u0026#34;: false }, \u0026#34;fail-on-severity\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;registry\u0026#34;: { \u0026#34;insecure-skip-tls-verify\u0026#34;: false, \u0026#34;insecure-use-http\u0026#34;: false, \u0026#34;auth\u0026#34;: [] }, \u0026#34;ignore\u0026#34;: null, \u0026#34;exclude\u0026#34;: [] }, \u0026#34;db\u0026#34;: { \u0026#34;built\u0026#34;: \u0026#34;2021-12-24T08:14:02Z\u0026#34;, \u0026#34;schemaVersion\u0026#34;: 3, \u0026#34;location\u0026#34;: \u0026#34;/home/user/.cache/grype/db/3\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;sha256:6c4777e1acea787e5335ccee6b5e4562cd1767b9cca138c07e0802efb2a74162\u0026#34;, \u0026#34;error\u0026#34;: null } } }\rSample Scan Data Sample Grype scans can be found here.\n","date":"0001-01-01","id":131,"permalink":"/en/connecting_your_tools/parsers/file/anchore_grype/","summary":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON files are created using the Grype CLI, using the \u0026lsquo;-o json\u0026rsquo; option.","tags":[],"title":"Anchore Grype"},{"content":"File Types DefectDojo parser accepts a .json file.\nUsing the Anchore CLI is the most reliable way to generate an Anchore report which DefectDojo can parse. When generating a report with the Anchore CLI, please use the following command to ensure complete data: anchore-cli --json image vuln \u0026lt;image:tag\u0026gt; all\nAcceptable JSON Format All properties are strings and are required by the parser.\n{ \u0026#34;imageDigest\u0026#34;: \u0026#34;sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34;, \u0026#34;vulnerabilities\u0026#34;: [ { \u0026#34;feed\u0026#34;: \u0026#34;example-feed\u0026#34;, \u0026#34;feed_group\u0026#34;: \u0026#34;example-feed-group\u0026#34;, \u0026#34;fix\u0026#34;: \u0026#34;1.2.4\u0026#34;, \u0026#34;package\u0026#34;: \u0026#34;example-package\u0026#34;, \u0026#34;package_cpe\u0026#34;: \u0026#34;cpe:2.3:a:*:example:1.2.3:*:*:*:*:*:*:*\u0026#34;, \u0026#34;package_name\u0026#34;: \u0026#34;example-package-name\u0026#34;, \u0026#34;package_path\u0026#34;: \u0026#34;path/to/package\u0026#34;, \u0026#34;package_type\u0026#34;: \u0026#34;dpkg\u0026#34;, \u0026#34;package_version\u0026#34;: \u0026#34;1.2.3\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://example.com/cve/CVE-2011-3389\u0026#34;, \u0026#34;vuln\u0026#34;: \u0026#34;CVE-2011-3389\u0026#34; }, ... ], \u0026#34;vulnerability_type\u0026#34;: \u0026#34;os\u0026#34; }\rSample Scan Data Sample Anchore-Engine scans can be found here.\n","date":"0001-01-01","id":132,"permalink":"/en/connecting_your_tools/parsers/file/anchore_engine/","summary":"File Types DefectDojo parser accepts a .json file.\nUsing the Anchore CLI is the most reliable way to generate an Anchore report which DefectDojo can parse.","tags":[],"title":"Anchore-Engine"},{"content":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample AnchoreCTL Policies Report scans can be found here.\n","date":"0001-01-01","id":133,"permalink":"/en/connecting_your_tools/parsers/file/anchorectl_policies/","summary":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample AnchoreCTL Policies Report scans can be found here.","tags":[],"title":"AnchoreCTL Policies Report"},{"content":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample AnchoreCTL Vuln Report scans can be found here.\n","date":"0001-01-01","id":134,"permalink":"/en/connecting_your_tools/parsers/file/anchorectl_vulns/","summary":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample AnchoreCTL Vuln Report scans can be found here.","tags":[],"title":"AnchoreCTL Vuln Report"},{"content":"Accepts AppCheck Web Application Scanner output in .json format.\nSample Scan Data Sample AppCheck Web Application Scanner scans can be found here.\n","date":"0001-01-01","id":135,"permalink":"/en/connecting_your_tools/parsers/file/appcheck_web_application_scanner/","summary":"Accepts AppCheck Web Application Scanner output in .json format.\nSample Scan Data Sample AppCheck Web Application Scanner scans can be found here.","tags":[],"title":"AppCheck Web Application Scanner"},{"content":"Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nSample Scan Data Sample AppSpider (Rapid7) scans can be found here.\n","date":"0001-01-01","id":136,"permalink":"/en/connecting_your_tools/parsers/file/appspider/","summary":"Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nSample Scan Data Sample AppSpider (Rapid7) scans can be found here.","tags":[],"title":"AppSpider (Rapid7)"},{"content":"JSON report format.\nSample Scan Data Sample Aqua scans can be found here.\n","date":"0001-01-01","id":137,"permalink":"/en/connecting_your_tools/parsers/file/aqua/","summary":"JSON report format.\nSample Scan Data Sample Aqua scans can be found here.","tags":[],"title":"Aqua"},{"content":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter \u0026#39;json\u0026#39; js.com.afr Sample Scan Data Sample Arachni Scanner scans can be found here.\n","date":"0001-01-01","id":138,"permalink":"/en/connecting_your_tools/parsers/file/arachni/","summary":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter \u0026#39;json\u0026#39; js.com.afr Sample Scan Data Sample Arachni Scanner scans can be found here.","tags":[],"title":"Arachni Scanner"},{"content":"AuditJS scanning tool using OSSIndex database and generated with --json or -j option (https://www.npmjs.com/package/auditjs).\nauditjs ossi --json \u0026gt; auditjs_report.json Sample Scan Data Sample AuditJS (OSSIndex) scans can be found here.\n","date":"0001-01-01","id":139,"permalink":"/en/connecting_your_tools/parsers/file/auditjs/","summary":"AuditJS scanning tool using OSSIndex database and generated with --json or -j option (https://www.npmjs.com/package/auditjs).\nauditjs ossi --json \u0026gt; auditjs_report.json Sample Scan Data Sample AuditJS (OSSIndex) scans can be found here.","tags":[],"title":"AuditJS (OSSIndex)"},{"content":"If you have a CI/CD pipeline, a daily scan process or any kind of repeated incoming report, setting up a Reimport process in advance is key to avoiding excessive duplicates. Reimport collapses the context and Findings associated with a recurring test into a single Test page, where you can review import history and track vulnerability changes across scans.\nCreate an Engagement to store the CI/CD results for the object youâ€™re running CI/CD on. This could be a code repository where you have CI/CD actions set up to run. Generally, you want a separate Engagement set up for each pipeline so that you can quickly understand where the Finding results are coming from.\nâ€‹ Each CI/CD action will import data to DefectDojo in a separate step, so each of those should be mapped to a separate Test. For example, if each pipeline execution runs an NPM-audit as well as a dependency scan, each scan result will need to flow into a Test (nested under the Engagement).\nâ€‹ You do not need to create a new Test each time the CI/CD action runs. Instead, you can Reimport data to the same test location. â€‹\nReimport in action DefectDojo will compare the incoming scan data with the existing scan data, and then apply changes to the Findings contained within your Test as follows:\nâ€‹\nCreate Findings Any vulnerabilities which were not contained in the previous import will be added to the Test automatically as new Findings.\nâ€‹\nIgnore existing Findings If any incoming Findings match Findings that already exist, the incoming Findings will be discarded rather than recorded as Duplicates. These Findings have been recorded already - no need to add a new Finding object. The Test page will show these Findings as Left Untouched.\nâ€‹\nClose Findings If there are any Findings that already exist in the Test but which are not present in the incoming report, you can choose to automatically set those Findings to Inactive and Mitigated (on the assumption that those vulnerabilities have been resolved since the previous import). The Test page will show these Findings as Closed.\nIf you donâ€™t want any Findings to be closed, you can disable this behavior on Reimport:\nUncheck the Close Old Findings checkbox if using the UI Set close_old_findings to False if using the API\nâ€‹ Reopen Findings If there are any Closed Findings which appear again in a Reimport, they will automatically be Reopened. The assumption is that these vulnerabilities have occurred again, despite previous mitigation. The Test page will track these Findings as Reactivated. If youâ€™re using a triage-less scanner, or you donâ€™t otherwise want Closed Findings to reactivate, you can disable this behavior on Reimport:\nSet do_not_reactivate to True if using the API Check the Do Not Reactivate checkbox if using the UI Working with Import History Import History for a given test is listed under the Test Overview header on the Test page.\nThis table shows each Import or Reimport as a single line with a Timestamp, along with Branch Tag, Build ID, Commit Hash and Version columns if those were specified.\nActions This header indicates the actions taken by an Import/Reimport.\n# created indicates the number of new Findings created at the time of Import/Reimport # closed shows the number of Findings that were closed by a Reimport (due to not existing in the incoming report). # left untouched shows the count of Open Findings which were unchanged by a Reimport (because they also existed in the incoming report). # reactivated shows any Closed Findings which were reopened by an incoming Reimport. Why not simply use Import? Although both methods are possible, Import should be reserved for new occurrences of Findings and Data, while Reimport should be applied for further iterations of the same data.\nIf your CI/CD pipeline runs an Import and creates a new Test object each time, each Import will give you a collection of discrete Findings which you will then need to manage as separate objects. Using Reimport alleviates this problem and eliminates the amount of â€˜cleanupâ€™ youâ€™ll need to do when a vulnerability is resolved.\nUsing Reimport allows you to store each recurring report on the same page, and maintains a continuity of each time new data was added to the Test.\nHowever, if youâ€™re using the same scanning tool in multiple locations or contexts, it may be more appropriate to create a separate Test for each location or context. This depends on your preferred method of organization.\n","date":"0001-01-01","id":140,"permalink":"/en/working_with_findings/finding_deduplication/avoiding-duplicates-reimport-recurring-tests/","summary":"If you have a CI/CD pipeline, a daily scan process or any kind of repeated incoming report, setting up a Reimport process in advance is key to avoiding excessive duplicates.","tags":[],"title":"Avoiding Duplicates: Reimport Recurring Tests"},{"content":"File Types AWS Inspector2 report can be imported in json format. Inspector2 name comes from API calls to \u0026ldquo;modern\u0026rdquo; Inspector API - aws inspector2 as opposite to Classic Inspector (previous version of the service), this is an example of how such report can be generated: aws inspector2 list-findings --filter-criteria '{\u0026quot;resourceId\u0026quot;:[{\u0026quot;comparison\u0026quot;:\u0026quot;EQUALS\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;i-instance_id_here\u0026quot;}]}' --region us-east-1 \u0026gt; inspector2_findings.json\nThis parser can help to get findings in a delegated admin account for AWS Inspector or in a standalone AWS account. The parser is developed mostly for a scenario where findings are obtained for a specific resource like an ECR image or an instance, and uploaded to a test in a DefectDojo engagement that represents a branch from a git repository.\nA minimal valid json file with no findings:\n{ \u0026#34;findings\u0026#34;: [] }\rDetailed API response format can be obtained here\nSample Scan Data Sample AWS Inspector2 findings can be found here.\n","date":"0001-01-01","id":141,"permalink":"/en/connecting_your_tools/parsers/file/aws_inspector2/","summary":"File Types AWS Inspector2 report can be imported in json format. Inspector2 name comes from API calls to \u0026ldquo;modern\u0026rdquo; Inspector API - aws inspector2 as opposite to Classic Inspector (previous version of the service), this is an example of how such report can be generated: aws inspector2 list-findings --filter-criteria '{\u0026quot;resourceId\u0026quot;:[{\u0026quot;comparison\u0026quot;:\u0026quot;EQUALS\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;i-instance_id_here\u0026quot;}]}' --region us-east-1 \u0026gt; inspector2_findings.","tags":[],"title":"AWS Inspector2 Scanner"},{"content":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file.\nSample Scan Data Sample AWS Prowler Scanner scans can be found here.\n","date":"0001-01-01","id":142,"permalink":"/en/connecting_your_tools/parsers/file/aws_prowler/","summary":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file.\nSample Scan Data Sample AWS Prowler Scanner scans can be found here.","tags":[],"title":"AWS Prowler Scanner"},{"content":"File Types DefectDojo parser accepts a native json file produced by prowler v3 with file extension .json or a ocsf-json file produced by prowler v4 with file extension .ocsf.json. Please note: earlier versions of AWS Prowler create output data in a different format. See our other prowler parser documentation if you are using an earlier version of AWS Prowler.\nJSON reports can be created from the AWS Prowler v3 CLI using the following command: prowler \u0026lt;provider\u0026gt; -M json\nJSON-OCSF reports can be created from the AWS Prowler v4 CLI using the following command: prowler \u0026lt;provider\u0026gt; -M json-ocsf\nAcceptable Prowler v3 JSON format Parser expects an array of assessments. All properties are strings and are required by the parser.\n[ { \u0026#34;AssessmentStartTime\u0026#34;: \u0026#34;example_timestamp\u0026#34;, \u0026#34;FindingUniqueId\u0026#34;: \u0026#34;example_uniqueIdFromTool\u0026#34;, \u0026#34;Provider\u0026#34;: \u0026#34;example_provider\u0026#34;, \u0026#34;CheckID\u0026#34;: \u0026#34;acm_certificates_expiration_check\u0026#34;, \u0026#34;CheckTitle\u0026#34;: \u0026#34;Check if ACM Certificates are about to expire in specific days or less\u0026#34;, \u0026#34;CheckType\u0026#34;: [ \u0026#34;Example ASFF-Compliant Finding Type\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;example_awsServiceName\u0026#34;, \u0026#34;SubServiceName\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;FAIL\u0026#34;, \u0026#34;StatusExtended\u0026#34;: \u0026#34;Example status description\u0026#34;, \u0026#34;Severity\u0026#34;: \u0026#34;example_severity\u0026#34;, \u0026#34;ResourceType\u0026#34;: \u0026#34;AwsCertificateManagerCertificate\u0026#34;, \u0026#34;ResourceDetails\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Example general test description.\u0026#34;, \u0026#34;Risk\u0026#34;: \u0026#34;Example test impact description.\u0026#34;, \u0026#34;RelatedUrl\u0026#34;: \u0026#34;https://docs.aws.amazon.com/config/latest/developerguide/acm-certificate-expiration-check.html\u0026#34;, \u0026#34;Remediation\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;NativeIaC\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Terraform\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;CLI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Other\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;Recommendation\u0026#34;: { \u0026#34;Text\u0026#34;: \u0026#34;Example recommendation.\u0026#34;, \u0026#34;Url\u0026#34;: \u0026#34;https://docs.aws.amazon.com/config/latest/developerguide/example_related_documentation.html\u0026#34; } }, \u0026#34;Compliance\u0026#34;: { \u0026#34;GDPR\u0026#34;: [ \u0026#34;article_32\u0026#34; ], ... }, \u0026#34;Categories\u0026#34;: [], \u0026#34;DependsOn\u0026#34;: [], \u0026#34;RelatedTo\u0026#34;: [], \u0026#34;Notes\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Profile\u0026#34;: null, \u0026#34;AccountId\u0026#34;: \u0026#34;example_accountId\u0026#34;, \u0026#34;OrganizationsInfo\u0026#34;: null, \u0026#34;Region\u0026#34;: \u0026#34;example_region\u0026#34;, \u0026#34;ResourceId\u0026#34;: \u0026#34;example.resource.id.com\u0026#34;, \u0026#34;ResourceArn\u0026#34;: \u0026#34;arn:aws:acm:us-east-1:999999999999:certificate/ffffffff-0000-0000-0000-000000000000\u0026#34;, \u0026#34;ResourceTags\u0026#34;: {} } ... ]\rAcceptable Prowler v4 JSON-OCSF format The parser expects an array of assessments. All properties are strings and are required by the parser.\n[{ \u0026#34;metadata\u0026#34;: { \u0026#34;event_code\u0026#34;: \u0026#34;iam_role_administratoraccess_policy_permissive_trust_relationship\u0026#34;, \u0026#34;product\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Prowler\u0026#34;, \u0026#34;vendor_name\u0026#34;: \u0026#34;Prowler\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;4.2.1\u0026#34; }, \u0026#34;version\u0026#34;: \u0026#34;1.2.0\u0026#34; }, \u0026#34;severity_id\u0026#34;: 4, \u0026#34;severity\u0026#34;: \u0026#34;High\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Suppressed\u0026#34;, \u0026#34;status_code\u0026#34;: \u0026#34;FAIL\u0026#34;, \u0026#34;status_detail\u0026#34;: \u0026#34;IAM Role myAdministratorExecutionRole has AdministratorAccess policy attached that has too permissive trust relationship.\u0026#34;, \u0026#34;status_id\u0026#34;: 3, \u0026#34;unmapped\u0026#34;: { \u0026#34;check_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;related_url\u0026#34;: \u0026#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_job-functions.html#jf_administrator\u0026#34;, \u0026#34;categories\u0026#34;: \u0026#34;trustboundaries\u0026#34;, \u0026#34;depends_on\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;related_to\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;notes\u0026#34;: \u0026#34;CAF Security Epic: IAM\u0026#34;, \u0026#34;compliance\u0026#34;: {} }, \u0026#34;activity_name\u0026#34;: \u0026#34;Create\u0026#34;, \u0026#34;activity_id\u0026#34;: 1, \u0026#34;finding_info\u0026#34;: { \u0026#34;created_time\u0026#34;: \u0026#34;2024-06-03T14:15:19.382075\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\u0026#34;, \u0026#34;product_uid\u0026#34;: \u0026#34;prowler\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;prowler-aws-iam_role_administratoraccess_policy_permissive_trust_relationship-123456789012-us-east-1-myAdministratorExecutionRole\u0026#34; }, \u0026#34;resources\u0026#34;: [ { \u0026#34;cloud_partition\u0026#34;: \u0026#34;aws\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;details\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;iam\u0026#34; }, \u0026#34;labels\u0026#34;: [], \u0026#34;name\u0026#34;: \u0026#34;myAdministratorExecutionRole\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AwsIamRole\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/myAdministratorExecutionRole\u0026#34; } ], \u0026#34;category_name\u0026#34;: \u0026#34;Findings\u0026#34;, \u0026#34;category_uid\u0026#34;: 2, \u0026#34;class_name\u0026#34;: \u0026#34;DetectionFinding\u0026#34;, \u0026#34;class_uid\u0026#34;: 2004, \u0026#34;cloud\u0026#34;: { \u0026#34;account\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AWS_Account\u0026#34;, \u0026#34;type_id\u0026#34;: 10, \u0026#34;uid\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;labels\u0026#34;: [] }, \u0026#34;org\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;provider\u0026#34;: \u0026#34;aws\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34; }, \u0026#34;event_time\u0026#34;: \u0026#34;2024-06-03T14:15:19.382075\u0026#34;, \u0026#34;remediation\u0026#34;: { \u0026#34;desc\u0026#34;: \u0026#34;Apply the principle of least privilege. Instead of AdministratorAccess, assign only the permissions necessary for specific roles and tasks. Create custom IAM policies with minimal permissions based on the principle of least privilege. If a role really needs AdministratorAccess, the trust relationship must be well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\u0026#34;, \u0026#34;references\u0026#34;: [ \u0026#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\u0026#34; ] }, \u0026#34;risk_details\u0026#34;: \u0026#34;The AWS-managed AdministratorAccess policy grants all actions for all AWS services and for all resources in the account and as such exposes the customer to a significant data leakage threat. It is therefore particularly important that the trust relationship is well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\u0026#34;, \u0026#34;type_uid\u0026#34;: 200401, \u0026#34;type_name\u0026#34;: \u0026#34;Create\u0026#34; }]\rSample Scan Data Unit tests of AWS Prowler v3 JSON and Prowler v4 JSON-OCSF can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/aws_prowler_v3.\n","date":"0001-01-01","id":143,"permalink":"/en/connecting_your_tools/parsers/file/aws_prowler_v3plus/","summary":"File Types DefectDojo parser accepts a native json file produced by prowler v3 with file extension .json or a ocsf-json file produced by prowler v4 with file extension .","tags":[],"title":"AWS Prowler V3"},{"content":"AWS Security Hub consumes, aggregates, organizes, and prioritizes findings from AWS security services and from the third-party product integrations. Security Hub processes these findings using a standard findings format called the AWS Security Finding Format (ASFF), which eliminates the need for time-consuming data conversion efforts. Then it correlates ingested findings across products to prioritize the most important ones.\nReference: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-findings-format.html\nProwler tool can generate this format with option -M json-asff.\nSample Scan Data Sample AWS Security Finding Format (ASFF) scans can be found here.\n","date":"0001-01-01","id":144,"permalink":"/en/connecting_your_tools/parsers/file/asff/","summary":"AWS Security Hub consumes, aggregates, organizes, and prioritizes findings from AWS security services and from the third-party product integrations. Security Hub processes these findings using a standard findings format called the AWS Security Finding Format (ASFF), which eliminates the need for time-consuming data conversion efforts.","tags":[],"title":"AWS Security Finding Format (ASFF)"},{"content":"File Types This DefectDojo parser accepts JSON files from AWS Security Hub. The JSON reports can be created from the AWS Security Hub CLI using the following command: aws securityhub get-findings.\nAWS Security Hub integrates with multiple AWS Tools. Thus, you can retrieve findings from various AWS sources through AWS Security Hub. This parser is able to handle the following findings retrieved over AWS Security Hub:\nAWS Security Hub Compliance Checks AWS Security Hub GuardDuty AWS Security Hub Inspector Example Commands to retrieve JSON output AWS Security Hub Compliance Checks: aws securityhub get-findings --filters ComplianceStatus=\u0026quot;[{Comparison=EQUALS,Value=FAILED}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json AWS Security Hub GuardDuty: aws securityhub get-findings --filters ProductName=\u0026quot;[{Value=GuardDuty,Comparison=EQUALS}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json AWS Security Hub Inspector: aws securityhub get-findings --filters ProductName=\u0026quot;[{Value=Inspector,Comparison=EQUALS}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json Sample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":145,"permalink":"/en/connecting_your_tools/parsers/file/awssecurityhub/","summary":"File Types This DefectDojo parser accepts JSON files from AWS Security Hub. The JSON reports can be created from the AWS Security Hub CLI using the following command: aws securityhub get-findings.","tags":[],"title":"AWS Security Hub"},{"content":"Azure Security Center recommendations can be exported from the user interface in CSV format.\nSample Scan Data Sample Azure Security Center Recommendations Scan scans can be found here.\n","date":"0001-01-01","id":146,"permalink":"/en/connecting_your_tools/parsers/file/azure_security_center_recommendations/","summary":"Azure Security Center recommendations can be exported from the user interface in CSV format.\nSample Scan Data Sample Azure Security Center Recommendations Scan scans can be found here.","tags":[],"title":"Azure Security Center Recommendations Scan"},{"content":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bandit, you will need to install and run the .json report formatter from your Bandit instance.\nSee Bandit documentation: https://bandit.readthedocs.io/en/latest/formatters/index.html\nAcceptable JSON Format All properties are expected as strings, except \u0026ldquo;metrics\u0026rdquo; properties, which are expected as numbers. All properties are required by the parser.\n{ \u0026#34;errors\u0026#34;: [], \u0026#34;generated_at\u0026#34;: \u0026#34;example-timestamp\u0026#34;, \u0026#34;metrics\u0026#34;: { \u0026#34;_totals\u0026#34;: { \u0026#34;CONFIDENCE.HIGH\u0026#34;: 1.0, \u0026#34;CONFIDENCE.LOW\u0026#34;: 0.0, \u0026#34;CONFIDENCE.MEDIUM\u0026#34;: 0.0, \u0026#34;CONFIDENCE.UNDEFINED\u0026#34;: 0.0, \u0026#34;SEVERITY.HIGH\u0026#34;: 0.0, \u0026#34;SEVERITY.LOW\u0026#34;: 1.0, \u0026#34;SEVERITY.MEDIUM\u0026#34;: 0.0, \u0026#34;SEVERITY.UNDEFINED\u0026#34;: 0.0, \u0026#34;loc\u0026#34;: 2, \u0026#34;nosec\u0026#34;: 0 }, \u0026#34;one/one.py\u0026#34;: { \u0026#34;CONFIDENCE.HIGH\u0026#34;: 1.0, \u0026#34;CONFIDENCE.LOW\u0026#34;: 0.0, \u0026#34;CONFIDENCE.MEDIUM\u0026#34;: 0.0, \u0026#34;CONFIDENCE.UNDEFINED\u0026#34;: 0.0, \u0026#34;SEVERITY.HIGH\u0026#34;: 0.0, \u0026#34;SEVERITY.LOW\u0026#34;: 1.0, \u0026#34;SEVERITY.MEDIUM\u0026#34;: 0.0, \u0026#34;SEVERITY.UNDEFINED\u0026#34;: 0.0, \u0026#34;loc\u0026#34;: 2, \u0026#34;nosec\u0026#34;: 0 } ... }, \u0026#34;results\u0026#34;: [ { \u0026#34;code\u0026#34;: \u0026#34;1 import os\\n2 assert False\\n\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;example.filename\u0026#34;, \u0026#34;issue_confidence\u0026#34;: \u0026#34;example_confidence\u0026#34;, \u0026#34;issue_severity\u0026#34;: \u0026#34;example_severity\u0026#34;, \u0026#34;issue_text\u0026#34;: \u0026#34;Example issue description.\u0026#34;, \u0026#34;line_number\u0026#34;: 2, \u0026#34;line_range\u0026#34;: [ 2 ], \u0026#34;more_info\u0026#34;: \u0026#34;https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\u0026#34;, \u0026#34;test_id\u0026#34;: \u0026#34;B101\u0026#34;, \u0026#34;test_name\u0026#34;: \u0026#34;assert_used\u0026#34; } ... ] }\rSample Scan Data Sample Bandit scans can be found here.\n","date":"0001-01-01","id":147,"permalink":"/en/connecting_your_tools/parsers/file/bandit/","summary":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bandit, you will need to install and run the .","tags":[],"title":"Bandit"},{"content":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bearer CLI, pass \u0026ldquo;-f json\u0026rdquo; to your Bearer command\nSee Bearer documentation: https://docs.bearer.com/reference/commands/\nSample Scan Data Sample Bearer scans can be found here\n","date":"0001-01-01","id":148,"permalink":"/en/connecting_your_tools/parsers/file/bearer_cli/","summary":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bearer CLI, pass \u0026ldquo;-f json\u0026rdquo; to your Bearer command","tags":[],"title":"Bearer CLI"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;BlackDuck API\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your BlackDuck API token in the API Key field.\nIn Add API Scan Configuration provide the ID of the project from which to import findings in the field Service key 1. Provide the version of the project from which to import findings in the field Service key 2.\n","date":"0001-01-01","id":149,"permalink":"/en/connecting_your_tools/parsers/api/blackduck/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Blackduck API"},{"content":"What Black Duck Binary Analysis gives you visibility into open source and third-party dependencies that have been compiled into executables, libraries, containers, and firmware. You can analyze individual files using an intuitive user interface or Black Duck multifactor open source detection, which automates the scanning of binary artifacts.\nUsing a combination of static and string analysis techniques coupled with fuzzy matching against the Black Duck KnowledgeBase, Black Duck Binary Analysis quickly and reliably identifies components, even if they\u0026rsquo;ve been modified.\nFor more info, check out Black Duck Binary Analysis here.\nWhy Open source vulnerabilities aren\u0026rsquo;t the only security issues that might be lurking in application binaries.\nBlack Duck Binary Analysis can also detect if sensitive information like email addresses, authorization tokens, compiler switches, and passwords are exposed, and it identifies when mobile applications request excessive permissionsâ€”all of which puts your organization and users\u0026rsquo; personal data at risk.\nHow Initiate Black Duck Binary Analysis scans using the UI, REST API, or drivers such as pwn_bdba_scan found within the security automation framework, PWN Import a single BDBA vulnerabilty csv results file into DefectDojo leveraging the UI, REST API, or drivers such as pwn_defectdojo_importscan or pwn_defectdojo_reimportscan. Sample Scan Data Sample Blackduck Binary Analysis scans can be found here.\n","date":"0001-01-01","id":150,"permalink":"/en/connecting_your_tools/parsers/file/blackduck_binary_analysis/","summary":"What Black Duck Binary Analysis gives you visibility into open source and third-party dependencies that have been compiled into executables, libraries, containers, and firmware.","tags":[],"title":"Blackduck Binary Analysis"},{"content":"Upload the zip file containing the security.csv and files.csv.\nSample Scan Data Sample Blackduck Component Risk scans can be found here.\n","date":"0001-01-01","id":151,"permalink":"/en/connecting_your_tools/parsers/file/blackduck_component_risk/","summary":"Upload the zip file containing the security.csv and files.csv.\nSample Scan Data Sample Blackduck Component Risk scans can be found here.","tags":[],"title":"Blackduck Component Risk"},{"content":"2 options:\nImport the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.csv in order to produce findings that bear file locations information. Import a single security.csv file. Findings will not have any file location information. Sample Scan Data Sample Blackduck Hub scans can be found here.\n","date":"0001-01-01","id":152,"permalink":"/en/connecting_your_tools/parsers/file/blackduck/","summary":"2 options:\nImport the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.","tags":[],"title":"Blackduck Hub"},{"content":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data Sample Brakeman Scan scans can be found here.\n","date":"0001-01-01","id":153,"permalink":"/en/connecting_your_tools/parsers/file/brakeman/","summary":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data Sample Brakeman Scan scans can be found here.","tags":[],"title":"Brakeman Scan"},{"content":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample Bugcrowd scans can be found here.\n","date":"0001-01-01","id":154,"permalink":"/en/connecting_your_tools/parsers/file/bugcrowd/","summary":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample Bugcrowd scans can be found here.","tags":[],"title":"Bugcrowd"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Bugcrowd API\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your BlackDuck API token in the API Key field. Set your API key directly in the format username:password in the API Token input, it will be added to the header 'Authorization': 'Token {}'.format(self.api_token),\nFor each product, you can configure 2 things:\nService key 1: the bugcrowd program code (it\u0026rsquo;s the slug name in the url for the program, url safe) Service key 2: the bugcrowd target name (the full name, it will be url-encoded, you can find it in https://tracker.bugcrowd.com//settings/scope/target_groups) It can be left empty so that all program submissions are imported That way, per product, you can use the same program but separate by target, which is a fairly common way of filtering/grouping Bugcrowd. Adding support for a 3rd filtering would be possible with Service Key 3, feel free to make a PR.\n","date":"0001-01-01","id":155,"permalink":"/en/connecting_your_tools/parsers/api/bugcrowd/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Bugcrowd API"},{"content":"Findings can be edited in bulk from a Finding List, which can be found either on the Findings page itself, or from within a Test.\nSelecting Findings for Bulk Edit When looking at a table with multiple Findings, such as the â€˜Findings From [tool]â€™ table on a Test Page or the All Findings list, you can use the checkboxes next to Findings to mark them for Bulk Edit.\nSelecting one or more Findings in this way will open the (hidden) Bulk Edit menu, which contains the following four options:\nBulk Update Actions: apply metadata changes to the selected Findings. Risk Acceptance Actions: create a Full Risk Acceptance to govern the selected Findings, or add the Findings to an existing Full Risk Acceptance Finding Group Actions: create a Finding Group made up of the selected Findings. Note that Finding Groups can only be created within an individual Test. Delete: delete the selected Findings. You will need to confirm this action in a new window. Bulk Update Actions Through the Bulk Update Actions menu, you can apply the following changes to any Findings you have selected:\nUpdate the Severity Apply a new Finding Status Change the Discovery or Planned Remediation Date of the Findings Add a Simple Risk Acceptance, if the option is enabled at the Product level Apply Tags or Notes to all of the selected Findings. Risk Acceptance Actions This page allows you to add a Full Risk Acceptance to the selected Findings. You can either create a new Full Risk Acceptance or add the Findings to one that already exists.\nFinding Group Actions This page allows you to create a new Finding Group from the Selected Findings, or add them to an existing Finding Group.\nHowever, Finding Groups can only be created within an individual Test - Findings from different Tests, Engagements or Products cannot be added to the same Finding Group.\nBulk Delete Findings You can also Delete selected Findings by clicking on the red Delete button. A popup window will appear asking you to confirm this decision.\n","date":"0001-01-01","id":156,"permalink":"/en/working_with_findings/findings_workflows/bulk-editing-findings/","summary":"Findings can be edited in bulk from a Finding List, which can be found either on the Findings page itself, or from within a Test.","tags":[],"title":"Bulk Editing Findings"},{"content":"Import the text output generated with bundle-audit check\nSample Scan Data Sample Bundler-Audit scans can be found here.\n","date":"0001-01-01","id":157,"permalink":"/en/connecting_your_tools/parsers/file/bundler_audit/","summary":"Import the text output generated with bundle-audit check\nSample Scan Data Sample Bundler-Audit scans can be found here.","tags":[],"title":"Bundler-Audit"},{"content":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML output.\nDastardly is a free, lightweight web application security scanner for your CI/CD pipeline. It is designed specifically for web developers, and checks your application for seven security issues that are likely to interest you during software development. Dastardly is based on the same scanner as Burp Suite (Burp Scanner).\nSample Scan Data Sample Burp Dastardly scans can be found here.\n","date":"0001-01-01","id":158,"permalink":"/en/connecting_your_tools/parsers/file/burp_dastardly/","summary":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML output.\nDastardly is a free, lightweight web application security scanner for your CI/CD pipeline.","tags":[],"title":"Burp Dastardly"},{"content":"File Types DefectDojo parser accepts a Standard Report as an HTML file. To parse an XML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp/\nSee also Burp documentation for info on how to export a Standard Report: https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nSample Scan Data Sample Burp Enterprise Scan scans can be found here.\n","date":"0001-01-01","id":159,"permalink":"/en/connecting_your_tools/parsers/file/burp_enterprise/","summary":"File Types DefectDojo parser accepts a Standard Report as an HTML file. To parse an XML file instead, use this method: https://documentation.","tags":[],"title":"Burp Enterprise Scan"},{"content":"Import the JSON data returned from the BurpSuite Enterprise GraphQL API. Append all the issues returned to a list and save it as the value for the key \u0026ldquo;Issues\u0026rdquo;. There is no need to filter duplicates, the parser will automatically combine issues with the same name.\nExample:\n{ \u0026#34;Issues\u0026#34;: [ { \u0026#34;issue_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Cross-site scripting (reflected)\u0026#34;, \u0026#34;description_html\u0026#34;: \u0026#34;Issue Description\u0026#34;, \u0026#34;remediation_html\u0026#34;: \u0026#34;Issue Remediation\u0026#34;, \u0026#34;vulnerability_classifications_html\u0026#34;: \u0026#34;\u0026lt;li\u0026gt;\u0026lt;a href=\\\u0026#34;https://cwe.mitre.org/data/definitions/79.html\\\u0026#34;\u0026gt;CWE-79: Improper Neutralization of Input During Web Page Generation (\u0026#39;Cross-site Scripting\u0026#39;)\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026#34;, \u0026#34;references_html\u0026#34;: \u0026#34;\u0026lt;li\u0026gt;\u0026lt;a href=\\\u0026#34;https://portswigger.net/web-security/cross-site-scripting\\\u0026#34;\u0026gt;Cross-site scripting\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026#34; }, \u0026#34;description_html\u0026#34;: \u0026#34;Details\u0026#34;, \u0026#34;remediation_html\u0026#34;: \u0026#34;Remediation Details\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;high\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/burp\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;https://portswigger.net\u0026#34;, \u0026#34;evidence\u0026#34;: [ { \u0026#34;request_index\u0026#34;: 0, \u0026#34;request_segments\u0026#34;: [ { \u0026#34;data_html\u0026#34;: \u0026#34;GET\u0026#34; }, { \u0026#34;highlight_html\u0026#34;: \u0026#34;data\u0026#34; }, { \u0026#34;data_html\u0026#34;: \u0026#34; HTTP More data\u0026#34; } ] }, { \u0026#34;response_index\u0026#34;: 0, \u0026#34;response_segments\u0026#34;: [ { \u0026#34;data_html\u0026#34;: \u0026#34;HTTP/2 200 OK \u0026#34; }, { \u0026#34;highlight_html\u0026#34;: \u0026#34;data\u0026#34; }, { \u0026#34;data_html\u0026#34;: \u0026#34;More data\u0026#34; } ] } ] } ] } Example GraphQL query to get issue details:\nquery Issue ($id: ID!, $serial_num: ID!) { issue(scan_id: $id, serial_number: $serial_num) { issue_type { name description_html remediation_html vulnerability_classifications_html references_html } description_html remediation_html severity path origin evidence { ... on Request { request_index request_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } ... on Response { response_index response_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } } } } Sample Scan Data Sample Burp GraphQL scans can be found here.\n","date":"0001-01-01","id":160,"permalink":"/en/connecting_your_tools/parsers/file/burp_graphql/","summary":"Import the JSON data returned from the BurpSuite Enterprise GraphQL API. Append all the issues returned to a list and save it as the value for the key \u0026ldquo;Issues\u0026rdquo;.","tags":[],"title":"Burp GraphQL"},{"content":"Import Burp REST API scan data in JSON format (/scan/[task_id] endpoint).\nSample Scan Data Sample Burp REST API scans can be found here.\n","date":"0001-01-01","id":161,"permalink":"/en/connecting_your_tools/parsers/file/burp_api/","summary":"Import Burp REST API scan data in JSON format (/scan/[task_id] endpoint).\nSample Scan Data Sample Burp REST API scans can be found here.","tags":[],"title":"Burp REST API"},{"content":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. To parse an HTML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp_enterprise/\nWhen the Burp report is generated, the recommended option is Base64 encoding both the request and response fields - e.g. check the box that says \u0026quot;Base64-encode requests and responses\u0026quot;. These fields will be processed and made available in the 'Finding View' page.\nSee also: Burp documentation - XML export is described under \u0026ldquo;Export Issue data\u0026rdquo;. https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nAcceptable XML Format All XML elements are required and will be parsed as strings.\n\u0026lt;issues burpVersion=\u0026#34;1.6.05\u0026#34; exportTime=\u0026#34;Sat Sep 13 22:39:44 CEST 2014\u0026#34;\u0026gt; \u0026lt;issue\u0026gt; \u0026lt;serialNumber\u0026gt;exampleSerialNumber\u0026lt;/serialNumber\u0026gt; \u0026lt;type\u0026gt;exampleTypeNumber\u0026lt;/type\u0026gt; \u0026lt;name\u0026gt;Example Issue Name\u0026lt;/name\u0026gt; \u0026lt;host ip=\u0026#34;192.168.187.137\u0026#34;\u0026gt;http://bwa\u0026lt;/host\u0026gt; \u0026lt;path\u0026gt;\u0026lt;![CDATA[/bodgeit/basket.jsp]]\u0026gt;\u0026lt;/path\u0026gt; \u0026lt;location\u0026gt;\u0026lt;![CDATA[/bodgeit/basket.jsp [b_id cookie]]]\u0026gt;\u0026lt;/location\u0026gt; \u0026lt;severity\u0026gt;Example Severity\u0026lt;/severity\u0026gt; \u0026lt;confidence\u0026gt;Firm\u0026lt;/confidence\u0026gt; \u0026lt;issueBackground\u0026gt;\u0026lt;![CDATA[Example issue background.]]\u0026gt;\u0026lt;/issueBackground\u0026gt; \u0026lt;remediationBackground\u0026gt;\u0026lt;![CDATA[Example remediation info.]]\u0026gt;\u0026lt;/issueDetail\u0026gt; \u0026lt;remediationDetail\u0026gt;\u0026lt;![CDATA[Example remediation details.]]\u0026gt;\u0026lt;/remediationDetail\u0026gt; \u0026lt;requestresponse\u0026gt; \u0026lt;request method=\u0026#34;POST\u0026#34; base64=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;![CDATA[exampleDataString=]]\u0026gt;\u0026lt;/request\u0026gt; \u0026lt;response base64=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;![CDATA[exampleBase64DataString]]\u0026gt;\u0026lt;/response\u0026gt; \u0026lt;responseRedirected\u0026gt;false\u0026lt;/responseRedirected\u0026gt; \u0026lt;/requestresponse\u0026gt; \u0026lt;/issue\u0026gt; ... \u0026lt;/issues\u0026gt;\rSample Scan Data Sample Burp scans can be found here.\n","date":"0001-01-01","id":162,"permalink":"/en/connecting_your_tools/parsers/file/burp/","summary":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. To parse an HTML file instead, use this method: https://documentation.","tags":[],"title":"Burp XML"},{"content":"Import JSON output of cargo-audit scan report https://crates.io/crates/cargo-audit\nSample Scan Data Sample CargoAudit Scan scans can be found here.\n","date":"0001-01-01","id":163,"permalink":"/en/connecting_your_tools/parsers/file/cargo_audit/","summary":"Import JSON output of cargo-audit scan report https://crates.io/crates/cargo-audit\nSample Scan Data Sample CargoAudit Scan scans can be found here.","tags":[],"title":"CargoAudit Scan"},{"content":"","date":"0001-01-01","id":164,"permalink":"/categories/","summary":"","tags":[],"title":"Categories"},{"content":"Here are the release notes for DefectDojo Pro (Cloud Version) releases. For Open Source release notes, please see the Releases page on GitHub.\nNov 17, 2024 Version 2.40.2\n(API) Added an API endpoint to get the DefectDojo version number: /api/v2/version (Pro) (API) Multiple Metadata objects can now be added to a single Endpoint, Finding or Product via POST or PATCH to /api/v2/metadata/ . Previously, only one Metadata key/value pair could be updated per call. (Beta UI) You can now Clear Alerts in the Beta UI. (Beta UI) Corrected an issue with Beta UIâ€™s form validation when trying to connect a Jira Project with an Engagement. (Beta UI) Fixed an issue in the Beta UI where new Product Tiles could not be created. (Reports) Changes have been made to the Report Generator\u0026rsquo;s description text to clarify how new reports are created from existing reports. (Findings) â€œVerifiedâ€ is now an optional status for many Finding workflows. This can be changed from the System Settings page in the Legacy UI (not yet implemented in Beta UI). (Tools) Update to AWS Prowler parser - can now handle the â€˜event_timeâ€™ parameter Nov 14, 2024 Version 2.40.1\n(API) Added a method to validate for file extensions, when \u0026lsquo;artifact\u0026rsquo; files are added to a test (images, for example) (Cloud Portal) Fixed an issue where QR codes were not being generated correctly for MFA setup. (Pro) (Dashboards) Insights dashboards can now filter by Product Tag (Pro) (Notifications) Added a new notification template for â€˜Engagement Closedâ€™ - Email, Alerts, Teams, Slack (Tools) Fixed an issue with the Burp Entreprise HTML parser not correctly handling certain reports (Tags) Tags are now forced to lowercase when created Nov 4, 2024 Version 2.40.0\n(API) Engagement_End_Date is now honored when submitted via /import /reimport endpoint. (API) Corrected an issue with the /import endpoint where old Findings were not being mitigated correctly. (Beta UI) Certain Error 400 notifications will now be displayed as â€˜toastsâ€™ in the beta UI with a better error description, rather than redirecting to a generic 400 page. (Beta UI) Dojo-CLI and Universal Importer are now available for download in-app. See External Tools menu in the top-right hand menu of the Beta UI. (Connectors) Multiple connectors of the same type can now be added. Each Connector will create a unique Engagement which will be populated with Findings. (Pro) (Connectors) AWS Security Hub connector can now find any AWS delegated accounts associated with a centralized account. All Security Hub Findings from a connector will be tagged with the appropriate AwsAccountId field, and additional Products can be added for each. (Pro) (CLI Tools) Dojo-CLI tool now available: a command-line tool which you can use to manage imports and exports to your Cloud instance. To get started, download the app from the External Tools menu. (Deduplication) Thereâ€™s no longer a brief service interruption when changes are applied to Deduplication Settings. Those changes can be applied without restarting the service. (Tools) Added a new parser for AWS Inspector2 Findings. Setting up multiple AWS Hub accounts with a Connector If you manage Security Hub findings for multiple accounts from a centralized administrator account, you will need to create the IAM user under that account and configure the Connector with it in order to retrieve findings from those sub-accounts with a single connector configuration.\n\u0026ldquo;Member\u0026rdquo; accounts (either invited manually or automatically associated when using AWS Organizations) will be detected by the Discover operation, and Products will be created for each of your account + region pairs based on the administrator account\u0026rsquo;s cross-region aggregation settings.\nSee this section of the AWS Docs about cross-region aggregation with multiple accounts for more information.\nOnce you have created your IAM user and assigned it the necessary permissions using an appropriate policy/role, you will need to generate an access key and provide the \u0026ldquo;Access Key\u0026rdquo; and \u0026ldquo;Secret Key\u0026rdquo; components in the relevant connector configuration fields. The \u0026ldquo;Location\u0026rdquo; field should be populated with the appropriate API endpoint for your region. For example, to retrieve results from the us-east-1 region, you would supply https://securityhub.us-east-1.amazonaws.com. Note that we rely on Security Hub\u0026rsquo;s cross-region aggregation to pull findings from more than one region. If cross-region aggregation is enabled, you should supply the API endpoint for your \u0026ldquo;Aggregation Region\u0026rdquo;. Additional linked regions will have ProductRecords created for them in DefectDojo based on your AWS account IDs and the region names. October 29, 2024 Version 2.39.4 / 2.39.3\n(API) Corrected \u0026lsquo;multiple positional arguments\u0026rsquo; issue with /import endpoint (Metrics) Dashboards can now handle multiple Products or Product Types simultaneously: this includes the Executive, Program, Remediation and Tool insights dashboards. (Pro) (Tools) OSV, Tenable parsers have been made more robust October 21, 2024 Version 2.39.1\n(Beta UI) Parent Object links have been added to the Metadata table to help contextualize the page you\u0026rsquo;re on (Beta UI) Improved \u0026ldquo;Toggle Columns\u0026rdquo; menu on tables (Beta UI) Added additional helptext for Simple Risk Acceptance, SLA Enforcement (Beta UI) Improved Test View with better Import History and Active Finding Severity Breakdown elements (Import) Development Environments which do not already exist can now be created via \u0026lsquo;auto create context\u0026rsquo; (Metrics) All Metrics dashboards can now be exported as a PDF (Remediation Insights, Program Insights, Tool Insights) (Pro) October 7, 2024 Version 2.39.0\n(Beta UI) Dropdown menus for Import Scan / Reimport Scan no longer block the active element of a form. (Beta UI) Finding counts by Severity now disregard Out Of Scope / False Positive Findings. (Dashboard) Tile filters with a Boolean filter of False are now saving correctly. E.G. If you tried to create a Tile with a filter condition of â€œHas Jira = Noâ€ previously this would not be applied correctly. (Jira) Added help text for \u0026lsquo;Push All Issues\u0026rsquo;. (Tools) AWS Security Hub EPSS score now parses correctly. September 30, 2024 Version 2.38.4\n(API) Object History can now be accessed via the API. (API Docs) Generating the response schema for certain API endpoints no longer breaks the Swagger interface. (Metrics) Added Executive Insights dashboard, Select a Product or Product type, and you can view an executive summary of that Product/Product Typeâ€™s security posture with relevant stats. (Pro) (Passwords) Password creation for new users can now be made optional upon request. This feature is toggled via the back-end. September 23, 2024 Version 2.38.3\n(API) /global_role endpoint now supports prefetching. (API) It is now possible to prefetch a Finding with attached files via API. (Login) A new \u0026ldquo;Forgot Username\u0026rdquo; link has been added to the login form. The link will navigate to a page which requests the user\u0026rsquo;s email address. The username will be sent to that address if it exists. Risk Acceptances Notes are now added to Findings when they are removed from Risk Acceptances. (Risk Acceptance) Risk Acceptance overhaul. Feature has been extended with new functions. See Risk Acceptance documentation for more details. Tools Qualys HackerGuardian parser added. Tools Semgrep Parser updated with new severity mappings. HackerOne parser updated and now supports bug bounty reports. Tools fixed an issue where certain tools would not process asyncronously: Whitehat_Sentinel, SSLyze, SSLscan, Qualys_Webapp, Mend, Intsights, H1, and Blackduck. September 16, 2024 Version 2.38.2\n(Beta UI) Jira integration in Beta UI now has parity with Legacy UI. Ability to Push To Jira has been added, and the Jira ticket view has been added to Findings, Engagements, and all other related objects in DefectDojo. (Finding SLAs) Added â€œMitigated Within SLAâ€ Finding filter, so that users can now count how many Findings were mitigated on time, and how many were not. Previously, we were only able to filter Findings that were currently violating SLA or not, rather than ones that had historically violated SLA or not. (Metrics) â€œMitigated Within SLAâ€ simple metric added to Remediation Insights page. (Reports) Custom Content text box no longer renders as HTML. (Tools) Wiz Parser now supports SCA format. (Tools) Fortify now supports a wider range of .fpr files. (Tools) Changed name of Netsparker Scan to Invicti Scan following their acquisition. Integrations that use the â€˜Netsparkerâ€™ terminology will still work as expected, but now â€˜Invictiâ€™ appears in our tools list. (Universal Importer) Tag Inheritance has been added to Universal Importer. Tags can now be added to Findings from that tool. (Pro) September 9, 2024 Version 2.39.1\n(Beta UI) Clearing a date filter and re-applying it no longer throws a 400 error. (Dashboard) Dashboard Tag Filters now work correctly in both legacy and beta UIs. (MFA) When an admin enforced Global MFA on a DefectDojo instance, there was a loop state that could occur with new users attempting to set up their accounts. This issue has been corrected, and new users can set a password before enabling MFA. (Permissions) When a user had permission to edit a Product, but not a Product Type, there was a bug where they were unable to submit an â€˜Edit Productâ€™ form (due to interaction with the Product Type). This has been corrected. (Reimport) Reimport now correctly records additional vulnerability IDs beyond 1. In the past, Findings that had more than one Vulnerability ID (a CVE, for example) would have those additional Vulnerability IDs discarded on reimport, so users were potentially losing those additional Vulnerability IDs. (Tools) Threat Composer parser added (Tools) Legitify parser added (Tools) EPSS score / percentile will now be imported from Aquasec files Sepember 3, 2024 Version 2.38.0\n(API) Better naming conventions on Mitigated and Discovered date filters: these are now labeled Mitigated/Discovered On, Mitigated/Discovered Before, Mitigated/Discovered After. (Beta UI) Pre-filtered Finding Routes added to Sidebar: you can now quickly filter for Active Findings, Mitigated Findings, All Risk Acceptances, All Finding Groups. (Beta UI) Beta UI Findings datatable can now apply every filter that the legacy UI could: filter Findings by (Last Reviewed, Mitigated Date, Endpoint Host, Reviewersâ€¦ etc). (Beta UI) Beta UI OAuth settings leading to a 404 loop - bug fixed and menu now works as expected. (Beta UI) Vulnerable Hosts page no longer returns 404. (Beta UI) Sorting the Findings data table by Reporter now functions correctly. (Connectors) Dependency-Track Connector now available. (Pro) (Deduplication Tuner) Deduplication Tuner now available in beta UI under Enterprise Settings \u0026gt; Deduplication Tuner. (Filters) Filtering Findings by Date now applies the filter as expected. (Filters) Sorting by Severity now orders by lowest-highest severity instead of alphabetically (Reimport) Reimporting Findings that have been Risk-Accepted no longer changes their status to â€˜Mitigatedâ€™. (Risk Acceptance) Updating the Simple Risk Acceptance or the Full Risk Acceptance flag on a Product now updates the Product as expected. August 28, 2024 Version 2.37.3\n(API) New Endpoint: /finding_groups allows you to GET, add Findings to, delete, or otherwise interact with Finding Groups. (Pro) (Beta UI) Relative date ranges for Findings have been added to Finding Filters (last 30 days, last 90 days, etc) (Beta UI) Bulk Edit / Risk Acceptance / Finding Group actions are now available in beta UI. (Beta UI) Finding Groups are now available in the beta UI. Selecting multiple Findings allows you to create a Finding Group, provided those Findings are in the same Test. (Beta UI) Enhanced Endpoint View now available in beta UI. (Beta UI) Jira Instances can now be added and edited via beta UI. (Connectors) SonarQube / SonarCloud Connector added. (Pro) (Questionnaires) Anonymous Questionnaires can now be added to an Engagement after they are completed. This solves an issue where users wanted to have their team complete questionnaires related to a Product without giving the user access to the complete Product on DefectDojo. (Reports) Report issue where images would disappear from reports has been corrected (SLAs) â€œSLA Violation in _ Daysâ€ notifications are no longer being sent for unenforced SLAs. (Tools) New Parser: AppCheck Web Application Scanning (Tools) Nmap Parser now handles script output August 7, 2024 Version Version 2.37.0\n(API) Created a method to handle simultaneous async reimports to the same Test via API (API) Minimum Severity flag now works as expected on /import, /reimport endpoints (Clearsale) (API) API errors now default to \u0026ldquo;Expose error details\u0026rdquo; (Beta UI) New Filter: by calculated SLA date (you can now filter for SLA due dates between a particular date range, for example) (Beta UI) New Filter: age of Finding (Beta UI) Improvements to pagination / loading behavior for large amounts of Findings (Beta UI) Added ability to Reimport Findings in new UI: (Connectors) Tenable Connector Released (Dashboard) Risk Acceptance tile now correctly filters Findings (Jira) Manually syncing multiple Findings with Jira (via Bulk Edit) now pushes notes correctly (Reports) Adding the WYSIWYG Heading to a Custom Report now applies a custom Header, instead of a generic â€˜WYSIWYG Headingâ€™ (SAML) Fixed issue where reconfiguring SAML could cause lockout (Tools) Wizcli Parser released (Tools) Rapplex Parser released (Tools) Kiuwan SCA Parser released (Tools) Test Types can now be set to Inactive so that they wonâ€™t appear in menus. This â€˜inactiveâ€™ setting can only be applied in the legacy UI, via Engagements \u0026gt; Test Types (or defectdojo.com/test_type) July 8, 2024 Version 2.36.0\n(Notifications) Improved email notifications with collapsible Finding lists for greater readability (SLAs) SLAs can now be optionally enforced. For each SLA associated with a Product you can set or unset the Enforce __ Finding Days box in the relevant SLA Configuration screen. When this box is unchecked, SLAs for Findings that match that Severity level will not be tracked or displayed in the UI. ","date":"0001-01-01","id":165,"permalink":"/en/changelog/changelog/","summary":"Here are the release notes for DefectDojo Pro (Cloud Version) releases. For Open Source release notes, please see the Releases page on GitHub.","tags":[],"title":"Changes \u0026 New Features"},{"content":" Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis) To generate the OSA report using Checkmarx CLI: ./runCxConsole.sh OsaScan -v -CxServer \u0026lt;...\u0026gt; -CxToken \u0026lt;..\u0026gt; -projectName \u0026lt;...\u0026gt; -enableOsa -OsaLocationPath \u0026lt;lib_folder\u0026gt; -OsaJson \u0026lt;output_folder\u0026gt;\nThat will generate three files, two of which are needed for defectdojo. Build the file for defectdojo with the jq utility: jq -s . CxOSAVulnerabilities.json CxOSALibraries.json\nData for SAST, SCA and KICS are supported.\nSample Scan Data Sample Checkmarx scans can be found here.\n","date":"0001-01-01","id":166,"permalink":"/en/connecting_your_tools/parsers/file/checkmarx/","summary":"Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis) To generate the OSA report using Checkmarx CLI: .","tags":[],"title":"Checkmarx"},{"content":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample Checkmarx One scans can be found here.\n","date":"0001-01-01","id":167,"permalink":"/en/connecting_your_tools/parsers/file/checkmarx_one/","summary":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample Checkmarx One scans can be found here.","tags":[],"title":"Checkmarx One Scan"},{"content":"File Types DefectDojo parser accepts Checkov scan data as a .JSON file.\nJSON files can be created from the Checkov CLI: https://www.checkov.io/2.Basics/CLI%20Command%20Reference.html\nAcceptable JSON Format { \u0026#34;check_type\u0026#34;: \u0026#34;terraform\u0026#34;, \u0026#34;results\u0026#34;: { \u0026#34;passed_checks\u0026#34;: [ ], \u0026#34;failed_checks\u0026#34;: [ { \u0026#34;check_id\u0026#34;: \u0026#34;CKV_AZURE_41\u0026#34;, \u0026#34;check_name\u0026#34;: \u0026#34;Ensure the key vault is recoverable\u0026#34;, \u0026#34;check_result\u0026#34;: { \u0026#34;result\u0026#34;: \u0026#34;FAILED\u0026#34; }, \u0026#34;code_block\u0026#34;: [ ], \u0026#34;file_path\u0026#34;: \u0026#34;file_path\u0026#34;, \u0026#34;file_line_range\u0026#34;: [ 1, 16 ], \u0026#34;resource\u0026#34;: \u0026#34;azurerm_key_vault.main\u0026#34;, \u0026#34;check_class\u0026#34;: \u0026#34;checkov.terraform.checks.resource.azure.KeyvaultRecoveryEnabled\u0026#34;, \u0026#34;guideline\u0026#34;: \u0026#34;https://docs.bridgecrew.io/docs/ensure-the-key-vault-is-recoverable\u0026#34; }, ... ], \u0026#34;skipped_checks\u0026#34;: [], \u0026#34;parsing_errors\u0026#34;: [] }, \u0026#34;summary\u0026#34;: { \u0026#34;passed\u0026#34;: 0, \u0026#34;failed\u0026#34;: 2, \u0026#34;skipped\u0026#34;: 0, \u0026#34;parsing_errors\u0026#34;: 0, \u0026#34;checkov_version\u0026#34;: \u0026#34;1.0.467\u0026#34; } }\rSample Scan Data Sample Checkov scans can be found here.\n","date":"0001-01-01","id":168,"permalink":"/en/connecting_your_tools/parsers/file/checkov/","summary":"File Types DefectDojo parser accepts Checkov scan data as a .JSON file.\nJSON files can be created from the Checkov CLI: https://www.","tags":[],"title":"Checkov Report"},{"content":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile Types DefectDojo parser accepts Chef Inspect log scan data as a .log or .txt file.\nSample Scan Data Sample Chef Inspect logs can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/chefinspect\n","date":"0001-01-01","id":169,"permalink":"/en/connecting_your_tools/parsers/file/chefinspect/","summary":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile Types DefectDojo parser accepts Chef Inspect log scan data as a .log or .","tags":[],"title":"Chef Inspect Log"},{"content":"You can import JSON reports of Docker image vulnerabilities found by a Clair scan or the Clair Klar client.\nSample Scan Data Sample Clair Scan scans can be found here.\n","date":"0001-01-01","id":170,"permalink":"/en/connecting_your_tools/parsers/file/clair/","summary":"You can import JSON reports of Docker image vulnerabilities found by a Clair scan or the Clair Klar client.\nSample Scan Data Sample Clair Scan scans can be found here.","tags":[],"title":"Clair Scan"},{"content":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON output.\nSample Scan Data Sample Cloudsploit (AquaSecurity) scans can be found here.\n","date":"0001-01-01","id":171,"permalink":"/en/connecting_your_tools/parsers/file/cloudsploit/","summary":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON output.\nSample Scan Data Sample Cloudsploit (AquaSecurity) scans can be found here.","tags":[],"title":"Cloudsploit (AquaSecurity)"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Cobalt.io\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your Cobalt.io API token in the API Key field and the desired org token in the Extras field.\nIn Add API Scan Configuration provide the ID of the asset from which to import findings in the field Service key 1. The ID can be found at the end of the URL when viewing the asset in your browser.\nIf you have more than one asset configured, you must also select which Cobalt.io API Scan Configuratio to use.\n","date":"0001-01-01","id":172,"permalink":"/en/connecting_your_tools/parsers/api/cobalt/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Cobalt.io API Import "},{"content":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found here.\n","date":"0001-01-01","id":173,"permalink":"/en/connecting_your_tools/parsers/file/cobalt/","summary":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found here.","tags":[],"title":"Cobalt.io Scan"},{"content":"Import Codechecker static analyzer report in JSON format: https://codechecker.readthedocs.io/en/latest/ Report format described here: https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#parse\nOne could make Codechecker JSON report using command like this:\nCodeChecker parse /path/to/codechecker/analyzer/output/directory -e json -o /path/to/output/file.json\rBefore this step you should build your project with Codechecker build process interception,\nodeChecker log -b \u0026#34;make -j8\u0026#34; -o ./my.project.codechecker.log\rthen analyze it\nCodeChecker analyze ./codechecker.log -o /path/to/codechecker/analyzer/output/directory\rSample Scan Data Sample Codechecker Report native scans can be found here.\n","date":"0001-01-01","id":174,"permalink":"/en/connecting_your_tools/parsers/file/codechecker/","summary":"Import Codechecker static analyzer report in JSON format: https://codechecker.readthedocs.io/en/latest/ Report format described here: https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#parse\nOne could make Codechecker JSON report using command like this:","tags":[],"title":"Codechecker Report native"},{"content":"CodeQL can be used to generate a SARIF report, that can be imported into Defect Dojo:\ncodeql database analyze db python-security-and-quality.qls --sarif-add-snippets --format=sarif-latest --output=security-extended.sarif\rThe same can be achieved by running the CodeQL GitHub action with the add-snippet property set to true.\n","date":"0001-01-01","id":175,"permalink":"/en/connecting_your_tools/parsers/file/codeql/","summary":"CodeQL can be used to generate a SARIF report, that can be imported into Defect Dojo:\ncodeql database analyze db python-security-and-quality.","tags":[],"title":"CodeQL"},{"content":"You will need Superuser access to use the System Settings page, which is required to complete this process.\nLike with Slack, Microsoft Teams can receive notifications to a specific channel. To do this, you will need to set up an incoming webhook on the channel where you wish to receive messages.\nComplete the process listed in the Microsoft Teams Documentation for creating a new Incoming Webhook. Keep your unique webhook.office.com link handy as you will need it in subsequent steps.\nâ€‹ 2. In DefectDojo, navigate to Configuration \u0026gt; System Settings from the sidebar. 3. Check the Enable Microsoft Teams notifications box. This will open a hidden section of the form, labeled â€˜Msteams urlâ€™.\nâ€‹\n4. Paste the webhook.office.com URL (created in Step 1) in the Msteams url box. Your Teams app will now listen to incoming Notifications from DefectDojo and post them to the channel you selected.\nNotes on the Teams integration Slack cannot apply any RBAC rules to the Teams channel that you are creating, and will therefore be sharing notifications for the entire DefectDojo system. There is no method in DefectDojo to filter system-wide Teams notifications by a Product Type, Product or Engagement. DefectDojo cannot send personal notifications to users on Microsoft Teams. ","date":"0001-01-01","id":176,"permalink":"/en/notifications/configure-a-microsoft-teams-integration/","summary":"You will need Superuser access to use the System Settings page, which is required to complete this process.\nLike with Slack, Microsoft Teams can receive notifications to a specific channel.","tags":[],"title":"Configure a Microsoft Teams Integration"},{"content":"DefectDojo can post Slack notifications in two different ways:\nSystem-wide notifications, which will be sent to a single Slack channel Personal notifications, which will only be sent to specific users. Here is an example of a Slack Notification sent from DefectDojo:\nâ€‹\nDefectDojo does not have a dedicated Slack app, but one can be easily created for your workspace by following this guide. A Slack app is required for both System and Personal notifications to be sent correctly.\nCreate a Slack application To set up a Slack connection to DefectDojo, youâ€™ll need to create a custom Slack app.\nBegin this process from the Slack Apps page: https://api.slack.com/apps. Click â€˜Create New Appâ€™. Select â€˜From App Manifestâ€™. Select your Slack workspace from the menu. Enter your App Manifest - you can copy and paste this JSON file, which includes all the permission settings required to allow the Slack integration to run.\nâ€‹ { \u0026#34;_metadata\u0026#34;: { \u0026#34;major_version\u0026#34;: 1, \u0026#34;minor_version\u0026#34;: 1 }, \u0026#34;display_information\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;DefectDojo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Notifications from DefectDojo. See https://support.defectdojo.com/en/articles/8863522-configure-slack for configuration steps.\u0026#34;, \u0026#34;background_color\u0026#34;: \u0026#34;#0000AA\u0026#34; }, \u0026#34;features\u0026#34;: { \u0026#34;bot_user\u0026#34;: { \u0026#34;display_name\u0026#34;: \u0026#34;DefectDojo Notifications\u0026#34; } }, \u0026#34;oauth_config\u0026#34;: { \u0026#34;scopes\u0026#34;: { \u0026#34;bot\u0026#34;: [ \u0026#34;chat:write\u0026#34;, \u0026#34;chat:write.customize\u0026#34;, \u0026#34;chat:write.public\u0026#34;, \u0026#34;incoming-webhook\u0026#34;, \u0026#34;users:read\u0026#34;, \u0026#34;users:read.email\u0026#34; ] }, \u0026#34;redirect_urls\u0026#34;: [ \u0026#34;https://slack.com/oauth/v2/authorize\u0026#34; ] } }\rReview the App Summary, and click Create App when youâ€™re done. Complete the installation by clicking the Install To Workplace button.\nConfigure your Slack integration in DefectDojo Youâ€™ll now need to configure the Slack integration on DefectDojo to complete the integration.\nYou will need Superuser access to access DefectDojo\u0026rsquo;s System Settings page.\nNavigate to the App Information page for your Slack App, from https://api.slack.com/apps. This will be the app that was created in the first section - Create a Slack application.\nâ€‹ Find your OAuth Access Token. This can be found in the Slack sidebar - Features / OAuth \u0026amp; Permissions. Copy the Bot User OAuth Token.\nâ€‹ 3. Open DefectDojo in a new tab, and navigate to Configuration \u0026gt; System Settings from the sidebar. 4. Check the Enable Slack notifications box. 5. Paste the Bot User OAuth Token from Step 1 in the Slack token field. 6. The Slack Channel field should correspond to the channel in your workspace where you want your notifications to be written by a DefectDojo bot. 7. If you want to change the name of the DefectDojo bot, you can enter a custom name here. If not, it will use DefectDojo Notifications as determined in the Slack App Manifest.\nOnce this process is complete, DefectDojo can send System-wide notifications to this channel. Select the Notifications which you want to send from the System Notifications page.\nNotes on System-Wide Notifications in Slack**:** Slack cannot apply any RBAC rules to the Slack channel that you are creating, and will therefore be sharing notifications for the entire DefectDojo system. There is no method in DefectDojo to filter system-wide Slack notifications to a Product Type, Product or Engagement.\nIf you want to apply RBAC-based filtering to your Slack messages, enabling personal notifications from Slack is a better option.\nSend Personal notifications to Slack If your team has a Slack integration enabled (through the above process), individual users can also configure notifications to send directly to your personal Slackbot channel.\nStart by navigating to your personal Profile page on DefectDojo. Find this by clicking the ðŸ‘¤ icon in the top-right corner. Select your DefectDojo Username from the list. (ðŸ‘¤ paul in our example)\nâ€‹ 2. Set your Slack Email Address in the menu. This field is nested underneath Additional Contact Information in DefectDojo.\nYou can now set specific notifications to be sent to your personal Slackbot channel. Other users on your Slack channel will not receive these messages.\n","date":"0001-01-01","id":177,"permalink":"/en/notifications/configure-a-slack-integration/","summary":"DefectDojo can post Slack notifications in two different ways:\nSystem-wide notifications, which will be sent to a single Slack channel Personal notifications, which will only be sent to specific users.","tags":[],"title":"Configure a Slack Integration"},{"content":"Users can connect to DefectDojo with a Username and Password, but if you prefer, you can allow users to authenticate using a Single Sign-On or SSO method. You can set up DefectDojo to work with your own SAML Identity Provider, but we also support many OAuth methods for authentication:\nAuth0 Azure AD GitHub Enterprise GitLab Google KeyCloak Okta All of these methods can only be configured by a Superuser in DefectDojo.\nâ€‹\nSet Up SAML Login If you would like to add DefectDojo to your SAML Identity Provider, here is the process to follow:\nStart from Plugin Manager \u0026gt; Enterprise Settings in DefectDojo.\nâ€‹ 2. Open the SAML tab from this page to configure your sign-on settings.\nâ€‹\n3. Complete the SAML form. Start by setting an Entity ID - this is either a label or a URL which your SAML Identity Provider can point to, and use to identify DefectDojo. This is a required field.\nâ€‹ 4. If you wish, set Login Button Text in DefectDojo. This text will appear on the button or link users click to initiate the login process.\nâ€‹ 5. You can also set a Logout URL to redirect your users to once they have logged out of DefectDojo.\nâ€‹ 6. The NameID Format has four options - Persistent, Transient, Entity and Encrypted.\nâ€‹\n- If you want your users to be consistently identified by SAML, use Persistent.\n- If you would prefer that users have a different SAML ID each time they access\nDefectDojo, choose Transient.\n- If youâ€™re ok with all of your users sharing a SAML NameID, you can select Entity.\n- If you would like to encrypt each userâ€™s NameID, you can use Encrypted as your NameID format.\nâ€‹ 7. Required Attributes are the attributes that DefectDojo requires from the SAML response.\nâ€‹ 8. Attribute Mapping contains a formula for how you want these attributes to be matched to a user. For example, if your SAML response returns an email, you can associate it with a DefectDojo user with the formula email=email.\nâ€‹\nThe left side of the â€˜=â€™ sign represents the attribute you want to map from the SAML response. The right side is a userâ€™s field in DefectDojo, which you want this attribute to map to.\nâ€‹\nThis is a required field for this form.\nâ€‹ 9. Remote SAML Metadata is the URL where your SAML Identity Provider is located.\nâ€‹ 10. If you would prefer to upload your own SAML Metadata, you can upload an XML file to Local SAML Metadata. You will need at least one metadata source before you can successfully use SAML.\nâ€‹ 11. Finally, check the Enable SAML checkbox at the bottom of this form to confirm that you want to use SAML to log in. Once this is enabled, you will see the Login With SAML button on the DefectDojo Login Page.\nAdditional SAML Options: Create Unknown User allows you to decide whether or not to automatically create a new user in DefectDojo if they arenâ€™t found in the SAML response.\nAllow Unknown Attributes allows you to authorize users who have attributes which are not found in the Attribute Mapping field.\nSign Assertions/Responses will require any incoming SAML responses to be signed.\nSign Logout Requests forces DefectDojo to sign any logout requests.\nForce Authentication determines whether you want to force your users to authenticate using your Identity Provider each time, regardless of existing sessions.\nEnable SAML Debugging will log more detailed SAML output for debugging purposes.\nSet up OAuth Login (Google, Gitlab, Auth0â€¦) Start by navigating to the Plugin Manager \u0026gt; Enterprise Settings page in DefectDojo.\nâ€‹ 2. From here, navigate to the OAuth tab and select the service you want to configure from the list.\nâ€‹\n3. Complete the relevant OAuth form.\nâ€‹ 4. Finally, check the Enable __ OAuth button from below, and click Submit.\nâ€‹\nUsers should now be able to sign in using the OAuth service you selected. A button will be added to the DefectDojo Login page to enable them to sign on using this method.\n","date":"0001-01-01","id":178,"permalink":"/en/user_management/configure-single-sign-on-login/","summary":"Users can connect to DefectDojo with a Username and Password, but if you prefer, you can allow users to authenticate using a Single Sign-On or SSO method.","tags":[],"title":"Configure Single-Sign On Login"},{"content":"DefectDojo has two different kinds of notifications: Personal (sent to a single account) and System (which are sent to all users).\nBoth your accountâ€™s Personal Notifications and the global System Notifications can be configured from the same page: âš™ï¸Configuration \u0026gt; Notifications in the sidebar.\nConfigure System notifications You will need Superuser access to change System-wide notifications.\nStart from the Notifications page (âš™ï¸ Configuration \u0026gt; Notifications in the sidebar). From the Scope drop down menu, you can select which set of notifications you wish to edit. Select System Notifications. Check the notification delivery method which you wish to use for each type of notification. You can select more than one. Configure Personal notifications Personal Notifications are sent in addition to System-Wide Notifications, and will apply to any Product, Product Type or other data type that you have access to. Personal Notification preferences only apply to a single user, and can only be set on the account which is configuring them.\nStart from the Notifications page (âš™ï¸Configuration \u0026gt; Notifications in the sidebar). From the Scope drop down menu, you can select which set of notifications you wish to edit. Select Personal Notifications. Check the notification method which you wish to use for each type of notification. You can select more than one. Personal Notifications cannot be sent via Microsoft Teams, as Teams only allows for posting Global notifications in a single channel.\nReceive Personal notifications for a specific Product In addition to standard personal notifications, DefectDojo Users can also receive notifications for activity on a specific Product. This is helpful when there are certain Products which a user needs to monitor more closely.\nThis configuration can be changed from the Notifications section on the Product page: e.g. your-instance.defectdojo.com/product/{id}.\nFrom here, you can set whether you want to receive ðŸ”” Alert, Mail or Slack notifications for actions taken on this particular Product. These notifications apply in addition to any system-wide notifications you are already receiving.\nMicrosoft Teams cannot send personal notifications of any kind, so Teams notifications cannot be chosen from this menu.\n","date":"0001-01-01","id":179,"permalink":"/en/notifications/configure-system--personal-notifications/","summary":"DefectDojo has two different kinds of notifications: Personal (sent to a single account) and System (which are sent to all users).","tags":[],"title":"Configure System \u0026 Personal Notifications"},{"content":"The Jira integration allows for bidirectional sync via webhook. DefectDojo receives Jira notifications at a unique address, which can allow for Jira comments to be received on Findings, or for Findings to be resolved via Jira depending on your configuration.\nLocating your Jira Webhook URL Your Jira Webhook is located on the System Settings form under Jira Integration Settings: Enterprise Settings \u0026gt; System Settings from the sidebar.\nConfiguring Jira to send updates to your Webhook Visit https:// \u0026lt;YOUR JIRA URL\u0026gt; /plugins/servlet/webhooks Click \u0026lsquo;Create a Webhook\u0026rsquo;. For the field labeled \u0026lsquo;URL\u0026rsquo; enter: https:// \u0026lt;YOUR DOJO DOMAIN\u0026gt; /jira/webhook/ \u0026lt;YOUR GENERATED WEBHOOK SECRET\u0026gt;. The Web Hook Secret is listed under the Jira Integration Settings as listed above. Under \u0026lsquo;Comments\u0026rsquo; enable \u0026lsquo;Created\u0026rsquo;. Under Issue enable \u0026lsquo;Updated\u0026rsquo;. Note that you do not need to create a Secret within Jira to use this webhook. The Secret is built into DefectDojo\u0026rsquo;s URL, so simply adding the complete URL to the Jira Webhook form is sufficient.\nDefectDojo\u0026rsquo;s Jira Webhook only accepts requests from the Jira API.\nTesting the Webhook Once you have one or more Issues created from DefectDojo Findings, you can test the Webhook by adding a Comment to one of those Findings. The Comment should be received by the Jira webhook as a note.\nIf this doesnâ€™t work correctly, it could be due to a Firewall issue on your Jira instance blocking the Webhook.\nDefectDojo\u0026rsquo;s Firewall Rules include a checkbox for Jira Cloud, which needs to be enabled before DefectDojo can receive Webhook messages from Jira. â€‹\n","date":"0001-01-01","id":180,"permalink":"/en/jira_integration/configuring-the-jira--defectdojo-webhook/","summary":"The Jira integration allows for bidirectional sync via webhook. DefectDojo receives Jira notifications at a unique address, which can allow for Jira comments to be received on Findings, or for Findings to be resolved via Jira depending on your configuration.","tags":[],"title":"Configuring the Jira \u003c\u003e DefectDojo Webhook"},{"content":"Jira Configurations are the starting point for DefectDojoâ€™s Jira integration. You can add multiple configurations to a DefectDojo instance, to allow for many different linked Jira Projects and boards.\nAdding a configuration does not cause any Findings to push right away - this is simply the first step. Once the Jira Configuration is created, it must be added to a Product before any information will push to Jira. See this guide for help with adding this integration to a Product.\nThe Jira Configuration Page The first step of setting up a Jira configuration is to add a Project to DefectDojo.\nIf you have not already done so, navigate to the System Settings page and check the box on Enable Jira Integration. You will need to do this before the âš™ï¸ Configuration \u0026gt; JIRA option shows up on the sidebar.\nâ€‹ Navigate to the âš™ï¸Configuration \u0026gt; JIRA page from the DefectDojo sidebar.\nâ€‹ â€‹ 3. You will see a list of all currently configured JIRA Projects which are linked to DefectDojo. To add a new Project Configuration, click the wrench icon and choose either the Add JIRA Configuration (Express) or Add JIRA Configuration options.\nAdd JIRA Configuration (Express) The Express method allows for a quicker method of linking a Project. Use the Express method if you simply want to connect a Jira Project quickly, and you arenâ€™t dealing with a complex Jira workflow.\nSelect a name for this Jira Configuration to use on DefectDojo.\nâ€‹ Select the URL for your companyâ€™s Jira instance - likely similar to https://yourcompany.atlassian.net if youâ€™re using a Jira Cloud installation.\nâ€‹ Enter your Username and Password for Jira. Alternatively, if your Jira instance uses a Personal Access Token (PAT) for authentication, you should instead enter the PAT in the Password field. The Username will not be used for authentication with PAT, but you can use this field as a label to indicate the name of the PAT you\u0026rsquo;re using.\nâ€‹ Select the Default issue type which you want to create Issues as in Jira. The options for this are Bug, Task, Story and Epic (which are standard Jira issue types) as well as Spike and Security, which are custom issue types. If you have a different Issue Type which you want to use, please contact support at defectdojo dot com\rfor assistance.\nâ€‹ Select your Issue Template - the two types are:\n- Jira_full, which will include all Finding information in Jira Issues\n- Jira_limited, which will include a smaller amount of Finding information and metadata.\nâ€‹\nIf you leave this field blank, it will default to Jira_full.\nâ€‹ Select one or more Jira Resolution types which will change the status of a Finding to Accepted (when the Resolution is triggered on the Issue). If you donâ€™t wish to use this automation, you can leave the field blank.\nâ€‹ Select one or more Jira Resolution types which will change the status of a Finding to False Positive (when the Resolution is triggered on the Issue). If you donâ€™t wish to use this automation, you can leave the field blank.\nâ€‹ Decide whether you wish to send SLA Notifications as a comment on a Jira issue.\nâ€‹ Decide whether you wish to automatically sync Findings with Jira. If this is enabled, Jira Issues will automatically be kept in sync with the related Findings. If this is not enabled, you will need to manually push any changes made to a Finding after the Issue has been created in Jira.\nâ€‹ Select your Issue key. In Jira, this is the string associated with an Issue (e.g. the word â€˜EXAMPLEâ€™ in an issue called EXAMPLE-123). If you donâ€™t know your issue key, create a new Issue in the Jira Project. In the screenshot below, we can see that the issue key on our Jira Project is DEF.\nâ€‹ â€‹ 11. Click Submit. DefectDojo will automatically look for appropriate mappings in Jira and add them to the configuration. You are now ready to link this configuration to one or more Products in DefectDojo.\nAdd Jira Configuration (Standard) The Standard Jira Configuration adds a few additional steps to allow for more precise control over Jira mappings and interactions. This can be changed after a Jira configuration has been added, even if it was created using the Express method.\nâ€‹\nAdditional Configuration Options Epic Name ID: If you have multiple Epic types in Jira, you can specify the one you want to use by finding its ID in the Jira Field Spec.\nâ€‹\nTo obtain the \u0026lsquo;Epic name id\u0026rsquo; visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/2/field and search for Epic Name. Copy the number out of cf[number] and paste it here.\nâ€‹\nâ€‹ Reopen Transition ID: If you want a specific Jira Transition to Reopen an issue, you can specify the Transition ID here. If using the Express Jira Configuration, DefectDojo will automatically find an appropriate Transition and create the mapping.\nâ€‹\nVisit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions? expand-transitions.fields to find the ID for your Jira instance. Paste it in the Reopen Transition ID field.\nâ€‹\nâ€‹ Close Transition ID: If you want a specific Jira Transition to Close an issue, you can specify the Transition ID here. If using the Express Jira Configuration, DefectDojo will automatically find an appropriate Transition and create the mapping.\nâ€‹\nVisit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions? expand-transitions.fields to find the ID for your Jira instance. Paste it in the Close Transition ID field.\nâ€‹\nâ€‹ Mapping Severity Fields: Each Jira Issue has an associated Priority, which DefectDojo will automatically assign based on the Severity of a Finding. Enter the names of each Priority which you want to map to, for Info, Low, Medium, High and Critical Severities.\nâ€‹\nâ€‹ Finding Text - if you want to add additional standardized text to each Issue created, you can enter that text here. This is not text that maps to any field in Jira, but additional text that is added to the Issue Description. \u0026ldquo;Created by DefectDojo\u0026rdquo; for example. Comments (in Jira) and Notes (in DefectDojo) can be kept in sync. This setting can be enabled once the Jira configuration has been added to a Product, via the Edit Product form.\nNext steps Now that you\u0026rsquo;ve set up your Jira Configuration, link it to one or more of your Products to have your Findings populate into Jira.\n","date":"0001-01-01","id":181,"permalink":"/en/jira_integration/connect-defectdojo-to-jira/","summary":"Jira Configurations are the starting point for DefectDojoâ€™s Jira integration. You can add multiple configurations to a DefectDojo instance, to allow for many different linked Jira Projects and boards.","tags":[],"title":"Connect DefectDojo to Jira"},{"content":"If you have difficulty accessing your DefectDojo instance, here are some steps you can follow to get reconnected:\nI can access the site, but I can\u0026rsquo;t log in You can reset the password for your account from the login page: yourcompanyinstance.cloud.defectdojo.com/login. Click \u0026lsquo;I forgot my password\u0026rsquo; in order to begin the process.\nâ€‹ 2. Enter your email address, and click \u0026ldquo;Reset my password\u0026rdquo;.\nâ€‹ 3. You should receive an email with the subject header \u0026ldquo;Password reset on yourcompanyinstance.cloud.defectdojo.com\u0026rdquo;. This email contains a link which you can click to set a new password.\nâ€‹\nIf you don\u0026rsquo;t receive an email, please check your Spam folder. Failing that, have your team\u0026rsquo;s DefectDojo admin confirm that you have an account registered on your instance.\nâ€‹\nI can\u0026rsquo;t access my company\u0026rsquo;s cloud.defectdojo site If your company\u0026rsquo;s cloud.defectdojo site does not load in your browser, or times out, it may be necessary for your company to change your firewall rules in order to accept your connection.\nFirewall rules can be changed in your Cloud Manager at https://cloud.defectdojo.com/accounts/manage_subscriptions.\nIf your company uses a shared VPN, proxy server or a similar tool, make sure itâ€™s authorized to connect to DefectDojo and that the IP address is included in DefectDojo\u0026rsquo;s Firewall rules.\nIf the problem persists, please contact support at defectdojo dot com\r.\nI can\u0026rsquo;t log in to the Cloud Manager If you canâ€™t access the Cloud Manager, navigate to the Login page at https://cloud.defectdojo.com/accounts/login/ and click â€œForgot your password?â€\nYouâ€™ll be prompted to enter your email address, and our team will send you an email with a link to reset your password and enter a new one.\nPlease note that this login method only works for the Cloud Manager, an admin site which your team members may not all have access to. Directly logging into your instance to use DefectDojo is only possible by directly connecting to yourcompanyinstance.cloud.defectdojo.com/login.\nI\u0026rsquo;ve lost access to my MFA codes For the Cloud Manager: If you lose access to your MFA codes, or Authenticator App, please contact DefectDojo Support at support at defectdojo dot com\r. For a DefectDojo Instance: It is not currently possible to remove MFA access from an account without an MFA code. The best option in this case is to create a new DefectDojo login, and re-grant all necessary permissions to this account. ","date":"0001-01-01","id":182,"permalink":"/en/cloud_management/connectivity-troubleshooting/","summary":"If you have difficulty accessing your DefectDojo instance, here are some steps you can follow to get reconnected:\nI can access the site, but I can\u0026rsquo;t log in You can reset the password for your account from the login page: yourcompanyinstance.","tags":[],"title":"Connectivity Troubleshooting"},{"content":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found here.\n","date":"0001-01-01","id":183,"permalink":"/en/connecting_your_tools/parsers/file/contrast/","summary":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found here.","tags":[],"title":"Contrast Scanner"},{"content":"","date":"0001-01-01","id":184,"permalink":"/contributors/","summary":"","tags":[],"title":"Contributors"},{"content":"Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\ndisplayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI) Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected\nSample Scan Data Sample Coverity API scans can be found here.\n","date":"0001-01-01","id":185,"permalink":"/en/connecting_your_tools/parsers/file/coverity_api/","summary":"Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\ndisplayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI) Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected","tags":[],"title":"Coverity API"},{"content":"File Types This DefectDojo parser accepts JSON files created from the Synopsys Coverity CLI using the following command: coverity scan.\nDocumentation for CLI can be found here.\nExample Commands to retrieve JSON output Run coverity scan --project-dir \u0026lt;project_dir\u0026gt; --local \u0026lt;result_file\u0026gt; --local-format json to create the JSON report.\nSample Scan Data Sample Coverity scans can be found here.\n","date":"0001-01-01","id":186,"permalink":"/en/connecting_your_tools/parsers/file/coverity_scan/","summary":"File Types This DefectDojo parser accepts JSON files created from the Synopsys Coverity CLI using the following command: coverity scan.","tags":[],"title":"Coverity Scan JSON Report"},{"content":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data Sample Crashtest Security scans can be found here.\n","date":"0001-01-01","id":187,"permalink":"/en/connecting_your_tools/parsers/file/crashtest_security/","summary":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data Sample Crashtest Security scans can be found here.","tags":[],"title":"Crashtest Security"},{"content":"If you have a significant number of DefectDojo users, you may want to create one or more Groups, in order to set the same Role-Based Access Control (RBAC) rules for many users simultaneously. Only Superusers can create User Groups.\nGroups can work in multiple ways:\nSet one, or many different Product or Product Type level Roles for all Group Members, allowing specific control over which Products or Product Types can be accessed and edited by the Group. Set a Global Role for all Group Members, giving them visibility and access to all Product or Product Types. Set Configuration Permissions for a Group, allowing them to change specific functionality around DefectDojo. For more information on Roles, please refer to our Introduction To Roles article.\nThe All Groups page From the sidebar, navigate to ðŸ‘¤Users \u0026gt; Groups to see a list of all active and inactive user groups.\nFrom here, you can create, delete or view your individual Group pages.\nCreating a new User Group Navigate to the ðŸ‘¤Users \u0026gt; Groups page on the sidebar. You will see a list of all existing User Groups, including their Name, Description, Number of Users, Global Role (if applicable) and Email.\nâ€‹ 2. Click the ðŸ› ï¸button next to the All Groups heading, and select + New Group.\nâ€‹\nâ€‹ 3. This will take you to a page where you can create a new Group. Set the Name for this Group, and add a Description if you wish.\nIf you want a weekly report sent to a particular Email address, you can enter that as well.\nYou can also select a Global Role that you wish to apply to this Group, if you wish. Adding a Global Role to the Group will give all Group Members access to all DefectDojo data, along with a limited amount of edit access depending on the Global Role you choose. See our Introduction To Roles article for more information.\nThe account that initially creates a Group will have an Owner Role for the Group by Default.\nViewing a Group Page Once you have created a Group, you can access it by selecting it in the menu listed under Users \u0026gt; Groups.\nThe Group Page can be customized with a Description.It features a list of all Group Members, as well as the assigned Products, Product Types, and the associated Role associated with each of these**.**\nYou can also see the Groupâ€™s Configuration Permissions listed here.\nManaging a Groupâ€™s Users Group Membership is managed from the individual Group page, which you can select from the list in the Users \u0026gt; Groups page. Click the highlighted Group Name to access the Group page that you wish to edit.\nIn order to view or edit a Groupâ€™s Membership, a User must have the appropriate Configuration permissions enabled as well as Membership in the Group (or Superuser status).\nAdd a User to a Group User Groups can have as many Users assigned as you wish. All Users in a Group will be given the associated Role on each Product or Product Type listed, but Users may also have Individual Roles which supersede the Group role.\nFrom the Group page, select + Add Users from the â˜° button at the edge of the Members heading.\nâ€‹ â€‹ 2. This will take you to the Add Some Group Members screen. Open the Users drop-down menu, and then check off each user that you wish to add to the Group.\nâ€‹\nâ€‹ 3. .Select the Group Role that you wish to assign these Users. This determines their ability to configure the Group.\nNote that adding a member to a Group will not allow them access to their own Group page by default. This is a separate Configuration permission which must be enabled first.\nEdit or Delete a Member from a User Group From the Group page, select the â‹® next to the Name of the User you wish to Edit or Delete from the Group. ðŸ“ Edit will take you to the Edit Member screen, where you can change this user\u0026rsquo;s Role (from Reader, Maintainer or Owner to a different choice).\nðŸ—‘ï¸ Delete removes a User\u0026rsquo;s Membership altogether. It will not remove any contributions or changes the User has made to the Product or Product Type.\n##\nManaging a Groupâ€™s Permissions Group Permissions are managed from the individual Group page, which you can select from the list in the Users \u0026gt; Groups page. Click the highlighted Group Name to access the Group page that you wish to edit.\nNote that only Superusers can edit a Groupâ€™s permissions (Product / Product Type, or Configuration).\nâ€‹\nAdd Product Roles or Product Type Roles for a Group You can register as many Product Roles or Product Type Roles as you wish in each Group.\nFrom the Group page, select + Add Product Types, or + Add Product from the relevant heading (Product Type Groups or Product Groups).\nâ€‹ 2. This will take you to a Register New Products / Product Types Page, where you can select a Product or Product Type to add from the drop-down menu.\n3. Select the Role that you want all Group members to have regarding this particular Product or Product Type.\nGroups cannot be assigned to Products or Product Types without a Role. If you\u0026rsquo;re not sure which Role you want a Group to have, Reader is a good \u0026lsquo;default\u0026rsquo; option. This will keep your Product state secure until you make your final decision about the Group Role.\nAssign Configuration Permissions to a Group If you want the Members in your Group to access Configuration functions, and control certain aspects of DefectDojo, you can assign these responsibilities from the Group page.\nAssign View, Add, Edit or Delete roles from the menu in the bottom-right hand corner. Checking off a Configuration Permission will immediately give the Group access to this particular function.\n","date":"0001-01-01","id":188,"permalink":"/en/user_management/create-a-user-group-for-shared-permissions/","summary":"If you have a significant number of DefectDojo users, you may want to create one or more Groups, in order to set the same Role-Based Access Control (RBAC) rules for many users simultaneously.","tags":[],"title":"Create a User Group for shared permissions"},{"content":"DefectDojoâ€™s API allows for robust pipeline solutions, which automatically ingest new scans to your instance. Automation like this can take a few different forms:\nA daily import which scans your environment on a daily basis, and then imports the results of the scan to DefectDojo (similar to our Connectors feature) A CI/CD pipeline which scans new code as it is deployed, and imports the results to DefectDojo as a triggered action These pipelines can be created by directly calling our API /reimport endpoint with an attached scan file in a way that closely resembles our Import Scan Form.\nUniversal Importer - out of the box CI/CD tool DefectDojo maintains a Universal Importer which can be set up with existing CI/CD pipelines, triggered via GitHub actions, or run in any other automated context. The Universal Importer runs in a separate container, and will call your DefectDojo instanceâ€™s API in the appropriate way.\nThe Universal Importer is a useful way to leverage the API without needing to create and maintain the necessary API calls in your own pipeline. This is generally a faster solution than writing your own code.\nIf you have an active DefectDojo subscription and want to request a copy of the Universal Importer, please contact us at support at defectdojo dot com\ralong with the operating system you want to use to run the tool.\nWorking with DefectDojoâ€™s API DefectDojoâ€™s API is documented in-app using the OpenAPI framework. You can access this documentation from the User Menu in the top right-hand corner, under â€˜API v2 OpenAPI3â€™.\n- The documentation can be used to test API calls with various parameters, and does so using your own userâ€™s API Token.\nIf you need to access an API token for a script or another integration, you can find that information under the API v2 Token option from the same menu.\nGeneral API Considerations Although our OpenAPI documentation is detailed regarding the parameters that can be used with each endpoint, it assumes that the reader has a solid understanding of DefectDojoâ€™s key concepts. (Product Hierarchy, Findings, Deduplication, etc). Users who want a working import integration but are less familiar with DefectDojo as a whole should consider our Universal Importer. DefectDojoâ€™s API can sometimes create unintended data objects, particularly if â€˜Auto-Create Contextâ€™ is used on the /import or /reimport endpoint. Fortunately, it is very difficult to accidentally delete data using the API. Most objects can only be removed using a dedicated DELETE call to the relevant endpoint. Specific notes on /import and /reimport endpoints The /reimport endpoint can be used for both an initial Import, or a â€œReimportâ€ which extends a Test with additional Findings. You do not need to first create a Test with /import before you can use the /reimport endpoint. As long as â€˜Auto Create Contextâ€™ is enabled, the /reimport endpoint can create a new Test, Engagement, Product or Product Type. In almost all cases, you can use the /reimport endpoint exclusively when adding data via API.\nHowever, the /import endpoint can instead be used for a pipeline where you always want to store each scan result in a discrete Test object, rather than using /reimport to handle the diff within a single Test object. Either option is acceptable, and the endpoint you choose depends on your reporting structure, or whether you need to inspect an isolated run of a Pipeline.\n","date":"0001-01-01","id":189,"permalink":"/en/connecting_your_tools/import_scan_files/api_pipeline_modelling/","summary":"DefectDojoâ€™s API allows for robust pipeline solutions, which automatically ingest new scans to your instance. Automation like this can take a few different forms:","tags":[],"title":"Creating an automated import pipeline via API"},{"content":"Normally, most of the Findings in your environment will be imported from other security tools. If you wish, you can add manual Finding entries as well, if you have vulnerabilities or work you wish to manage that was not created from a scan tool.\nFrom the DefectDojo Sidebar, open the New Finding link by clicking Manage \u0026gt; Findings \u0026gt; New Finding.\nâ€‹ â€‹ 2. This opens the New Finding form, which you can fill out with any relevant information surrounding your Finding. You will need to assign this Finding to a previously created Test in DefectDojo.\n","date":"0001-01-01","id":190,"permalink":"/en/working_with_findings/findings_workflows/creating-findings-manually/","summary":"Normally, most of the Findings in your environment will be imported from other security tools. If you wish, you can add manual Finding entries as well, if you have vulnerabilities or work you wish to manage that was not created from a scan tool.","tags":[],"title":"Creating Findings Manually"},{"content":"Before you can create an Issue in Jira, you\u0026rsquo;ll need to have\na Jira integration configured that same Jira integration linked to a Product Please see the guides above for help with this process.\nHow Findings are pushed to Jira A Product with a JIRA mapping can push Findings to Jira as Issues. This can be managed in two different ways:\nFindings can be created as Issues manually, per-Finding. Findings can be pushed automatically if the \u0026lsquo;Push All Issues\u0026rsquo; setting is enabled on a Product. (This applies only to Findings that are Active and Verified). Additionally, you have the option to push Finding Groups to Jira instead of individual Findings. This will create a single Issue which contains many related DefectDojo Findings.\nPushing a Finding to Jira Manually From a Finding page in DefectDojo, navigate to the JIRA heading. If the Finding does not already exist in JIRA as an Issue, the JIRA header will have a value of \u0026lsquo;None\u0026rsquo;.\nâ€‹ Clicking on the arrow next to the None value will create a new Jira issue. The State the issue is created in will depend on your team\u0026rsquo;s workflow and Jira configuration with DefectDojo. If the Finding does not appear, refresh the page.\nâ€‹\nâ€‹ â€‹ 3. Once the Issue is created, DefectDojo will create a link to the issue made up of the Jira key and the Issue ID. This link will also have a red trash can next to it, to allow you to delete the Issue from Jira.\nâ€‹\n4. Clicking the Arrow again will push all changes made to an issue to Jira, and update the Jira Issue accordingly. If \u0026lsquo;Push All Issues\u0026rsquo; setting is enabled on the Finding\u0026rsquo;s associated Product, this process will happen automatically.\nHow Jira Issues and Findings interact Jira issues will impact their associated Finding in certain ways.\nJira Comments If a comment is added to a Jira Issue, the same comment will be added to the Finding, under the Notes section. Likewise, if a Note is added to a Finding, the Note will be added to the Jira issue as a comment. Jira Status Changes The Jira Configuration on DefectDojo has entries for two Jira Transitions which will trigger a status change on a Finding.\nWhen the \u0026lsquo;Close\u0026rsquo; Transition is performed on Jira, the associated Finding will also Close, and become marked as Inactive and Mitigated on DefectDojo. DefectDojo will record this change on the Finding page under the Mitigated By heading.\nâ€‹ When the \u0026lsquo;Reopen\u0026rsquo; Transition is performed on the Jira Issue, the associated Finding will be set as Active on DefectDojo, and will lose its Mitigated status. Push Finding Groups as Jira Issues If you have Finding Groups enabled, you can push a Group of Findings to Jira as a single Issue rather than separate Issues for each Finding.\nThe Jira Issue associated with a Finding Group cannot be interacted with or deleted by DefectDojo, however. It must be deleted directly from the Jira instance.\nAutomatically Create and Push Finding Groups With Auto-Push To Jira Enabled, and a Group By option selected on import:\nAs long as the Finding Groups are being created successfully, the Finding Group is what will automatically push to Jira as an Issue, not the individual Findings.\nChange Jira settings for a specific Engagement Different Engagements within a Product can have different underlying Jira settings as a result. By default, Engagements will \u0026lsquo;inherit Jira settings from product\u0026rsquo;, meaning that they will share the same Jira settings as the Product they are nested under.\nHowever, you can change an Engagement\u0026rsquo;s Product Key, Issue Template, Custom Fields, Jira Labels, Default Assignee to be different from the default Product settings\nYou can access this page from the Edit Engagement page: your-instance.defectdojo.com/engagement/[id]/edit.\nThe Edit Engagement page can be found from the Engagement page, by clicking the â˜° menu next to the engagement\u0026rsquo;s Description.\n","date":"0001-01-01","id":191,"permalink":"/en/jira_integration/creating-issues-in-jira/","summary":"Before you can create an Issue in Jira, you\u0026rsquo;ll need to have\na Jira integration configured that same Jira integration linked to a Product Please see the guides above for help with this process.","tags":[],"title":"Creating Issues in Jira"},{"content":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan Report scans can be found here.\n","date":"0001-01-01","id":192,"permalink":"/en/connecting_your_tools/parsers/file/cred_scan/","summary":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan Report scans can be found here.","tags":[],"title":"CredScan Report"},{"content":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample Scan Data Sample Crunch42 Scan scans can be found here.\n","date":"0001-01-01","id":193,"permalink":"/en/connecting_your_tools/parsers/file/crunch42/","summary":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample Scan Data Sample Crunch42 Scan scans can be found here.","tags":[],"title":"Crunch42 Scan"},{"content":"CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.\nFrom: https://www.cyclonedx.org/\nExample with Anchore Grype:\n./grype defectdojo/defectdojo-django:1.13.1 -o cyclonedx \u0026gt; report.xml Example with cyclonedx-bom tool:\npip install cyclonedx-bom cyclonedx-py Usage: cyclonedx-py [OPTIONS] Options: -i \u0026lt;path\u0026gt; - the alternate filename to a frozen requirements.txt -o \u0026lt;path\u0026gt; - the bom file to create -j - generate JSON instead of XML Sample Scan Data Sample CycloneDX scans can be found here.\n","date":"0001-01-01","id":194,"permalink":"/en/connecting_your_tools/parsers/file/cyclonedx/","summary":"CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.","tags":[],"title":"CycloneDX"},{"content":"Import report in JSON generated with -j option\nSample Scan Data Sample DawnScanner scans can be found here.\n","date":"0001-01-01","id":195,"permalink":"/en/connecting_your_tools/parsers/file/dawnscanner/","summary":"Import report in JSON generated with -j option\nSample Scan Data Sample DawnScanner scans can be found here.","tags":[],"title":"DawnScanner"},{"content":"Import compliance, malware, secret, vulnerability reports from Deepfence Threatmapper in XLSX file format.\nSample Scan Data Sample Threatmapper scans can be found here. In this link are both .xlsx and .csv listed. They contain the same content, but csv can be read in the Browser, but only xlsx is supported by the parser.\n","date":"0001-01-01","id":196,"permalink":"/en/connecting_your_tools/parsers/file/deepfence_threatmapper/","summary":"Import compliance, malware, secret, vulnerability reports from Deepfence Threatmapper in XLSX file format.\nSample Scan Data Sample Threatmapper scans can be found here.","tags":[],"title":"Deepfence Threatmapper"},{"content":"If you have an excessive amount of duplicate Findings which you want to delete, you can set Delete Deduplicate Findings as an option in the System Settings.\nDelete Deduplicate Findings, combined with the Maximum Duplicates field allows DefectDojo to limit the amount of Duplicate Findings stored. When this field is enabled, DefectDojo will only keep a certain number of Duplicate Findings.\nWhich duplicates will be deleted? The original Finding will never be deleted automatically from DefectDojo, but once the threshold for Maximum Duplicates is crossed, DefectDojo will automatically delete the oldest Duplicate Finding.\nFor example, letâ€™s say that you had your Maximum Duplicates field set to â€˜1â€™.\nFirst, you import Test 1. Your report contains a vulnerability which is recorded as Finding A. Later, you import Test 2 contains the same vulnerability. This will be recorded as Finding B, and Finding B will be marked as a duplicate of Finding A. Later still, you import Test 3 which also contains that vulnerability. This will be recorded as Finding C, which will be marked as a duplicate of Finding A. At this time, Finding B will be deleted from DefectDojo as the threshold for maximum duplicates has been crossed. Applying this setting Applying Delete Deduplicate Findings will begin a deletion process immediately. This setting can be applied on the System Settings page. See Enabling Deduplication for more information.\n","date":"0001-01-01","id":197,"permalink":"/en/working_with_findings/finding_deduplication/delete-deduplicate-findings/","summary":"If you have an excessive amount of duplicate Findings which you want to delete, you can set Delete Deduplicate Findings as an option in the System Settings.","tags":[],"title":"Delete Deduplicate Findings"},{"content":"OWASP Dependency Check output can be imported in Xml format. This parser ingests the vulnerable dependencies and inherits the suppressions.\nSuppressed vulnerabilities are tagged with the tag: suppressed. Suppressed vulnerabilities are marked as mitigated. If the suppression is missing any \u0026lt;notes\u0026gt; tag, it tags them as no_suppression_document. Related vulnerable dependencies are tagged with related tag. Sample Scan Data Sample Dependency Check scans can be found here.\n","date":"0001-01-01","id":198,"permalink":"/en/connecting_your_tools/parsers/file/dependency_check/","summary":"OWASP Dependency Check output can be imported in Xml format. This parser ingests the vulnerable dependencies and inherits the suppressions.","tags":[],"title":"Dependency Check"},{"content":"Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format. See here for more info on this JSON format: https://docs.dependencytrack.org/integrations/file-formats/\nSample Scan Data Sample Dependency Track scans can be found here.\n","date":"0001-01-01","id":199,"permalink":"/en/connecting_your_tools/parsers/file/dependency_track/","summary":"Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format.","tags":[],"title":"Dependency Track"},{"content":"Import of JSON report from https://github.com/Yelp/detect-secrets\nSample Scan Data Sample Detect-secrets scans can be found here.\n","date":"0001-01-01","id":200,"permalink":"/en/connecting_your_tools/parsers/file/detect_secrets/","summary":"Import of JSON report from https://github.com/Yelp/detect-secrets\nSample Scan Data Sample Detect-secrets scans can be found here.","tags":[],"title":"Detect-secrets"},{"content":"Import JSON reports of OWASP docker-bench-security. docker-bench-security is a script that make tests based on CIS Docker Benchmark.\nSample Scan Data Sample docker-bench-security Scanner scans can be found here.\n","date":"0001-01-01","id":201,"permalink":"/en/connecting_your_tools/parsers/file/dockerbench/","summary":"Import JSON reports of OWASP docker-bench-security. docker-bench-security is a script that make tests based on CIS Docker Benchmark.\nSample Scan Data Sample docker-bench-security Scanner scans can be found here.","tags":[],"title":"docker-bench-security Scanner"},{"content":"Import JSON container image linter reports https://github.com/goodwithtech/dockle\nSample Scan Data Sample Dockle Report scans can be found here.\n","date":"0001-01-01","id":202,"permalink":"/en/connecting_your_tools/parsers/file/dockle/","summary":"Import JSON container image linter reports https://github.com/goodwithtech/dockle\nSample Scan Data Sample Dockle Report scans can be found here.","tags":[],"title":"Dockle Report"},{"content":"Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nSample Scan Data Sample DrHeader scans can be found here.\n","date":"0001-01-01","id":203,"permalink":"/en/connecting_your_tools/parsers/file/drheader/","summary":"Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nSample Scan Data Sample DrHeader scans can be found here.","tags":[],"title":"DrHeader"},{"content":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample Scan Data Sample DSOP Scan scans can be found here.\n","date":"0001-01-01","id":204,"permalink":"/en/connecting_your_tools/parsers/file/dsop/","summary":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample Scan Data Sample DSOP Scan scans can be found here.","tags":[],"title":"DSOP Scan"},{"content":"Import Edgescan vulnerabilities by API or JSON file\nAll parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nStep 1: Add tool configuration\nSelect the gear icon from the left hand side of the page. Click on the Tool Configuration option and then + Add Tool Configuration from the dropdown menu. Once presented with a series of fields, set Tool Type to \u0026ldquo;Edgescan\u0026rdquo; and Authentication Type to \u0026ldquo;API Key\u0026rdquo;. Paste your Edgescan API key in the API Key field. Click on the Submit button. Step 2: Add and configure a product\nSelect the hamburger menu icon from the left hand side of the page. Click on the All Products option and then + Add Product. Fill in the fields presented. Once the product is added, click on the Settings option then Add API Scan Configuration. Select the previously added Edgescan Tool Configuration. Provide the edgescan asset ID(s) that you wish to import the findings for in the field Service key 1. Note that multiple asset IDs should be comma separated with no spacing. If you want to import vulnerabilities for all assets, simply leave the Service key 1 field empty. Step 3: Importing scan results\nAfter the previous steps are complete, you can import the findings by selecting the Findings option on the product\u0026rsquo;s page and then Import Scan Results. Once you are presented with a series of fields, select Edgescan Scan as the scan type. If you have more than one asset configured, you must also select which Edgescan API Scan Configuration to use. Click on the Import button. Important Reminder:\nTo ensure you\u0026rsquo;re not introducing duplicate vulnerabilities, always use the \u0026ldquo;Re-Upload Scan\u0026rdquo; option when re-importing findings from Edgescan. This can be found within the engagement\u0026rsquo;s options by clicking on Engagements , then the active engagement in question, then Edgescan Scan and selecting \u0026ldquo;Re-Upload Scan\u0026rdquo; from the dropdown menu located on the right. ","date":"0001-01-01","id":205,"permalink":"/en/connecting_your_tools/parsers/api/edgescan/","summary":"Import Edgescan vulnerabilities by API or JSON file\nAll parsers which using API have common basic configuration step but with different values.","tags":[],"title":"Edgescan"},{"content":"Import Edgescan vulnerabilities by JSON file or API - no file required\n","date":"0001-01-01","id":206,"permalink":"/en/connecting_your_tools/parsers/file/edgescan/","summary":"Import Edgescan vulnerabilities by JSON file or API - no file required","tags":[],"title":"Edgescan"},{"content":"Records can be Edited, Ignored or Deleted from the Manage Records \u0026amp; Operations Page.\nAlthough Mapped and Unmapped records are located in separate tables, they can both be edited in the same way.\nFrom the Records table, click the blue â–¼ Arrow next to the State column on a given Record. From there, you can select Edit Record, or Delete Record.\nEdit a Record Clicking Edit Record will open a window which allows you to change the destination product in DefectDojo. You can either select an existing Product from the drop-down menu, or you can type in the name of a new Product you wish to create.\nChange the Mapping of a Record The scan data associated with a Record can be directed to flow into a different Product by changing the mapping.\nSelect, or type in the name of a new Product from the drop-down menu to the right.\nEdit the State of a Record The State of a Record can be changed from this menu as well. Records can be switched from Good to Ignored (or vice versa) by choosing an option from the State dropdown list.\nIgnoring a Record If you wish to â€˜switch offâ€™ one of the records or disregard the data itâ€™s sending to DefectDojo, you can choose to â€˜Ignoreâ€™ the record. An â€˜Ignoredâ€™ record will move to the Unmapped Records list and will not push any new data to DefectDojo.\nYou can Ignore a Mapped Record (which will remove the mapping), or a New Record (from the unmapped Records list).\nRestoring an Ignored Record If you would like to remove the Ignored status from a record, you can change it back to New with the same State dropdown menu.\nIf Auto-Map Records is enabled, the Record will return to its original mapping once the Discover operation runs again.\nâ€‹ If Auto-Map Records is not enabled, DefectDojo will not automatically restore a previous mapping, so youâ€™ll need to set up the mapping for this Record again. Delete a Record You can also Delete Records, which will remove them from the Unmapped or Mapped Records table.\nKeep in mind that the Discover function will always import all records from a tool - meaning that even if a Record is deleted from DefectDojo, it will become re-discovered later (and will return to the list of Records to be mapped again).\nIf you plan on removing the underlying Vendor-Equivalent Product from your scan tool, then Deleting the Record is a good option. Otherwise, the next Discover operation will see that the associated data is missing, and this Record will change state to \u0026lsquo;Missing\u0026rsquo;.\nâ€‹ However, if the underlying Vendor-Equivalent Product still exists, it will be Discovered again on a future Discover operation. To prevent this behaviour, you can instead Ignore the Record. Does this affect any imported data? No. All Findings, Tests and Engagements created by a sync record will remain in DefectDojo even after a Record is deleted. Deleting a record or a configuration will only remove the data-flow process, and wonâ€™t delete any vulnerability data from DefectDojo or your tool.\nNext Steps If your Records have been mapped, learn how to import data via Sync operations. ","date":"0001-01-01","id":207,"permalink":"/en/connecting_your_tools/connectors/edit_ignore_delete_records/","summary":"Records can be Edited, Ignored or Deleted from the Manage Records \u0026amp; Operations Page.\nAlthough Mapped and Unmapped records are located in separate tables, they can both be edited in the same way.","tags":[],"title":"Edit, Ignore or Delete Records"},{"content":"If you want to add notes or update the language on a Finding to be more relevant to the current situation, you can do so through the Edit Finding form.\nOpening the Edit Finding Form You can update a Finding by opening the âš™ï¸ Gear Menu in the top and clicking Edit Finding.\nThis will open the Edit Finding form, where you can edit the metadata, change the Findingâ€™s Status and add additional information.\nEdit Finding Form: Fields \u0026ldquo;Test\u0026rdquo; cannot be edited: Findings always have to be associated with a Test object, and cannot be moved out of that context. However, the Engagement containing a Test can be moved to another Product.\nâ€‹ Found By is the scan tool which discovered this Finding. Note that you can add additional scan tools beyond the tool associated with the Test.\nâ€‹ Title is created from the scan report, but you can edit this title to be more meaningful if you need to. Note that this may affect Deduplication, as Deduplication generally uses the titles of Findings to identify duplicates.\nâ€‹ Date is meant to represent the date the Finding was uncovered by the scanner - not necessarily the date the Finding was imported into DefectDojo. This date is pulled from the scan report, but you can update this date to be more accurate if you need to (for example, if working with historical data, or if using a scanning tool which does not log discovery dates).\nâ€‹ Description is the description of a Finding provided by the scan tool. You can add or remove information from the Finding Description if you wish.\nâ€‹ Severity is calculated based on several factors. At a base level, this will be the Severity reported by a tool, but a Findingâ€™s Severity can be affected by EPSS changes. You can also manually adjust the Findingâ€™s Severity to an appropriate level.\nâ€‹ Tags are generic text labels that you can use to organize your Findings via Filters - or they can simply be used as shorthand to identify a specific Finding.\nâ€‹ Active / Verified are the primary Finding statuses used by a tool. Active Findings are Findings that are currently active in your network and have been reported by a tool. Verified means that this Finding has been confirmed to exist by a team member.\nâ€‹ SAST / DAST are labels used to organize your Findings into the context they were discovered in. Generally, this label is populated based on the scanning tool used, but you can adjust this to a more accurate level (for example, if the Finding was found by both a SAST and a DAST tool). ","date":"0001-01-01","id":208,"permalink":"/en/working_with_findings/findings_workflows/editing-findings/","summary":"If you want to add notes or update the language on a Finding to be more relevant to the current situation, you can do so through the Edit Finding form.","tags":[],"title":"Editing Findings"},{"content":"Rather than Deduplicating across an entire Product, you can set a deduplication scope to be within a single Engagement exclusively.\nNavigating to the Edit Engagement page To enable Deduplication within a New Engagement, start with the + New Engagement option from the sidebar, which you can find by opening the ðŸ“¥Engagements sub-menu.\nâ€‹ â€‹\nTo enable Deduplication within an existing Engagement: from the All Engagements page, select the Edit Engagement option from the â‹® menu.\nâ€‹ You can also open this menu from a specific Engagement Page by clicking the âš™ï¸Gear icon in the top-right hand corner.\nâ€‹ Completing the Edit Engagement form Start by opening the Optional Fields + menu at the bottom of the Edit Engagement form. Click the â˜ Deduplication Within This Engagement box. Submit the form. ","date":"0001-01-01","id":209,"permalink":"/en/working_with_findings/finding_deduplication/enabling-deduplication-within-an-engagement/","summary":"Rather than Deduplicating across an entire Product, you can set a deduplication scope to be within a single Engagement exclusively.","tags":[],"title":"Enabling Deduplication within an Engagement"},{"content":"Deduplication can be implemented at either a Product level or at a more narrow Engagement level. This article describes the more common approach of deduplicating within a single Product.\nStart by navigating to the System Settings page. This is nested under Settings \u0026gt; Pro Settings \u0026gt; âš™ï¸System Settings on the sidebar. 2. Deduplication and Finding Settings are at the top of the System Settings menu.\nâ€‹\nEnable Finding Deduplication Enable Finding Deduplication will turn on the Deduplication Algorithm for all Findings. Deduplication will be triggered on all subsequent imports - when this happens, DefectDojo will look at any Findings contained in the destination Product, and deduplicate as per your settings.\nDelete Deduplicate Findings Delete Deduplicate Findings, combined with the Maximum Duplicates field allows DefectDojo to limit the amount of Duplicate Findings stored. When this field is enabled, DefectDojo will only keep a certain number of Duplicate Findings.\nApplying Delete Deduplicate Findings will begin a deletion process immediately. DefectDojo will look at each Finding with Duplicates recorded, and will delete old duplicate Findings until the Maximum Duplicate number has been reached.\nFor more information on how DefectDojo determines what to delete, see our guide to Deleting Deduplicate Findings.\n","date":"0001-01-01","id":210,"permalink":"/en/working_with_findings/finding_deduplication/enabling-product-level-deduplication/","summary":"Deduplication can be implemented at either a Product level or at a more narrow Engagement level. This article describes the more common approach of deduplicating within a single Product.","tags":[],"title":"Enabling Product-Level Deduplication"},{"content":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint scans can be found here.\n","date":"0001-01-01","id":211,"permalink":"/en/connecting_your_tools/parsers/file/eslint/","summary":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint scans can be found here.","tags":[],"title":"ESLint"},{"content":"Each Finding created in DefectDojo has a Status which communicates relevant information. Statuses help your team keep track of their progress in resolving issues.\nEach Finding status has a context-specific meaning which will need to be defined by your own team. These are our suggestions, but your team\u0026rsquo;s usage may vary.\nActive Findings â€˜This Finding has been discovered by a scanning tool.â€™\nBy default, any new Finding created in DefectDojo will be labeled as Active. Active in this case means â€˜this is a new Finding that DefectDojo has not recorded on a past importâ€™. If a Finding has been Mitigated in the past, but appears in a scan again in the future, the status of that Finding will reopen to reflect that the vulnerability has returned.\nVerified Findings â€˜This Finding has been confirmed by our team to exist.â€™\nJust because a tool records a problem does not necessarily mean the Finding requires engineering attention. Therefore, new Findings are also labeled as Unverified by default.\nIf youâ€™re able to confirm that the Finding does exist, you can mark it as Verified.\nIf you donâ€™t need to manually verify each Finding, you can automatically mark them as Verified during import, or disregard this Status.\nOpen Findings â€˜There is work to be done on these Findings.â€™\nOnce a Finding is Active, it will be labeled as an Open Finding, regardless of whether or not it has been Verified.\nOpen Findings can be seen from the Findings \u0026gt; Open Findings view of DefectDojo.\nClosed Findings **â€˜**The Vulnerability recorded here is no longer activeâ€™.\nOnce the work on a Finding is complete, you can manually Close it from the Close Findings option. Alternatively, if a scan is re-imported into DefectDojo which does not contain a previously-recorded Finding, the previously-recorded Finding will automatically close.\nUnder Review â€˜I have sent this Finding to one or more team members to look at.â€™\nWhen a Finding is Under Review, it needs to be reviewed by a team member. You can put a Finding under review by Selecting Request Peer Review from the Findingâ€™s drop-down menu.\nRisk Accepted â€˜Our team has evaluated the risk associated with this Finding, and weâ€™ve agreed that we can safely delay fixing it.â€™\nFindings cannot always be remediated or addressed for various reasons. You can add a Risk Acceptance to a Finding with the Add Risk Acceptance option. Risk Acceptances allow you to upload files and enter notes to support a Risk Acceptance decision.\nRisk Acceptances have expiry dates, at which time you can reevaluate the impact of the Finding and decide what to do next.\nOut Of Scope â€˜This Finding was discovered by our scanning tool, but detecting this kind of vulnerability was not the direct goal of our test.â€™\nWhen you mark a Finding as Out Of Scope, you are indicating that it is not directly relevant to the Engagement or Test it is contained within.\nIf you have a testing and remediation effort related to a specific aspect of your software, you can use this Status to indicate that this Finding is not part of your effort.\nFalse Positive â€˜This Finding was discovered by our scanning tool, but after reviewing the Finding we have discovered that this reported vulnerability does not exist.â€™\nOnce youâ€™ve reviewed a Finding, you might discover that the vulnerability reported does not actually exist. The False Positive status allows DefectDojo to keep track of this information, and future imports will also apply the False Positive status to this Finding.\nIf a different scanning tool finds a similar Finding, it will not be recorded as a False Positive. DefectDojo can only compare Findings within the same tool to determine if a Finding has already been recorded.\nInactive â€˜This Finding was discovered previously but it was either mediated or does not require immediate attention.â€™\nIf a Finding is marked as Inactive, this means that the issue currently has no impact on the software environment and does not need to be addressed. This status does not necessarily mean that the issue has been resolved.\n","date":"0001-01-01","id":212,"permalink":"/en/working_with_findings/finding-status-definitions/","summary":"Each Finding created in DefectDojo has a Status which communicates relevant information. Statuses help your team keep track of their progress in resolving issues.","tags":[],"title":"Finding Status Definitions"},{"content":"You can either import the findings in .xml or in .fpr file format. If you import a .fpr file, the parser will look for the file \u0026lsquo;audit.fvdl\u0026rsquo; and analyze it. An extracted example can be found here.\nSample Scan Data Sample Fortify scans can be found here.\nGenerate XML Output from Foritfy This section describes how to import XML generated from a Fortify FPR. It assumes you already have, or know how to acquire, an FPR file. Once you have the FPR file you will need use Fortify\u0026rsquo;s ReportGenerator tool (located in the bin directory of your fortify install). FORTIFY_INSTALL_ROOT/bin/ReportGenerator\nBy default, the Report Generator tool does not display all issues, it will only display one per category. To get all issues, copy the DefaultReportDefinitionAllIssues.xml to:\nFORTIFY_INSTALL_ROOT/Core/config/reports\nOnce this is complete, you can run the following command on your .fpr file to generate the required XML:\n./path/to/ReportGenerator -format xml -f /path/to/output.xml -source /path/to/downloaded/artifact.fpr -template DefaultReportDefinitionAllIssues.xml\r","date":"0001-01-01","id":213,"permalink":"/en/connecting_your_tools/parsers/file/fortify/","summary":"You can either import the findings in .xml or in .fpr file format. If you import a .fpr file, the parser will look for the file \u0026lsquo;audit.","tags":[],"title":"Fortify"},{"content":"Import Generic findings in CSV or JSON format.\nAttributes supported for CSV:\nDate: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value. Url: Url associated with the finding. Severity: Severity of the finding. Must be one of Info, Low, Medium, High, or Critical. Description: Description of the finding. Can be multiple lines if enclosed in double quotes. Mitigation: Possible Mitigations for the finding. Can be multiple lines if enclosed in double quotes. Impact: Detailed impact of the finding. Can be multiple lines if enclosed in double quotes. References: References associated with the finding. Can be multiple lines if enclosed in double quotes. Active: Indicator if the finding is active. Must be empty, TRUE or FALSE Verified: Indicator if the finding has been verified. Must be empty, TRUE, or FALSE FalsePositive: Indicator if the finding is a false positive. Must be TRUE, or FALSE. Duplicate:Indicator if the finding is a duplicate. Must be TRUE, or FALSE The CSV expects a header row with the names of the attributes.\nExample of JSON format:\n{ \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as dict\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars Ã  qu\u0026#39;il est beau\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36234\u0026#34;, \u0026#34;cwe\u0026#34;: 261, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/first.cpp\u0026#34;, \u0026#34;line\u0026#34;: 13, \u0026#34;endpoints\u0026#34;: [ { \u0026#34;host\u0026#34;: \u0026#34;exemple.com\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as strings\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars Ã  qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36235\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/two.cpp\u0026#34;, \u0026#34;line\u0026#34;: 135, \u0026#34;endpoints\u0026#34;: [ \u0026#34;http://urlfiltering.paloaltonetworks.com/test-command-and-control\u0026#34;, \u0026#34;https://urlfiltering.paloaltonetworks.com:2345/test-pest\u0026#34; ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars Ã  qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36236\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/threeeeeeeeee.cpp\u0026#34;, \u0026#34;line\u0026#34;: 1353 } ] }\rThis parser supports an attributes that accept files as Base64 strings. These files are attached to the respective findings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Vuln with image\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;files\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Screenshot from 2017-04-10 16-54-19.png\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;iVBORw0KGgoAAAANSUhEUgAABWgAAAK0CAIAAAARSkPJAAAAA3N\u0026lt;...\u0026gt;TkSuQmCC\u0026#34; } ] } ] }\rThis parser supports an attribute name and type to be able to define TestType. Based on this, you can define custom HASHCODE_FIELDS or DEDUPLICATION_ALGORITHM in the settings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;My custom Test type\u0026#34;, \u0026#34;findings\u0026#34;: [ ] }\rSample Scan Data Sample Generic Findings Import scans can be found here.\n","date":"0001-01-01","id":214,"permalink":"/en/connecting_your_tools/parsers/file/generic/","summary":"Import Generic findings in CSV or JSON format.\nAttributes supported for CSV:\nDate: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value.","tags":[],"title":"Generic Findings Import"},{"content":"Import Ggshield findings in JSON format.\nSample Scan Data Sample Ggshield scans can be found here.\n","date":"0001-01-01","id":215,"permalink":"/en/connecting_your_tools/parsers/file/ggshield/","summary":"Import Ggshield findings in JSON format.\nSample Scan Data Sample Ggshield scans can be found here.","tags":[],"title":"Ggshield"},{"content":"Import findings from Github vulnerability scan (GraphQL Query): https://help.github.com/en/github/managing-security-vulnerabilities\nCurrently the parser is able to manage only RepositoryVulnerabilityAlert object. The parser has some kind of search feature which detect the data in the report.\nHere is the mandatory objects and attributes:\nvulnerabilityAlerts (RepositoryVulnerabilityAlert object) + id + createdAt (optional) + vulnerableManifestPath + state (optional) + securityVulnerability (SecurityVulnerability object) + severity (CRITICAL/HIGH/LOW/MODERATE) + package (optional) + name (optional) + advisory (SecurityAdvisory object) + description + summary + description + identifiers + value + references (optional) + url (optional) + cvss (optional) + score (optional) + vectorString (optional) + cwes (optional)\rReferences:\nhttps://docs.github.com/en/graphql/reference/objects#repositoryvulnerabilityalert https://docs.github.com/en/graphql/reference/objects#securityvulnerability Github v4 graphql query to fetch data, with extended information like the repository name and url, alert number.\nquery getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } Another example of Python script, to have a function that queries any repository, with support for paginated responses and get all findings. Has a filter to only get OPEN dependabot alerts but this can be removed in the GraphQL query\ndef make_query(after_cursor=None): return \u0026#34;\u0026#34;\u0026#34; query getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } \u0026#34;\u0026#34;\u0026#34;.replace( \u0026#34;AFTER\u0026#34;, \u0026#39;\u0026#34;{}\u0026#34;\u0026#39;.format(after_cursor) if after_cursor else \u0026#34;null\u0026#34; ) # accumulates all pages data into a single object def get_dependabot_alerts_repository(repo, owner): keep_fetching = True after_cursor = None output_result = {\u0026#34;data\u0026#34;: {\u0026#34;repository\u0026#34;: {\u0026#34;vulnerabilityAlerts\u0026#34;: {\u0026#34;nodes\u0026#34;: []}}}} while keep_fetching: headers = {\u0026#34;Authorization\u0026#34;: AUTH_TOKEN} request = requests.post( url=\u0026#34;https://api.github.com/graphql\u0026#34;, json={ \u0026#34;operationName\u0026#34;: \u0026#34;getVulnerabilitiesByRepoAndOwner\u0026#34;, \u0026#34;query\u0026#34;: make_query(after_cursor), \u0026#34;variables\u0026#34;: {\u0026#34;name\u0026#34;: repo, \u0026#34;owner\u0026#34;: owner}, }, headers=headers, ) result = request.json() output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;name\u0026#34;] = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][ \u0026#34;name\u0026#34; ] output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;url\u0026#34;] = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;url\u0026#34;] if result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;totalCount\u0026#34;] == 0: return None output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;nodes\u0026#34;] += result[ \u0026#34;data\u0026#34; ][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;nodes\u0026#34;] keep_fetching = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;pageInfo\u0026#34;][ \u0026#34;hasNextPage\u0026#34; ] after_cursor = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;pageInfo\u0026#34;][ \u0026#34;endCursor\u0026#34; ] print( \u0026#34;Fetched {} alerts for repo {}/{}\u0026#34;.format( result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;totalCount\u0026#34;], owner, repo, ) ) return json.dumps(output_result, indent=2)\rSample Scan Data Sample Github Vulnerability scans can be found here.\n","date":"0001-01-01","id":216,"permalink":"/en/connecting_your_tools/parsers/file/github_vulnerability/","summary":"Import findings from Github vulnerability scan (GraphQL Query): https://help.github.com/en/github/managing-security-vulnerabilities\nCurrently the parser is able to manage only RepositoryVulnerabilityAlert object. The parser has some kind of search feature which detect the data in the report.","tags":[],"title":"Github Vulnerability"},{"content":"GitLab API Fuzzing Report report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab API Fuzzing Report Scan scans can be found here.\n","date":"0001-01-01","id":217,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_api_fuzzing/","summary":"GitLab API Fuzzing Report report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab API Fuzzing Report Scan scans can be found here.","tags":[],"title":"GitLab API Fuzzing Report Scan"},{"content":"GitLab Container Scan report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab Container Scan scans can be found here.\n","date":"0001-01-01","id":218,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_container_scan/","summary":"GitLab Container Scan report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab Container Scan scans can be found here.","tags":[],"title":"GitLab Container Scan"},{"content":"GitLab DAST Report in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab DAST Report scans can be found here.\n","date":"0001-01-01","id":219,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_dast/","summary":"GitLab DAST Report in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab DAST Report scans can be found here.","tags":[],"title":"GitLab DAST Report"},{"content":"Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nSample Scan Data Sample GitLab Dependency Scanning Report scans can be found here.\n","date":"0001-01-01","id":220,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_dep_scan/","summary":"Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nSample Scan Data Sample GitLab Dependency Scanning Report scans can be found here.","tags":[],"title":"GitLab Dependency Scanning Report"},{"content":"Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nSample Scan Data Sample GitLab SAST Report scans can be found here.\n","date":"0001-01-01","id":221,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_sast/","summary":"Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nSample Scan Data Sample GitLab SAST Report scans can be found here.","tags":[],"title":"GitLab SAST Report"},{"content":"GitLab Secret Detection Report file can be imported in JSON format (option \u0026ndash;json).\nSample Scan Data Sample GitLab Secret Detection Report scans can be found here.\n","date":"0001-01-01","id":222,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_secret_detection_report/","summary":"GitLab Secret Detection Report file can be imported in JSON format (option \u0026ndash;json).\nSample Scan Data Sample GitLab Secret Detection Report scans can be found here.","tags":[],"title":"GitLab Secret Detection Report"},{"content":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample Gitleaks scans can be found here.\n","date":"0001-01-01","id":223,"permalink":"/en/connecting_your_tools/parsers/file/gitleaks/","summary":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample Gitleaks scans can be found here.","tags":[],"title":"Gitleaks"},{"content":"Google Cloud has a Artifact Registry that you can enable security scans https://cloud.google.com/artifact-registry/docs/analysis Once a scan is completed, results can be pulled via API/gcloud https://cloud.google.com/artifact-analysis/docs/metadata-storage and exported to JSON\nFile Types DefectDojo parser accepts Google Cloud Artifact Vulnerability Scan data as a .json file.\nSample Scan Data Sample reports can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/gcloud_artifact_scan\n","date":"0001-01-01","id":224,"permalink":"/en/connecting_your_tools/parsers/file/gcloud_artifact_scan/","summary":"Google Cloud has a Artifact Registry that you can enable security scans https://cloud.google.com/artifact-registry/docs/analysis Once a scan is completed, results can be pulled via API/gcloud https://cloud.","tags":[],"title":"Google Cloud Artifact Vulnerability Scan"},{"content":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample Gosec Scanner scans can be found here.\n","date":"0001-01-01","id":225,"permalink":"/en/connecting_your_tools/parsers/file/gosec/","summary":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample Gosec Scanner scans can be found here.","tags":[],"title":"Gosec Scanner"},{"content":"JSON vulnerability report generated by govulncheck tool, using a command like govulncheck -json . \u0026gt;\u0026gt; report.json\nSample Scan Data Sample Govulncheck scans can be found here.\n","date":"0001-01-01","id":226,"permalink":"/en/connecting_your_tools/parsers/file/govulncheck/","summary":"JSON vulnerability report generated by govulncheck tool, using a command like govulncheck -json . \u0026gt;\u0026gt; report.json\nSample Scan Data Sample Govulncheck scans can be found here.","tags":[],"title":"Govulncheck"},{"content":"Import HackerOne cases findings in JSON format\nSample Scan Data Sample HackerOne Cases scans can be found here.\n","date":"0001-01-01","id":227,"permalink":"/en/connecting_your_tools/parsers/file/h1/","summary":"Import HackerOne cases findings in JSON format\nSample Scan Data Sample HackerOne Cases scans can be found here.","tags":[],"title":"HackerOne Cases"},{"content":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample Hadolint scans can be found here.\n","date":"0001-01-01","id":228,"permalink":"/en/connecting_your_tools/parsers/file/hadolint/","summary":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample Hadolint scans can be found here.","tags":[],"title":"Hadolint"},{"content":"Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nSample Scan Data Sample Harbor Vulnerability scans can be found here.\n","date":"0001-01-01","id":229,"permalink":"/en/connecting_your_tools/parsers/file/harbor_vulnerability/","summary":"Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nSample Scan Data Sample Harbor Vulnerability scans can be found here.","tags":[],"title":"Harbor Vulnerability"},{"content":"The HCL Appscan has the possibility to export the results in PDF, XML and CSV formats within the portal. However, this parser only supports the import of XML generated from HCL Appscan on cloud.\nSample Scan Data Sample HCL Appscan scans can be found here.\n","date":"0001-01-01","id":230,"permalink":"/en/connecting_your_tools/parsers/file/hcl_appscan/","summary":"The HCL Appscan has the possibility to export the results in PDF, XML and CSV formats within the portal. However, this parser only supports the import of XML generated from HCL Appscan on cloud.","tags":[],"title":"HCL Appscan"},{"content":"Import findings from Horusec scan.\n./horusec_linux_x64 start -O=report.json -o json -i=\u0026#34;tests/\u0026#34;\rReferences:\nGitHub repository Sample Scan Data Sample Horusec scans can be found here.\n","date":"0001-01-01","id":231,"permalink":"/en/connecting_your_tools/parsers/file/horusec/","summary":"Import findings from Horusec scan.\n./horusec_linux_x64 start -O=report.json -o json -i=\u0026#34;tests/\u0026#34;\rReferences:\nGitHub repository Sample Scan Data Sample Horusec scans can be found here.","tags":[],"title":"Horusec"},{"content":"Connectors import data to DefectDojo on a regular interval (which you defined when adding the connector). However, if you want to import data manually (such as if you want to import historical data) you can follow this process:\nSelect the tool which you want to test from Configured Connections, and click the Manage Configuration button. From the drop-down list, select Manage Records and Operations.\nRun Discover Manually To have DefectDojo search for, and import new records from the API, click the ðŸ”Ž Discover button. This button is located next to the Unmapped Records header. Run Sync Manually To have DefectDojo import new data from each Mapped Record, click the Sync button. This button is located next to the Mapped Records header. If there are no Mapped Records associated with this Connector, DefectDojo will not be able to import any data via Sync. You may need to run a Discover operation first, or map each record to a Product.\n","date":"0001-01-01","id":232,"permalink":"/en/connecting_your_tools/connectors/run_operations_manually/","summary":"Connectors import data to DefectDojo on a regular interval (which you defined when adding the connector). However, if you want to import data manually (such as if you want to import historical data) you can follow this process:","tags":[],"title":"How to run Operations manually"},{"content":"Custom Dashboard Tiles can be added, edited or deleted by any user with Superuser Permissions.\nAdding a new Dashboard Tile New Dashboard tiles can be added by opening the + (plus icon)menu on the Dashboard. New Dashboard tiles will always be created at the bottom of the Dashboard Tiles section.\nSelect the kind of Tile you want to add, which will then bring you to the Add Dashboard Tile form.\nEditing a Dashboard Tile If you wish to edit a Dashboard Tile, you can click the Header of the Tile, which will also open the Dashboard Tile form.\nAdd / Edit Dashboard Tile form From here you can set your Dashboard Tileâ€™s options:\n* Select an Icon for your tile (1)\nSet the Header textfor your tile (3) Set the Footer textfor your tile Set the Color of your icon Dynamic Color Tile If you want to set your tile to change color based on the associated count of Findings, Products or other objects returned by the filter, you can enable Dynamic Color Tile in this menu. The color of the tile Icon will change from Green -\u0026gt; Yellow -\u0026gt; Red as the object count changes.\nDynamic Color Minimum is the bottom of the range. If the Object count is equal to or less than this number, the tile Icon will be set to Green. Dynamic Color Maximum is the top of the range. If the Object count is equal to or greater than this number, the tile Icon will be set to Red. Any number between the Minimum or the Maximum will set the filter to Yellow. Example 1: Critical Findings Count Say you wanted to set up a Dynamic Color Tile to track our Critical Findings. You can set your Dynamic Color parameters as follows:\nSet Dynamic Color Minimum to 0. As long as you have 0 active Critical Findings, this tile will be Green. Set Dynamic Color Maximum to 5. If you have 5 or more Critical Findings active in our environment, the tile will turn Red to indicate thereâ€™s timely action required to address these Findings. If you have 1-4 Critical Findings in your instance, the filter will be Yellow to indicate that weâ€™re not in an â€˜emergencyâ€™ situation but we should be aware of these Findings. Of course, your teamâ€™s standards and acceptable range for this kind of filter may differ from our example.\nInverted Maximum and Minimum If your Maximum is lower than your Minimum, the range will still compute correctly.\nExample 2: Passing Products Count\nSay you wanted to set up a Tile which tracks your Passing Products with a Dynamic Color. An acceptable count of Passing Products for you is 5 or more, and a â€˜failingâ€™ state is 2 or fewer Passing Products.\nYou can set your Dynamic Color Maximum of 2, and a Dynamic Color Minimum of 5, the Tile will apply colors as follows:\nIf the filter returns 2 Objects or fewer , the tile will be Red, indicating that very few of your Products are passing. If the filter returns 5 Objects or greater, the tile will be Green, indicating that a healthy amount of your Products are passing. If the filter returns a value between those two numbers, the tile will be Yellow, indicating that a significant, but non-critical amount of your Products are not passing. Tile Filter Index To set a specific context for your tile, you can set various Tile Filters. Click the Tile Filters + button at the bottom of the form to expand the Tile Filters menu.\nFilters are optional. Each Tile has a different set of relevant filters which can be selected.\nProduct Tile Product Name Contains: type in one or more partial matches of Product Names, separated by commas Product Name Exact: type in one or more exact matches of Product Names, separated by commas Product Type: Select one or more options from the list Business Criticality: Select one or more options from the list Platform: Select one or more options from the list Lifecycle: Select one or more options from the list Origin: Select one or more options from the list External Audience: Yes/No Internet Accessible: Yes/No Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Outside of SLA: Yes/No Engagement Tile Product Name Contains: type in one or more partial matches of Product Names, separated by commas Product Type: Select one or more options from the list Engagement Name Contains: type in one or more partial matches of Engagements, separated by commas Engagement Lead: Select a single option from the list Engagement Version: type in an Engagement Version Test Version: type in a Test Version Product Lifecycle: Select one or more options from the list Engagement Status: Select one or more options from the list Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Test Tile Test Name Contains: type in one or more partial matches of Test Names, separated by commas Test Type: select a single Test Type from the list Engagement: select a single Engagement from the list Test Version: type in a Test Version Branch/Tag: type in a Branch/Tag Build ID: type in a Build ID Commit Hash: type in a Commit Hash Engagement Tag Contains: type in one or more partial matches of tags, separated by commas Engagement Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Product Tag Contains: type in one or more partial matches of tags, separated by commas Product Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Finding Tile Name Contains: enter a partial match of a Finding Name from the menu Component Name Contains: enter a partial match of a Component Name from the menu Date: select an option from the menu CWE: type in an exact match of a CWE Severity: select one or more Severities from the menu Last Reviewed: select an option from the menu Last Status Update: select an option from the menu Mitigated Date: select an option from the menu Reported By: select one or more Users from the menu Product Type: select one or more Product Types from the menu Product: select one or more Products from the menu Product Lifecycle: select one or more Product Lifecycle states from the menu Engagement: select one or more Engagements from the menu Engagement Version: type in an exact match of an Engagement Version Test Type: select one or more Test from the menu Test Version: type in an exact match of a Test Version Active: Yes/No Verified: Yes/No Duplicate: Yes/No Mitigated: Yes/No Out Of Scope: Yes/No False Positive: Yes/No Has Components: Yes/No Has Notes: Yes/No File Path Contains: type in a partial match of a File Path Unique ID From Tool: type in an exact match of a Unique ID From Tool Vulnerability ID From Tool: type in an exact match of a Vulnerability From Tool Vulnerability ID: type in an exact match of a Vulnerability Service Contains: type in a partial match of a Service Parameter Contains: type in a partial match of an Parameter Payload Contains: type in a partial match of an Payload Risk Accepted: Yes/No Has Group: select an option from the list Planned Remediation Date: select an option from the list Planned Remediation Version: type in a Planned Remediation Version Reviewers: select one or more Users from the list Endpoint Host Contains: type in a partial match of an Endpoint Host Outside of SLA: Yes/No Effort For Fixing: select an option from the list Has Tags: Yes/No Tags: type in one or more partial matches of Finding tags, separated by commas Tag Contains: type in one or more partial matches of Finding tags, separated by commas Does Not Have Tags: type in one or more exact matches of Finding tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of Finding tags, separated by commas Test Tags: type in one or more exact matches of tags, separated by commas Test Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Engagement Tags: type in one or more exact matches of tags, separated by commas Engagement Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Product Tags: type in one or more exact matches of tags, separated by commas Product Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Endpoint Tile Protocol Contains: type in a partial match of a Protocol from the menu User Info Contains: type in a partial match of User Info from the menu Host Contains: type in a partial match of a Host from the menu Port Contains: type in a partial match of a Port from the menu Path Contains: type in a partial match of a Path from the menu Query Contains: type in a partial match of a Query from the menu Fragment Contains: type in a partial match of a Fragment from the menu Product: select one or more Products from the menu Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas SLA Violation Tile Days Before Expiration: select an option from the menu Include All Products: Yes/No Included Products: select one or more Products from the menu Scan Time Violation Tile Days Since Last Scan: select an option from the menu Include All Products: Yes/No Included Products: select one or more Products from the menu Product Grade Tile Product Grade: select a single Product Grade from the menu Comparison Operator: select a Comparison Operator from the menu, related to Product Grade Include All Products: Yes/No Included Products: select one or more Products from the menu ","date":"0001-01-01","id":233,"permalink":"/en/dashboard/how-to-add-edit-or-delete-dashboard-tiles/","summary":"Custom Dashboard Tiles can be added, edited or deleted by any user with Superuser Permissions.\nAdding a new Dashboard Tile New Dashboard tiles can be added by opening the + (plus icon)menu on the Dashboard.","tags":[],"title":"How-To: Add, Edit or Delete Dashboard Tiles"},{"content":"Superusers can choose which Metrics Charts are displayed on the Dashboard. To do this, select the Edit Dashboard Configuration option from the top-right hand gear menu.\nThis will open the Dashboard Configuration Settings window.\nDashboard Configuration Options Display Graphs determines whether or not the Historical Finding Severity and Reported Finding Severity charts are visible. Display Surveys determines whether or not the Unassigned Answered Engagement Questionnaires table is visible. Display Data Tables determines whether or not the Top 10 / Bottom 10 Graded Products tables are visible. Reset Dashboard Configuration If you would like to reset your Dashboard to a default state, you can do so by selecting Reset Dashboard Configuration from the top-right hand gear menu.\nNote that this will remove any Custom Dashboard Tiles which have been added to your instance.\n","date":"0001-01-01","id":234,"permalink":"/en/dashboard/how-to-edit-dashboard-configuration/","summary":"Superusers can choose which Metrics Charts are displayed on the Dashboard. To do this, select the Edit Dashboard Configuration option from the top-right hand gear menu.","tags":[],"title":"How-To: Edit Dashboard Configuration"},{"content":"One of DefectDojoâ€™s strengths is that the data model can accommodate many different use-cases and applications. Youâ€™ll likely change your approach as you master the software and discover ways to optimize your workflow.\nBy default, DefectDojo does not delete any duplicate Findings that are created. Each Finding is considered to be a separate instance of a vulnerability. So in this case, Duplicate Findings can be an indicator that a process change is required to your workflow.\nStep 1: Clean up your excess Duplicates Fortunately, DefectDojoâ€™s Deduplication settings allow you to mass-delete duplicates once a certain threshold has been crossed. This feature makes the cleanup process easier. To learn more about this process, see our article on Finding Deduplication \u0026lt;-link will go here.\nStep 2: Evaluate your Engagements for redundancies Once youâ€™ve cleaned up your duplicate Findings, itâ€™s a good practice to look at the Product which contained them to see if thereâ€™s a clear culprit. You might find that there are Engagements contained within which have a redundant context.\nDuplicate or Reused Engagements Engagements store one or more Tests for a particular testing context. That context is ultimately up to you to define for yourself, but if you see a few Engagements within your Product which should share the same context, consider combining them into a single engagement.\nâ€‹\nQuestions to ask when defining Engagement context: If I wanted to make a report on this work, would the Engagement contain all of the relevant information I need? Are we proactively creating Engagements ahead of time or are they being created â€˜ad-hocâ€™ by my import process? Are we using the right kind of Engagement - Interactive or CI/CD? What section of the codebase is being worked on by tests: is each repository a separate context or could multiple repositories make up a shared context for testing? Who are the stakeholders involved with the Productt, and how will I share results with them? Step 3: Check for redundant Tests If you discover that separate Tests have been created which capture the same testing context, this may be an indicator that these tests can be consolidated into a single Reimport.\nDefectDojo has two methods for importing test data to create Findings: Import and Reimport. Both of these methods are very similar, but the key difference between the two is that Import always creates a new Test, while Reimport can add new data to an existing Test. Itâ€™s also worth noting that Reimport does not create duplicate Findings within that Test.\nEach time you import new vulnerability reports into DefectDojo, those reports will be stored in a Test object. A Test object can be created by a user ahead of time to hold a future Import. If a user wants to import data without specifying a Test destination, a new Test will be created to store the incoming report.\nTests are flexible objects, and although they can only hold one kind of report, they can handle multiple instances of that same report through the Reimport method. To learn more about Reimport, see our article on this topic.\nWhen are Duplicate Findings acceptable? Duplicate Findings are not always indicative of a problem. There are many cases where keeping duplicates is the preferred approach. For example:\nIf your team uses and reports on Interactive Engagements. If you want to create a discrete report on a single Test specifically, you would want to know if thereâ€™s an occurrence of a Finding that was already uncovered earlier. If you have Engagements which are contextually separated (for example, because they cover different repositories) you would want to be able to flag Findings which are occurring in both places. ","date":"0001-01-01","id":235,"permalink":"/en/working_with_findings/findings_workflows/how-to-manage-duplicate-findings/","summary":"One of DefectDojoâ€™s strengths is that the data model can accommodate many different use-cases and applications. Youâ€™ll likely change your approach as you master the software and discover ways to optimize your workflow.","tags":[],"title":"How-To: Manage Duplicate Findings"},{"content":"Import JSON report of the Humble scanner https://github.com/rfc-st/humble\nSample Scan Data Sample Humble Report scans can be found here.\n","date":"0001-01-01","id":236,"permalink":"/en/connecting_your_tools/parsers/file/humble/","summary":"Import JSON report of the Humble scanner https://github.com/rfc-st/humble\nSample Scan Data Sample Humble Report scans can be found here.","tags":[],"title":"Humble Report"},{"content":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI Report scans can be found here.\n","date":"0001-01-01","id":237,"permalink":"/en/connecting_your_tools/parsers/file/huskyci/","summary":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI Report scans can be found here.","tags":[],"title":"HuskyCI Report"},{"content":"Import JSON reports from THC Hydra.\nHydra can discover weak login credentials on different types of services (e.g. RDP).\nAs Hydra cannot provide a severity rating (as it doesn\u0026rsquo;t know how severe a weak login is at this scanned service), all imported findings will be rated \u0026lsquo;High\u0026rsquo;.\nSample JSON report:\n{ \u0026#34;errormessages\u0026#34;: [ \u0026#34;[ERROR] Error Message of Something\u0026#34;, \u0026#34;[ERROR] Another Message\u0026#34;, \u0026#34;These are very free form\u0026#34; ], \u0026#34;generator\u0026#34;: { \u0026#34;built\u0026#34;: \u0026#34;2019-03-01 14:44:22\u0026#34;, \u0026#34;commandline\u0026#34;: \u0026#34;hydra -b jsonv1 -o results.json ... ...\u0026#34;, \u0026#34;jsonoutputversion\u0026#34;: \u0026#34;1.00\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;http-post-form\u0026#34;, \u0026#34;software\u0026#34;: \u0026#34;Hydra\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v8.5\u0026#34; }, \u0026#34;quantityfound\u0026#34;: 1, \u0026#34;results\u0026#34;: [ { \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;login\u0026#34;: \u0026#34;bill@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;bill\u0026#34;, \u0026#34;port\u0026#34;: 9999, \u0026#34;service\u0026#34;: \u0026#34;http-post-form\u0026#34; } ], \u0026#34;success\u0026#34;: false }\rSample Scan Data Sample Hydra scans can be found here.\n","date":"0001-01-01","id":238,"permalink":"/en/connecting_your_tools/parsers/file/hydra/","summary":"Import JSON reports from THC Hydra.\nHydra can discover weak login credentials on different types of services (e.g. RDP).\nAs Hydra cannot provide a severity rating (as it doesn\u0026rsquo;t know how severe a weak login is at this scanned service), all imported findings will be rated \u0026lsquo;High\u0026rsquo;.","tags":[],"title":"Hydra"},{"content":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan DAST scans can be found here.\n","date":"0001-01-01","id":239,"permalink":"/en/connecting_your_tools/parsers/file/ibm_app/","summary":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan DAST scans can be found here.","tags":[],"title":"IBM AppScan DAST"},{"content":"XML Scan Result File from Immuniweb Scan.\nSample Scan Data Sample Immuniweb Scan scans can be found here.\n","date":"0001-01-01","id":240,"permalink":"/en/connecting_your_tools/parsers/file/immuniweb/","summary":"XML Scan Result File from Immuniweb Scan.\nSample Scan Data Sample Immuniweb Scan scans can be found here.","tags":[],"title":"Immuniweb Scan"},{"content":"One of the things we understand at DefectDojo is that every companyâ€™s security needs are completely different. There is no â€˜one-size-fits-allâ€™ approach. As your organization changes, having a flexible approach is key.\nDefectDojo allows you to connect your security tools in a flexible way to match those changes.\nScan Upload Methods When DefectDojo receives a vulnerability report from a security tool, it will create Findings based on the vulnerabilities contained within that report. DefectDojo acts as the central repository for these Findings where they can be triaged, remediated or otherwise addressed by you and your team.\nThere are four main ways that DefectDojo can upload Finding reports:\nVia direct import through the UI (â€œAdd Findingsâ€) Via API endpoint (allowing for automated data ingest) Via Connectors for certain tools, an â€˜out of the boxâ€™ data integration Via Smart Upload for certain tools, an importer designed to handle infrastructure scans Comparing Upload Methods UI Import API Import Connectors Smart Upload Supported Scan Types All (see Supported Tools) All (see Supported Tools) Snyk, Semgrep, Burp Suite, AWS Security Hub, Probely, Checkmarx, Tenable Nexpose, NMap, OpenVas, Qualys, Tenable Can it be automated? Not directly, though method can be automated through API Yes, calls to API can be made manually or via script Yes, Connectors is a natively automated process which leverages your toolâ€™s API to rapidly import data Yes, can be automated via /smart_upload_import API endpoint Product Hierarchy Each of these methods can create Product Hierarchy on the spot. Product Hierarchy refers to DefectDojoâ€™s Product Types, Products, Engagements or Tests: objects in DefectDojo which help organize your data into relevant context.\nVulnerability data can be imported into an existing Product Hierarchy. Product Types, Products, Engagements and Tests can all be created in advance, and then data can be imported to that location in DefectDojo. The contextual Product Hierarchy can be created at the time of import. When importing a report, you can create a new Product Type, Product, Engagement and/or Test. This is handled by DefectDojo through the â€˜auto-create contextâ€™ option. Next Steps If you have a brand new DefectDojo instance, learning how to use the Import Scan Form is a great starting point. If you want to learn how to translate DefectDojoâ€™s organizational system into a robust pipeline, you can start by consulting our article on Core Data Classes. If you want to set up Connectors to work with a supported tool, see our Introducing Connectors article. ","date":"0001-01-01","id":241,"permalink":"/en/connecting_your_tools/import_intro/","summary":"One of the things we understand at DefectDojo is that every companyâ€™s security needs are completely different. There is no â€˜one-size-fits-allâ€™ approach.","tags":[],"title":"Import Methods"},{"content":"If you have a brand new DefectDojo instance, the Import Scan Form is a logical first step to learn the software and set up your environment. From this form, you upload a scan file from a supported tool, which will create Findings to represent those vulnerabilities. While filling out the form, you can decide whether to:\nStore these Findings under an existing Product Type / Product / Engagement or Create a new Product Type / Product / Engagement to store these Findings Itâ€™s easy to reorganize your Product Hierarchy in DefectDojo, so itâ€™s ok if youâ€™re not sure how to set things up yet.\nFor now, itâ€™s good to know that Engagements can store data from multiple tools, which can be useful if youâ€™re running different scans concurrently.\nAccessing the Import Scan Form The Import Scan form can be accessed from multiple locations:\nVia the Import \u0026gt; Add Findings menu option on the sidebar From a Productâ€™s â€˜â‹®â€™ (horizontal dots) Menu, from a Products Table From the âš™ï¸Gear Menu on a Product Page Completing the Import Scan Form The Import Scan form will create a new Test nested under an Engagement, which will contain a unique Finding for each vulnerability contained within your scan file.\nThe Test will be created with a name that matches the Scan Type: e.g. a Tenable scan will be titled â€˜Tenable Scanâ€™.\nForm Options Scan File: by clicking on the Choose button, you can select a file from your computer to upload. Scan Date (optional): if you want to select a single Scan Date to be applied to all Findings that result from this import, you can select the date in this field.\nIf you do not select a Scan Date, Findings created from this report will use the date specified by the tool. SLAs for each Finding will be calculated based on their date. Scan Type: select the tool used to create this data. Product Type / Product / Engagement Name: select the Product Type, Product, and Engagement Name which you want to create a new Test under. You can also create a new Product Type, Product and/or Engagement at this time if you wish to, by entering the names of the objects that you want to create. Environment: select an Environment that corresponds to the data youâ€™re uploading. Tags: if you want to use tags to further organize your Test data, you can add Tags using this form. Type in the name of the tag you want to create, and press Enter on your keyboard to add it to the list of tags. Process Findings Asynchronously: this field is enabled by default, but it can be disabled if you wish. See explanation below. Process Findings Asynchronously When this field is enabled, DefectDojo will use a background process to populate your Test file with Findings. This allows you to continue working with DefectDojo while Findings are being created from your scan file.\nWhen this field is disabled, DefectDojo will wait until all Findings have been successfully created before you can proceed to the next screen. This could take significant time depending on the size of your file.\nThis option is especially relevant when using the API. If uploading data with Process Findings Asynchronously turned off, DefectDojo will not return a successful response until all Findings have been created successfully,\nOptional Fields Minimum Severity: If you only want to create Findings for a particular Severity level and above, you can select the minimum Severity level here. All vulnerabilities with lower severity than this field will be ignored. Active: if you want to set all of the incoming Findings to either Active or Inactive, you can specify that here. Otherwise, DefectDojo will use the toolâ€™s vulnerability data to determine whether the Finding is Active or Inactive. This option is relevant if you need your team to manually triage and verify Findings from a particular tool. Verified: as with Active you can set the new set of Findings to either Verified or Unverified by default. This depends on your workflow preferences. For example, if your team prefers to assume Findings are verified unless proven otherwise, you can set this field to True. Version, Branch Tag, Commit Hash, Build ID, Service can all be specified if you want to include these details in the Test. Source Code Management URI can also be specified. This form option must be a valid URI. Group By: if you want to create Finding Groups out of this File, you can specify the grouping method here. Next Steps Once your upload has completed, you should be redirected to the Test Page which contains the Findings found in the scan file. You can start working with those results right away, but feel free to consult the following articles:\nLearn how to organize your Product Hierarchy to manage different contexts for your Findings and Tests: Core Data Classes. Learn how to add new Findings to this test: Reimport Data To Extend a Test ","date":"0001-01-01","id":242,"permalink":"/en/connecting_your_tools/import_scan_files/import_scan_ui/","summary":"If you have a brand new DefectDojo instance, the Import Scan Form is a logical first step to learn the software and set up your environment.","tags":[],"title":"Import Scan Form"},{"content":"The Dashboard is likely the first page you\u0026rsquo;ll see when you open DefectDojo. It summarizes your teamâ€™s performance, and provides tracking tools to monitor specific areas of your vulnerability tracking environment.\nThe dashboard has two components:\nCustomizable Dashboard Tiles, which you can use to visualize the metrics which are relevant to you. Pre-built Dashboard Charts, which visualize your teamâ€™s overall performance. Each team member shares a single dashboard, but the results of the dashboard are restricted by their role and Product Membership. Team members will only see calculated stats for the Products, Engagements, Findings or other objects that they have access to. For more information, see our guides on User Permissions and Roles.\nDashboard Tiles Tiles are designed to provide relevant information and speed up navigation within DefectDojo.\nTiles can:\nAct as shortcuts for particular sets of Findings, Products, or other objects Visualize metrics related to your Product Provide alerts on particular activity, track SLA Violations, failing imports or new Critical Findings Tiles are pinned to the top section of your ðŸ  Home page.\nFor more information about creating and editing Dashboard Tiles, see our guides on this topic**:**\nDashboard Tile Summary Add, Edit or Delete Dashboard Tiles Dashboard Charts Located beneath Dashboard Tiles, DefectDojo has five pre-built charts:\nHistorical Finding Severity pie-chart Reported Finding Severity histogram, by month Unassigned Answered Engagement Questionnaires table Top 10 Graded Products table Bottom 10 Graded Products table These charts can be added or removed from the dashboard via Dashboard Configuration.\nHistorical Finding Severity This chart organizes all Findings created in DefectDojo by Severity, so that you can see the overall distribution of vulnerability levels in your environment.\nReported Finding Severity This chart allows you to monitor the volume and severity distribution of incoming Findings per month.\nUnassigned Answered Engagement Questionnaires If you have completed Engagement Questionnaires for review, those will be listed in this table.\nTop 10 / Bottom 10 Graded Products This section summarizes the Graded performance of each Product in your instance, counting the Highest and Lowest scoring Products.\nFinding Counts of each severity are calculated by the tile, but note that Product Grade is only assigned based on Active Findings, so there may be Inactive Findings counted in this table which do not contribute to the Grade.\nTo understand how grades are calculated, see our guide to Product Health Grading.\nNext Steps Change or reset your dashboard display by editing your dashboard configuration. Learn how to customize your DefectDojo instance with custom Dashboard Tiles. ","date":"0001-01-01","id":243,"permalink":"/en/dashboard/introduction-to-dashboard-features/","summary":"The Dashboard is likely the first page you\u0026rsquo;ll see when you open DefectDojo. It summarizes your teamâ€™s performance, and provides tracking tools to monitor specific areas of your vulnerability tracking environment.","tags":[],"title":"Introduction to Dashboard Features"},{"content":"Findings are the main way that DefectDojo standardizes and guides the reporting and remediation process of your security tools. Regardless of whether a vulnerability was reported in SonarQube, Acunetix, or your teamâ€™s custom tool, Findings give you the ability to manage each vulnerability in the same way.\nWhat are Findings? Findings in DefectDojo are made up of the following components:\nThe reported vulnerability data in question The â€˜statusâ€™ of the Finding, used to track remediation, risk acceptance or other decisions made around the vulnerability Other metadata related to the Finding. For example, this could include the location of a Finding in your network, a toolâ€™s suggestions for remediation, or links to an associated CWE or EPSS score. In addition to storing the vulnerability data and providing a remediation framework, DefectDojo also enhances your Findings in the following ways:\nAutomatically adding related EPSS scores to a Finding to describe exploitability Automatically translating a security toolâ€™s severity metric into a Severity score for each Finding, which confers an SLA onto the Finding according to your Productâ€™s SLA Configuration. Overall, DefectDojo Findings are designed to work with the Product Hierarchy to standardize your efforts, and apply a consistent method to each Product.\nA Finding Page The Finding Page contains various components. Each will be populated by the Import process when the Finding is created.\nThe Title of the Finding: Usually this is a descriptive shorthand which identifies the vulnerability or issue detected. This section is also where user-created Tags are displayed if they exist.\nâ€‹\nFinding Overview: This section contains five separate pages of relevant information for the Finding: Description, Mitigation, Impact, References and Notes. These fields can be populated automatically based on the incoming vulnerability data, or they can be edited by a DefectDojo user to provide additional context.\nâ€‹\nâ€‹**- Description** is a more detailed summary and explanation of the Finding in question.\nâ€‹**- Mitigation** is a suggested method for mitigating the Finding so that it is no longer present in your system.\nâ€‹**- Impact** describes the impact of the vulnerability on your security posture. This page might hold descriptive text, or it may include a CVSS Vector String, which is a shorthand way to communicate the vulnerabilityâ€™s overall exploitability and with the consequences of an exploitation to your organization. Impact is closely related to a Findingâ€™s Severity field.\nâ€‹**- References** will list any links or additional information relevant to this Finding if included.\nâ€‹**- Notes** is a page where you can record any other relevant information to this Finding. Notes are â€˜DefectDojo-onlyâ€™ metadata, and they are not created at the time of import. Use this field to track your mitigation progress or to add more specific detail to the Finding.\nâ€‹\nAdditional Details: This section lists other details related to this Finding, if relevant:\nRequest/Response Pairs associated with the vulnerability Steps To Reproduce the vulnerability Severity Justification where you can record a more detailed explanation of the severity or impact of the Finding.\nâ€‹\nâ€‹ Metadata: This section contains filterable metadata related to the Finding:\nID: the ID value of the Finding in DefectDojo Severity: the Severity value of the Finding. Can be Info, Low, Medium, High or Critical. Finding Severities are directly related to the Findingâ€™s calculated SLA, based on the Product the Finding is stored in. Status: the status of the Finding. Can be either Active or Inactive. In addition to these, Findings can also have a Status of Duplicate, Mitigated, False Positive, Out Of Scope, Risk Accepted or Under Defect Review. These Statuses explain the State of the Finding in more detail. Type: this field describes how the Finding was found, either via a Static (SAST) evaluation of the source code, or through a Dynamic (DAST) evaluation of the Product as it was running. This field is defined by the tool type. Location: this field describes the related File Path to your vulnerability, if relevant. Line: this field describes the line of code containing the vulnerability, if relevant. Date Discovered: this field shows either the date the Finding was imported to DefectDojo, or the date the Finding was discovered by the Tool. Age: this calculated field shows the number of days the Finding has been active. Reporter: this is the username of the DefectDojo account who created this Finding. CWE: this field is a link to the external CWE (Common Weakness Enumeration) definition which applies to this Finding. Vulnerability ID: if there is a particular ID value for this vulnerability within the tool itself, it will be tracked here. EPSS Score / Percentile: if the source data has a CWE value, DefectDojo will automatically pull an EPSS Score and Percentile (Exploit Prediction Scoring System). EPSS represents the likelihood that a software vulnerability can be exploited, based on real-world exploit data. EPSS scores are updated on an ongoing basis, using the latest exploitation data from First. Found By: This will list the scanner used to find this vulnerability.\nâ€‹ Example Finding Workflows How you work with Findings in DefectDojo depends on your teamâ€™s responsibilities within your organization. Here are some examples of these processes, and how DefectDojo can help:\nDiscover and Report vulnerabilities If youâ€™re in charge of security reporting for many different contexts, software Products or teams, DefectDojo can report on those vulnerabilities uncovered. Using the Product Hierarchy, you can organize your Finding data into the appropriate context. For example:\nEach Product in DefectDojo can have a different SLA configuration, so that you can instantly flag Findings that are discovered in Production or other highly sensitive environments. You can create a report directly from a Product Type, Product, Engagement or Test to â€˜zoom in and outâ€™ of your security context. Tests contain results from a single tool, Engagements can combine multiple Tests, Products can contain multiple Engagements, Product Types can contain multiple Products. For more information on creating a Report, see our guides to Custom Reporting.\nTriage Vulnerabilities using Finding Status If your team needs to validate the Findings discovered, you can do so by manually applying the Verified status to Findings as you review them. You can also apply other statuses, such as:\nFalse Positive: A tool detected the threat, but the threat is not active in the environment. Out Of Scope: Active, but irrelevant to the current testing effort. Risk Accepted: Active, but determined not to be a priority to address until the Risk Acceptance expires. Under Review: may or may not be Active - your team is still investigating. Mitigated: This issue has been resolved since the Finding was created. If a tool reports a previously triaged Finding on a subsequent import, DefectDojo will remember the Findingâ€™s previous status and update accordingly. Findings with False Positive, Out Of Scope, Risk Accepted and Under Review statuses will remain as they are, but any Finding that has been Mitigated will be reactivated to let you know that the Finding has returned to the Test environment.\nEnsure Team-wide Consensus and Accountability with Risk Acceptances Part of a security teamâ€™s responsibility is to collaborate with developers to prioritize and deprioritize security issue remediation. This is where Risk Acceptances come in. Adding a Risk Acceptance to a Finding allows you to:\nStore records and â€˜artifactâ€™ files on DefectDojo - these could be emails from colleagues acknowledging the Risk Acceptance, meeting notes, or simply a written justification for accepting the risk from your own security team. Add an expiration date to the Risk Acceptance, so that the vulnerability can be re-examined after a given period of time. Any Appsec team member understands that issue mitigation canâ€™t be prioritized exclusively by developer teams, so Risk Acceptances help you log those sensitive decisions when they are made.\nMonitor current vulnerabilities using CWEs and EPSS scores Sometimes, the exploitability and threat posed by a known vulnerability can change based on new data. To keep your work up to date, DefectDojo has partnered with First.org to maintain a database of the latest EPSS scores related to Findings. Any Findings in DefectDojo will be kept up to date automatically according to their EPSS, which is directly based on the CWE of the Finding.\nIf a Findingâ€™s EPSS score changes (i.e. the related Finding becomes more exploitable or less exploitable), the Severity of the Finding will adjust accordingly.\nNext Steps: Learn how to add or adjust data on your Findings through the Edit Findings menu. Learn how to update Findings in bulk using the Bulk Edit menu. Learn how to apply Risk Acceptances to Findings which create a record of sensitive decisions made surrounding risk-accepted vulnerabilities. ","date":"0001-01-01","id":244,"permalink":"/en/working_with_findings/introduction-to-findings/","summary":"Findings are the main way that DefectDojo standardizes and guides the reporting and remediation process of your security tools. Regardless of whether a vulnerability was reported in SonarQube, Acunetix, or your teamâ€™s custom tool, Findings give you the ability to manage each vulnerability in the same way.","tags":[],"title":"Introduction to Findings"},{"content":"IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.).\nManual Import Use the Export CSV feature in the IntSights Threat Command GUI to create an IntSights Alerts.csv file. This CSV file can then be imported into Defect Dojo.\nAutomated Import The IntSights get-complete-alert API only returns details for a single alert. To automate the process, individually fetch details for each alert and append to a list. The list is then saved as the value for the key \u0026ldquo;Alerts\u0026rdquo;. This JSON object can then be imported into Defect Dojo.\nExample:\n{ \u0026quot;Alerts\u0026quot;:[ { \u0026quot;_id\u0026quot;:\u0026quot;5c80egf83b4a3900078b6be6\u0026quot;, \u0026quot;Details\u0026quot;:{ \u0026quot;Source\u0026quot;:{ \u0026quot;URL\u0026quot;:\u0026quot;https://www.htbridge.com/websec/?id=ABCDEF\u0026quot;, \u0026quot;Date\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;Type\u0026quot;:\u0026quot;Other\u0026quot;, \u0026quot;NetworkType\u0026quot;:\u0026quot;ClearWeb\u0026quot; }, \u0026quot;Images\u0026quot;:[ \u0026quot;5c80egf833963a40007e01e8d\u0026quot;, \u0026quot;5c80egf833b4a3900078b6bea\u0026quot;, \u0026quot;5c80egf834626bd0007bd64db\u0026quot; ], \u0026quot;Title\u0026quot;:\u0026quot;HTTP headers weakness in example.com web server\u0026quot;, \u0026quot;Tags\u0026quot;:[], \u0026quot;Type\u0026quot;:\u0026quot;ExploitableData\u0026quot;, \u0026quot;Severity\u0026quot;:\u0026quot;Critical\u0026quot;, \u0026quot;SubType\u0026quot;:\u0026quot;VulnerabilityInTechnologyInUse\u0026quot;, \u0026quot;Description\u0026quot;:\u0026quot;X-XSS-PROTECTION and CONTENT-SECURITY-POLICY headers were not sent by the server, which makes it vulnerable for various attack vectors\u0026quot; }, \u0026quot;Assignees\u0026quot;:[ \u0026quot;5c3c8f99903dfd0006ge5e61\u0026quot; ], \u0026quot;FoundDate\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;Assets\u0026quot;:[ { \u0026quot;Type\u0026quot;:\u0026quot;Domains\u0026quot;, \u0026quot;Value\u0026quot;:\u0026quot;example.com\u0026quot; } ], \u0026quot;TakedownStatus\u0026quot;:\u0026quot;NotSent\u0026quot;, \u0026quot;IsFlagged\u0026quot;:false, \u0026quot;UpdateDate\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;RelatedIocs\u0026quot;:[], \u0026quot;RelatedThreatIDs\u0026quot;:[], \u0026quot;Closed\u0026quot;:{ \u0026quot;IsClosed\u0026quot;:false } } ] } Sample Scan Data Sample IntSights Report scans can be found here.\n","date":"0001-01-01","id":245,"permalink":"/en/connecting_your_tools/parsers/file/intsights/","summary":"IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.","tags":[],"title":"IntSights Report"},{"content":"Vulnerabilities List - JSON report\nSample Scan Data Sample Invicti scans can be found here.\n","date":"0001-01-01","id":246,"permalink":"/en/connecting_your_tools/parsers/file/invicti/","summary":"Vulnerabilities List - JSON report\nSample Scan Data Sample Invicti scans can be found here.","tags":[],"title":"Invicti"},{"content":"File Types Accepts a JSON File, generated from the JFrog Artifact Summary API Call.\nSample Scan Data / Unit Tests Sample JFrog Xray API Summary Artifact Scans can be found here.\nLink To Tool See JFrog Documentation: https://jfrog.com/help/r/jfrog-rest-apis/summary\n","date":"0001-01-01","id":247,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_api_summary_artifact/","summary":"File Types Accepts a JSON File, generated from the JFrog Artifact Summary API Call.\nSample Scan Data / Unit Tests Sample JFrog Xray API Summary Artifact Scans can be found here.","tags":[],"title":"JFrog Xray API Summary Artifact Scan"},{"content":"Import the JSON format for the \u0026quot;JFrog Xray On Demand Binary Scan\u0026quot; file. Use this importer for Xray version 3.X\nJFrog file documentation:\nhttps://jfrog.com/help/r/jfrog-cli/on-demand-binary-scan\nSample Scan Data Sample JFrog Xray On Demand Binary Scan scans can be found here.\n","date":"0001-01-01","id":248,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_on_demand_binary_scan/","summary":"Import the JSON format for the \u0026quot;JFrog Xray On Demand Binary Scan\u0026quot; file. Use this importer for Xray version 3.X","tags":[],"title":"JFrog Xray On Demand Binary Scan"},{"content":"Import the JSON format for the \u0026quot;Security \u0026amp; Compliance | Reports\u0026quot; export. Jfrog\u0026rsquo;s Xray tool is an add-on to their Artifactory repository that does Software Composition Analysis, see https://www.jfrog.com/confluence/display/JFROG/JFrog+Xray for more information. \u0026quot;Xray Unified\u0026quot; refers to Xray Version 3.0 and later.\nSample Scan Data Sample JFrog XRay Unified scans can be found here.\n","date":"0001-01-01","id":249,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_unified/","summary":"Import the JSON format for the \u0026quot;Security \u0026amp; Compliance | Reports\u0026quot; export. Jfrog\u0026rsquo;s Xray tool is an add-on to their Artifactory repository that does Software Composition Analysis, see https://www.","tags":[],"title":"JFrog XRay Unified"},{"content":"Import the JSON format for the \u0026quot;Security Export\u0026quot; file. Use this importer for Xray version 2.X\nSample Scan Data Sample JFrogXRay scans can be found here.\n","date":"0001-01-01","id":250,"permalink":"/en/connecting_your_tools/parsers/file/jfrogxray/","summary":"Import the JSON format for the \u0026quot;Security Export\u0026quot; file. Use this importer for Xray version 2.X\nSample Scan Data Sample JFrogXRay scans can be found here.","tags":[],"title":"JFrogXRay"},{"content":"Import of JSON report from https://github.com/Checkmarx/kics\nSample Scan Data Sample KICS Scanner scans can be found here.\n","date":"0001-01-01","id":251,"permalink":"/en/connecting_your_tools/parsers/file/kics/","summary":"Import of JSON report from https://github.com/Checkmarx/kics\nSample Scan Data Sample KICS Scanner scans can be found here.","tags":[],"title":"KICS Scanner"},{"content":"Import Kiuwan SAST Scan in CSV format. Export as CSV Results on Kiuwan, or via the Kiuwan REST API endpoint vulnerabilities/export (type=csv).\nSample Scan Data Sample Kiuwan Scanner scans can be found here.\n","date":"0001-01-01","id":252,"permalink":"/en/connecting_your_tools/parsers/file/kiuwan/","summary":"Import Kiuwan SAST Scan in CSV format. Export as CSV Results on Kiuwan, or via the Kiuwan REST API endpoint vulnerabilities/export (type=csv).","tags":[],"title":"Kiuwan Scanner (SAST)"},{"content":"Import Kiuwan Insights Scan in JSON format. Export via API endpoint insights/analysis/security as json and create a file for importing to DefectDojo.\nExample Code Data can be fetched from the Kiuwan REST API like this:\nimport requests, json headers = {\u0026#39;Authorization\u0026#39;: \u0026#39;Basic $KIUWAN_TOKEN\u0026#39;, \u0026#39;Accept\u0026#39; : \u0026#39;application/json\u0026#39;} appName = \u0026#34;Test\u0026#34; analysisCode = \u0026#34;A-111-1111111111\u0026#34; URL = \u0026#34;https://api.kiuwan.com/insights/analysis/security?analysisCode=\u0026#34; + analysisCode + \u0026#34;\u0026amp;application=\u0026#34; + appName response = requests.get(url = URL, headers = headers) jsonResponse = r.json() data = jsonResponse[\u0026#34;data\u0026#34;] saveFile(\u0026#34;result.json\u0026#34;, json.dumps(data, indent=2))\rSample Scan Data Sample Kiuwan Scanner scans can be found here.\n","date":"0001-01-01","id":253,"permalink":"/en/connecting_your_tools/parsers/file/kiuwan_sca/","summary":"Import Kiuwan Insights Scan in JSON format. Export via API endpoint insights/analysis/security as json and create a file for importing to DefectDojo.","tags":[],"title":"Kiuwan Scanner (SCA i.e. \"Insights\")"},{"content":"Import KrakenD Audit Scan results in JSON format. You can use the following command to audit the KrakenD configuration which then can be uploaded to DefectDojo:\nkrakend audit -c krakend.json -f \u0026#34;{{ marshal . }}\u0026#34; \u0026gt;\u0026gt; recommendations.json\rSample Scan Data Sample KrakenD Audit scans can be found here.\n","date":"0001-01-01","id":254,"permalink":"/en/connecting_your_tools/parsers/file/krakend_audit/","summary":"Import KrakenD Audit Scan results in JSON format. You can use the following command to audit the KrakenD configuration which then can be uploaded to DefectDojo:","tags":[],"title":"KrakenD Audit Scan"},{"content":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan Data Sample kube-bench Scanner scans can be found here.\n","date":"0001-01-01","id":255,"permalink":"/en/connecting_your_tools/parsers/file/kubebench/","summary":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan Data Sample kube-bench Scanner scans can be found here.","tags":[],"title":"kube-bench Scanner"},{"content":"Kubeaudit is a command line tool and a Go package to audit Kubernetes clusters for various different security concerns. The output of of Kubeaudit which is supported within this parser is JSON. The tool can be found here\nSample Scan Data Sample Kubeaudit scans can be found here.\n","date":"0001-01-01","id":256,"permalink":"/en/connecting_your_tools/parsers/file/kubeaudit/","summary":"Kubeaudit is a command line tool and a Go package to audit Kubernetes clusters for various different security concerns. The output of of Kubeaudit which is supported within this parser is JSON.","tags":[],"title":"Kubeaudit Scan"},{"content":"Import JSON reports of kube-hunter scans. Use \u0026ldquo;kube-hunter \u0026ndash;report json\u0026rdquo; to produce the report in json format.\nSample Scan Data Sample kubeHunter Scanner scans can be found here.\n","date":"0001-01-01","id":257,"permalink":"/en/connecting_your_tools/parsers/file/kubehunter/","summary":"Import JSON reports of kube-hunter scans. Use \u0026ldquo;kube-hunter \u0026ndash;report json\u0026rdquo; to produce the report in json format.\nSample Scan Data Sample kubeHunter Scanner scans can be found here.","tags":[],"title":"kubeHunter Scanner"},{"content":"Kubescape is a K8s open-source tool providing a Kubernetes single pane of glass, including risk analysis, security compliance, RBAC visualizer, and image vulnerability scanning. Kubescape scans K8s clusters, YAML files, and HELM charts, detecting misconfigurations according to multiple frameworks (such as the NSA-CISA, MITRE ATT\u0026amp;CKÂ®), software vulnerabilities, and RBAC (role-based-access-control) violations at early stages of the CI/CD pipeline, calculates risk score instantly and shows risk trends over time.\nThe parser supports json output files\nSample Scan Data Sample Kubescape scans can be found here.\n","date":"0001-01-01","id":258,"permalink":"/en/connecting_your_tools/parsers/file/kubescape/","summary":"Kubescape is a K8s open-source tool providing a Kubernetes single pane of glass, including risk analysis, security compliance, RBAC visualizer, and image vulnerability scanning.","tags":[],"title":"Kubescape Scanner"},{"content":"File Types This DefectDojo parser accepts JSON files (in flattened format) from Legitify. For further details regarding the results, please consult the relevant documentation.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":259,"permalink":"/en/connecting_your_tools/parsers/file/legitify/","summary":"File Types This DefectDojo parser accepts JSON files (in flattened format) from Legitify. For further details regarding the results, please consult the relevant documentation.","tags":[],"title":"Legitify"},{"content":"Once you have run your first Discover operation, you should see a list of Mapped or Unmapped records on the Manage Records and Operations page.\nWhat\u0026rsquo;s a Record? A Record is a connection between a DefectDojo Product and a Vendor-Equivalent-Product. You can use your Records list to control the flow of data between your tool and DefectDojo.\nRecords are created and updated during the Discover operation, which DefectDojo runs daily to look for new Vendor-Equivalent Products.\nRecords have various attributes, including:\nThe State of the Record The Product the Record imports data to When the Record was First and Last Discovered (by the Discover process) When the Record mapping was Finalized by a user A link to the DefectDojo Product How Records are Mapped Each Record needs to have a Mapping assigned. The Mapping tells DefectDojo where to store the scan data from the tool. A Mapped Record assigns the Vendor-Equivalent Product to a DefectDojo Product, and tells the Connector to start importing scan data to that location (as Engagements and Tests).\nYou can assign Mappings yourself, or you can have DefectDojo assign them automatically.\nAuto-Mapping If you have Auto-Mapping enabled, new Records will be Mapped to Products automatically. Each time DefectDojo Discovers a new Record, a matching DefectDojo Product will be automatically created for each Record**.** That Record will be stored under Mapped Records to indicate that it is ready to import data to DefectDojo.\nIf you don\u0026rsquo;t have Auto-Mapping enabled, you can make your own decisions about where you want data to flow. Each time the Connector finds a new Vendor-Equivalent Product (via Discover), it will add a new Record to your Unmapped Records list, and you can then manually assign that Record to a new or existing Product in DefectDojo.\nMapping - Example Workflow: David has just finished setting up a connector for his BurpSuite tool, and runs a Discover operation. David has Burp set up to scan 4 different \u0026lsquo;Sites\u0026rsquo;, and DefectDojo creates a new Record for each of those Sites.\nIf David decides to use Auto-Mapping, DefectDojo will create a new Product for each Site. From now on, when DefectDojo runs a Synchronize operation, the Connector will import scan data directly from the Site into the Product (via the Record mapping)\nâ€‹ If David leaves Auto-Mapping off, DefectDojo will still discover those 4 Sites and create Records, but it won\u0026rsquo;t import any data until David creates the Mappings himself.\nâ€‹ David can always change how these mappings are set up later. Maybe he wants to consolidate the output of a few different Burp Sites into a single Product. Or maybe he\u0026rsquo;s looking to have a Product which records scan data from a few different tools - including Burp. It\u0026rsquo;s easy for David to change where Burp scan data is stored into DefectDojo by changing the Mapping of these Records. How Records interact with Products Once a Record is Mapped, DefectDojo will be ready to import your toolâ€™s scans through a Sync Operation. Connectors can work alongside other DefectDojo import processes or interactive testing.\nRecord Mappings are designed to be non-invasive. If you map a Product to a Record which contains existing Engagements or Findings, those existing Engagements and Findings will not be affected or overwritten by the data sync process.\nâ€‹ All data created via a connector will be stored under a single Engagement called Global Connectors. That Engagement will create a separate Test for each Connector mapped to the Product.\nâ€‹ This makes it possible to send scan data from multiple Connectors to the same Product. All of the data will be stored in the same Engagement, but each Connector will store data in a separate Test.\nTo learn more about Products, Engagements and Tests, see our Core Data Classes Overview.\nRecord States - Glossary Each Record has an associated state to communicate how the Record is working.\nNew A New Record is an Unmapped Record which DefectDojo has Discovered. It can be Mapped to a Product or Ignored. To Map a new Record to a Product, see our guide on Editing Records.\nGood \u0026lsquo;Good\u0026rsquo; indicates that a Record is Mapped and operating correctly. Future Discover Operations check to see if the underlying Vendor-Equivalent Product still exists, to ensure that the Sync operation will run correctly.\nIgnored \u0026lsquo;Ignored\u0026rsquo; Records have been successfully Discovered, but a DefectDojo user has decided not to map the data to a Product. If you wish to change a New or Mapped Record to Ignored, or re-map an Ignored Record, see our guide on Editing Records.\nWarning States: Stale or Missing If the connection between tool and DefectDojo changes, the state of a Record will change to let you know.\nStale A Mapping is moved to â€˜Staleâ€™ when a related Product, Engagement or Test has been deleted from DefectDojo. The mapping still exists, but there isnâ€™t anywhere in DefectDojo for the Toolâ€™s data to import to.\nStale records can be remapped to an existing Product, or Ignored if the scan data is no longer relevant.\nMissing If a Record has been Mapped, but the source data (or Vendor-Equivalent Product) is not being detected by DefectDojo, the Record will be labeled as Missing.\nDefectDojo Connectors will adapt to name changes, directory changes and other data shifts, so this is possibly because the related Vendor-Equivalent Product was deleted from the Tool youâ€™re using.\nIf you intended to remove the Vendor Equivalent Product from your tool, you can Delete a Missing Record. If not, you\u0026rsquo;ll need to troubleshoot the problem within the Tool so that the source data can be Discovered correctly.\n","date":"0001-01-01","id":260,"permalink":"/en/connecting_your_tools/connectors/manage_records/","summary":"Once you have run your first Discover operation, you should see a list of Mapped or Unmapped records on the Manage Records and Operations page.","tags":[],"title":"Manage Records"},{"content":"File Types Accepts a JSON file, generated from the Mend* Unified Agent.\nSample Scan Data / Unit Tests Unit tests for Mend JSON files can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/mend\nLink To Tool See documentation: https://docs.mend.io/bundle/unified_agent/page/example_of_a_unified_agent_json_report.html\nFormerly known as Whitesource.\n","date":"0001-01-01","id":261,"permalink":"/en/connecting_your_tools/parsers/file/mend/","summary":"File Types Accepts a JSON file, generated from the Mend* Unified Agent.\nSample Scan Data / Unit Tests Unit tests for Mend JSON files can be found at https://github.","tags":[],"title":"Mend Scan"},{"content":"The Meterian JSON report output file can be imported.\nSample Scan Data Sample Meterian Scanner scans can be found here.\n","date":"0001-01-01","id":262,"permalink":"/en/connecting_your_tools/parsers/file/meterian/","summary":"The Meterian JSON report output file can be imported.\nSample Scan Data Sample Meterian Scanner scans can be found here.","tags":[],"title":"Meterian Scanner"},{"content":"Import XML report\nSample Scan Data Sample Microfocus Webinspect Scanner scans can be found here.\n","date":"0001-01-01","id":263,"permalink":"/en/connecting_your_tools/parsers/file/microfocus_webinspect/","summary":"Import XML report\nSample Scan Data Sample Microfocus Webinspect Scanner scans can be found here.","tags":[],"title":"Microfocus Webinspect Scanner"},{"content":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scanner scans can be found here.\n","date":"0001-01-01","id":264,"permalink":"/en/connecting_your_tools/parsers/file/mobsf/","summary":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scanner scans can be found here.","tags":[],"title":"MobSF Scanner"},{"content":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scorecard Scanner scans can be found here.\n","date":"0001-01-01","id":265,"permalink":"/en/connecting_your_tools/parsers/file/mobsf_scorecard/","summary":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scorecard Scanner scans can be found here.","tags":[],"title":"MobSF Scorecard Scanner"},{"content":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan Data Sample Mobsfscan scans can be found here.\n","date":"0001-01-01","id":266,"permalink":"/en/connecting_your_tools/parsers/file/mobsfscan/","summary":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan Data Sample Mobsfscan scans can be found here.","tags":[],"title":"Mobsfscan"},{"content":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory Scanner scans can be found here.\n","date":"0001-01-01","id":267,"permalink":"/en/connecting_your_tools/parsers/file/mozilla_observatory/","summary":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory Scanner scans can be found here.","tags":[],"title":"Mozilla Observatory Scanner"},{"content":"This parser helps to parse Microsoft Defender Findings and supports two types of imports:\nYou can import a JSON output file from the api/vulnerabilities/machinesVulnerabilities endpoint of Microsoft defender. You can upload a custom zip file which include multiple JSON files from two Microsoft Defender Endpoints. For that you have to make your own zip file and include two folders (machines/ and vulnerabilities/) within the zip file. For vulnerabilities/ you can attach multiple JSON files from the api/vulnerabilities/machinesVulnerabilities REST API endpoint of Microsoft Defender. Furthermore, in machines/ you can attach the JSON output from the api/machines REST API endpoint of Microsoft Defender. Then, the parser uses the information in both folders to add more specific information like the affected IP Address to the finding. Sample Scan Data Sample MS Defender Parser scans can be found here.\n","date":"0001-01-01","id":268,"permalink":"/en/connecting_your_tools/parsers/file/ms_defender/","summary":"This parser helps to parse Microsoft Defender Findings and supports two types of imports:\nYou can import a JSON output file from the api/vulnerabilities/machinesVulnerabilities endpoint of Microsoft defender.","tags":[],"title":"MS Defender Parser"},{"content":"Nancy output file (go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json) can be imported in JSON format.\nFile Types This parser expects a JSON file.\nCommand Used To Generate Output `go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json` Sample Scan Data Sample Nancy scans can be found here.\nLink To Tool See Nancy on GitHub: https://github.com/sonatype-nexus-community/nancy\n","date":"0001-01-01","id":269,"permalink":"/en/connecting_your_tools/parsers/file/nancy/","summary":"Nancy output file (go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json) can be imported in JSON format.\nFile Types This parser expects a JSON file.","tags":[],"title":"Nancy Scan"},{"content":"Vulnerabilities List - JSON report\nNetsparker has now become Invicti. Please plan to migrate automation scripts to use the Invicti Scan\nSample Scan Data Sample Netsparker scans can be found here.\n","date":"0001-01-01","id":270,"permalink":"/en/connecting_your_tools/parsers/file/netsparker/","summary":"Vulnerabilities List - JSON report\nNetsparker has now become Invicti. Please plan to migrate automation scripts to use the Invicti Scan","tags":[],"title":"Netsparker"},{"content":"Imports compliance scans returned by REST API.\nSample Scan Data Sample NeuVector (compliance) scans can be found here.\n","date":"0001-01-01","id":271,"permalink":"/en/connecting_your_tools/parsers/file/neuvector/","summary":"Imports compliance scans returned by REST API.\nSample Scan Data Sample NeuVector (compliance) scans can be found here.","tags":[],"title":"NeuVector (compliance)"},{"content":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample NeuVector (REST) scans can be found here.\n","date":"0001-01-01","id":272,"permalink":"/en/connecting_your_tools/parsers/file/neuvector_compliance/","summary":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample NeuVector (REST) scans can be found here.","tags":[],"title":"NeuVector (REST)"},{"content":"Use the full XML export template from Nexpose.\nSample Scan Data Sample Nexpose XML 2.0 (Rapid7) scans can be found here.\n","date":"0001-01-01","id":273,"permalink":"/en/connecting_your_tools/parsers/file/nexpose/","summary":"Use the full XML export template from Nexpose.\nSample Scan Data Sample Nexpose XML 2.0 (Rapid7) scans can be found here.","tags":[],"title":"Nexpose XML 2.0 (Rapid7)"},{"content":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\nXML output (old) new XML output (with nxvmlversion=\u0026quot;1.2\u0026quot; type) JSON output See: https://github.com/sullo/nikto\nSample Scan Data Sample Nikto scans can be found here.\n","date":"0001-01-01","id":274,"permalink":"/en/connecting_your_tools/parsers/file/nikto/","summary":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\nXML output (old) new XML output (with nxvmlversion=\u0026quot;1.2\u0026quot; type) JSON output See: https://github.","tags":[],"title":"Nikto"},{"content":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found here.\n","date":"0001-01-01","id":275,"permalink":"/en/connecting_your_tools/parsers/file/nmap/","summary":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found here.","tags":[],"title":"Nmap"},{"content":"Node Security Platform (NSP) output file can be imported in JSON format.\nSample Scan Data Sample Node Security Platform scans can be found here.\n","date":"0001-01-01","id":276,"permalink":"/en/connecting_your_tools/parsers/file/nsp/","summary":"Node Security Platform (NSP) output file can be imported in JSON format.\nSample Scan Data Sample Node Security Platform scans can be found here.","tags":[],"title":"Node Security Platform"},{"content":"Input Type: This parser takes JSON Lines Output from Nosey Parker: https://github.com/praetorian-inc/noseyparkerSupports\nSupports version 0.16.0: https://github.com/praetorian-inc/noseyparker/releases/tag/v0.16.0\nThings to note about the Nosey Parker Parser: All findings are marked with a severity of \u0026lsquo;High\u0026rsquo; The deduplication algorithm marks a unique finding by the secret, filepath, and line number all together The Nosey Parker tool allows for both full history scans of a repo and targeted branch scans The Parser does NOT differentiate between the 2 scan types (may be future functionality)\nFor full history scans:\nThe scan will pick up secrets committed in the past that have since been removed If a secret is removed from source code, it will still show up in the next scan When importing findings via the Dojo API, make sure to use the parameter do_not_reactivate which will keep existing findings closed, without reactivating them For targeted branch scans:\nKeep in mind there may be active secrets that are either in the git history or not in the current branch JSON Lines Format: The parser only accepts .jsonl reports. Each line of the JSON Lines file from NoseyParker corresponds to a unique secret found with metadata for every match.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":277,"permalink":"/en/connecting_your_tools/parsers/file/noseyparker/","summary":"Input Type: This parser takes JSON Lines Output from Nosey Parker: https://github.com/praetorian-inc/noseyparkerSupports\nSupports version 0.16.0: https://github.com/praetorian-inc/noseyparker/releases/tag/v0.16.0\nThings to note about the Nosey Parker Parser: All findings are marked with a severity of \u0026lsquo;High\u0026rsquo; The deduplication algorithm marks a unique finding by the secret, filepath, and line number all together The Nosey Parker tool allows for both full history scans of a repo and targeted branch scans The Parser does NOT differentiate between the 2 scan types (may be future functionality)","tags":[],"title":"Nosey Parker"},{"content":"Note: This parser only supports import from NPM Audit v6 or older.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'advisories' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v6 or older due to missing relevant fields, including:\nFinding created / updated dates Relevant CVE number Finding overview (description Field) Recommendation Issue reference CWE Exploitability See NPM\u0026rsquo;s issue on GitHub for more information. https://github.com/npm/npm-audit-report/issues/45\nAttempting to import a file from a later version of NPM Audit will raise an error message.\nSample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","date":"0001-01-01","id":278,"permalink":"/en/connecting_your_tools/parsers/file/npm_audit/","summary":"Note: This parser only supports import from NPM Audit v6 or older.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format.","tags":[],"title":"NPM Audit"},{"content":"Note: This parser only supports import from NPM Audit v7 or newer.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'vulnerabilities' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v7 or newer. It aims to provide the same information as the non-JSON formatted output.\nAttempting to import a file from a version less than 7 of NPM Audit will raise an error message.\nCommand Used To Generate Output Either of these commands will work:\n`npm audit \u0026ndash;json` `npm audit fix \u0026ndash;dry-run \u0026ndash;json` Sample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","date":"0001-01-01","id":279,"permalink":"/en/connecting_your_tools/parsers/file/npm_audit_7_plus/","summary":"Note: This parser only supports import from NPM Audit v7 or newer.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format.","tags":[],"title":"NPM Audit Version 7+"},{"content":"Import JSON output of nuclei scan report https://github.com/projectdiscovery/nuclei\nSample Scan Data Sample Nuclei scans can be found here.\n","date":"0001-01-01","id":280,"permalink":"/en/connecting_your_tools/parsers/file/nuclei/","summary":"Import JSON output of nuclei scan report https://github.com/projectdiscovery/nuclei\nSample Scan Data Sample Nuclei scans can be found here.","tags":[],"title":"Nuclei"},{"content":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data Sample Openscap Vulnerability Scan scans can be found here.\n","date":"0001-01-01","id":281,"permalink":"/en/connecting_your_tools/parsers/file/openscap/","summary":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data Sample Openscap Vulnerability Scan scans can be found here.","tags":[],"title":"Openscap Vulnerability Scan"},{"content":"You can either upload the exported results of an OpenVAS Scan in a .csv or .xml format.\nSample Scan Data Sample OpenVAS scans can be found here.\n","date":"0001-01-01","id":282,"permalink":"/en/connecting_your_tools/parsers/file/openvas/","summary":"You can either upload the exported results of an OpenVAS Scan in a .csv or .xml format.\nSample Scan Data Sample OpenVAS scans can be found here.","tags":[],"title":"OpenVAS Parser"},{"content":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample ORT evaluated model Importer scans can be found here.\n","date":"0001-01-01","id":283,"permalink":"/en/connecting_your_tools/parsers/file/ort/","summary":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample ORT evaluated model Importer scans can be found here.","tags":[],"title":"ORT evaluated model Importer"},{"content":"Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nSample Scan Data Sample OssIndex Devaudit scans can be found here.\n","date":"0001-01-01","id":284,"permalink":"/en/connecting_your_tools/parsers/file/ossindex_devaudit/","summary":"Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nSample Scan Data Sample OssIndex Devaudit scans can be found here.","tags":[],"title":"OssIndex Devaudit"},{"content":"Use OSV-Scanner to find existing vulnerabilities affecting your project\u0026rsquo;s dependencies.\nSample Scan Data Sample OSV Scanner output can be found here.\n","date":"0001-01-01","id":285,"permalink":"/en/connecting_your_tools/parsers/file/osv_scanner/","summary":"Use OSV-Scanner to find existing vulnerabilities affecting your project\u0026rsquo;s dependencies.\nSample Scan Data Sample OSV Scanner output can be found here.","tags":[],"title":"OSV Scanner"},{"content":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample Outpost24 Scan scans can be found here.\n","date":"0001-01-01","id":286,"permalink":"/en/connecting_your_tools/parsers/file/outpost24/","summary":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample Outpost24 Scan scans can be found here.","tags":[],"title":"Outpost24 Scan"},{"content":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data Sample PHP Security Audit v2 scans can be found here.\n","date":"0001-01-01","id":287,"permalink":"/en/connecting_your_tools/parsers/file/php_security_audit_v2/","summary":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data Sample PHP Security Audit v2 scans can be found here.","tags":[],"title":"PHP Security Audit v2"},{"content":"Import results from the PHP Symfony Security Checker.\nSample Scan Data Sample PHP Symfony Security Checker scans can be found here.\n","date":"0001-01-01","id":288,"permalink":"/en/connecting_your_tools/parsers/file/php_symfony_security_check/","summary":"Import results from the PHP Symfony Security Checker.\nSample Scan Data Sample PHP Symfony Security Checker scans can be found here.","tags":[],"title":"PHP Symfony Security Checker"},{"content":"Import pip-audit JSON scan report.\nFile Types This parser expects a JSON file.\nThe parser can handle legacy and current JSON format.\nThe current format has added a dependencies element:\n{ \u0026quot;dependencies\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;pyopenssl\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;23.1.0\u0026quot;, \u0026quot;vulns\u0026quot;: [] }, ... ] ... } The legacy format does not include the dependencies key:\n[ { \u0026quot;name\u0026quot;: \u0026quot;adal\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;1.2.2\u0026quot;, \u0026quot;vulns\u0026quot;: [] }, ... ] Sample Scan Data Sample pip-audit Scan scans can be found here.\nLink To Tool pip-audit\n","date":"0001-01-01","id":289,"permalink":"/en/connecting_your_tools/parsers/file/pip_audit/","summary":"Import pip-audit JSON scan report.\nFile Types This parser expects a JSON file.\nThe parser can handle legacy and current JSON format.","tags":[],"title":"pip-audit Scan"},{"content":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.\n","date":"0001-01-01","id":290,"permalink":"/en/connecting_your_tools/parsers/file/pmd/","summary":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.","tags":[],"title":"PMD Scan"},{"content":"Popeye Parser documentation. Popeye is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations. For more information about the tool, please visit the public repository https://github.com/derailed/popeye.\nPopeye reports. Popeye offer different format to export their reports, in this case for the parser we have selected to be done with JSON option for simplicity. Support for other report types planned for future.\nJSON reports have the following structure:\n{ \u0026#34;popeye\u0026#34;: { \u0026#34;score\u0026#34;: 100, \u0026#34;grade\u0026#34;: \u0026#34;B\u0026#34;, \u0026#34;sanitizers\u0026#34;: [ { \u0026#34;sanitizer\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;gvr\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;tally\u0026#34;: { \u0026#34;ok\u0026#34;: 1, \u0026#34;info\u0026#34;: 0, \u0026#34;warning\u0026#34;: 0, \u0026#34;error\u0026#34;: 0, \u0026#34;score\u0026#34;: 100 }, \u0026#34;issues\u0026#34;: { \u0026#34;Version\u0026#34;: [ { \u0026#34;group\u0026#34;: \u0026#34;__root__\u0026#34;, \u0026#34;gvr\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;level\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;[POP-406] K8s version OK\u0026#34; } ] } } ] } }\rThey offer a list of \u0026ldquo;sanitizers\u0026rdquo; that is the list of scanned resources in the cluster. At the same time, each sanitizer will have a list of issues, in this case the issues names will match to specific resources of the cluster (pods, roles, clusterroles, etc.) where each one will have inside a list of specific findings for that resource (issue in the report).\nThis parser goes through every finding inside the issues of every sanitizer looking for the ones with level 1 (Info), 2 (Warning) or 3 (Error) to be created as findings in DefectDojo.\nFindings severity matching. Popeye scan findings don\u0026rsquo;t match to public vulnerabilities, it just looks for possible informational topic, warnings or errors in kubernetes resources definition or configuraiton, so they categorize their findings the following way:\nSeverity 0: Ok Severity 1: Info Severity 2: Warning Severity 3: Error To match it to DefectDojo severity formula, Secerity 0 (Ok) findings from Popeye will be ignored as those are checks that does not need an action to be resolved. For the rest:\nSeverity 1 (Info) Popeye findings will be created as Severity \u0026ldquo;Info\u0026rdquo; findings in DefectDojo. Severity 2 (Warning) Popeye findings will be created as Severity \u0026ldquo;Low\u0026rdquo; findings in DefectDojo. Severity 3 (Errors) Popeye findings will be created as Severity \u0026ldquo;High\u0026rdquo; findingsi in DefectDojo. Sample Scan Data Sample Popeye scans can be found here.\n","date":"0001-01-01","id":291,"permalink":"/en/connecting_your_tools/parsers/file/popeye/","summary":"Popeye Parser documentation. Popeye is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations.","tags":[],"title":"Popeye"},{"content":"DefectDojo can calculate a grade for your Products based on the amount of Findings contained within. Grades are ranked from A - F.\nNote that only Active \u0026amp; Verified Findings contribute to a Product Grade - unverified Findings will not have an impact.\nProduct Grade Calculation Every Product Grade starts at 100 (with no Findings).\nGrade calculation starts by looking at the highest Severity level of a Finding in a Product, and reducing the Product Health to a base level.\nHighest Severity Level of a Finding Maximum Grade Critical 40 High 60 Medium 80 Low 95 Further points are then deducted from the Grade for each additional Finding:\nSeverity Level of an additional Finding Grade Reduced by Critical 5 High 3 Medium 2 Low 1 ","date":"0001-01-01","id":292,"permalink":"/en/working_with_findings/organizing_engagements_tests/product-health-grade/","summary":"DefectDojo can calculate a grade for your Products based on the amount of Findings contained within. Grades are ranked from A - F.","tags":[],"title":"Product Health Grade"},{"content":"DefectDojo uses five main data classes to organize your work: Product Types, Products, Engagements, Tests, and Findings.\nDefectDojo is made to be flexible to conform to your team, rather than making your team conform to the tool. You\u0026rsquo;ll be able to design a robust, adaptable workspace once you understand how these data classes can be used to organize your work.\nProduct Types The first category of data you\u0026rsquo;ll need to set up in DefectDojo is a Product Type. Product Types are intended to categorize Products in a specific way. This could be:\nby business domain by development team by security team Product Types can have Role-Based Access Control rules applied, which limit team members\u0026rsquo; ability to view and interact with their data (including any underlying Products with Engagement, Test and Finding data). For more information on user roles, see our Introduction To Roles article.\nWhat can a Product Type represent? If a particular software project has many distinct deployments or versions, it may be worth creating a single Product Type which covers the scope of the entire project, and having each version exist as individual Products.\nâ€‹ You also might consider using Product Types to represent stages in your software development process: one Product Type for \u0026lsquo;In Development\u0026rsquo;, one Product Type for \u0026lsquo;In Production\u0026rsquo;, etc.\nâ€‹ Ultimately, it\u0026rsquo;s your decision how you wish to organize your Products, and what you Product Type to represent. Your DefectDojo hierarchy may need to change to fit your security teams\u0026rsquo; needs. Products A Product in DefectDojo is intended to represent any project, program, or product that you are currently testing. The Product hosts all of the security work and testing history related to the underlying goal.\nProducts always have:\na unique Name a Description a product Type an assigned SLA Configuration Products can be as broad or as specific in scope as you wish. By default, Products are completely separate objects in the hierarchy, but they can be grouped together by Product Type.\nProducts are \u0026lsquo;walled-off\u0026rsquo; and do not interact with other Products. DefectDojo\u0026rsquo;s Smart Features, such as Deduplication, only apply within the context of a single Product.\nLike Product Types, Products can have Role-Based Access Control rules applied, which limit team members\u0026rsquo; ability to view and interact with them (as well as any underlying Engagement, Test and Finding data). For more information on user roles, see our Introduction To Roles article.\nWhat can a Product represent? DefectDojo\u0026rsquo;s concept of a \u0026lsquo;Product\u0026rsquo; will not necessarily correspond 1:1 to what your organization would refer to as a \u0026lsquo;Product\u0026rsquo;. Software development is complex, and security needs can vary greatly even within the scope of a single piece of software.\nThe following scenarios are good reasons to consider creating a separate DefectDojo Product:\n\u0026ldquo;ExampleProduct\u0026rdquo; has a Windows version, a Mac version, and a Cloud version \u0026ldquo;ExampleProduct 1.0\u0026rdquo; uses completely different software components from \u0026ldquo;ExampleProduct 2.0\u0026rdquo;, and both versions are actively supported by your company. The team assigned to work on \u0026ldquo;ExampleProduct version A\u0026rdquo; is different than the product team assigned to work on \u0026ldquo;ExampleProduct version B\u0026rdquo;, and needs to have different security permissions assigned as a result. These variations within a single Product can also be handled at the Engagement level. Note that Engagements don\u0026rsquo;t have access control in the way Products and Product Types do.\nEngagements Once a Product is set up, you can begin creating and scheduling Engagements. Engagements are meant to represent moments in time when testing is taking place, and contain one or more Tests.\nEngagements always have:\na unique Name target Start and End dates Status (Not Started, In Progress, Cancelled, Completed\u0026hellip;) an assigned Testing Lead an associated Product There are two types of Engagement: Interactive and CI/CD.\nAn Interactive Engagement is typically run by an engineer. Interactive Engagements are focused on testing the application while the app is running, using an automated test, human tester, or any activity â€œinteractingâ€ with the application functionality. See OWASP\u0026rsquo;s definition of IAST. A CI/CD Engagement is for automated integration with a CI/CD pipeline. CI/CD Engagements are meant to import data as an automated action, triggered by a step in the release process. Engagements can be tracked using DefectDojo\u0026rsquo;s Calendar view.\nWhat can an Engagement represent? Engagements are meant to represent groups of related testing efforts. How you wish to group your testing efforts depends on your approach.\nIf you have a planned testing effort scheduled, an Engagement offers you a place to store all of the related results. Here\u0026rsquo;s an example of this kind of Engagement:\nEngagement: ExampleSoftware 1.5.2 - Interactive Testing Effort In this example, a security team runs multiple tests on the same day as part of a software release.\nTest: Nessus Scan Results (March 12) Test: NPM Scan Audit Results (March 12) Test: Snyk Scan Results (March 12)\nâ€‹ You can also organize CI/CD Test results within an Engagement. These kinds of Engagements are \u0026lsquo;Open-Ended\u0026rsquo; meaning that they don\u0026rsquo;t have a date, and will instead add additional data each time the associated CI/CD actions are run.\nEngagement: ExampleSoftware CI/CD Testing In this example, multiple CI/CD scans are automatically imported as Tests every time a new software release is created.\nTest: 1.5.2 Scan Results (March 12) Test: 1.5.1 Scan Results (March 3) Test: 1.5.0 Scan Results (February 14) Engagements can be organized however works best for your team. All Engagements nested under a Product can be viewed by the team assigned to work on the Product.\nTests Tests are a grouping of activities conducted by engineers to attempt to discover flaws in a product.\nTests always have:\na unique Test Title a specific **Test Type (**API Test, Nessus Scan, etc) an associated test Environment an associated Engagement Tests can be created in different ways. Scan data can be directly imported to an Engagement, which will then create a new Test containing that data. Tests can also be created in advance without scan data, as part of planning future Engagements.\nHow do Tests interact with each other? Tests take your testing data and group it into Findings. Generally, security teams will be running the same testing effort repeatedly, and Tests in DefectDojo allow you to handle this process in an elegant way.\nPreviously imported tests can be reimported - If you\u0026rsquo;re running the same type of test within the same Engagement context, you can Reimport the test results after each completed scan. DefectDojo will compare the Reimported data to the existing result, and will not create new Findings if duplicates exist in the scan data.\nTests can be imported separately - If you run the same test on a Product within separate Engagements, DefectDojo will still compare the data with previous Tests to find duplicate Findings. This allows you to keep track of previously mitigated or risk-accepted Findings.\nIf a Test is added directly to a Product without an Engagement, a generic Engagement will be created automatically to contain the Test. This allows for ad-hoc data imports.\nExamples of Tests:\nBurp Scan from Oct. 29, 2015 to Oct. 29, 2015 Nessus Scan from Oct. 31, 2015 to Oct. 31, 2015 API Test from Oct. 15, 2015 to Oct. 20, 2015 Findings Once data has been added uploaded to a Test, the results of that data will be listed in the Test as individual Findings for review.\nA finding represents a specific flaw discovered while testing.\nFindings always have:\na unique Finding Name the Date they were uncovered multiple associated Statuses, such as Active, Verified or False Positive an associated Test a Severity level: Critical, High, Medium, Low, and Informational (Info). Findings can be added through a data import, but they can also be added manually to a Test.\nExamples of Findings:\nOpenSSL â€˜ChangeCipherSpecâ€™ MiTM Potential Vulnerability Web Application Potentially Vulnerable to Clickjacking Web Browser XSS Protection Not Enabled ","date":"0001-01-01","id":293,"permalink":"/en/working_with_findings/organizing_engagements_tests/product-hierarchy-overview/","summary":"DefectDojo uses five main data classes to organize your work: Product Types, Products, Engagements, Tests, and Findings.\nDefectDojo is made to be flexible to conform to your team, rather than making your team conform to the tool.","tags":[],"title":"Product Hierarchy: Overview"},{"content":"This parser imports the Progpilot SAST JSON output. The scanner can be found here.\nSample Scan Data Sample Progpilot Parser scans can be found here.\n","date":"0001-01-01","id":294,"permalink":"/en/connecting_your_tools/parsers/file/progpilot/","summary":"This parser imports the Progpilot SAST JSON output. The scanner can be found here.\nSample Scan Data Sample Progpilot Parser scans can be found here.","tags":[],"title":"Progpilot"},{"content":"What is PTART? PTART is a Pentest and Security Auditing Reporting Tool developed by the Michelin CERT (https://github.com/certmichelin/PTART)\nImporting Reports Reports can be exported to JSON format from the PTART web UI, and imported into DefectDojo by using the \u0026ldquo;PTART Report\u0026rdquo; importer.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":295,"permalink":"/en/connecting_your_tools/parsers/file/ptart/","summary":"What is PTART? PTART is a Pentest and Security Auditing Reporting Tool developed by the Michelin CERT (https://github.com/certmichelin/PTART)\nImporting Reports Reports can be exported to JSON format from the PTART web UI, and imported into DefectDojo by using the \u0026ldquo;PTART Report\u0026rdquo; importer.","tags":[],"title":"PTART Reports"},{"content":" (Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON results generated by the pwn_sast Driver. This driver scans source code repositories for security anti-patterns that may result in vulnerability identification. More driver results coming soon\u0026hellip; Sample Scan Data Sample PWN Security Automation Framework scans can be found here.\n","date":"0001-01-01","id":296,"permalink":"/en/connecting_your_tools/parsers/file/pwn_sast/","summary":"(Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON results generated by the pwn_sast Driver. This driver scans source code repositories for security anti-patterns that may result in vulnerability identification.","tags":[],"title":"PWN Security Automation Framework"},{"content":"Qualys Hacker Guardian CSV export\nSample Scan Data Sample Qualys Scan scans can be found here.\n","date":"0001-01-01","id":297,"permalink":"/en/connecting_your_tools/parsers/file/qualys_hacker_guardian/","summary":"Qualys Hacker Guardian CSV export\nSample Scan Data Sample Qualys Scan scans can be found here.","tags":[],"title":"Qualys Hacker Guardian Scan"},{"content":"Qualys WebGUI output files can be imported in XML format.\nSample Scan Data Sample Qualys Infrastructure Scan (WebGUI XML) scans can be found here.\n","date":"0001-01-01","id":298,"permalink":"/en/connecting_your_tools/parsers/file/qualys_infrascan_webgui/","summary":"Qualys WebGUI output files can be imported in XML format.\nSample Scan Data Sample Qualys Infrastructure Scan (WebGUI XML) scans can be found here.","tags":[],"title":"Qualys Infrastructure Scan (WebGUI XML)"},{"content":"Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.\nA CSV formatted Qualys Scan Report can also be used. Ensure the following values are checked in the Scan Report Template config:\nCVSS Version = CVSSv3\nVulnerability Details Threat Impact Solution Patches and Workarounds Virtual Patches and Mitigating Controls Results Sample Scan Data Sample Qualys Scan scans can be found here.\n","date":"0001-01-01","id":299,"permalink":"/en/connecting_your_tools/parsers/file/qualys/","summary":"Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.","tags":[],"title":"Qualys Scan"},{"content":"Qualys WebScan output files can be imported in XML format.\nSample Scan Data Sample Qualys Webapp Scan scans can be found here.\n","date":"0001-01-01","id":300,"permalink":"/en/connecting_your_tools/parsers/file/qualys_webapp/","summary":"Qualys WebScan output files can be imported in XML format.\nSample Scan Data Sample Qualys Webapp Scan scans can be found here.","tags":[],"title":"Qualys Webapp Scan"},{"content":"Import JSON report of Rapplex - Web Application Security Scanner\nSample Scan Data Sample Rapplex scans can be found here.\n","date":"0001-01-01","id":301,"permalink":"/en/connecting_your_tools/parsers/file/rapplex/","summary":"Import JSON report of Rapplex - Web Application Security Scanner\nSample Scan Data Sample Rapplex scans can be found here.","tags":[],"title":"Rapplex Scan"},{"content":"You can import a JSON report which was retrieved through the REST API of Red Hat Satellite. The scanner can be found here.\nSample Scan Data Sample Red Hat Satellite scans can be found here.\n","date":"0001-01-01","id":302,"permalink":"/en/connecting_your_tools/parsers/file/redhatsatellite/","summary":"You can import a JSON report which was retrieved through the REST API of Red Hat Satellite. The scanner can be found here.","tags":[],"title":"Red Hat Satellite"},{"content":"Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nSample Scan Data Sample Retire.js scans can be found here.\n","date":"0001-01-01","id":303,"permalink":"/en/connecting_your_tools/parsers/file/retirejs/","summary":"Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nSample Scan Data Sample Retire.js scans can be found here.","tags":[],"title":"Retire.js"},{"content":"â€˜Risk Acceptedâ€™ is a special status that can be applied to a Finding in two ways:\nRisk Accepted can be freely applied as a Status if â€˜Simple Risk Acceptanceâ€™ is enabled. You can also create Full Risk Acceptances, which are objects stored in DefectDojo to capture a risk acceptance decision made by your team. A Full Risk Acceptance is a special object in DefectDojo, used when Active Findings are â€˜backloggedâ€™ by your team. Often, both security teams and developer teams will decide when a Risk Acceptance is appropriate. In DefectDojo, your team can create Risk Acceptances which capture the internal decision making process and can be used as a source of truth.\nAbout Full Risk Acceptances Each Full Risk Acceptance can store details about the following:\nThe Security teamâ€™s recommendation to a Product owner or other stakeholder Description of the decision made by stakeholders The DefectDojo user involved in the decision making process One or more Findings governed by the Risk Acceptance Findings can be added to a Risk Acceptance regardless of the Product, Test or Engagement they are in.\nAny Findings associated with a Full Risk Acceptance will be set to Inactive, Risk Accepted.\nGenerally, any Risk Acceptances should follow your internal security policy and be re-examined at an appropriate time. As a result, Risk Acceptances also have expiration dates. Once a Risk Acceptance expires, any Findings will be set to Active again.\nAdding a new Full Risk Acceptance Risk Acceptances can be added to a Finding in two ways:\nUsing the Bulk Edit menu, when looking at a list of Findings Using the Add Risk Acceptance button on an individual Finding ##\nTo create a New Risk Acceptance, complete the Add to New Risk Acceptance form on a Finding you wish to Risk Accept.\n1. Create a Name for the Risk Acceptance. 2. Select the Owner of the Risk Acceptance - this is generally meant to be the DefectDojo team member responsible for the decision to Risk Accept the Finding 3. Complete the Optional Fields with any relevant information. If you want to set an Expiration Date or a Warning for that Expiration Date, you can do so here as well. If you donâ€™t specify a date, the Default Risk Acceptance / Default Risk Acceptance Expiration days will be used from the System Settings page. 4. Select whether you want to Reactivate or Restart SLAs on any associated Findings once the Risk Acceptance expires.\nSimple Risk Acceptances If you donâ€™t want to create a Full Risk Acceptance object and would prefer to simply apply a status of â€˜Risk Acceptedâ€™ to a Finding, you can do so through the Bulk Edit menu. This method is called Simple Risk Acceptance.\nBefore you can apply a Simple Risk Acceptance to a Finding, Simple Risk Acceptance will need to be enabled at the Product level. This setting can be found on the Edit Product Form.\nApplying a Simple Risk Acceptance With one or more Findings selected, open Bulk Update Actions. Navigate to Simple Risk Acceptance Status and select either Accept Risk or Unaccept Risk. Once you have submitted the Bulk Update, â€˜Risk Acceptedâ€™ will be applied to any Findings selected without the need to create a Risk Acceptance object (with an expiration date or additional metadata).\nLocating Risk Accepted Findings The sidebar in DefectDojo allows you to quickly find any Risk Accepted Findings by opening Manage \u0026gt; Risk Acceptances. From here you can view the Risk Acceptance objects themselves, or view a list of Risk Accepted Findings.\n","date":"0001-01-01","id":304,"permalink":"/en/working_with_findings/risk-acceptances/","summary":"â€˜Risk Acceptedâ€™ is a special status that can be applied to a Finding in two ways:\nRisk Accepted can be freely applied as a Status if â€˜Simple Risk Acceptanceâ€™ is enabled.","tags":[],"title":"Risk Acceptances"},{"content":"Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \u0026#34;url_endpoint\u0026#34;: \u0026#34;https://api.riskrecon.com/v1\u0026#34;, \u0026#34;api_key\u0026#34;: \u0026#34;you-api-key\u0026#34;, \u0026#34;companies\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Company 1\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [\u0026#34;127.0.0.1\u0026#34;], \u0026#34;host_name\u0026#34;: [\u0026#34;localhost\u0026#34;], \u0026#34;asset_value\u0026#34;: [], \u0026#34;severity\u0026#34;: [\u0026#34;critical\u0026#34;, \u0026#34;high\u0026#34;], \u0026#34;priority\u0026#34;: [], \u0026#34;hosting_provider\u0026#34;: [], \u0026#34;country_name\u0026#34;: [] } }, { \u0026#34;name\u0026#34;: \u0026#34;Company 2\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;ip_address\u0026#34;: [\u0026#34;0.0.0.0\u0026#34;] } } ], \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [], \u0026#34;host_name\u0026#34;: [], \u0026#34;asset_value\u0026#34;: [], \u0026#34;severity\u0026#34;: [\u0026#34;critical\u0026#34;], \u0026#34;priority\u0026#34;: [], \u0026#34;hosting_provider\u0026#34;: [], \u0026#34;country_name\u0026#34;: [] } } More than one company finding list can be queried with it's own set of filters. Company 1 shows all available fitlers, while Company 2 shows that empty filters need not be present. To query all companies in your Risk Recon instance, simple remove the \u0026quot;companies\u0026quot; field entirely. If the \u0026quot;companies\u0026quot; field is not present, and filtering is still requested, the \u0026quot;filters\u0026quot; field can be used to filter all findings across all companies. It carries the same behavior as the company filters. The \u0026quot;filters\u0026quot; field is disregarded in the prescense of the \u0026quot;companies\u0026quot; field. Removing both fields will allow retrieval of all findings in the Risk Recon instance. Sample Scan Data Sample Risk Recon API Importer scans can be found here.\n","date":"0001-01-01","id":305,"permalink":"/en/connecting_your_tools/parsers/file/risk_recon/","summary":"Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \u0026#34;url_endpoint\u0026#34;: \u0026#34;https://api.riskrecon.com/v1\u0026#34;, \u0026#34;api_key\u0026#34;: \u0026#34;you-api-key\u0026#34;, \u0026#34;companies\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Company 1\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [\u0026#34;127.","tags":[],"title":"Risk Recon API Importer"},{"content":"Import Rubocop JSON scan report (with option -f json).\nSample Scan Data Sample Rubocop Scan scans can be found here.\n","date":"0001-01-01","id":306,"permalink":"/en/connecting_your_tools/parsers/file/rubocop/","summary":"Import Rubocop JSON scan report (with option -f json).\nSample Scan Data Sample Rubocop Scan scans can be found here.","tags":[],"title":"Rubocop Scan"},{"content":"From: https://github.com/newrelic/rusty-hog Import the JSON output. Rusty Hog is a secret scanner built in Rust for performance, and based on TruffleHog which is written in Python.\nDefectDojo currently supports the parsing of the following Rusty Hog JSON outputs:\nChoctaw Hog: Scans for secrets in a Git repository. Duroc Hog: Scans for secrets in directories, files, and archives. Gottingen Hog: Scans for secrets in a JIRA issue. Essex Hog: Scans for secrets in a Confluence page. RustyHog scans only one target at a time. This is not efficient if you want to scan all targets (e.g. all JIRA tickets) and upload each single report to DefectDojo. Rusty-Hog-Wrapper deals with this and scans a whole JIRA Project or Confluence Space, merges the findings into a valid file which can be uploaded to DefectDojo. (This is no official recommendation from DefectDojo, but rather a pointer in a direction on how to use this vulnerability scanner in a more efficient way.)\nSample Scan Data Sample Rusty Hog parser scans can be found here.\n","date":"0001-01-01","id":307,"permalink":"/en/connecting_your_tools/parsers/file/rusty_hog/","summary":"From: https://github.com/newrelic/rusty-hog Import the JSON output. Rusty Hog is a secret scanner built in Rust for performance, and based on TruffleHog which is written in Python.","tags":[],"title":"Rusty Hog parser"},{"content":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif\nSARIF parser customizes the Test_Type with data from the report. For example, a report with Dockle as a driver name will produce a Test with a Test_Type named Dockle Scan (SARIF)\nCurrent implementation is limited and will aggregate all the findings in the SARIF file in one single report.\nSupport for de-duplication (fingerprinting) SARIF parser take into account data for fingerprinting. It\u0026rsquo;s base on fingerprints and partialFingerprints properties. It\u0026rsquo;s possible to activate de-duplication based on this data by customizing settings.\n# in your settings.py file DEDUPLICATION_ALGORITHM_PER_PARSER[\u0026#34;SARIF\u0026#34;] = DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE\rSample Scan Data Sample SARIF scans can be found here.\n","date":"0001-01-01","id":308,"permalink":"/en/connecting_your_tools/parsers/file/sarif/","summary":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif","tags":[],"title":"SARIF"},{"content":"Scantist is an open source management platform. Scan and remediate open source security, licensing and compliance risks across your software development lifecycle. Here you can find more information: https://scantist.com/\nSample Scan Data Sample Scantist Scan scans can be found here.\n","date":"0001-01-01","id":309,"permalink":"/en/connecting_your_tools/parsers/file/scantist/","summary":"Scantist is an open source management platform. Scan and remediate open source security, licensing and compliance risks across your software development lifecycle.","tags":[],"title":"Scantist Scan"},{"content":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects. See https://github.com/nccgroup/ScoutSuite\nSample Scan Data Sample ScoutSuite scans can be found here.\n","date":"0001-01-01","id":310,"permalink":"/en/connecting_your_tools/parsers/file/scout_suite/","summary":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects.","tags":[],"title":"ScoutSuite"},{"content":"Import Semgrep output (\u0026ndash;json)\nSample Scan Data Sample Semgrep JSON Report scans can be found here.\n","date":"0001-01-01","id":311,"permalink":"/en/connecting_your_tools/parsers/file/semgrep/","summary":"Import Semgrep output (\u0026ndash;json)\nSample Scan Data Sample Semgrep JSON Report scans can be found here.","tags":[],"title":"Semgrep JSON Report"},{"content":"Introduction to Permission Types Individual users have four different kinds of permission that they can be assigned:\nUsers can be assigned as Members to Products or Product Types. This allows them to view and interact with Data Types (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on the role they are assigned on the specific Product. Users can have multiple Product or Product Type memberships, with different levels of access.\nâ€‹ Users can also have Configuration Permissions assigned, which allow them to access configuration pages in DefectDojo. Configuration Permissions are not related to Products or Product Types.\nâ€‹ Users can be assigned Global Roles, which give them a standardized level of access to all Products and Product Types.\nâ€‹ Users can be set up as Superusers: administrator level roles which give them control and access to all DefectDojo data and configuration. You can also create Groups if you want to assign Product Membership, Configuration Permissions or Global Roles to a group of users at the same time. If you have a large number of users in DefectDojo, such as a dedicated testing team for a particular Product, Groups may be a more helpful feature.\nSuperusers \u0026amp; Global Roles Part of your Role-Based Access Control (RBAC) configuration may require you to create additional Superusers, or users with Global Roles.\nSuperusers (Admins) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. They can also change access rules for all users in DefectDojo. Superusers will also receive notifications for all system issues and alerts. Users with Global Roles can view and interact with any Data Type (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on their assigned Role. For more information about each Role and associated privileges, please refer to our Introduction to Roles article. Users can also have specific Configuration Permissions assigned, allowing them to access certain DefectDojo configuration pages. Users have no Configuration Permissions by default. By default, the first account created on a new DefectDojo instance will have Superuser permissions. That user will be able to edit permissions for all subsequent DefectDojo users. Only an existing Superuser can add another superuser, or add a Global Role to a user.\nAdd Superuser or Global Role status to an existing user Navigate to the ðŸ‘¤ Users \u0026gt; Users page on the sidebar. You will see a list of all registered accounts on DefectDojo, along with each account\u0026rsquo;s Active status, Global Roles, and other relevant User data.\nâ€‹ â€‹ 2. Click the name of the account that you wish to give Superuser privileges to. This will bring you to their User Page.\nâ€‹ 3. From the Default Information section of their User Page, open the â˜° menu and select Edit.\nâ€‹\nâ€‹ 4. From the Edit User page:\nâ€‹\nFor Superuser Status, check off the â˜‘ï¸Superuser Status box, located in the user\u0026rsquo;s Default Information.\nâ€‹\nTo assign a Global Role, select one from the dropdown Global Role menu at the bottom of the page.\nâ€‹\nâ€‹ 5. Click Submit to accept these changes.\nâ€‹\nProduct \u0026amp; Product Type Membership By default, any new account created on DefectDojo will not have permission to view any Product Level Data. They will need to be assigned membership to each Product they want to view and interact with.\nProduct \u0026amp; Product Type membership can only be configured by Superusers, Maintainers or Owners. Maintainers \u0026amp; Owners can only configure membership on Products / Product Types that they are already assigned to. Global Maintainers \u0026amp; Owners can configure membership on any Product or Product Type, as can Superusers. Users can have two kinds of membership simultaneously at the Product level:\nThe Role conferred by their underlying Product Type membership, if applicable Their Product-specific Role, if one exists. If a user has already been added as a Product Type member, and does not require an additional level of permissions on a specific Product, there is no need to add them as a Product Member.\nAdding a new Member to a Product or Product Type Navigate to the Product or Product Type which you want to assign a user to. You can select the Product from the list under Products \u0026gt; All Products. 2. Locate the Members heading, click the â˜° menu, and select + Add Users. 3. This will take you to a page where you can Register new Members. Select a User from the dropdown Users menu. 4. Select the Role that you want that User to have on this Product or Product Type: API Importer, Reader, Writer, Maintainer or Owner.\nâ€‹\nUsers cannot be assigned as Members on a Product or Product Type without also having a Role. If you\u0026rsquo;re not sure which Role you want a new user to have, Reader is a good \u0026lsquo;default\u0026rsquo; option. This will keep your Product state secure until you make your final decision about their Role.\nEdit Or Delete a Member from a Product or Product Type Members can have their Role changed within a Product or Product Type.\nWithin the Product or Product Type page, navigate to the Members heading and click the â‹® button next to the User who you want to Edit or Delete.\nðŸ“ Edit will take you to the Edit Member screen, where you can change this user\u0026rsquo;s Role (from API Importer, Reader, Writer, Maintainer or Owner to a different choice).\nðŸ—‘ï¸ Delete removes a User\u0026rsquo;s Membership altogether. It will not remove any contributions or changes the User has made to the Product or Product Type.\nIf you can\u0026rsquo;t Edit or Delete a user\u0026rsquo;s Membership (the â‹® is not visible) it\u0026rsquo;s because they have this Membership conferred at a Product Type level. A user can have two levels of membership within a Product - one assigned at the Product Type level and another assigned at the Product level. Adding an additional Product role to a user with a related Product Type role If a User has a Product Type-level Role, they will also be assigned Membership with this Role to every underlying Product within the category. However, if you want this User to have a special Role on a specific Product within that Product Type, you can give them an additional Role on the Product level.\nFrom the Product page, navigate to the Members heading, click the â˜° menu, and select + Add Users (as if you were adding a new User to the Product). Select the User\u0026rsquo;s name from the drop-down menu, and select the Product Role you want that User to be assigned. A Product Role will supersede a userâ€™s standard Product Type Role or Global Role. For example, if a User has a Product Type Role of Reader, but is also assigned as an Owner on a Product nested under that Product Type, they will have additional Owner permissions added for that Product only.\nHowever, this does not work in reverse. If a User has a Product Type Role or Global Role of Owner, assigning them a Reader role on a particular Product will not take away their Owner permissions. Roles cannot take away permissions granted to a User by other Roles, they can only add additional permissions.\nConfiguration Permissions Many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their superuser status. These Configuration Permissions allow regular users to access and contribute to parts of DefectDojo outside of their standard Product or Product Role assignment.\nConfiguration Permissions are not related to a specific Product or Product Type - users can have configuration permissions assigned without the need for other statuses or Product / Product Type Membership.\nâ€‹\nList of Configuration Permissions Credential Manager: Access to the âš™ï¸Configuration \u0026gt; Credential Manager page Development Environments: Manage the Engagements \u0026gt; Environments list Finding Templates: Access to the Findings \u0026gt; Finding Templates page Groups: Access the ðŸ‘¤Users \u0026gt; Groups page Jira Instances: Access the âš™ï¸Configuration \u0026gt; JIRA page Language Types:Access the Language Types API endpoint Login Banner: Edit the âš™ï¸Configuration \u0026gt; Login Banner page Announcements: Access âš™ï¸Configuration \u0026gt; Announcements Note Types: Access the âš™ï¸Configuration \u0026gt; Note Types page Product Types: n/a Questionnaires: Access the Questionnaires \u0026gt; All Questionnaires page Questions: Access the Questionnaires \u0026gt; Questions page Regulations: Access the âš™ï¸Configuration \u0026gt; Regulations page SLA Configuration: Access the âš™ï¸Configuration \u0026gt; SLA Configuration page Test Types: Add or edit a Test Type (under Engagements \u0026gt; Test Types) Tool Configuration: Access the âš™ï¸Configuration \u0026gt; Tool Types page Tool Types: Access the âš™ï¸Configuration \u0026gt; Tool Types page Users: Access the ðŸ‘¤Users \u0026gt; Users page Add Configuration Permissions to a User Only Superusers can add Configuration Permissions to a User.\nNavigate to the ðŸ‘¤ Users \u0026gt; Users page on the sidebar. You will see a list of all registered accounts on DefectDojo, along with each account\u0026rsquo;s Active status, Global Roles, and other relevant User data.\nâ€‹ â€‹ 2. Click the name of the account that you wish to edit.\nâ€‹ 3. Navigate to the Configuration Permissions List. This is located on the right-hand side of the User Page.\nâ€‹ 4. Select the User Configuration Permissions you wish to add.\nâ€‹\nFor a detailed breakdown of User Configuration Permissions, please refer to our Permission Chart.\n","date":"0001-01-01","id":312,"permalink":"/en/user_management/set-a-users-permissions/","summary":"Introduction to Permission Types Individual users have four different kinds of permission that they can be assigned:\nUsers can be assigned as Members to Products or Product Types.","tags":[],"title":"Set a User's Permissions"},{"content":"The process for adding a second Cloud instance is more or less the same as adding your first instance. This guide assumes you\u0026rsquo;ve already set up your initial DefectDojo server, and have an agreement with our Sales team to add another instance.\nIf you have not already requested an additional Cloud instance, please contact info at defectdojo dot com\rbefore proceeding.\nStep 1: Open the New Subscription process You can start this process from the following link: https://cloud.defectdojo.com/accounts/onboarding/, or by clicking ðŸ›’ New Subscription from the Cloud Manager page (cloud.defectdojo.com).\nStep 2: Set your Server Label Enter your company\u0026rsquo;s Name and the Server Label you want to use with DefectDojo. You will then have a custom domain created for your DefectDojo instance on our servers.\nKeep your company name the same as before, but create a new Server Label and check the \u0026ldquo;Use Server Label in Domain\u0026rdquo; button, so that you can easily differentiate between your servers.\nStep 3: Select a Server Location Select a Server Location from the drop-down menu. As before, we recommend selecting a server that is geographically closest to your users to reduce server latency.\nStep 4: Configure your Firewall Rules Enter the IP address ranges, subnet mask and labels that you want to allow to access DefectDojo. Additional IP addresses and rules can be added or changed by your team after your instance is up and running.\nIf you wish, these firewall rules can be different from the rules on your main DefectDojo instance.\nIf you want to use external services with this instance (GitHub or JIRA), check the appropriate boxes listed under Select External Services.\nStep 5: Confirm your Plan type and Billing Frequency At the end of our process, you\u0026rsquo;ll be put in touch with our sales team, who can accurately quote your new server. We recommend you select the Plan Type which has the server specifications you require for the new instance.\nA second server may not require the same storage, CPU and RAM requirements as your \u0026lsquo;main\u0026rsquo; instance, but this will depend on your team\u0026rsquo;s technical requirements.\nStep 6: Review and Submit your Request We\u0026rsquo;ll prompt you to look over your request one more time. Once submitted, only Firewall rules can be changed by your team without assistance from Support.\nAfter reviewing and accepting DefectDojo\u0026rsquo;s License and Support Agreement, please click Meet The Creators. Our Support team will reach out to you when the process is complete and your server has been provisioned.\n","date":"0001-01-01","id":313,"permalink":"/en/cloud_management/set-up-an-additional-cloud-instance/","summary":"The process for adding a second Cloud instance is more or less the same as adding your first instance. This guide assumes you\u0026rsquo;ve already set up your initial DefectDojo server, and have an agreement with our Sales team to add another instance.","tags":[],"title":"Set up an additional Cloud instance"},{"content":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan scans can be found here.\n","date":"0001-01-01","id":314,"permalink":"/en/connecting_your_tools/parsers/file/skf/","summary":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan scans can be found here.","tags":[],"title":"SKF Scan"},{"content":"Smart upload is a specialized importer that ingests reports from infrastructure scanning tools, including:\nNexpose NMap OpenVas Qualys Tenable Smart Upload is unique in that it can split Findings from a scan file into separate Products. This is relevant in an Infrastructure scanning context, where the Findings may apply to many different teams, have different implicit SLAs, or need to be included in separate reports due to where they were discovered in your infrastructure.\nSmart Upload handles this by sorting incoming findings based on the Endpoints discovered in the scan. At first, those Findings will need to be manually assigned, or directed into the correct Product from an Unassigned Findings list. However, once a Finding has been assigned to a Product, all subsequent Findings that share an Endpoint or Host will be sent to the same Product.\nSmart Upload menu options The Smart Upload menu is stored in a collapsible section of the sidebar.\nAdd Findings allows you to import a new scan file, similar to DefectDojoâ€™s Import Scan method Unassigned Findings lists all Findings from Smart Upload which have yet to be assigned to a Product. The Smart Upload Form The Smart Upload Import Scan form is essentially the same as the Import Scan form. See our notes on the Import Scan Form for more details.\nUnassigned Findings Once a Smart Upload has been completed, any Findings which are not automatically assigned to a Product (based on their Endpoint) will be placed in the Unassigned Findings list. The first Smart Upload for a given tool does not yet have any method to Assign Findings, so each Finding from this file will be sent to this page for sorting.\nUnassigned Findings are not included in the Product Hierarchy and will not appear in reports, filters or metrics until they have been assigned.\nWorking with Unassigned Findings You can select one or more Unassigned Findings for sorting with the checkbox, and perform one of the following actions:\nAssign to New Product, which will create a new Product Assign to Existing Product which will move the Finding into an existing Product Disregard Selected Findings, which will remove the Finding from the list Whenever a Finding is assigned to a New or Existing Product, it will be placed in a dedicated Engagement called â€˜Smart Uploadâ€™. This Engagement will contain a Test named according to the Scan Type (e.g. Tenable Scan). Subsequent Findings uploaded via Smart Upload which match those Endpoints will be placed under that Engagement \u0026gt; Test.\nDisregarded Findings If a Finding is Disregarded it will be removed from the Unassigned Findings list. However, the Finding will not be recorded in memory, so subsequent scan uploads may cause the Finding to appear in the Unassigned Findings list again.\n","date":"0001-01-01","id":315,"permalink":"/en/connecting_your_tools/import_scan_files/smart_upload/","summary":"Smart upload is a specialized importer that ingests reports from infrastructure scanning tools, including:\nNexpose NMap OpenVas Qualys Tenable Smart Upload is unique in that it can split Findings from a scan file into separate Products.","tags":[],"title":"Smart Upload"},{"content":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk scans can be found here.\n","date":"0001-01-01","id":316,"permalink":"/en/connecting_your_tools/parsers/file/snyk/","summary":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).","tags":[],"title":"Snyk"},{"content":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk Code scans can be found here.\n","date":"0001-01-01","id":317,"permalink":"/en/connecting_your_tools/parsers/file/snyk_code/","summary":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).","tags":[],"title":"Snyk Code"},{"content":"Solar Appscreener report file can be imported in CSV format from Detailed_Results.csv\nSample Scan Data Sample Solar Appscreener Scan scans can be found here.\n","date":"0001-01-01","id":318,"permalink":"/en/connecting_your_tools/parsers/file/solar_appscreener/","summary":"Solar Appscreener report file can be imported in CSV format from Detailed_Results.csv\nSample Scan Data Sample Solar Appscreener Scan scans can be found here.","tags":[],"title":"Solar Appscreener Scan"},{"content":"SonarQube Scan There are two ways to retrieve findings from SonarQube. You can either use the soprasteria package or the SonarQube REST API directly. Both ways (SonarQube REST API and Soprasteria) are depicted below.\nSample Scan Data Sample SonarQube scans can be found here.\nSonarQube REST API You can retrieve the JSON directly from SonarQube if you use one of the following REST API endpoint:\n\u0026lt;sonarqubeurl\u0026gt;/api/issues/search?projects=\u0026lt;projectkey\u0026gt; \u0026lt;sonarqubeurl\u0026gt;/api/hotspots/search?projectKey=\u0026lt;projectkey\u0026gt; JSON The REST API JSON output can be uploaded to DefectDojo with \u0026ldquo;SonarQube Scan\u0026rdquo;.\nZIP If you have too many findings in one project, you can implement a small script to handle pagination and put all JSON files in a .zip file. This zip file can also be parsed from DefectDojo with \u0026ldquo;SonarQube Scan\u0026rdquo;.\nSoprasteria Soprasteria SonarQube Scan (Aggregates findings per cwe, title, description, file_path.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u0026gt;= 1.1.0 Recommend version for both format \u0026gt;= 3.1.2\nSoprasteria SonarQube Scan Detailed (Import all findings from SonarQube html report.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u0026gt;= 1.1.0. Recommend version for both format \u0026gt;= 3.1.2\n","date":"0001-01-01","id":319,"permalink":"/en/connecting_your_tools/parsers/file/sonarqube/","summary":"SonarQube Scan There are two ways to retrieve findings from SonarQube. You can either use the soprasteria package or the SonarQube REST API directly.","tags":[],"title":"SonarQube"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;SonarQube\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Note the url must be in the format of https://\u0026lt;sonarqube_host\u0026gt;/api Paste your SonarQube API token in the \u0026ldquo;API Key\u0026rdquo; field. By default the tool will import vulnerabilities issues and security hotspots only, but additional filters can be setup using the Extras field separated by commas (e.g. BUG,VULNERABILITY,CODE_SMELL). When using SonarCloud, you must also specify the Organization ID in the Extras field as follows OrgID=sonarcloud-organzation-ID. If also specifying issue type filters, please seperate the items in the Extras field by a vertical bar as follows BUG,VULNERABILITY,CODE_SMELL|OrgID=sonarcloud-organzation-ID\nIn \u0026ldquo;Add API Scan Configuration\u0026rdquo;\nService key 1 must be the SonarQube project key, which can be found by navigating to a specific project and selecting the value from the url https://\u0026lt;sonarqube_host\u0026gt;/dashboard?id=key. When you do not provide a SonarQube project key, DefectDojo will use the name of the Product as the project key in SonarQube. If you would like to import findings from multiple projects, you can specify multiple keys as separated API Scan Configuration in the Product settings. If using SonarCloud, the orginization ID can be used from step 1, but it can be overiden by supplying a different orginization ID in the Service key 2 input field. Multiple SonarQube API Configurations In the import or re-import dialog you can select which API Scan Configuration shall be used. If you do not choose any, DefectDojo will use the API Scan Configuration of the Product if there is only one defined or the SonarQube Tool Configuration if there is only one.\nMulti Branch Scanning If using a version of SonarQube with multi branch scanning, the branch tha be scanned can be supplied in the branch_tag fieild at import/re-import time. If the branch does not exist, a notification will be generated in the alerts table indicating that branch to be imported does not exist. If a branch name is not supplied during import/re-import, the default branch of the SonarQube project will be used.\nNote:: If https is used for the SonarQube, the certificate must be trusted by the DefectDojo instance.\n","date":"0001-01-01","id":320,"permalink":"/en/connecting_your_tools/parsers/api/sonarqube/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"SonarQube API Import"},{"content":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here.\n","date":"0001-01-01","id":321,"permalink":"/en/connecting_your_tools/parsers/file/sonatype/","summary":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here.","tags":[],"title":"Sonatype"},{"content":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can be found here.\n","date":"0001-01-01","id":322,"permalink":"/en/connecting_your_tools/parsers/file/spotbugs/","summary":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can be found here.","tags":[],"title":"SpotBugs"},{"content":"Import JSON output of ssh_audit report. See https://github.com/jtesta/ssh-audit\nSample Scan Data Sample SSH Audit scans can be found here.\n","date":"0001-01-01","id":323,"permalink":"/en/connecting_your_tools/parsers/file/ssh_audit/","summary":"Import JSON output of ssh_audit report. See https://github.com/jtesta/ssh-audit\nSample Scan Data Sample SSH Audit scans can be found here.","tags":[],"title":"SSH Audit"},{"content":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs scans can be found here.\n","date":"0001-01-01","id":324,"permalink":"/en/connecting_your_tools/parsers/file/ssl_labs/","summary":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs scans can be found here.","tags":[],"title":"SSL Labs"},{"content":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan scans can be found here.\n","date":"0001-01-01","id":325,"permalink":"/en/connecting_your_tools/parsers/file/sslscan/","summary":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan scans can be found here.","tags":[],"title":"Sslscan"},{"content":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan\nSample Scan Data Sample Sslyze Scan scans can be found here.\n","date":"0001-01-01","id":326,"permalink":"/en/connecting_your_tools/parsers/file/sslyze/","summary":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan","tags":[],"title":"Sslyze Scan"},{"content":"Import the JSON webhook event from StackHawk. For more information, check out our docs on hooking up StackHawk to Defect Dojo\nSample Scan Data Sample StackHawk HawkScan scans can be found here.\n","date":"0001-01-01","id":327,"permalink":"/en/connecting_your_tools/parsers/file/stackhawk/","summary":"Import the JSON webhook event from StackHawk. For more information, check out our docs on hooking up StackHawk to Defect Dojo","tags":[],"title":"StackHawk HawkScan"},{"content":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser will accept Pipeline, Registry and Runtime reports created from the UI\nMore information available at our reporting docs page\nSample Scan Data Sample Sysdig Vulnerability Reports scans can be found here.\n","date":"0001-01-01","id":328,"permalink":"/en/connecting_your_tools/parsers/file/sysdig_reports/","summary":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser will accept Pipeline, Registry and Runtime reports created from the UI","tags":[],"title":"Sysdig Vulnerability Reports"},{"content":"","date":"0001-01-01","id":329,"permalink":"/tags/","summary":"","tags":[],"title":"Tags"},{"content":"Run Talisman in CLI mode and use \u0026ldquo;\u0026ndash;scan\u0026rdquo; argument to scan the git commit history along with \u0026ldquo;\u0026ndash;reportDirectory\u0026rdquo; argument to save the scan reports to a directory. The report will be in JSON format.\nAdditionally, you can set up Git Hooks to automate the scan and then send the generated reports to DefectDojo using its API.\nExample:\n#!/bin/sh # Set DefectDojo API credential and other variables DEFECTDOJO_API_KEY=\u0026#34;your-api-key\u0026#34; DEFECTDOJO_URL=\u0026#34;https://your-defectdojo-url.com\u0026#34; TALISMAN_RESULTS_DIR=\u0026#34;$HOME\u0026#34; # Run talisman in CLI mode and output the result in JSON format CMD=\u0026#34;talisman --scan --ignoreHistory --reportDirectory $TALISMAN_RESULTS_DIR\u0026#34; $CMD # Extract the result result=$(jq \u0026#39;.results[].filename\u0026#39; \u0026#34;${TALISMAN_RESULTS_DIR}/talisman_reports/data/report.json\u0026#34;) # Check if result is not empty if [ -n \u0026#34;$result\u0026#34; ]; then # If talisman found issues, send the JSON output to DefectDojo API endpoint curl -X POST \\ -H \u0026#34;Authorization: Token $DEFECTDOJO_API_KEY\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#34;@$TALISMAN_RESULTS_DIR/talisman_reports/data/report.json\u0026#34; \\ \u0026#34;$DEFECTDOJO_URL/api/v2/import-scan/\u0026#34; # Exit with a non-zero status code to indicate that the commit should be rejected exit 1 else # If talisman did not find any issues, exit with a zero status code exit 0 fi\rSample Scan Data Sample Talisman scans can be found here.\n","date":"0001-01-01","id":330,"permalink":"/en/connecting_your_tools/parsers/file/talisman/","summary":"Run Talisman in CLI mode and use \u0026ldquo;\u0026ndash;scan\u0026rdquo; argument to scan the git commit history along with \u0026ldquo;\u0026ndash;reportDirectory\u0026rdquo; argument to save the scan reports to a directory.","tags":[],"title":"Talisman"},{"content":"Reports can be imported in the CSV, and .nessus (XML) report formats. Legacy Nessus and Nessus WAS reports are supported\nSample Scan Data Sample Tenable scans can be found here.\n","date":"0001-01-01","id":331,"permalink":"/en/connecting_your_tools/parsers/file/tenable/","summary":"Reports can be imported in the CSV, and .nessus (XML) report formats. Legacy Nessus and Nessus WAS reports are supported","tags":[],"title":"Tenable"},{"content":"Import JSON output of terrascan scan report https://github.com/accurics/terrascan\nSample Scan Data Sample Terrascan scans can be found here.\n","date":"0001-01-01","id":332,"permalink":"/en/connecting_your_tools/parsers/file/terrascan/","summary":"Import JSON output of terrascan scan report https://github.com/accurics/terrascan\nSample Scan Data Sample Terrascan scans can be found here.","tags":[],"title":"Terrascan"},{"content":"Import CSV output of testssl scan report.\nSample Scan Data Sample Testssl Scan scans can be found here.\n","date":"0001-01-01","id":333,"permalink":"/en/connecting_your_tools/parsers/file/testssl/","summary":"Import CSV output of testssl scan report.\nSample Scan Data Sample Testssl Scan scans can be found here.","tags":[],"title":"Testssl Scan"},{"content":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan Data Sample TFSec scans can be found here.\n","date":"0001-01-01","id":334,"permalink":"/en/connecting_your_tools/parsers/file/tfsec/","summary":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan Data Sample TFSec scans can be found here.","tags":[],"title":"TFSec"},{"content":"The Operations Page provides an overview of your connector\u0026rsquo;s Discover \u0026amp; Sync Operations, along with additional details for each. These operations are tracked using a table.\nTo access a Connector\u0026rsquo;s Operations Page, open Manage Records \u0026amp; Operations for the connector you wish to edit, and then switch to the \u0026lt;/\u0026gt; Operations From (tool) tab.\nThe Operations Table Each entry on the Operations Table is a record of an operation event, with the following traits:\nType describes whether the event was a Sync or a Discover operation. Status describes whether the event ran successfully. Trigger describes how the event was triggered - was it a Scheduled operation which ran automatically, or a Manual operation which was triggered by a DefectDojo user? The Start \u0026amp; End Time of each operation is recorded here, along with the Duration. Next Steps Learn more about Discover and Sync operations from our guides. ","date":"0001-01-01","id":335,"permalink":"/en/connecting_your_tools/connectors/operations_page/","summary":"The Operations Page provides an overview of your connector\u0026rsquo;s Discover \u0026amp; Sync Operations, along with additional details for each. These operations are tracked using a table.","tags":[],"title":"The Operations Page"},{"content":"File Types DefectDojo parser accepts a .json file.\nJSON reports are created from the Threagile tool (default name risks.json) using the following command:\ndocker run --rm -it -v \u0026#34;$(pwd)\u0026#34;:/app/work threagile/threagile -verbose -model /app/work/threagile.yaml -output /app/work\rAcceptable JSON Format Parser expects an array of finding. All properties are strings. Required fields are the following\n\u0026ldquo;category\u0026rdquo; \u0026ldquo;title\u0026rdquo; \u0026ldquo;severity\u0026rdquo; \u0026ldquo;synthetic_id\u0026rdquo; \u0026ldquo;exploitation_impact\u0026rdquo; catergory fields is used to set both the title of the Finding as well as the cwe. most_relevant_technical_asset field is used to determine the component.\n[ { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;unchecked\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eEnergon\\u003c/b\\u003e via \\u003cb\\u003eEnergonToPolicyRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@energon-ta\\u003eenergontopolicyregofilestorage@energon-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;energon-ta\\u003eenergontopolicyregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;in-discussion\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIAMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMBachendAPIPoliciesRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage@iam-sidecar-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;accepted\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIDMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMSidecarPoliciesRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage@idm-sidecar-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, ... ]\rSample Scan Data Sample Threagile scans can be found here.\n","date":"0001-01-01","id":336,"permalink":"/en/connecting_your_tools/parsers/file/threagile/","summary":"File Types DefectDojo parser accepts a .json file.\nJSON reports are created from the Threagile tool (default name risks.json) using the following command:","tags":[],"title":"Threagile"},{"content":"File Types This DefectDojo parser accepts JSON files from Threat Composer. The tool supports the export of JSON report out of the browser local storage to a local file.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":337,"permalink":"/en/connecting_your_tools/parsers/file/threat_composer/","summary":"File Types This DefectDojo parser accepts JSON files from Threat Composer. The tool supports the export of JSON report out of the browser local storage to a local file.","tags":[],"title":"Threat Composer"},{"content":"When setting up a Connector for a supported tool, you\u0026rsquo;ll need to give DefectDojo specific information related to the tool\u0026rsquo;s API. At a base level, you\u0026rsquo;ll need:\nLocation -a field whichgenerallyrefers to your tool\u0026rsquo;s URL in your network, Secret - generally an API key. Some tools will require additional API-related fields beyond Location and Secret. They may also require you to make changes on their side to accommodate an incoming Connector from DefectDojo.\nEach tool has different API requirements, and this guide is intended to help you set up the tool\u0026rsquo;s API so that DefectDojo can connect.\nWhenever possible, we recommend creating a new \u0026lsquo;DefectDojo Bot\u0026rsquo; account within your Security Tool which will only be used by the Connector. This will help you better differentiate between actions manually taken by your team, and automated actions taken by the Connector.\nSupported Connectors AWS Security Hub The AWS Security Hub connector uses an AWS access key to interact with the Security Hub APIs.\nPrerequisites Rather than use the AWS access key from a team member, we recommend creating an IAM User in your AWS account specifically for DefectDojo, with that user\u0026rsquo;s permissions limited to those necessary for interacting with Security Hub.\nAWS\u0026rsquo;s \u0026ldquo;**AWSSecurityHubReadOnlyAccess**policy\u0026rdquo; provides the required level of access for a connector. If you would like to write a custom policy for a Connector, you will need to include the following permissions:\nDescribeHub GetFindingAggregator GetFindings ListFindingAggregators A working policy definition might look like the following:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AWSSecurityHubConnectorPerms\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;securityhub:DescribeHub\u0026#34;, \u0026#34;securityhub:GetFindingAggregator\u0026#34;, \u0026#34;securityhub:GetFindings\u0026#34;, \u0026#34;securityhub:ListFindingAggregators\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }\rPlease note: we may need to use additional API actions in the future to provide the best possible experience, which will require updates to this policy.\nOnce you have created your IAM user and assigned it the necessary permissions using an appropriate policy/role, you will need to generate an access key, which you can then use to create a Connector.\nConnector Mappings Enter the appropriate AWS API Endpoint for your region in the Location field**:** for example, to retrieve results from the us-east-1 region, you would supply https://securityhub.us-east-1.amazonaws.com 2. Enter a valid AWS Access Key in the Access Key field. 3. Enter a matching Secret Key in the Secret Key field.\nDefectDojo can pull Findings from more than one region using Security Hub\u0026rsquo;s cross-region aggregation feature. If cross-region aggregation is enabled, you should supply the API endpoint for your \u0026ldquo;Aggregation Region\u0026rdquo;. Additional linked regions will have ProductRecords created for them in DefectDojo based on your AWS account ID and the region name.\nBurpSuite DefectDojoâ€™s Burp connector calls Burpâ€™s GraphQL API to fetch data.\nPrerequisites Before you can set up this connector, you will need an API key from a Burp Service Account. Burp user accounts donâ€™t have API keys by default, so you may need to create a new user specifically for this purpose.\nSee Burp Documentation for a guide on setting up a Service Account user with an API key.\nConnector Mappings Enter Burpâ€™s root URL in the Location field: this is the URL where you access the Burp tool. Enter a valid API Key in the Secret field. This is the API key associated with your Burp Service account. See the official Burp documentation for more information on the Burp API.\nCheckmarx ONE DefectDojo\u0026rsquo;s Checkmarx ONE connector calls the Checkmarx API to fetch data.\nConnector Mappings Enter your Tenant Name in the Checkmarx Tenant field. This name should be visible on the Checkmarx ONE login page in the top-right hand corner:\n\u0026quot; Tenant: \u0026lt;your tenant name\u0026gt; \u0026quot;\nâ€‹ 2. Enter a valid API key. You may need to generate a new one: see Checkmarx API Documentation for details. 3. Enter your tenant location in the Location field. This URL is formatted as follows:\nâ€‹https://\u0026lt;your-region\u0026gt;.ast.checkmarx.net/ . Your Region can be found at the beginning of your Checkmarx URL when using the Checkmarx app. https://ast.checkmarx.net is the primary US server (which has no region prefix).\nDependency-Track This connector fetches data from a on-premise Dependency-Track instance, via REST API.\nâ€‹Connector Mappings\nEnter your local Dependency-Track server URL in the Location field. Enter a valid API key in the Secret field. To generate a Dependency-Track API key:\nAccess Management: Navigate to Administration \u0026gt; Access Management \u0026gt; Teams in the Dependency-Track interface. Teams Setup: You can either create a new team or select an existing one. Teams allow you to manage API access based on group membership. Generate API Key: In the selected team\u0026rsquo;s details page, find the \u0026ldquo;API Keys\u0026rdquo; section. Click the + button to generate a new API key. Assign Permissions: In the \u0026ldquo;Permissions\u0026rdquo; section of the team\u0026rsquo;s page, click the + button to open the permissions selector. Choose VIEW_PORTFOLIO and VIEW_VULNERABILITY permissions to enable API access to project portfolios and vulnerability details. Click \u0026ldquo;Select\u0026rdquo; to confirm and save these permissions. For more information, see Dependency-Track Documentation.\nProbely This connector uses the Probely REST API to fetch data.\nâ€‹Connector Mappings\nEnter the appropriate API server address in the Location field. (either https://api.us.probely.com/ or https://api.eu.probely.com/ ) Enter a valid API key in the Secret field. You can find an API key under the User \u0026gt; API Keys menu in Probely.\nSee Probely documentation for more info.\nSemGrep This connector uses the SemGrep REST API to fetch data.\nConnector Mappings Enter https://semgrep.dev/api/v1/in the Location field.\nEnter a valid API key in the Secret field. You can find this on the Tokens page:\nâ€‹\n\u0026ldquo;Settings\u0026rdquo; in the left navbar \u0026gt; Tokens \u0026gt; Create new token (https://semgrep.dev/orgs/-/settings/tokens) See SemGrep documentation for more info.\nSonarQube The SonarQube Connector can fetch data from either a SonarCloud account or from a local SonarQube instance.\nFor SonarCloud users:\nEnter https://sonarcloud.io/ in the Location field. Enter a valid API key in the Secret field. For SonarQube (on-premise) users:\nEnter the base url of your SonarQube instance in the Location field: for example https://my.sonarqube.com/ Enter a valid API key in the Secret field. This will need to be a User API Token Type. API tokens can be found and generated via My Account -\u0026gt; Security -\u0026gt; Generate Token in the SonarQube app. For more information, see SonarQube documentation.\nSnyk The Snyk connector uses the Snyk REST API to fetch data.\nConnector Mappings Enter https://api.snyk.io/rest or https://api.eu.snyk.io/rest (for a regional EU deployment) in the Location field. Enter a valid API key in the Secret field. API Tokens are found on a user\u0026rsquo;s Account Settings page in Snyk. See the Snyk API documentation for more info.\nTenable The Tenable connector uses the Tenable.io REST API to fetch data.\nOn-premise Tenable Connectors are not available at this time.\nConnector Mappings Enter https://cloud.tenable.com in the Location field. Enter a valid API key in the Secret field. See Tenable\u0026rsquo;s API Documentation for more info.\n","date":"0001-01-01","id":338,"permalink":"/en/connecting_your_tools/connectors/connectors_tool_reference/","summary":"When setting up a Connector for a supported tool, you\u0026rsquo;ll need to give DefectDojo specific information related to the tool\u0026rsquo;s API.","tags":[],"title":"Tool-Specific API Reference (Connectors)"},{"content":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can be found here.\n","date":"0001-01-01","id":339,"permalink":"/en/connecting_your_tools/parsers/file/trivy/","summary":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can be found here.","tags":[],"title":"Trivy"},{"content":"JSON report of trivy operator scanner.\nTo import the generated Vulnerability Reports, you can also use the trivy-dojo-report-operator.\nSample Scan Data Sample Trivy Operator scans can be found here.\n","date":"0001-01-01","id":340,"permalink":"/en/connecting_your_tools/parsers/file/trivy_operator/","summary":"JSON report of trivy operator scanner.\nTo import the generated Vulnerability Reports, you can also use the trivy-dojo-report-operator.\nSample Scan Data Sample Trivy Operator scans can be found here.","tags":[],"title":"Trivy Operator"},{"content":"JSON Output of Trufflehog. Supports version 2 and 3 of https://github.com/trufflesecurity/trufflehog\nSample Scan Data Sample Trufflehog scans can be found here.\n","date":"0001-01-01","id":341,"permalink":"/en/connecting_your_tools/parsers/file/trufflehog/","summary":"JSON Output of Trufflehog. Supports version 2 and 3 of https://github.com/trufflesecurity/trufflehog\nSample Scan Data Sample Trufflehog scans can be found here.","tags":[],"title":"Trufflehog"},{"content":"JSON Output of Trufflehog3, a fork of TruffleHog located at https://github.com/feeltheajf/truffleHog3\nSample Scan Data Sample Trufflehog3 scans can be found here.\n","date":"0001-01-01","id":342,"permalink":"/en/connecting_your_tools/parsers/file/trufflehog3/","summary":"JSON Output of Trufflehog3, a fork of TruffleHog located at https://github.com/feeltheajf/truffleHog3\nSample Scan Data Sample Trufflehog3 scans can be found here.","tags":[],"title":"Trufflehog3"},{"content":"CSV output of Trustwave vulnerability scan.\nSample Scan Data Sample Trustwave scans can be found here.\n","date":"0001-01-01","id":343,"permalink":"/en/connecting_your_tools/parsers/file/trustwave/","summary":"CSV output of Trustwave vulnerability scan.\nSample Scan Data Sample Trustwave scans can be found here.","tags":[],"title":"Trustwave"},{"content":"Trustwave Fusion API report file can be imported in JSON format\nSample Scan Data Sample Trustwave Fusion API Scan scans can be found here.\n","date":"0001-01-01","id":344,"permalink":"/en/connecting_your_tools/parsers/file/trustwave_fusion_api/","summary":"Trustwave Fusion API report file can be imported in JSON format\nSample Scan Data Sample Trustwave Fusion API Scan scans can be found here.","tags":[],"title":"Trustwave Fusion API Scan"},{"content":"JSON output of the twistcli tool. Example:\n./twistcli images scan \u0026lt;REGISTRY/REPO:TAG\u0026gt; --address https://\u0026lt;SECURE_URL_OF_TWISTLOCK_CONSOLE\u0026gt; --user \u0026lt;USER\u0026gt; --details --output-file=\u0026lt;PATH_TO_SAVE_JSON_FILE\u0026gt; The CSV output from the UI is now also accepted.\nSample Scan Data Sample Twistlock scans can be found here.\n","date":"0001-01-01","id":345,"permalink":"/en/connecting_your_tools/parsers/file/twistlock/","summary":"JSON output of the twistcli tool. Example:\n./twistcli images scan \u0026lt;REGISTRY/REPO:TAG\u0026gt; --address https://\u0026lt;SECURE_URL_OF_TWISTLOCK_CONSOLE\u0026gt; --user \u0026lt;USER\u0026gt; --details --output-file=\u0026lt;PATH_TO_SAVE_JSON_FILE\u0026gt; The CSV output from the UI is now also accepted.","tags":[],"title":"Twistlock"},{"content":"Role Permission Chart This chart is intended to list all permissions related to a Product or Product Type, as well as which permissions are available to each role.\nSection Permission Reader Writer Maintainer Owner API Imp Product / Product Type Access View assigned Product or Product Type Â¹ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ View nested Products, Engagements, Tests, Findings, Endpoints â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Add new Products (within assigned Product Type) Â² â˜‘ï¸ â˜‘ï¸ Delete assigned Products or Product Types â˜‘ï¸ Product / Product Type Membership Add Users as Members (excluding Owner Role) â˜‘ï¸ â˜‘ï¸ Edit member Roles (excluding Owner Role) â˜‘ï¸ â˜‘ï¸ Edit member Roles (including Owner Role) â˜‘ï¸ Remove self from Product / Product Type membership â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Add an Owner Role to another User â˜‘ï¸ Edit an associated Product/Product Type Membership within a GroupÂ³ â˜‘ï¸ Delete an associated Product/Product Type Membership within a GroupÂ³ Engagements (Within a Product) Add, Edit Engagements â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Add, Edit Risk Acceptances â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Engagements â˜‘ï¸ â˜‘ï¸ Tests (Within a Product) Add Tests â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Edit Tests â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Tests â˜‘ï¸ â˜‘ï¸ Findings (Within a Product) Add Findings â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Edit Findings â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Import, Reimport Scan Results â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Findings â˜‘ï¸ â˜‘ï¸ Add, Edit, Delete Finding Groups â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Other Data (Within a Product) Add, Edit Endpoints â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Endpoints â˜‘ï¸ â˜‘ï¸ Edit Benchmarks â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Benchmarks â˜‘ï¸ â˜‘ï¸ View Note History â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Add, Edit, Delete Own Notes â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Edit Other Notes â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Delete Other Notes â˜‘ï¸ â˜‘ï¸ A user who is assigned permissions at the Product level only cannot view the Product Type it is contained in. When a new Product is added underneath a Product Type, all Product Type-level Users will be added as Members of the new Product with their Product Type-level Role. The user who wishes to make changes to a Group must also have Edit Group Configuration Permissions, and a Maintainer or Owner Group Configuration Role in the Group they wish to edit. Configuration Permission Chart Each Configuration Permission refers to a particular function in the software, and has an associated set of actions a user can perform related to this function.\nThe majority of Configuration Permissions give users access to certain pages in the UI.\nConfiguration Permission View â˜‘ï¸ Add â˜‘ï¸ Edit â˜‘ï¸ Delete â˜‘ï¸ Credential Manager Access the âš™ï¸Configuration \u0026gt; Credential Manager page Add new entries to the Credential Manager Edit Credential Manager entries Delete Credential Manager entries Development Environments n/a Add new Development Environments to the ðŸ—“ï¸Engagements \u0026gt; Environments list Edit Development Environments in the ðŸ—“ï¸Engagements \u0026gt; Environments list Delete Development Environments from the ðŸ—“ï¸Engagements \u0026gt; Environments list Finding TemplatesÂ¹ Access the Findings \u0026gt; Finding Templates page Add a Finding Template Edit a Finding Template Delete a Finding Template Groups Access the ðŸ‘¤Users \u0026gt; Groups page Add a new User Group Superuser only Superuser only Jira Instances Access the âš™ï¸Configuration \u0026gt; JIRA page Add a new JIRA Configuration Edit an existing JIRA Configuration Delete a JIRA Configuration Language Types Login Banner n/a n/a Edit the login banner, located under âš™ï¸Configuration \u0026gt; Login Banner n/a Announcements n/a n/a Configure Announcements, located under âš™ï¸Configuration \u0026gt; Announcements n/a Note Types Access the âš™ï¸Configuration \u0026gt; Note Types page Add a Note Type Edit a Note Type Delete a Note Type Product Types n/a Add a new Product Type (under Products \u0026gt; Product Type) n/a n/a Questionnaires Access the Questionnaires \u0026gt; All Questionnaires page Add a new Questionnaire Edit an existing Questionnaire Delete a Questionnaire Questions Access the Questionnaires \u0026gt; Questions page Add a new Question Edit an existing Question n/a Regulations n/a Add a Regulation to the âš™ï¸Configuration \u0026gt; Regulations page Edit an existing Regulation Delete a Regulation SLA Configuration Access the âš™ï¸Configuration \u0026gt; SLA Configuration page Add a new SLA Configuration Edit an existing SLA Configuration Delete an SLA Configuration Test Types n/a Add a new Test Type (under Engagements \u0026gt; Test Types) Edit an existing Test Type n/a Tool Configuration Access the âš™ï¸Configuration \u0026gt; Tool Configuration page Add a new Tool Configuration Edit an existing Tool Configuration Delete a Tool Configuration Tool Types Access the âš™ï¸Configuration \u0026gt; Tool Types page Add a new Tool Type Edit an existing Tool Type Delete a Tool Type Users Access the ðŸ‘¤Users \u0026gt; Users page Add a new User to DefectDojo Edit an existing User Delete a User Access to the Finding Templates page also requires the Writer, Maintainer or Owner Global Role for this user. Group Configuration Permissions Configuration Permission Reader Maintainer Owner View Group â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Remove self from Group â˜‘ï¸ â˜‘ï¸ â˜‘ï¸ Edit a Memberâ€™s role in a Group â˜‘ï¸ â˜‘ï¸ Edit or Delete a Product or Product Type Membership from a GroupÂ¹ â˜‘ï¸ â˜‘ï¸ Change a Group Memberâ€™s role to Owner â˜‘ï¸ Delete Group â˜‘ï¸ This also requires the User to have at least a Maintainer Role on the Product or Product Type which they wish to edit. ","date":"0001-01-01","id":346,"permalink":"/en/user_management/user-permission-charts/","summary":"Role Permission Chart This chart is intended to list all permissions related to a Product or Product Type, as well as which permissions are available to each role.","tags":[],"title":"User Permission Charts"},{"content":"DefectDojo does not currently support passing any Issue-specific information into these Custom Fields - these fields will need to be updated manually in Jira after the issue is created. Each Custom Field will only be created from DefectDojo with a default value.\nJira Cloud now allows you to create a default Custom Field value directly in-app. See Atlassian\u0026rsquo;s documentation on Custom Fields for more information on how to configure this.\nDefectDojo\u0026rsquo;s built-in Jira Issue Types (Bug, Task, Story and Epic) are set up to work \u0026lsquo;out of the box\u0026rsquo;. Data fields in DefectDojo will automatically map to the corresponding fields in Jira. By default, DefectDojo will assign Priority, Labels and a Reporter to any new Issue it creates.\nSome Jira configurations require additional custom fields to be accounted for before an issue can be created. This process will allow you to account for these custom fields in your DefectDojo -\u0026gt; Jira integration, ensuring that issues are created successfully. These custom fields will be added to any API calls sent from DefectDojo to a linked Jira instance.\nIf you donâ€™t already use Custom Fields in Jira, there is no need to follow this process.\nProcess Summary Recording the names of your Custom Fields in Jira (Jira UI) Determine the Key values for the new Custom Fields (Jira Field Spec Endpoint) Locate the acceptable data for each Custom Field, using the Key values as a reference (Jira Issue Endpoint) Create a Field Reference JSON block to track all of the Custom Field Keys and acceptable data (Jira Issue Endpoint) Store the JSON block in the associated DefectDojo Product, to allow Custom Fields to be created from Jira (DefectDojo UI) Test your work and ensure that all required data is flowing from Jira properly Step 1: Record the names of your Custom Fields in Jira Jira supports a variety of different Context Fields, including Date Pickers, Custom Labels, Radio Buttons. Each of these Context Fields will have a different Key value that can be found in the Jira API.\nWrite down the names of each required Custom Field, as you will need to search through the Jira API to find them in the next step.\nExample of a Custom Field list (your Custom Field names will be different):\nDefectDojo Custom URL Field Another example of a Custom Field \u0026hellip; Step 2: Finding your Jira Custom Field Key Values Start this process by navigating to the Field Spec URL for your entire Jira instance.\nHere is an example of a Field Spec URL:\nhttps://yourcompany-example.atlassian.net/rest/api/2/field\nThe API will return a long string of JSON, which should be formatted into readable text (using a code editor, browser extension or https://jsonformatter.org/).\nThe JSON returned from this URL will contain all of your Jira custom fields, most of which are irrelevant to DefectDojo and have values of â€œNullâ€. Each object in this API response corresponds to a different field in Jira. You will need to search for the objects that have â€œnameâ€ attributes which match the names of each Custom Field you created in the Jira UI, and then note the value of their â€œkeyâ€ attribute.\nâ¬† Here is an example of a Custom URL Field on an issue, how the Custom URL Field appears in the JSON output.\nOnce youâ€™ve found the matching object in the JSON output, you can determine the â€œkeyâ€ value - in this case, it\u0026rsquo;s customfield_10050.\nJira generates different key values for each Custom Field, but these key values do not change once created. If you create another Custom Field in the future, it will have a new key value.\nExpanding our Custom Field list:\nâ€œDefectDojo Custom URL Fieldâ€ = customfield_10050 â€œAnother example of a Custom Fieldâ€ = customfield_12345 \u0026hellip; Step 3 - Finding the Custom Fields on a Jira Issue Locate an Issue in Jira that contains the Custom Fields which you recorded in Step 2. Copy the Issue Key for the title (should look similar to â€œEXAMPLE-123â€) and navigate to the following URL:\nhttps://yourcompany-example.atlassian.net/rest/api/2/issue/EXAMPLE-123\nThis will return another string of JSON.\nAs before, API output will contain lots of customfield_## object parameters with null values - these are custom fields that Jira adds by default, which arenâ€™t relevant to this issue. It will also contain customfield_## values that match the Custom Field Key values that you found in the previous step. Unlike with the Field Spec output, you wonâ€™t see names identifying any of these custom fields, which is why you needed to record the key values in Step 2.\nExample:\nWe know that customfield_10050 represents the DefectDojo Custom URL Field because we recorded it in Step 2. We can now see that customfield_10050 contains a value of â€œhttps://google.comâ€ in the EXAMPLE-123 issue.\nStep 4 - Creating a JSON Field Reference from each Jira Custom Field Key Youâ€™ll now need to take the value of each of the Custom Fields from your list and store them in a JSON object (to use as a reference). You can ignore any Custom Fields that donâ€™t correspond to your list.\nThis JSON object will contain all of the default values for new Jira Issues. We recommend using names that are easy for your team to recognize as â€˜defaultâ€™ values that need to be changed: â€˜change-me.comâ€™, â€˜Change this paragraph.â€™ etc.\nExample:\nFrom step 3, we now know that Jira expects a URL string for \u0026ldquo;customfield_10050â€. We can use this to build our example JSON object.\nSay we had also located a DefectDojo-related short text field, which we identified as \u0026ldquo;customfield_67890â€. We would look at this field in our second API output, look at the associated value, and reference the stored value in our example JSON object as well.\nâ€‹\nYour JSON object will start to look like this as you add more Custom Fields to it.\n{ \u0026#34;customfield_10050\u0026#34;: \u0026#34;https://change-me.com\u0026#34;, \u0026#34;customfield_67890\u0026#34;: \u0026#34;This is the short text custom field.\u0026#34; }\rRepeat this process until all of the DefectDojo-relevant custom fields from Jira have been added to your JSON Field Reference.\nData types \u0026amp; Jira Syntax Some fields, such as Date fields, may relate to multiple custom fields in Jira. If that is the case, youâ€™ll need to add both fields to your JSON Field Reference.\n\u0026#34;customfield_10040\u0026#34;: \u0026#34;1970-01-01\u0026#34;, \u0026#34;customfield_10041\u0026#34;: \u0026#34;1970-01-01T03:30:00.000+0200\u0026#34;,\rOther fields, such as the Label field, may be tracked as a list of strings - please make sure your JSON Field Reference uses a format that matches API output from Jira.\n// a list of custom labels on a Jira object \u0026#34;customfield_10042\u0026#34;: [ \u0026#34;custom-label-one\u0026#34;, \u0026#34;this-is-default\u0026#34;, \u0026#34;change-me-please\u0026#34; ],\rOther custom fields may contain additional, contextual information that should be removed from the Field Reference. For example, the Custom Multichoice Field contains an extra block in the API output, which youâ€™ll need to remove, as this block stores the current value of the field.\nyou should remove the extra object from this field: \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; }, { \u0026#34;self\u0026#34;: \u0026#34;example.url...\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;C\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;example ID\u0026#34; } ]\rinstead, you can shorten this to the following and disregard the second part: \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ] Example Completed Field Reference Here is a complete JSON Field Reference, with in-line comments explaining what each custom field pertains to. This is meant as an all-encompassing example. Your JSON will contain different key values and data points depending on the Custom Values you want to use during issue creation.\n{ \u0026#34;customfield_10050\u0026#34;: \u0026#34;https://change-me.com\u0026#34;, \u0026#34;customfield_10049\u0026#34;: \u0026#34;This is a short text custom field\u0026#34;, // two different fields, but both correspond to the same custom date attribute \u0026#34;customfield_10040\u0026#34;: \u0026#34;1970-01-01\u0026#34;, \u0026#34;customfield_10041\u0026#34;: \u0026#34;1970-01-01T03:30:00.000+0200\u0026#34;, // a list of custom labels on a Jira object \u0026#34;customfield_10042\u0026#34;: [ \u0026#34;custom-label-one\u0026#34;, \u0026#34;this-is-default\u0026#34;, \u0026#34;change-me-please\u0026#34; ], // custom number field \u0026#34;customfield_10043\u0026#34;: 0, // custom paragraph field \u0026#34;customfield_10044\u0026#34;: \u0026#34;This is a very long winded way to say CHANGE ME PLEASE\u0026#34;, // custom radio button field \u0026#34;customfield_10045\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;radio button option\u0026#34; }, // custom multichoice field \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ], // custom checkbox field \u0026#34;customfield_10039\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ], // custom select list (singlechoice) field \u0026#34;customfield_10048\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;1\u0026#34; } }\rStep 5 - Adding the Custom Fields to a DefectDojo Product You can now add these custom fields to the associated DefectDojo Product, in the Custom Fields section. Once again,\nNavigate to Edit Product - defectdojo.com/product/ID/edit . Navigate to Custom fields and paste the JSON Field Reference as plain text in the Custom Fields box. Click â€˜Submitâ€™. Step 6 - Testing your Jira Custom Fields from a new Finding: Now, when you create a new Finding in the Jira-associated Product, Jira will automatically create all of these Custom Fields in Jira according to the JSON block contained within. These Custom Fields will be created with the default (â€œchange-me-pleaseâ€, etc.) values.\nWithin the Product on DefectDojo, navigate to the Findings \u0026gt; Add New Finding page. Make sure the Finding is both Active and Verified to ensure that it pushes to Jira, and then confirm on the Jira side that the Custom Fields are successfully created without any inconsistencies.\n","date":"0001-01-01","id":347,"permalink":"/en/jira_integration/using-custom-fields/","summary":"DefectDojo does not currently support passing any Issue-specific information into these Custom Fields - these fields will need to be updated manually in Jira after the issue is created.","tags":[],"title":"Using Custom Fields in Jira"},{"content":"Logging into DefectDojo\u0026rsquo;s Cloud Manager allows you to configure your account settings and manage your subscription with DefectDojo Cloud.\nNew Subscription This page allows you to request a new, or additional Cloud instance from DefectDojo.\nManage Subscriptions The Subscription Management page shows all of your currently active Cloud instances, and allows you to configure the Firewall settings for each instance.\nTo edit or add firewall rules from within the DefectDojo cloud site, navigate to the Manage Subscriptions page, then click the Edit Subscription button in the top right corner of the subscription you wish to edit.\nOnce on the Edit Subscription page, enter the IP Address, Mask, and Label for the rule you wish to add. If more than one firewall rule is needed, click Add New Range to create a new empty rule.\nTo save these newly added firewall rules, click Submit at the bottom of the page to save and update the firewall rules on your DefectDojo cloud instance.\nFirewall rules can also be updated from within your DefectDojo cloud instance. For more information on modifying firewall rules from within your instance, detailed documentation can be found here:\nhttps://documentation.defectdojo.com/proprietary_plugins/01_plus/cloud_portal/#firewall-rules\nResources The Resources page contains a Contact Us form, which you can use to get in touch with our Support team.\nIt also contains a link to our Open-Source Documentation, which can be viewed at https://documentation.defectdojo.com.\nAccount Settings The account settings page has four sections:\nUser Contact allows you to set your Username, Email Address, First Name and Last Name. Email Accounts allows you to add additional email addresses to your accounts. Adding an additional email account will send a verification email to the new address. Manage Social Accounts allows you to connect DefectDojo Cloud to your GitHub or Google credentials, which can be used to log in instead of a username and password. MFA Settings allow you to add an MFA code to Google Authenticator, 1Password or similar apps. Adding an additional step to your login process is a good proactive step to prevent unauthorized access. Add MFA to your login process This can also be done from the following link: https://cloud.defectdojo.com/settings/mfa/configure/\nBegin by installing an Authenticator app which supports QR code authentication on your smartphone or computer. Once you\u0026rsquo;ve done this, click Generate QR Code. Scan the QR code provided in DefectDojo using your Authenticator app, and then enter the six-digit code provided by your app. Click Enable Multi-Factor Authentication. ","date":"0001-01-01","id":348,"permalink":"/en/cloud_management/using-the-cloud-manager/","summary":"Logging into DefectDojo\u0026rsquo;s Cloud Manager allows you to configure your account settings and manage your subscription with DefectDojo Cloud.\nNew Subscription This page allows you to request a new, or additional Cloud instance from DefectDojo.","tags":[],"title":"Using the Cloud Manager"},{"content":"DefectDojo allows you to create Custom Reports for external audiences, which summarize the Findings or Endpoints that you wish to report on. Custom Reports can include branding and boilerplate text, and can also be used as Templates for future reports.\nOpening the Report Builder The Report Builder can be opened from the ðŸ“„Reports page on the sidebar.\nThe report builder page is organized in two columns. The left Report Format column is where you can design your report, using widgets from the right Available Widgets column.\nStep 1: Set Report Options From the Report Options section, you can take the following actions:\nSet a Report Name for the Report or Template Include user-created Finding Notes in the report Include Finding Images in the report Upload a header Image to the report Select a header image for your report To add an image to the top of your report, click the Choose File button and upload an image to DefectDojo.\nThe image will automatically resize to fit the document, and will render directly above your Report Name.\nStep 2: Add content to your report with Widgets Once you have set your Report Options, you can begin to design your report using DefectDojoâ€™s widgets.\nWidgets are content elements of a report which can be added by dragging and dropping them into the Report Format column. The final Report will be generated based on the position of each Widget, with the Report Name and Header Image rendered at the top.\nThe elements of your report can be reordered by dragging and dropping your widgets into a new order. To remove a widget from a report, click and drag it back to the right column. Widgets can also be collapsed by clicking on the grey header, for ease in navigation through a report builder. The Findings Widget, WYSIWYG Widget and the Endpoints widget can be used more than once. Cover Page Widget The Cover Page Widget allows you to set a Heading, Sub heading and additional metadata for your report. You can only have a single Cover Page for a given Report.\nExecutive Summary Widget The Executive Summary widget is intended to summarize your report at a glance. It contains a Heading (defaults to Executive Summary), as well as a text box which can contain whatever information you feel is required to summarize the report.\nYou can also Include SLAs in your executive summary. To add images, markup formatting or anything beyond pure text, consider adding a WYSIWYG Content Widget immediately after the executive summary.\nYou can only have a single Executive Summary for a given Report. If your Report contains multiple SLA configurations (I.E. you have Findings from separate Products which each have their own standards for SLA) each SLA configuration will be listed on the Executive Summary as a separate row. Severities Widget As each organization will have different definitions for each severity level, the Severities Widget allows you to define the Severity Levels used in your report for ease of understanding.\nTable Of Contents Widget The Table Of Contents Widget creates a list of each Finding in your report, for quicker access to specific Findings. The table of contents will create a separate heading for each Severity contained within the report. Each Finding listed in the table of contents will have an anchor link attached to quickly jump to the Finding in the report.\n* Set an optional Heading for your Table Of Contents if you wish.\nYou can add a section of Custom Content, which will add text underneath the Heading. You can upload an image to the Table Of Contents by clicking the Choose File button next to the Image line. The uploaded image will render directly above the Heading selected. Images will be resized to fit the document. WYSIWYG Content Widget The WYSIWYG (What You See Is What You Get) widget can be used to add a section containing text and images in your report. Multiple copies of this Widget can be added to add context to other sections of your report.\nWYSIWYG Content can include an optional Heading. Images can be added to a WYSIWYG widget by dragging and dropping them directly into the Content box. Images inserted into the Content box will render at their full resolution. You can add multiple WYSIWYG widgets to a report. Findings Widget The Findings Widget provides a list and summary of each Finding you want to include in your report. You can set the scope of the Findings you wish to include with Filters.\nThe Findings Widget is divided into two sections. The upper section contains a list of filters which can be used to determine which Findings you want to include, and the lower section contains the resulting list of Findings after filters are applied.\nTo apply filters to your Findings widget, set the filter parameters and click the Apply Filter button at the bottom. You can preview the results of your filter by checking the Findings list located underneath the Filters section.\n* The resulting list of Findings will be split up into sections by Severity Level. Note that DefectDojo data model components (Test, Engagement or Product) will not be represented in the report, only a list of Findings.\nAs with Widgets, the Filters section can be expanded and collapsed by clicking the gret Filters header. You can add multiple separate Findings Widgets to your report with different filter parameters if you want the report to contain more than one list of Findings. Only the Findings you are authorized to view are included in these listings, with respect to Role-Based Access Control Example Rendered Finding List Vulnerable Endpoints Widget The Vulnerable Endpoints widget is similar to the Findings widget. You can use this widget to list all Findings for specific Endpoints, and sort the Finding list by Endpoint instead of by Severity level.\nThe Vulnerable Endpoints widget will list each active Finding for the Endpoints selected. Rather than creating a single list of unsorted Findings this feature will separate them into their Endpoint context.\nAs with the Findings Widget, the Vulnerable Endpoints Widget is divided into a Filter section and a list of resulting Endpoints from the filter parameters.\nSelect the parameters for the Endpoints you wish to include here and click the Apply Findings button at the bottom. You can preview the results of your filter by checking the Endpoints list located underneath the Filters section.\nYou can add multiple separate Vulnerable Widgets to your report with different filter parameters if you want the report to contain more than one list. Only the Findings you are authorized to view are included in these listings, with respect to Role-Based Access Control. -------------- (separator) Widget This Widget will render a light grey horizontal line to divide between sections.\nStep 3: Publishing and viewing your Report Once you have finished building your report, you can generate it by clicking the green â€˜Runâ€™ button at the bottom of the Report Format section.\nThis will automatically take you to the Generated Reports page, and your report will begin to generate in the background. You can check on the Status of your report by reading the Status column next to it, and refreshing the page periodically.\nOnce your report has generated, you can view it by either clicking on the Status (which will be set to â€˜Complete: View Reportâ€™), or by opening the â‹® menu next to your report and selecting View Report.\nStep 4: Exporting a Report Only DefectDojo users will have access to Reports stored in the software, but Reports are set up in a way where they can be exported or printed easily.\nThe easiest method to use is to Print To PDF - with an HTML Report open, open a Print dialog in your browser and set Save To PDF as the Print Destination.\nReport formatting suggestions WYSIWYG sections can be used to contextualize or summarize Finding lists. We recommend using this widget throughout your report in between Findings or Vulnerable Endpoints widgets. ","date":"0001-01-01","id":349,"permalink":"/en/pro_reports/using-the-report-builder/","summary":"DefectDojo allows you to create Custom Reports for external audiences, which summarize the Findings or Endpoints that you wish to report on.","tags":[],"title":"Using the Report Builder"},{"content":"Veracode reports can be ingested in either XML or JSON Format\nDetailed XML Report JSON REST Findings from /appsec/v2/applications/{application_guid}/findings/ Acceptable scan types include STATIC, DYNAMIC, and SCA Findings with a status of CLOSED will not be imported into DefectDojo Acceptable formats are as follows: Findings list Requires slight modification of the response returned from the API Exmample of a request being: url \u0026lt;endpoint\u0026gt; | jq \u0026quot;{findings}\u0026quot; Desired Format: { \u0026#34;findings\u0026#34;: [ { ... }, ... ] }\rEmbedded This response can be saved directly to a file and uploaded Not as ideal for crafting a refined report consisting of multiple requests Desired Format: { \u0026#34;_embedded\u0026#34;: { \u0026#34;findings\u0026#34;: [ { ... }, ... ] }, \u0026#34;_links\u0026#34;: { ... }, \u0026#34;page\u0026#34;: { ... } }\rSample Scan Data Sample Veracode scans can be found here.\n","date":"0001-01-01","id":350,"permalink":"/en/connecting_your_tools/parsers/file/veracode/","summary":"Veracode reports can be ingested in either XML or JSON Format\nDetailed XML Report JSON REST Findings from /appsec/v2/applications/{application_guid}/findings/ Acceptable scan types include STATIC, DYNAMIC, and SCA Findings with a status of CLOSED will not be imported into DefectDojo Acceptable formats are as follows: Findings list Requires slight modification of the response returned from the API Exmample of a request being: url \u0026lt;endpoint\u0026gt; | jq \u0026quot;{findings}\u0026quot; Desired Format: { \u0026#34;findings\u0026#34;: [ { .","tags":[],"title":"Veracode"},{"content":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode SourceClear scans can be found here.\n","date":"0001-01-01","id":351,"permalink":"/en/connecting_your_tools/parsers/file/veracode_sca/","summary":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode SourceClear scans can be found here.","tags":[],"title":"Veracode SourceClear"},{"content":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data Sample Visual Code Grepper (VCG) scans can be found here.\n","date":"0001-01-01","id":352,"permalink":"/en/connecting_your_tools/parsers/file/vcg/","summary":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data Sample Visual Code Grepper (VCG) scans can be found here.","tags":[],"title":"Visual Code Grepper (VCG)"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nImport Vulners Audit results, no file required.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Vulners\u0026rdquo; and add the API Key\nIn the Product settings select Add API Scan Configuration and select the previously added Vulners API Tool Configuration.\nAfter this is done, you can import the findings by selecting \u0026ldquo;Vulners\u0026rdquo; as the scan type.\nDetailed installation steps can be found in vulners documentation.\nUse following instructions to generate Vulners API Key.\nMore details about DefectDojo-plugin integration can be found at vulners integrations page.\n","date":"0001-01-01","id":353,"permalink":"/en/connecting_your_tools/parsers/api/vulners/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Vulners"},{"content":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be found here.\n","date":"0001-01-01","id":354,"permalink":"/en/connecting_your_tools/parsers/file/wapiti/","summary":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be found here.","tags":[],"title":"Wapiti Scan"},{"content":"File Types DefectDojo parser accepts a .json file from Wazuh. The export from Wazuh can be done via 2 ways. Choose the one which you prefer.\nexport the Wazuh findings from API and upload them to DefectDojo. This method may be the easiest one but does export all known vulnerabilities at once. It is not possible to sort them after clients or any other categories. You will receive all vulnerabilities in one engagement. It also does not output the endpoint of a finding. export the findings via the script available here. The script fetches the findings by Wazuh client groups and saves them as json, ready for upload. You will receive one file per group allowing you to separate the clients via engagements in Wazuh. It also exports the endpoints hostname and displays them in DefectDojo UI. Independent of your above choice: Have in mind to adjust the max file size via \u0026ldquo;DD_SCAN_FILE_MAX_SIZE\u0026rdquo; if you see files larger than the default value of 100MB. Depending on the amount and category of integrated devices, the file size jumps rapidly.\nAcceptable JSON Format Parser expects a .json file structured as below.\n{ \u0026#34;data\u0026#34;: { \u0026#34;affected_items\u0026#34;: [ { \u0026#34;architecture\u0026#34;: \u0026#34;amd64\u0026#34;, \u0026#34;condition\u0026#34;: \u0026#34;Package less than 4.3.2\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-1234-123123\u0026#34;, \u0026#34;cvss2_score\u0026#34;: 0, \u0026#34;cvss3_score\u0026#34;: 5.5, \u0026#34;detection_time\u0026#34;: \u0026#34;2023-02-08T13:55:10Z\u0026#34;, \u0026#34;external_references\u0026#34;: [ \u0026#34;https://nvd.nist.gov/vuln/detail/CVE-YYYY-XXXXX\u0026#34;, \u0026#34;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-YYYY-XXXXX\u0026#34; ], \u0026#34;name\u0026#34;: \u0026#34;asdf\u0026#34;, \u0026#34;published\u0026#34;: \u0026#34;2022-09-01\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;VALID\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;CVE-YYYY-XXXXX affects asdf\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PACKAGE\u0026#34;, \u0026#34;updated\u0026#34;: \u0026#34;2022-09-07\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;4.3.1\u0026#34; } ], \u0026#34;failed_items\u0026#34;: [], \u0026#34;total_affected_items\u0026#34;: 1, \u0026#34;total_failed_items\u0026#34;: 0 }, \u0026#34;error\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;All selected vulnerabilities were returned\u0026#34; }\rSample Scan Data Sample Wazuh Scanner scans can be found here.\n","date":"0001-01-01","id":355,"permalink":"/en/connecting_your_tools/parsers/file/wazuh/","summary":"File Types DefectDojo parser accepts a .json file from Wazuh. The export from Wazuh can be done via 2 ways. Choose the one which you prefer.","tags":[],"title":"Wazuh Scanner"},{"content":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).\nHTTP Return Code Severity missing Low 200 - 299 High 300 - 399 Low 400 - 499 Medium = 500 | Low\nSample Scan Data Sample Wfuzz JSON importer scans can be found here.\n","date":"0001-01-01","id":356,"permalink":"/en/connecting_your_tools/parsers/file/wfuzz/","summary":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).","tags":[],"title":"Wfuzz JSON importer"},{"content":"Import Whispers JSON results. https://github.com/adeptex/whispers\nSample Scan Data Sample Whispers scans can be found here.\n","date":"0001-01-01","id":357,"permalink":"/en/connecting_your_tools/parsers/file/whispers/","summary":"Import Whispers JSON results. https://github.com/adeptex/whispers\nSample Scan Data Sample Whispers scans can be found here.","tags":[],"title":"Whispers"},{"content":"WhiteHat Sentinel output from api/vuln/query_site can be imported in JSON format.\nSample Scan Data Sample WhiteHat Sentinel scans can be found here.\n","date":"0001-01-01","id":358,"permalink":"/en/connecting_your_tools/parsers/file/whitehat_sentinel/","summary":"WhiteHat Sentinel output from api/vuln/query_site can be imported in JSON format.\nSample Scan Data Sample WhiteHat Sentinel scans can be found here.","tags":[],"title":"WhiteHat Sentinel"},{"content":"This parser imports scan results from wiz. You have to use Report Type Standard when you export the results. The file format will be .csv which is parsable within DefectDojo.\nSample Scan Data Sample Wiz Scanner scans can be found here.\n","date":"0001-01-01","id":359,"permalink":"/en/connecting_your_tools/parsers/file/wiz/","summary":"This parser imports scan results from wiz. You have to use Report Type Standard when you export the results. The file format will be .","tags":[],"title":"Wiz Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli dir scan --path ./ -o scan_dir.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":360,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_dir/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli Dir Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli iac scan --path ./ -o scan_iac.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":361,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_iac/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli IaC Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli docker scan --image wizcli-imagescan -o scan_img.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":362,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_img/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli Img Scanner"},{"content":"Once you have created one or more Reports in DefectDojo you can take further actions, including:\nUsing a report as a template for subsequent reports Re-running a report with updated data Deleting an old or unused reportsa Use a report as a Template DefectDojo allows you to easily create Report templates with your team logo, boilerplate text and a standardized content order.\nIf you want to change the way a report is set up, or create a new one with a similar layout, you can re-open the Report Builder by selecting View Template from the â‹® menu next to the report you wish to use as a template.\nThere are two places where you can find a Report Template to use:\nFrom the Generated Reports page, where you can see a list of completed reports From the Report Templates page, where you can see a list of previously run reports, including reports which were deleted from the Generated Reports page. Both of these pages can be found in the ðŸ“„ Reports tab on the sidebar.\nTo access the Report Templates page, open ðŸ“„Reports \u0026gt; Report Templates from the sidebar. From that table, you can open the report builder by clicking the â‹® menu next to the report you wish to use as a template.\nEvery time you make changes to a template or previous report, the result will be saved as a new report under Generated Reports so that you don\u0026rsquo;t lose the older version. If you like, the older version can be deleted.\nRe-Running a Report DefectDojo Reports are â€˜frozen in timeâ€™ - to keep your records consistent, they do not update automatically when DefectDojo experiences data changes.\nHowever, if you want to create an updated version of a previously created report, you can do so by selecting Re-run Report from the â‹® menu next to the report you wish to generate.\nSelecting this option will create a new report in the Generated Reports list, with a different Created timestamp to indicate that the report was run at a separate time.\nDeleting a Report If you no longer need a report, you can delete it by selecting Delete Report from the â‹® menu next to the report you wish to delete. Note that this will only remove the report from the Generated Reports list - a record of the report will still exist under Report Templates if you want to re-run it.\n","date":"0001-01-01","id":363,"permalink":"/en/pro_reports/working-with-generated-reports/","summary":"Once you have created one or more Reports in DefectDojo you can take further actions, including:\nUsing a report as a template for subsequent reports Re-running a report with updated data Deleting an old or unused reportsa Use a report as a Template DefectDojo allows you to easily create Report templates with your team logo, boilerplate text and a standardized content order.","tags":[],"title":"Working with Generated Reports"},{"content":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can be found here.\n","date":"0001-01-01","id":364,"permalink":"/en/connecting_your_tools/parsers/file/wpscan/","summary":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can be found here.","tags":[],"title":"Wpscan Scanner"},{"content":"Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nSample Scan Data Sample Xanitizer scans can be found here.\n","date":"0001-01-01","id":365,"permalink":"/en/connecting_your_tools/parsers/file/xanitizer/","summary":"Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nSample Scan Data Sample Xanitizer scans can be found here.","tags":[],"title":"Xanitizer"},{"content":"Import Yarn Audit scan report in JSON format. Use something like yarn audit --json \u0026gt; yarn_report.json.\nSample Scan Data Sample Yarn Audit scans can be found here.\n","date":"0001-01-01","id":366,"permalink":"/en/connecting_your_tools/parsers/file/yarn_audit/","summary":"Import Yarn Audit scan report in JSON format. Use something like yarn audit --json \u0026gt; yarn_report.json.\nSample Scan Data Sample Yarn Audit scans can be found here.","tags":[],"title":"Yarn Audit"},{"content":"ZAP XML report format (with or without requests and responses).\nSample Scan Data Sample Zed Attack Proxy scans can be found here.\n","date":"0001-01-01","id":367,"permalink":"/en/connecting_your_tools/parsers/file/zap/","summary":"ZAP XML report format (with or without requests and responses).\nSample Scan Data Sample Zed Attack Proxy scans can be found here.","tags":[],"title":"Zed Attack Proxy"}]