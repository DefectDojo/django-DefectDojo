[{"content":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.\nUsing docker images provided in DockerHub If you're using latest, then you need to pre pull the latest from DockerHub to update.\nThe generic upgrade method for docker compose are as follows:\nPull the latest version\ndocker pull defectdojo/defectdojo-django:latest docker pull defectdojo/defectdojo-nginx:latest\rIf you would like to use a version other than the latest, specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2 docker pull defectdojo/defectdojo-nginx:1.10.2\rIf you would like to use alpine based images, you specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2-alpine docker pull defectdojo/defectdojo-nginx:1.10.2-alpine\rGo to the directory where your docker-compose.yml file lives\nStop DefectDojo: docker compose stop\nRe-start DefectDojo, allowing for container recreation: docker compose up -d\nDatabase migrations will be run automatically by the initializer. Check the output via docker compose logs initializer or relevant k8s command\nIf you have the initializer disabled (or if you want to be on the safe side), run the migration command: docker compose exec uwsgi /bin/bash -c \u0026quot;python manage.py migrate\u0026quot;\nBuilding your local images If you build your images locally and do not use the ones from DockerHub, the instructions are the same, with the caveat that you must build your images first.\nPull the latest DefectDojo changes\ngit fetch git pull git merge origin/master\rThen replace the first step of the above generic upgrade method for docker compose with: docker compose build\ngodojo installations If you have installed DefectDojo on \u0026ldquo;iron\u0026rdquo; and wish to upgrade the installation, please see the instructions in the repo.\n","date":"0001-01-01","id":0,"permalink":"/en/open_source/upgrading/upgrading_guide/","summary":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.","tags":[],"title":"Upgrading Guide"},{"content":"There are no special instructions for upgrading to 2.45.x. Check the Release Notes for the contents of the release.\nStarting with release 2.45.0 Experimental Docker builds for linux/arm64 are published with each release.\n","date":"0001-01-01","id":1,"permalink":"/en/open_source/upgrading/2.45/","summary":"There are no special instructions for upgrading to 2.45.x. Check the Release Notes for the contents of the release.\nStarting with release 2.","tags":[],"title":"Upgrading to DefectDojo Version 2.45.x"},{"content":"Hash Code changes The Burp parser now has a custom deduplication configuration to make deduplication more accurate. To recalculate the hash code and deduplicate existing Burp findings, please execute the following command:\ndocker compose exec uwsgi /bin/bash -c \u0026quot;python manage.py dedupe.py --parser 'Burp Scan' --hash_code_only\u0026quot; This command has various command line arguments to tweak its behavior, for example to trigger a run of the deduplication process. See dedupe.py for more information.\nCheck the Release Notes for the contents of the release.\n","date":"0001-01-01","id":2,"permalink":"/en/open_source/upgrading/2.44/","summary":"Hash Code changes The Burp parser now has a custom deduplication configuration to make deduplication more accurate. To recalculate the hash code and deduplicate existing Burp findings, please execute the following command:","tags":[],"title":"Upgrading to DefectDojo Version 2.44.0"},{"content":"AWS Parser Endpoint Migrations The structure of AWS Endpoints changed slightly. In the past ARNs of Services were imported with invalid digits leading to broken Endpoints. The Endpoints thus changed slightly. \u0026ldquo;:\u0026rdquo;, \u0026quot; \u0026quot; \u0026amp; \u0026ldquo;/\u0026rdquo; are replaced by \u0026ldquo;_\u0026rdquo;.\nAn Migration is added as part of this release to avoid duplicates at the next import. It can take some time, depending on the amount of AWS Endpoints in the DB.\nCheck the Release Notes for the contents of the release.\n","date":"0001-01-01","id":3,"permalink":"/en/open_source/upgrading/2.44.1/","summary":"AWS Parser Endpoint Migrations The structure of AWS Endpoints changed slightly. In the past ARNs of Services were imported with invalid digits leading to broken Endpoints.","tags":[],"title":"Upgrading to DefectDojo Version 2.44.1"},{"content":"\rDefectDojo Inc. and open-source contributors maintain this documentation to support both the Community and Pro editions of DefectDojo.\nWhat is DefectDojo? DefectDojo is a DevSecOps platform. DefectDojo streamlines DevSecOps by serving as an aggregator and single pane of glass for your security tools.\nDefectDojo has smart features to enhance and tune the results from your security tools including the ability to merge findings, remember false positives, and distill duplicates.\nDefectDojo also integrates with JIRA, provides metrics / reports, and can also be used for traditional pen test management.\nWhat does DefectDojo do? Whether you\u0026rsquo;re a one-person security team for a small organization, or a CISO overseeing a large amount of software projects, DefectDojo allows you to organize your security work, and easily report your organization\u0026rsquo;s security posture to other stakeholders.\nWhile security process automation and integrated development pipelines are the ultimate end goals of DefectDojo, this software is a bug tracker at its core for security vulnerabilities, which is meant to ingest, organize and standardize reports from many security tools.\nDefectDojo\u0026rsquo;s Product:Engagement model enables allows you to take inventory of your development environment and immediately place new security Findings in context.\nTrack and report on vulnerabilities and test results across repositories and development branches, using CI/CD integration Ingest Pen tester reports and capture point-in-time snapshots of your security profile Create and track Risk Acceptances for security vulnerabilities Set and enforce SLAs to reflect your organization\u0026rsquo;s policies for vulnerability remediation Filter out redundant data using DefectDojo\u0026rsquo;s deduplication algorithm Here are some examples of ways DefectDojo can be implemented, with DefectDojo co-founder and CTO Matt Tesauro:\nHow does DefectDojo work? Whether you\u0026rsquo;re a Pro or an Open-Source user, we have many resources that can help you get started with DefectDojo.\nOur New User Checklist covers the fundamentals of setting up your DefectDojo environment and setting up your import, triage and reporting workflows.\nWe support a large amount of security tool integrations to help fit DefectDojo in your DevSecOps program.\nOur team maintains a YouTube Channel which hosts tutorials, archived Office Hours events and other content. New subscribers are always welcome!\nOpen-Source DefectDojo The Open-Source edition of DefectDojo is available on GitHub.\nInstallation Guides There are a few supported ways to install DefectDojo\u0026rsquo;s Open Source edition:\nDocker Compose is the easiest method to install the core program and services required to run DefectDojo. Kubernetes is not fully supported at the Open-Source level, but this guide can be referenced and used as a starting point to integrate DefectDojo into Kubernetes architecture. Other guides for working with an Open-Source install:\nArchitecture gives you an overview of each service and component used by DefectDojo. Running In Production provides system requirements, performance tweaks and maintenance processes for running DefectDojo on a production server. Note that this guide strictly covers Docker Compose installs, not Kubernetes. If you run into trouble with an Open Source install, we highly recommend asking questions on the OWASP Slack. Our community members are active on the # defectdojo channel and can help you with issues you‚Äôre facing.\nOnline Demo A running example of DefectDojo (Open-Source Edition) is available on our demo server, using the credentials admin / 1Defectdojo@demo#appsec. The demo server is refreshed regularly and provisioned with some sample data.\nüüß DefectDojo Pro Edition DefectDojo Inc. hosts a commercial edition of this software, which includes:\nadditional features, smart features and UI improvements cloud hosting, with regular backups, updates and maintenance premium support and implementation guidance For more information, check out our Pricing page at defectdojo.com. After filling out a quick survey to assess your organization\u0026rsquo;s needs we\u0026rsquo;ll provide you with a custom quote for DefectDojo.\nDefectDojo Pro edition is available as a cloud-hosted SaaS offering but is also available for installation on-premises.\nConnect With Us To get in touch with our team, you can always reach out to info@defectdojo.com. Follow DefectDojo Inc. on LinkedIn for company updates. DefectDojo hosts online presentations for AppSec professionals that can be accessed live or on demand - check us out on our Events page. Many of these are also available on our YouTube Channel. ","date":"2021-02-02","id":4,"permalink":"/en/about_defectdojo/about_docs/","summary":"DefectDojo Inc. and open-source contributors maintain this documentation to support both the Community and Pro editions of DefectDojo.\nWhat is DefectDojo?","tags":[],"title":"About Our Documentation"},{"content":"Note: The Universal Parser is only available in DefectDojo Pro.\nThe Universal Parser is currently in Beta. See our announcement presentation for more information.\nAbout Universal Parser DefectDojo has a large, regularly updated library of parsers to help security teams ingest data. However, sometimes users have a tool that\u0026rsquo;s unsupported by the parsers, or they may want to import data into the DefectDojo model differently from the way the parser does.\nDefectDojo\u0026rsquo;s Universal Parser is meant to give our users with unsupported report types a path forward, to import and map any JSON, CSV or XML file.\nThe Universal Parser is:\nA quick way to support file formats for which we do not have Community parsers, such as reports produced by internal tools A tool to help you ingest data, even if a Community parser is out-of-date or doesn\u0026rsquo;t structure findings the way you would like An alternative to custom scripting to transform tool reports into the CSV/JSON format expected by the \u0026ldquo;Generic Findings Import\u0026rdquo; scan type Designed to be easy to use for anyone, with no coding and minimal configuration required The Universal Parser is not:\nA comprehensive replacement for open source parsers, Connectors, or carefully-massaged \u0026ldquo;Generic Findings Import\u0026rdquo; reports Capable of handling nuanced, branching logic to structure findings The Universal Parser configuration is only available in the beta UI, though you can still import scans using a Universal Parser via the old UI or API.\nStep 1: Creating a new Universal Parser You can create a new Universal Parser by clicking the \u0026ldquo;New Universal Parser\u0026rdquo; button in the navigation bar under the \u0026ldquo;Import\u0026rdquo; section, or from the link on the \u0026ldquo;Add Findings\u0026rdquo; page.\nThe first screen will ask you for a scan file and a parser name.\nThe file should:\nHave a recognized extension (see supported file extensions below) Contain enough finding-like objects to be representative of real reports - i.e., one that includes values in all optional fields Not be larger than about 1-2MB - beyond this point it will generally just take longer to parse the file, without any benefit The parser name will be used when creating the Test_Type for this new parser. You\u0026rsquo;ll find your newly-created Universal Parser in the scan types drop-down on the \u0026ldquo;Add Findings\u0026rdquo; page with a name like \u0026ldquo;Universal Parser - MyCustomParser\u0026rdquo;. Parser names must be unique to prevent confusion when selecting a scan type for imports.\nStep 2: Mapping your Finding fields After uploading an example scan file, selecting a parser name, and clicking \u0026ldquo;Next\u0026rdquo;, the following page will let you configure the way this Universal Parser will populate finding fields when using this configuration to perform imports. On the right, you will find a selection of DefectDojo finding fields (output fields). Drop-down menus to the left of each output field allow you to select which item(s) (input fields) from your scan file\u0026rsquo;s structure should be used to populate them.\nExample:\nIf you\u0026rsquo;ve uploaded a scan file in JSON format that looks like this:\n{ \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Finding 1 Title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Finding 1 Description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;CRITICAL\u0026#34;, \u0026#34;CVE\u0026#34;: \u0026#34;CVE-2025-12345\u0026#34;, ... }, { \u0026#34;title\u0026#34;: \u0026#34;Finding 2 Title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Finding 2 Description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;LOW\u0026#34;, \u0026#34;CVE\u0026#34;: \u0026#34;CVE-2025-54321\u0026#34;, ... }, ... ] }\rYou\u0026rsquo;ll see a hierarchical representation of the unique fields we detected based on the structure of the input file, with icons indicating the type of each field (if we can determine this). You can then select the \u0026ldquo;title\u0026rdquo; input field in the drop-down menu that populates the \u0026ldquo;Title\u0026rdquo; output field, the \u0026ldquo;description\u0026rdquo; input field can go with the \u0026ldquo;Description\u0026rdquo; output field, and so on.\nInput field names don\u0026rsquo;t have to match the names of output fields, and your scan file may not have an equivalent to all DefectDojo output fields.\nRequired fields The following output fields require an input field mapping:\nTitle Severity Description About severities A Universal Parser will accept any case variation of the DefectDojo severities - \u0026ldquo;CRITICAL\u0026rdquo;, \u0026ldquo;Critical\u0026rdquo;, \u0026ldquo;cRiTiCaL\u0026rdquo;, etc. - and apply it to your findings. Any value that doesn\u0026rsquo;t match a DefectDojo severity will be replaced with \u0026ldquo;Info\u0026rdquo;. This mirrors how parsers and Connectors work today: unknown values are generally mapped to \u0026ldquo;Info\u0026rdquo;.\nMulti-select fields Some output fields will accept multiple input fields. If you decide to select more than one input field, we will provide that field\u0026rsquo;s value under a header with that input field\u0026rsquo;s name.\nExample\ndescription\nThis was pulled from a field called \u0026ldquo;description\u0026rdquo; in the input file\ndetailed_description\nThis was pulled from a field called \u0026ldquo;detailed_description\u0026rdquo; in the input file\nStep 3: Previewing your Findings Once you\u0026rsquo;ve selected your mappings from input fields to output fields, you can click the \u0026ldquo;Next\u0026rdquo; button to see a preview of what the Findings from your input file will look like once they are imported to DefectDojo with your chosen configuration. Some fields will have an \u0026ldquo;expand\u0026rdquo; button next to them to allow you to see the full, rendered MarkDown of what that field will look like. We will only render previews of the first 25 Findings from your input file, but you can also see how many findings were detected in the whole scan file.\nIf the previews don\u0026rsquo;t look like you expected, you can hit the \u0026ldquo;Back\u0026rdquo; button to tweak the mappings. Once you are satisfied with your configuration, click the \u0026ldquo;Submit\u0026rdquo; button to create your new Universal Parser. This will not perform an import automatically.\nOnce your Universal Parser is created, you\u0026rsquo;ll be redirected to the \u0026ldquo;Add Findings\u0026rdquo; page where you can upload and import a scan file matching the structure of the example file you provided in Step 1.\nAdditional notes about Universal Parser configuration Choosing the right input fields Each vendor may produce very different scan report formats, some of which will map more closely to DefectDojo\u0026rsquo;s finding model than others. We allow for significant flexibility in what we will accept, but we must impose some structure to ensure that findings don\u0026rsquo;t get garbled in the translation from input to output. While we can accommodate optional input fields, we don\u0026rsquo;t accept \u0026ldquo;global\u0026rdquo; fields, or fields that occur a different number of times than the number of finding objects.\nExample { \u0026#34;scan_type\u0026#34;: \u0026#34;MyToolScan\u0026#34;, // \u0026lt;- There is only one instance of this field, which doesn\u0026#39;t match the number of findings \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Finding 1 Title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Finding 1 Description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;CRITICAL\u0026#34;, \u0026#34;CVE\u0026#34;: \u0026#34;CVE-2025-12345\u0026#34;, // \u0026lt;- This optional field only appears in Finding 1 - that\u0026#39;s okay! ... }, { \u0026#34;title\u0026#34;: \u0026#34;Finding 2 Title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Finding 2 Description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;CRITICAL\u0026#34;, ... // \u0026lt;- While there is no \u0026#34;CVE\u0026#34; field here, we can still query for it and simply default to a null value }, ... 5 more findings ... ], \u0026#34;global_details\u0026#34;: [ { \u0026#34;nested_detail\u0026#34;: \u0026#34;Global detail 1\u0026#34; }, { \u0026#34;nested_detail\u0026#34;: \u0026#34;Global detail 2\u0026#34; // \u0026lt;- The number of \u0026#34;global_details\u0026#34; objects (2) does not match the number of individual finding objects (7) } ] }\rAfter saving a Universal Parser You can edit the Test_Type associated with your Universal Parser to change:\nWhether it is \u0026ldquo;active\u0026rdquo; or not. If not, it will not appear as an option in the \u0026ldquo;Scan Type\u0026rdquo; drop-down on the \u0026ldquo;Add Findings\u0026rdquo; page Whether its findings should be marked \u0026ldquo;static\u0026rdquo; or \u0026ldquo;dynamic\u0026rdquo; You can tweak the same-tool and cross-tool deduplication hash codes, as well as the reimport hash codes, for your Universal Parser under \u0026ldquo;Enterprise Settings\u0026rdquo;. By default, only same-tool deduplication and reimport hash codes are populated, with the required values Title, Severity, and Description. ","date":"0001-01-01","id":5,"permalink":"/en/connecting_your_tools/parsers/universal_parser/","summary":"Note: The Universal Parser is only available in DefectDojo Pro.\nThe Universal Parser is currently in Beta. See our announcement presentation for more information.","tags":[],"title":"üåê Universal Parser (Pro)"},{"content":"DefectDojo\u0026rsquo;s Jira integration can be used to push Finding data to one or more Jira Projects. By doing so, you can integrate DefectDojo into your standard development workflow. Here are some examples of how this can work:\nThe AppSec team can selectively push Findings to a Jira Project used by developers, so that issue remediation can be appropriately prioritized alongside regular development. Developers on this board don\u0026rsquo;t need to access DefectDojo - they can keep all their work in one place. DefectDojo can push ALL Findings to a bidirectional Jira Project which the AppSec team uses, which allows them to split up issue validation. This board keeps in sync with DefectDojo and allows for complex remediation workflows. DefectDojo can selectively push Findings from separate Products \u0026amp;/or Engagements to separate Jira Projects, to keep things in their proper context. Setting Up Jira Setting Up Jira requires the following steps:\nConnect a Jira Instance, either with a username / password or an API token. Multiple instances can be linked. Add that Jira Instance to one or more Products or Engagements within DefectDojo. If you wish to use bidirectional sync, create a Jira Webhook which will send updates to DefectDojo. Step 1: Connect a Jira Instance Connecting a Jira Instance is the first step to take when setting up DefectDojo‚Äôs Jira integration. Please note Jira Service Management is currently not supported.\nRequired information from Jira Atlassian uses different ways of authentication between Jira Cloud and Jira Data Center.\nfor Jira Cloud, you will need:\na Jira URL, i.e. https://yourcompany.atlassian.net/ an account with permissions to create and update issues in your Jira instance. This can be: A standard username / password combination A username / API Token combination for Jira Data Center (or Server), you will need:\na Jira URL, i.e. https://jira.yourcompany.com an account with permissions to create and update issues in your Jira instance. This can be: A emailaddress / Personal Access Token combination Optionally, you can map:\nJira Transitions to trigger Re-Opening and Closing Findings Jira Resolutions which can apply Risk Acceptance and False Positive statuses to Findings (optional) Multiple Jira Projects can be handled by a single Jira Instance connection, as long as the Jira account / token used by DefectDojo has permission to create Issues in the associated Jira Project.\nAdd a Jira Instance (Pro UI) If you have not already done so, navigate to the System Settings page and check the box on Enable Jira Integration.\nNavigate to the Enterprise Settings \u0026gt; Jira Instances \u0026gt; + New Jira Instance page from the DefectDojo sidebar.\nSelect a Configuration Name for this Jira Instance to use in DefectDojo. This name is simply a label for the Instance connection in DefectDojo, and does not need to be related to any Jira data.\nSelect the URL for your company‚Äôs Jira instance - likely similar to https://**yourcompany**.atlassian.net if you‚Äôre using a Jira Cloud installation.\nEnter an appropriate authetication method in the Username / Password fields for Jira:\nFor standard username / password Jira authentication, enter a Jira Username and corresponding Password in these fields. For authentication with a user\u0026rsquo;s API token (Jira Cloud) enter the Username with the corresponding API token in the password field. For authentication with a Jira Personal Access Token (aka PAT, used in Jira Data Center and Jira Server only), enter the PAT in the password field. Username is not used for authentication with a Jira PAT, but the field is still required in this form, so you can use a placeholder value here to identify your PAT. Note that the user associated with this connection have permission to create Issues and access data in your Jira instance.\nYou will need to provide values for an Epic Name ID, Re-open Transition ID and Close Transition ID. These values can be changed later. While logged into Jira, you can access these values from the following URLs: Epic Name ID: visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/2/field and search for Epic Name. Copy the number out of number and paste it here. Re-open Transition ID: visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions?expand-transitions.fields to find the ID for your Jira instance. Paste it in the Reopen Transition ID field. Close Transition ID: Visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions?expand-transitions.fields to find the ID for your Jira instance. Paste it in the Close Transition ID field. Select the Default issue type which you want to create Issues as in Jira. The options for this are Bug, Task, Story and Epic (which are standard Jira issue types) as well as Spike and Security, which are custom issue types. If you have a different Issue Type which you want to use, please contact support at defectdojo dot com\rfor assistance.\nSelect your Issue Template, which will determine the Issue Description when Issues are created in Jira.\nThe two types are:\nJira_full, which will include all Finding information in Jira Issues Jira_limited, which will include a smaller amount of Finding information and metadata. If you leave this field blank, it will default to Jira_full. If you need a different kind of template, Pro users can reach out to support at defectdojo dot com\rIf you wish, enter the name of a Jira Resolution which will change the status of a Finding to Accepted or to False Positive (when the Resolution is triggered on the Issue). The form can be submitted from here. If you wish, you can further customize your Jira integration under Optional Fields. Clicking this button will allow you to apply generic text to Jira Issues or change the mapping of Jira Severity Mappings.\nAdd a Jira Instance (Classic UI / Open-Source) If you have not already done so, navigate to the System Settings page and check the box on Enable Jira Integration. You will need to do this before the ‚öôÔ∏è Configuration \u0026gt; JIRA option shows up on the sidebar. ‚Äã\nNavigate to the ‚öôÔ∏è Configuration \u0026gt; JIRA page from the DefectDojo sidebar. ‚Äã You will see a list of all currently configured Jira Projects which are linked to DefectDojo. To add a new Project Configuration, click the wrench icon and choose either the Add Jira Configuration (Express) or Add Jira Configuration options.\nAdd Jira Configuration (Express) The Express method allows for a quicker method of linking a Project. Use the Express method if you simply want to connect a Jira Project quickly, and you aren‚Äôt dealing with a complex Jira workflow.\nSelect a name for this Jira Configuration to use in DefectDojo. This name is simply a label for the Instance connection in DefectDojo, and does not need to be related to any Jira data. ‚Äã Select the URL for your company‚Äôs Jira instance - likely similar to https://**yourcompany**.atlassian.net if you‚Äôre using a Jira Cloud installation. ‚Äã Enter an appropriate authetication method in the Username / Password fields for Jira: For standard username / password Jira authentication, enter a Jira Username and corresponding Password in these fields. For authentication with a user\u0026rsquo;s API token (Jira Cloud) enter the Username with the corresponding API token in the password field. For authentication with a Jira Personal Access Token (aka PAT, used in Jira Data Center and Jira Server only), enter the PAT in the password field. Username is not used for authentication with a Jira PAT, but the field is still required in this form, so you can use a placeholder value here to identify your PAT. ‚Äã Select the Default issue type which you want to create Issues as in Jira. The options for this are Bug, Task, Story and Epic (which are standard Jira issue types) as well as Spike and Security, which are custom issue types. If you have a different Issue Type which you want to use, please contact support at defectdojo dot com\rfor assistance. ‚Äã Select your Issue Template, which will determine the Issue Description when Issues are created in Jira. The two types are:\nJira_full, which will include all Finding information in Jira Issues Jira_limited, which will include a smaller amount of Finding information and metadata. If you leave this field blank, it will default to Jira_full.\nSelect one or more Jira Resolution types which will change the status of a Finding to Accepted (when the Resolution is triggered on the Issue). If you don‚Äôt wish to use this automation, you can leave the field blank. ‚Äã Select one or more Jira Resolution types which will change the status of a Finding to False Positive (when the Resolution is triggered on the Issue). If you don‚Äôt wish to use this automation, you can leave the field blank. ‚Äã Decide whether you wish to send SLA Notifications as a comment on a Jira issue. ‚Äã Decide whether you wish to automatically sync Findings with Jira. If this is enabled, Jira Issues will automatically be kept in sync with the related Findings. If this is not enabled, you will need to manually push any changes made to a Finding after the Issue has been created in Jira. ‚Äã Select your Issue key. In Jira, this is the string associated with an Issue (e.g. the word ‚ÄòEXAMPLE‚Äô in an issue called EXAMPLE-123). If you don‚Äôt know your issue key, create a new Issue in the Jira Project. In the screenshot below, we can see that the issue key on our Jira Project is DEF. ‚Äã ‚Äã Click Submit. DefectDojo will automatically look for appropriate mappings in Jira and add them to the configuration. You are now ready to link this configuration to one or more Products in DefectDojo. Add Jira Configuration (Standard) The Standard Jira Configuration adds a few additional steps to allow for more precise control over Jira mappings and interactions. This can be changed after a Jira configuration has been added, even if it was created using the Express method. ‚Äã\nAdditional Form Options Epic Name ID: If you have multiple Epic types in Jira, you can specify the one you want to use by finding its ID in the Jira Field Spec. ‚Äã To obtain the \u0026lsquo;Epic name id\u0026rsquo; visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/2/field and search for Epic Name. Copy the number out of number and paste it here. ‚Äã ‚Äã\nReopen Transition ID: If you want a specific Jira Transition to Reopen an issue, you can specify the Transition ID here. If using the Express Jira Configuration, DefectDojo will automatically find an appropriate Transition and create the mapping. ‚Äã Visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions?expand-transitions.fields to find the ID for your Jira instance. Paste it in the Reopen Transition ID field. ‚Äã\nClose Transition ID: If you want a specific Jira Transition to Close an issue, you can specify the Transition ID here. If using the Express Jira Configuration, DefectDojo will automatically find an appropriate Transition and create the mapping. ‚Äã Visit https://\u0026lt;YOUR JIRA URL\u0026gt;/rest/api/latest/issue/\u0026lt;ANY VALID ISSUE KEY\u0026gt;/transitions?expand-transitions.fields to find the ID for your Jira instance. Paste it in the Close Transition ID field. ‚Äã\nMapping Severity Fields: Each Jira Issue has an associated Priority, which DefectDojo will automatically assign based on the Severity of a Finding. Enter the names of each Priority which you want to map to, for Info, Low, Medium, High and Critical Severities.\nFinding Text - if you want to add additional standardized text to each Issue created, you can enter that text here. This is not text that maps to any field in Jira, but additional text that is added to the Issue Description. \u0026ldquo;Created by DefectDojo\u0026rdquo; for example.\nComments (in Jira) and Notes (in DefectDojo) can be kept in sync. This setting can be enabled once the Jira configuration has been added to a Product, via the Edit Product form.\nStep 2: Connect a Product or Engagement to Jira Each Product or Engagement in DefectDojo has its own settings which govern how Findings are converted to JIRA Issues. From here, you can decide the associated JIRA Project and set the default behaviour for creating Issues, Epics, Labels and other JIRA metadata.\nAdd Jira to a Product or Engagement (Pro UI) You can find this page by clicking the Gear menu on a Product or Engagement - ‚öôÔ∏è and opening the Jira Project Settings page.\nJira Instance If you have multiple instances of Jira set up, for separate products or teams within your organization, you can indicate which Jira Project you want DefectDojo to create Issues in. Select a Project from the drop-down menu.\nIf this menu doesn\u0026rsquo;t list any Jira instances, confirm that those Projects are connected in your global Jira Configuration for DefectDojo - yourcompany.defectdojo.com/jira.\nProject key This is the key of the Project that you want to use with DefectDojo. The Project Key for a given project can be found in the URL.\nIssue template Here you can determine how much DefectDojo metadata you want to send to Jira. Select one of two options:\njira_full: Issues will track all of the parameters from DefectDojo - a full Description, CVE, Severity, etc. Useful if you need complete Finding context in Jira (for example, if someone is working on this Issue who doesn\u0026rsquo;t have access to DefectDojo). Here is an example of a jira_full Issue:\n‚Äã Jira_limited: Issues will only track the DefectDojo link, the Product/Engagement/Test links, the Reporter and Environment fields. All other fields are tracked in DefectDojo only. Useful if you don\u0026rsquo;t require full Finding context in Jira (for example, if someone is working on this Issue who mainly works in DefectDojo, and doesn\u0026rsquo;t need the full picture in JIRA as well.) ‚ÄãHere is an example of a jira_limited Issue:\nComponent If you manage your Jira project using Components, you can assign the appropriate Component for DefectDojo here.\nCustom fields\nIf you don‚Äôt need to use Custom Fields with DefectDojo issues, you can leave this field as ‚Äònull‚Äô.\nHowever, if your Jira Project Settings require you to use Custom Fields on new Issues, you will need to hard-code these mappings.\nNote that DefectDojo cannot send any Issue-specific metadata as Custom Fields, only a default value. This section should only be set up if your JIRA Project requires that these Custom Fields exist in every Issue in your project.\nFollow this guide to get started working with Custom Fields.\nJira labels\nSelect the relevant labels that you want the Issue to be created with in Jira, e.g. DefectDojo, YourProductName..\nDefault assignee The name of the default assignee in Jira. If left blank, DefectDojo will follow the default behaviour in your Jira Project when creating Issues.\nAdd Jira to a Product or Engagement (Classic UI / Open-Source) In the Classic UI, you can find Jira settings by opening the Edit Product or Edit Engagement form. \u0026ldquo;üìù Edit\u0026rdquo; button under Settings on the page:\nList of Jira settings Jira settings are located near the bottom of the Product Settings page.\nJira Instance If you have multiple instances of Jira set up, for separate products or teams within your organization, you can indicate which Jira Project you want DefectDojo to create Issues in. Select a Project from the drop-down menu.\nIf this menu doesn\u0026rsquo;t list any Jira instances, confirm that those Projects are connected in your global Jira Configuration for DefectDojo - yourcompany.defectdojo.com/jira.\nProject key This is the key of the Project that you want to use with DefectDojo. The Project Key for a given project can be found in the URL.\nIssue template Here you can determine how much DefectDojo metadata you want to send to Jira. Select one of two options:\njira_full: Issues will track all of the parameters from DefectDojo - a full Description, CVE, Severity, etc. Useful if you need complete Finding context in Jira (for example, if someone is working on this Issue who doesn\u0026rsquo;t have access to DefectDojo). Here is an example of a jira_full Issue:\n‚Äã Jira_limited: Issues will only track the DefectDojo link, the Product/Engagement/Test links, the Reporter and Environment fields. All other fields are tracked in DefectDojo only. Useful if you don\u0026rsquo;t require full Finding context in Jira (for example, if someone is working on this Issue who mainly works in DefectDojo, and doesn\u0026rsquo;t need the full picture in JIRA as well.) ‚ÄãHere is an example of a jira_limited Issue:‚Äã\nComponent If you manage your Jira project using Components, you can assign the appropriate Component for DefectDojo here.\nCustom fields\nIf you don‚Äôt need to use Custom Fields with DefectDojo issues, you can leave this field as ‚Äònull‚Äô.\nHowever, if your Jira Project Settings require you to use Custom Fields on new Issues, you will need to hard-code these mappings.\nJira Cloud now allows you to create a default Custom Field value directly in-app. See Atlassian\u0026rsquo;s documentation on Custom Fields for more information on how to configure this.\nNote that DefectDojo cannot send any Issue-specific metadata as Custom Fields, only a default value. This section should only be set up if your JIRA Project requires that these Custom Fields exist in every Issue in your project.\nFollow this guide to get started working with Custom Fields.\nJira labels\nSelect the relevant labels that you want the Issue to be created with in Jira, e.g. DefectDojo, YourProductName..\nDefault assignee The name of the default assignee in Jira. If left blank, DefectDojo will follow the default behaviour in your Jira Project when creating Issues.\nAdditional Form Options Enable Connection With Jira Project Jira integrations can be removed from your instance only if no related Issues have been created. If Issues have been created, there is no way to completely remove a Jira Instance from DefectDojo.\nHowever, you can disable your Jira integration by disabling it at the Product level. This will not delete or change any existing Jira tickets created by DefectDojo, but will disable any further updates.\nAdd Vulnerability Id as a Jira label This allows you to add the Vulnerability ID data as a Jira Label automatically. Vulnerability IDs are added to Findings from individual security tools - these may be Common Vulnerabilities and Exposures (CVE) IDs or a different format, specific to the tool reporting the Finding.\nEnable Engagement Epic Mapping (For Products) In DefectDojo, Engagements represent a collection of work. Each Engagement contains one or more tests, which contain one or more Findings which need to be mitigated. Epics in Jira work in a similar way, and this checkbox allows you to push Engagements to Jira as Epics.\nAn Engagement in DefectDojo - note the three findings listed at the bottom.\n‚Äã How the same Engagement becomes an Epic when pushed to JIRA - the Engagement\u0026rsquo;s Findings are also pushed, and live inside the Engagement as Child Issues. Push All Issues If checked, DefectDojo will automatically push any Active and Verified Findings to Jira as Issues. If left unchecked, all Findings will need to be pushed to Jira manually.\nPush Notes If enabled, Jira comments will populate on the associated Finding in DefectDojo, under Notes on the issue(screenshot), and vice versa; Notes on Findings will be added to the associated Jira Issue as Comments.\nSend SLA Notifications As Comments If enabled, any Issue which breaches DefectDojo‚Äôs Service Level Agreement rules will have comments added to the Jira issue indicating this. These comments will be posted daily until the Issue is resolved.\nService Level Agreements can be configured under Configuration \u0026gt; SLA Configuration in DefectDojo and assigned to each Product.\nSend Risk Acceptance Expiration Notifications As Comment? If enabled, any Issue where the associated DefectDojo Risk Acceptance expires will have a comment added to the Jira issue indicating this. These comments will be posted daily until the Issue is resolved.\nEngagement-Level Jira Settings Different Engagements within a Product can have different underlying Jira settings as a result. By default, Engagements will \u0026lsquo;inherit Jira settings from product\u0026rsquo;, meaning that they will share the same Jira settings as the Product they are nested under.\nHowever, you can change an Engagement\u0026rsquo;s Product Key, Issue Template, Custom Fields, Jira Labels, Default Assignee to be different from the default Product settings\nYou can access this page from the Edit Engagement page: your-instance.defectdojo.com/engagement/[id]/edit.\nThe Edit Engagement page can be found from the Engagement page, by clicking the ‚ò∞ menu next to the engagement\u0026rsquo;s Description.\nStep 3: Configure Bidirectional Sync: Jira Webhook The Jira integration allows for bidirectional sync via webhook. DefectDojo receives Jira notifications at a unique address, which can allow for Jira comments to be received on Findings, or for Findings to be resolved via Jira depending on your configuration.\nLocating your Jira Webhook URL Your Jira Webhook is located on the System Settings form under Jira Integration Settings: Enterprise Settings \u0026gt; System Settings from the sidebar.\nCreating the Jira Webhook Visit **https:// \\\u0026lt;YOUR JIRA URL\\\u0026gt; /plugins/servlet/webhooks** Click \u0026lsquo;Create a Webhook\u0026rsquo;. For the field labeled \u0026lsquo;URL\u0026rsquo; enter: https:// \\\u0026lt;**YOUR DOJO DOMAIN**\\\u0026gt; /jira/webhook/ \\\u0026lt;**YOUR GENERATED WEBHOOK SECRET**\\\u0026gt;. The Web Hook Secret is listed under the Jira Integration Settings as listed above. Under \u0026lsquo;Comments\u0026rsquo; enable \u0026lsquo;Created\u0026rsquo;. Under Issue enable \u0026lsquo;Updated\u0026rsquo;. Make sure your JIRA instance trusts the SSL certificate used by your DefectDojo instance. For JIRA Cloud DefectDojo must use a valid SSL/TLS certificate, signed by a globally trusted certificate authority Note that you do not need to create a Secret within Jira to use this webhook. The Secret is built into DefectDojo\u0026rsquo;s URL, so simply adding the complete URL to the Jira Webhook form is sufficient.\nDefectDojo\u0026rsquo;s Jira Webhook only accepts requests from the Jira API.\nTesting the Webhook Once you have one or more Issues created from DefectDojo Findings, you can test the Webhook by adding a Comment to one of those Findings. The Comment should be received by the Jira webhook as a note.\nIf this doesn‚Äôt work correctly, it could be due to a Firewall issue on your Jira instance blocking the Webhook.\nDefectDojo\u0026rsquo;s Firewall Rules include a checkbox for Jira Cloud, which needs to be enabled before DefectDojo can receive Webhook messages from Jira. Testing the Jira integration Test 1: Do Findings successfully push to Jira? In order to test that the Jira integration is working properly, you can add a new blank Finding to the Product associated with Jira in DefectDojo. Product \u0026gt; Findings \u0026gt; Add New Finding.\nAdd whatever title severity and description you wish, and then click ‚ÄúFinished‚Äù. The Finding should appear as an Issue in Jira with all of the relevant metadata.\nIf Jira Issues are not being created correctly, check your Notifications for error codes.\nConfirm that the Jira User associated with DefectDojo\u0026rsquo;s Jira Configuration has permission to create and update issues on that particular Jira Project. Test 2: Jira Webhooks send to DefectDojo In order to test the Jira webhooks, add a Note to a Finding which also exists in JIRA as an Issue (for example, the test issue in the section above).\nIf the webhooks are configured correctly, you should see the Note in Jira as a Comment on the issue.\nIf this doesn‚Äôt work correctly, it could be due to a Firewall issue on your Jira instance blocking the Webhook.\nDefectDojo\u0026rsquo;s Firewall Rules include a checkbox for Jira Cloud, which needs to be enabled before DefectDojo can receive Webhook messages from Jira. Disconnecting from Jira Jira integrations can be removed from your instance only if no related Issues have been created. If Issues have been created, there is no way to completely remove a Jira Instance from DefectDojo.\nHowever, you can disable your Jira integration by disabling it at the Product level. From the Edit Product form (Classic UI) or from the Jira Product Settings (Beta UI) you can uncheck the \u0026ldquo;Enable Connection With Jira Project\u0026rdquo; option. This will not delete or change any existing Jira tickets created by DefectDojo, but will disable any further updates.\nPushing Findings To Jira Pushing Findings To Jira A Product with a JIRA mapping can push Findings to Jira as Issues. This can be managed in two different ways:\nFindings can be created as Issues manually, per-Finding. Findings can be pushed automatically if the \u0026lsquo;Push All Issues\u0026rsquo; setting is enabled on a Product. (This applies only to Findings that are Active and Verified). Additionally, you have the option to push Finding Groups to Jira instead of individual Findings. This will create a single Issue which contains many related DefectDojo Findings.\nPushing a Finding Manually From a Finding page in DefectDojo, navigate to the JIRA heading. If the Finding does not already exist in JIRA as an Issue, the JIRA header will have a value of \u0026lsquo;None\u0026rsquo;.\n‚Äã\nClicking on the arrow next to the None value will create a new Jira issue. The State the issue is created in will depend on your team\u0026rsquo;s workflow and Jira configuration with DefectDojo. If the Finding does not appear, refresh the page.\n‚Äã Once the Issue is created, DefectDojo will create a link to the issue made up of the Jira key and the Issue ID. This link will also have a red trash can next to it, to allow you to delete the Issue from Jira.\n‚Äã Clicking the Arrow again will push all changes made to an issue to Jira, and update the Jira Issue accordingly. If \u0026lsquo;Push All Issues\u0026rsquo; setting is enabled on the Finding\u0026rsquo;s associated Product, this process will happen automatically.\nJira Comments If a comment is added to a Jira Issue, the same comment will be added to the Finding, under the Notes section. Likewise, if a Note is added to a Finding, the Note will be added to the Jira issue as a comment. Jira Status Changes The Jira Configuration on DefectDojo has entries for two Jira Transitions which will trigger a status change on a Finding.\nWhen the \u0026lsquo;Close\u0026rsquo; Transition is performed on Jira, the associated Finding will also Close, and become marked as Inactive and Mitigated on DefectDojo. DefectDojo will record this change on the Finding page under the Mitigated By heading.\n‚Äã When the \u0026lsquo;Reopen\u0026rsquo; Transition is performed on the Jira Issue, the associated Finding will be set as Active on DefectDojo, and will lose its Mitigated status.\nPush Finding Groups as Jira Issues If you have Finding Groups enabled, you can push a Group of Findings to Jira as a single Issue rather than separate Issues for each Finding.\nThe Jira Issue associated with a Finding Group cannot be interacted with or deleted by DefectDojo, however. It must be deleted directly from the Jira instance.\nAutomatically Create and Push Finding Groups With Auto-Push To Jira Enabled, and a Group By option selected on import:\nAs long as the Finding Groups are being created successfully, the Finding Group is what will automatically push to Jira as an Issue, not the individual Findings.\nCustom Fields in Jira DefectDojo does not currently support passing any Issue-specific information into these Custom Fields - these fields will need to be updated manually in Jira after the issue is created. Each Custom Field will only be created from DefectDojo with a default value.\nJira Cloud now allows you to create a default Custom Field value directly in-app. See Atlassian\u0026rsquo;s documentation on Custom Fields for more information on how to configure this.\nDefectDojo\u0026rsquo;s built-in Jira Issue Types (Bug, Task, Story and Epic) are set up to work \u0026lsquo;out of the box\u0026rsquo;. Data fields in DefectDojo will automatically map to the corresponding fields in Jira. By default, DefectDojo will assign Priority, Labels and a Reporter to any new Issue it creates.\nSome Jira configurations require additional custom fields to be accounted for before an issue can be created. This process will allow you to account for these custom fields in your DefectDojo -\u0026gt; Jira integration, ensuring that issues are created successfully. These custom fields will be added to any API calls sent from DefectDojo to a linked Jira instance.\nIf you don‚Äôt already use Custom Fields in Jira, there is no need to follow this process.\nRecording the names of your Custom Fields in Jira (Jira UI) Determine the Key values for the new Custom Fields (Jira Field Spec Endpoint) Locate the acceptable data for each Custom Field, using the Key values as a reference (Jira Issue Endpoint) Create a Field Reference JSON block to track all of the Custom Field Keys and acceptable data (Jira Issue Endpoint) Store the JSON block in the associated DefectDojo Product, to allow Custom Fields to be created from Jira (DefectDojo UI) Test your work and ensure that all required data is flowing from Jira properly Step 1: Record the names of your Custom Fields in Jira Jira supports a variety of different Context Fields, including Date Pickers, Custom Labels, Radio Buttons. Each of these Context Fields will have a different Key value that can be found in the Jira API.\nWrite down the names of each required Custom Field, as you will need to search through the Jira API to find them in the next step.\nExample of a Custom Field list (your Custom Field names will be different):\nDefectDojo Custom URL Field Another example of a Custom Field \u0026hellip; Step 2: Finding your Jira Custom Field Key Values Start this process by navigating to the Field Spec URL for your entire Jira instance.\nHere is an example of a Field Spec URL:\nhttps://yourcompany-example.atlassian.net/rest/api/2/field\nThe API will return a long string of JSON, which should be formatted into readable text (using a code editor, browser extension or https://jsonformatter.org/).\nThe JSON returned from this URL will contain all of your Jira custom fields, most of which are irrelevant to DefectDojo and have values of ‚ÄúNull‚Äù. Each object in this API response corresponds to a different field in Jira. You will need to search for the objects that have ‚Äúname‚Äù attributes which match the names of each Custom Field you created in the Jira UI, and then note the value of their ‚Äúkey‚Äù attribute.\nOnce you‚Äôve found the matching object in the JSON output, you can determine the ‚Äúkey‚Äù value - in this case, it\u0026rsquo;s customfield_10050.\nJira generates different key values for each Custom Field, but these key values do not change once created. If you create another Custom Field in the future, it will have a new key value.\nExpanding our Custom Field list:\n‚ÄúDefectDojo Custom URL Field‚Äù = customfield_10050 ‚ÄúAnother example of a Custom Field‚Äù = customfield_12345 \u0026hellip; Step 3 - Finding the Custom Fields on a Jira Issue Locate an Issue in Jira that contains the Custom Fields which you recorded in Step 2. Copy the Issue Key for the title (should look similar to ‚ÄúEXAMPLE-123‚Äù) and navigate to the following URL:\nhttps://yourcompany-example.atlassian.net/rest/api/2/issue/EXAMPLE-123\nThis will return another string of JSON.\nAs before, API output will contain lots of customfield_## object parameters with null values - these are custom fields that Jira adds by default, which aren‚Äôt relevant to this issue. It will also contain customfield_## values that match the Custom Field Key values that you found in the previous step. Unlike with the Field Spec output, you won‚Äôt see names identifying any of these custom fields, which is why you needed to record the key values in Step 2.\nExample:\nWe know that customfield_10050 represents the DefectDojo Custom URL Field because we recorded it in Step 2. We can now see that customfield_10050 contains a value of ‚Äúhttps://google.com‚Äù in the EXAMPLE-123 issue.\nStep 4 - Creating a JSON Field Reference from each Jira Custom Field Key You‚Äôll now need to take the value of each of the Custom Fields from your list and store them in a JSON object (to use as a reference). You can ignore any Custom Fields that don‚Äôt correspond to your list.\nThis JSON object will contain all of the default values for new Jira Issues. We recommend using names that are easy for your team to recognize as ‚Äòdefault‚Äô values that need to be changed: ‚Äòchange-me.com‚Äô, ‚ÄòChange this paragraph.‚Äô etc.\nExample:\nFrom step 3, we now know that Jira expects a URL string for \u0026ldquo;customfield_10050‚Äù. We can use this to build our example JSON object.\nSay we had also located a DefectDojo-related short text field, which we identified as \u0026ldquo;customfield_67890‚Äù. We would look at this field in our second API output, look at the associated value, and reference the stored value in our example JSON object as well.\n‚Äã\nYour JSON object will start to look like this as you add more Custom Fields to it.\n{ \u0026#34;customfield_10050\u0026#34;: \u0026#34;https://change-me.com\u0026#34;, \u0026#34;customfield_67890\u0026#34;: \u0026#34;This is the short text custom field.\u0026#34; }\rRepeat this process until all of the DefectDojo-relevant custom fields from Jira have been added to your JSON Field Reference.\nData types \u0026amp; Jira Syntax Some fields, such as Date fields, may relate to multiple custom fields in Jira. If that is the case, you‚Äôll need to add both fields to your JSON Field Reference.\n\u0026#34;customfield_10040\u0026#34;: \u0026#34;1970-01-01\u0026#34;, \u0026#34;customfield_10041\u0026#34;: \u0026#34;1970-01-01T03:30:00.000+0200\u0026#34;,\rOther fields, such as the Label field, may be tracked as a list of strings - please make sure your JSON Field Reference uses a format that matches API output from Jira.\n// a list of custom labels on a Jira object \u0026#34;customfield_10042\u0026#34;: [ \u0026#34;custom-label-one\u0026#34;, \u0026#34;this-is-default\u0026#34;, \u0026#34;change-me-please\u0026#34; ],\rOther custom fields may contain additional, contextual information that should be removed from the Field Reference. For example, the Custom Multichoice Field contains an extra block in the API output, which you‚Äôll need to remove, as this block stores the current value of the field.\nyou should remove the extra object from this field: \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; }, { \u0026#34;self\u0026#34;: \u0026#34;example.url...\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;C\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;example ID\u0026#34; } ]\rinstead, you can shorten this to the following and disregard the second part: \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ] Example Completed Field Reference Here is a complete JSON Field Reference, with in-line comments explaining what each custom field pertains to. This is meant as an all-encompassing example. Your JSON will contain different key values and data points depending on the Custom Values you want to use during issue creation.\n{ \u0026#34;customfield_10050\u0026#34;: \u0026#34;https://change-me.com\u0026#34;, \u0026#34;customfield_10049\u0026#34;: \u0026#34;This is a short text custom field\u0026#34;, // two different fields, but both correspond to the same custom date attribute \u0026#34;customfield_10040\u0026#34;: \u0026#34;1970-01-01\u0026#34;, \u0026#34;customfield_10041\u0026#34;: \u0026#34;1970-01-01T03:30:00.000+0200\u0026#34;, // a list of custom labels on a Jira object \u0026#34;customfield_10042\u0026#34;: [ \u0026#34;custom-label-one\u0026#34;, \u0026#34;this-is-default\u0026#34;, \u0026#34;change-me-please\u0026#34; ], // custom number field \u0026#34;customfield_10043\u0026#34;: 0, // custom paragraph field \u0026#34;customfield_10044\u0026#34;: \u0026#34;This is a very long winded way to say CHANGE ME PLEASE\u0026#34;, // custom radio button field \u0026#34;customfield_10045\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;radio button option\u0026#34; }, // custom multichoice field \u0026#34;customfield_10047\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ], // custom checkbox field \u0026#34;customfield_10039\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;A\u0026#34; } ], // custom select list (singlechoice) field \u0026#34;customfield_10048\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;1\u0026#34; } }\rStep 5 - Adding the Custom Fields to a DefectDojo Product You can now add these custom fields to the associated DefectDojo Product, in the Custom Fields section. Once again,\nNavigate to Edit Product - defectdojo.com/product/ID/edit . Navigate to Custom fields and paste the JSON Field Reference as plain text in the Custom Fields box. Click ‚ÄòSubmit‚Äô. Step 6 - Testing your Jira Custom Fields from a new Finding: Now, when you create a new Finding in the Jira-associated Product, Jira will automatically create all of these Custom Fields in Jira according to the JSON block contained within. These Custom Fields will be created with the default (‚Äúchange-me-please‚Äù, etc.) values.\nWithin the Product on DefectDojo, navigate to the Findings \u0026gt; Add New Finding page. Make sure the Finding is both Active and Verified to ensure that it pushes to Jira, and then confirm on the Jira side that the Custom Fields are successfully created without any inconsistencies.\n","date":"0001-01-01","id":6,"permalink":"/en/share_your_findings/jira_guide/","summary":"DefectDojo\u0026rsquo;s Jira integration can be used to push Finding data to one or more Jira Projects. By doing so, you can integrate DefectDojo into your standard development workflow.","tags":[],"title":"üìã Jira Integration Guide"},{"content":"DefectDojo is designed to ingest bulk reports from tools, creating one or more Findings based on the content of the report. When using DefectDojo, you‚Äôll most likely be ingesting reports from the same tool on a regular basis, which means that duplicate Findings are highly likely.\nThis is where Deduplication comes in, a Smart feature which you can set up to automatically manage duplicate Findings.\nHow DefectDojo handles duplicates First, you import Test 1. Your report contains a vulnerability which is recorded as Finding A. Later, you import Test 2 which contains the same vulnerability. This will be recorded as Finding B, and Finding B will be marked as a duplicate of Finding A. Later still, you import Test 3 which also contains that vulnerability. This will be recorded as Finding C, which will be marked as a duplicate of Finding A. By creating and marking Duplicates in this way, DefectDojo ensures that all the work for the ‚Äòoriginal‚Äô vulnerability is centralized on the original Finding page, without creating separate contexts, or giving your team the impression that there are multiple separate vulnerabilities which need to be addressed.\nBy default, these Tests would need to be nested under the same Product for Deduplication to be applied. If you wish, you can further limit the Deduplication scope to a single Engagement.\nDuplicate Findings are set as Inactive by default. This does not mean the Duplicate Finding itself is Inactive. Rather, this is so that your team only has a single active Finding to work on and remediate, with the implication being that once the original Finding is Mitigated, the Duplicates will also be Mitigated.\nDeduplication vs Reimport Deduplication and Reimport are similar processes but they have a key difference:\nWhen you Reimport to a Test, the Reimport process looks at incoming Findings, filters and discards any matches. Those matches will never be created as Findings or Finding Duplicates. Deduplication is applied \u0026lsquo;passively\u0026rsquo; on Findings that have already been created. It will identify duplicates in scope and label them, but it will not delete or discard the Finding unless \u0026lsquo;Delete Deduplicate Findings\u0026rsquo; is enabled. The \u0026lsquo;reimport\u0026rsquo; action of discarding a Finding always happens before deduplication; DefectDojo cannot deduplicate Findings that are never created as a result of Reimport\u0026rsquo;s filtering. When are duplicates appropriate? Duplicates are useful when you‚Äôre dealing with shared, but discrete Testing contexts. For example, if your Product is uploading Test results for two different repositories, which need to be compared, it‚Äôs useful to know which vulnerabilities are shared across those repositories.\nHowever, if DefectDojo is creating excess duplicates, this can also be a sign that you need to adjust your pipelines or import processes.\nWhat do my duplicates indicate? The same vulnerability, but found in a different context: this is the appropriate way to use Duplicate Findings. If you have many components which are affected by the same vulnerability, you would likely want to know which components are affected to understand the scope of the problem.\n‚Äã The same vulnerability, found in the same context: better options exist for this case. If the Duplicate Finding does not give you any new context on the vulnerability, or if you find yourself frequently ignoring or deleting your duplicate Findings, this is a sign that your process can be improved. For example, Reimport allows you to effectively manage incoming reports from a CI/CD pipeline. Rather than create a completely new Finding object for each duplicate, Reimport will make a note of the incoming duplicate without creating the Duplicate Finding at all. ","date":"0001-01-01","id":7,"permalink":"/en/working_with_findings/finding_deduplication/about_deduplication/","summary":"DefectDojo is designed to ingest bulk reports from tools, creating one or more Findings based on the content of the report.","tags":[],"title":"About Deduplication"},{"content":"\rNGINX The webserver NGINX delivers all static content, e.g. images, JavaScript files or CSS files.\nuWSGI uWSGI is the application server that runs the DefectDojo platform, written in Python/Django, to serve all dynamic content.\nMessage Broker The application server sends tasks to a Message Broker for asynchronous execution. Currently, only Redis is supported as a broker.\nCelery Worker Tasks like deduplication or the JIRA synchronization are performed asynchronously in the background by the Celery Worker.\nCelery Beat In order to identify and notify users about things like upcoming engagements, DefectDojo runs scheduled tasks. These tasks are scheduled and run using Celery Beat.\nInitializer The Initializer setups / maintains the database and syncs / runs migrations after version upgrades. It shuts itself down after all tasks are performed.\nDatabase The Database stores all the application data of DefectDojo. Currently only PostgreSQL is supported.\n","date":"0001-01-01","id":8,"permalink":"/en/open_source/installation/architecture/","summary":"NGINX The webserver NGINX delivers all static content, e.g. images, JavaScript files or CSS files.\nuWSGI uWSGI is the application server that runs the DefectDojo platform, written in Python/Django, to serve all dynamic content.","tags":[],"title":"Architecture"},{"content":"Audit logs for DefectDojo can be accessed in a few different ways.\nIndividual Object Logs DefectDojo objects each have an associated Object History, which can be accessed through the UI. These histories are recorded for Products, Engagements, Tests, Findings and Endpoints, as well as Risk Acceptances. In the Classic (Open-Source) UI, this history is found under the \u0026lsquo;‚ò∞\u0026rsquo; (hamburger) menu on an object. In the Pro UI, this history is found under the blue \u0026lsquo;‚öôÔ∏è\u0026rsquo; (gear) menu for the object in question.\nObject History Endpoint (Pro Only) DefectDojo Pro users have access to a /history API path for these objects to view similar data. For example: /api/v2/findings/{id}/history/.\nAudit Log Endpoint (Pro Only) DefectDojo Pro users also have access to a dedicated /audit_log endpoint for their entire instance. This log can only be accessed by users or API tokens with superuser permissions.\nThis API returns 31 days of audit logs.\nSending default or empty parameters will return the last 31 days of audit logs.\nParameter window_month which will take a month and year in the format MM-YYYY and provide the audit logs for that month.\nYou can set the window_start parameter to limit these logs to a shorter window, rather than returning the entire month.\nFor more information, see the API documentation, located in your instance: your-instance.cloud.defectdojo.com/api/v2/oa3/swagger-ui/\n","date":"0001-01-01","id":9,"permalink":"/en/customize_dojo/user_management/audit_logging/","summary":"Audit logs for DefectDojo can be accessed in a few different ways.\nIndividual Object Logs DefectDojo objects each have an associated Object History, which can be accessed through the UI.","tags":[],"title":"Audit Logs"},{"content":"All commands assume that you\u0026rsquo;re located at the root of the django-DefectDojo cloned repo.\nPre-requisites You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally. Checkout dev and make sure you\u0026rsquo;re up to date with the latest changes. It\u0026rsquo;s advised that you create a dedicated branch for your development, such as git checkout -b parser-name. It is easiest to use the docker compose deployment as it has hot-reload capbility for uWSGI. Set up your environment to use the dev environment:\n$ docker/setEnv.sh dev\nPlease have a look at DOCKER.md for more details.\nDocker images You will want to build your docker images locally, and eventually pass in your local user\u0026rsquo;s uid to be able to write to the image (handy for database migration files). Assuming your user\u0026rsquo;s uid is 1000, then:\n$ docker compose build --build-arg uid=1000 Which files do you need to modify? File Purpose dojo/tools/\u0026lt;parser_dir\u0026gt;/__init__.py Empty file for class initialization dojo/tools/\u0026lt;parser_dir\u0026gt;/parser.py The meat. This is where you write your actual parser. The class name must be the Python module name without underscores plus Parser. Example: When the name of the Python module is dependency_check, the class name shall be DependencyCheckParser unittests/scans/\u0026lt;parser_dir\u0026gt;/{many_vulns,no_vuln,one_vuln}.json Sample files containing meaningful data for unit tests. The minimal set. unittests/tools/test_\u0026lt;parser_name\u0026gt;_parser.py Unit tests of the parser. dojo/settings/settings.dist.py If you want to use a modern hashcode based deduplication algorithm doc/content/en/integrations/parsers/\u0026lt;file/api\u0026gt;/\u0026lt;parser_file\u0026gt;.md Documentation, what kind of file format is required and how it should be obtained Factory contract Parsers are loaded dynamicaly with a factory pattern. To have your parser loaded and works correctly, you need to implement the contract.\nyour parser MUST be in a sub-module of module dojo.tools ex: dojo.tools.my_tool.parser module your parser MUST be a class in this sub-module. ex: dojo.tools.my_tool.parser.MyToolParser The name of this class MUST be the Python module name without underscores and with Parser suffix. ex: dojo.tools.my_tool.parser.MyToolParser This class MUST have an empty constructor or no constructor This class MUST implement 3 methods: def get_scan_types(self) This function return a list of all the scan_type supported by your parser. This identifiers are used internally. Your parser can support more than one scan_type. For example some parsers use different identifier to modify the behavior of the parser (aggregate, filter, etc\u0026hellip;) def get_label_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (short label) def get_description_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (long description) def get_findings(self, file, test) This function return a list of findings If your parser have more than 1 scan_type (for detailled mode) you MUST implement def set_mode(self, mode) method Example:\nclass MyToolParser(object): def get_scan_types(self): return [\u0026#34;My Tool Scan\u0026#34;, \u0026#34;My Tool Scan detailed\u0026#34;] def get_label_for_scan_types(self, scan_type): if scan_type == \u0026#34;My Tool Scan\u0026#34;: return \u0026#34;My Tool XML Scan aggregated by ...\u0026#34; else: return \u0026#34;My Tool XML Scan\u0026#34; def get_description_for_scan_types(self, scan_type): return \u0026#34;Aggregates findings per cwe, title, description, file_path. SonarQube output file can be imported in HTML format. Generate with https://github.com/soprasteria/sonar-report version \u0026gt;= 1.1.0\u0026#34; def requires_file(self, scan_type): return False # mode: # None (default): aggregates vulnerabilites per sink filename (legacy behavior) # \u0026#39;detailed\u0026#39; : No aggregation mode = None def set_mode(self, mode): self.mode = mode def get_findings(self, file, test): \u0026lt;...\u0026gt;\rAPI Parsers DefectDojo has a limited number of API parsers. While we won\u0026rsquo;t remove these connectors, adding API connectors has been problematic and thus we cannot accept new API parsers / connectors from the community at this time for supportability reasonsing. To maintain a high quality API connector, it is necessary to have a license to the tool. To get that license requires partnership with the author or vendor. We\u0026rsquo;re close to announcing a new program to help address this and bring API connectors to DefectDojo.\nTemplate Generator Use the template parser to quickly generate the files required. To get started you will need to install cookiecutter.\n$ pip install cookiecutter Then generate your scanner parser from the root of django-DefectDojo:\n$ cookiecutter https://github.com/DefectDojo/cookiecutter-scanner-parser Read more on the template configuration variables.\nThings to pay attention to Here is a list of considerations that will make the parser robust for both common cases and edge cases.\nDo not parse URLs by hand We use 2 modules to handle endpoints:\nhyperlink dojo.models with a specific class to handle processing around URLs to create endpoints Endpoint. All the existing parser use the same code to parse URL and create endpoints. Using Endpoint.from_uri() is the best way to create endpoints. If you really need to parse an URL, use hyperlink module.\nGood example:\nif \u0026#34;url\u0026#34; in item: endpoint = Endpoint.from_uri(item[\u0026#34;url\u0026#34;]) finding.unsaved_endpoints = [endpoint]\rVery bad example:\nu = urlparse(item[\u0026#34;url\u0026#34;]) endpoint = Endpoint(host=u.host) finding.unsaved_endpoints = [endpoint]\rUse the right libraries to parse information Various file formats are handled through libraries. In order to keep DefectDojo slim and also don\u0026rsquo;t extend the attack surface, keep the number of libraries used minimal and take other parsers as an example.\ndefusedXML in favour of lxml As xml is by default an unsecure format, the information parsed from various xml output has to be parsed in a secure way. Within an evaluation, we determined that defusedXML is the library which we will use in the future to parse xml files in parsers as this library is rated more secure. Thus, we will only accept PRs with the defusedxml library.\nNot all attributes are mandatory Parsers may have many fields, out of which many of them may be optional. It better to not set attribute if you don\u0026rsquo;t have data instead of filling with values like NA, No data etc\u0026hellip;\nCheck class dojo.models.Finding\nData could be missing in the source report Always make sure you include checks to avoid potential KeyError errors (e.g. field does not exist), for those fields you are not absolutely certain will always be in file that will get uploaded. These translate to 500 error, and do not look good.\nGood example:\nif \u0026#34;mykey\u0026#34; in data: finding.cwe = data[\u0026#34;mykey\u0026#34;]\rDo not parse CVSS by hand (vector, score or severity) Data can have CVSS vectors or scores. Don\u0026rsquo;t write your own CVSS score algorithm. For parser, we rely on module cvss.\nIt\u0026rsquo;s easy to use and will make the parser aligned with the rest of the code.\nExample of use:\nfrom cvss.cvss3 import CVSS3 import cvss.parser vectors = cvss.parser.parse_cvss_from_text(\u0026#34;CVSS:3.0/S:C/C:H/I:H/A:N/AV:P/AC:H/PR:H/UI:R/E:H/RL:O/RC:R/CR:H/IR:X/AR:X/MAC:H/MPR:X/MUI:X/MC:L/MA:X\u0026#34;) if len(vectors) \u0026gt; 0 and type(vectors[0]) is CVSS3: print(vectors[0].severities()) # this is the 3 severities cvssv3 = vectors[0].clean_vector() severity = vectors[0].severities()[0] vectors[0].compute_base_score() cvssv3_score = vectors[0].scores()[0] print(severity) print(cvssv3_score)\rGood example:\nvectors = cvss.parser.parse_cvss_from_text(item[\u0026#39;cvss_vect\u0026#39;]) if len(vectors) \u0026gt; 0 and type(vectors[0]) is CVSS3: finding.cvss = vectors[0].clean_vector() finding.severity = vectors[0].severities()[0] # if your tool does generate severity\rBad example (DIY):\ndef get_severity(self, cvss, cvss_version=\u0026#34;2.0\u0026#34;): cvss = float(cvss) cvss_version = float(cvss_version[:1]) # If CVSS Version 3 and above if cvss_version \u0026gt;= 3: if cvss \u0026gt; 0 and cvss \u0026lt; 4: return \u0026#34;Low\u0026#34; elif cvss \u0026gt;= 4 and cvss \u0026lt; 7: return \u0026#34;Medium\u0026#34; elif cvss \u0026gt;= 7 and cvss \u0026lt; 9: return \u0026#34;High\u0026#34; elif cvss \u0026gt;= 9: return \u0026#34;Critical\u0026#34; else: return \u0026#34;Informational\u0026#34; # If CVSS Version prior to 3 else: if cvss \u0026gt; 0 and cvss \u0026lt; 4: return \u0026#34;Low\u0026#34; elif cvss \u0026gt;= 4 and cvss \u0026lt; 7: return \u0026#34;Medium\u0026#34; elif cvss \u0026gt;= 7 and cvss \u0026lt;= 10: return \u0026#34;High\u0026#34; else: return \u0026#34;Informational\u0026#34;\rDeduplication algorithm By default a new parser uses the \u0026rsquo;legacy\u0026rsquo; deduplication algorithm documented at https://documentation.defectdojo.com/usage/features/#deduplication-algorithms\nPlease use a pre-defined deduplication algorithm where applicable.\nUnit tests Each parser must have unit tests, at least to test for 0 vuln, 1 vuln and many vulns. You can take a look at how other parsers have them for starters. The more quality tests, the better.\nIt\u0026rsquo;s important to add checks on attributes of findings. For ex:\nwith self.subTest(i=0): finding = findings[0] self.assertEqual(\u0026#34;test title\u0026#34;, finding.title) self.assertEqual(True, finding.active) self.assertEqual(True, finding.verified) self.assertEqual(False, finding.duplicate) self.assertIn(finding.severity, Finding.SEVERITIES) self.assertEqual(\u0026#34;CVE-2020-36234\u0026#34;, finding.vulnerability_ids[0]) self.assertEqual(261, finding.cwe) self.assertEqual(\u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, finding.cvssv3) self.assertIn(\u0026#34;security\u0026#34;, finding.tags) self.assertIn(\u0026#34;network\u0026#34;, finding.tags) self.assertEqual(\u0026#34;3287f2d0-554f-491b-8516-3c349ead8ee5\u0026#34;, finding.unique_id_from_tool) self.assertEqual(\u0026#34;TEST1\u0026#34;, finding.vuln_id_from_tool)\rUse with to open example files In order to make certain that file handles are closed properly, please use the with pattern to open files. Instead of:\ntestfile = open(\u0026#34;path_to_file.json\u0026#34;) ... testfile.close()\ruse:\nwith open(\u0026#34;path_to_file.json\u0026#34;) as testfile: ...\rThis ensures the file is closed at the end of the with statement, even if an exception occurs somewhere in the block.\nTest database To test your unit tests locally, you first need to grant some rights. Get your MySQL root password from the docker compose logs, login as root and issue the following commands:\nMYSQL\u0026gt; grant all privileges on test_defectdojo.* to defectdojo@\u0026#39;%\u0026#39;; MYSQL\u0026gt; flush privileges; Run your tests This local command will launch the unit test for your new parser\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py test unittests.tools.\u0026lt;your_unittest_py_file\u0026gt;.\u0026lt;main_class_name\u0026gt; -v2\u0026#39; or like this:\n$ ./run-unittest.sh --test-case unittests.tools.\u0026lt;your_unittest_py_file\u0026gt;.\u0026lt;main_class_name\u0026gt; Example for the aqua parser:\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py test unittests.tools.test_aqua_parser.TestAquaParser -v2\u0026#39; or like this:\n$ ./run-unittest.sh --test-case unittests.tools.test_aqua_parser.TestAquaParser If you want to run all unit tests, simply run $ docker-compose exec uwsgi bash -c 'python manage.py test unittests -v2'\nEndpoint validation Some types of parsers create a list of endpoints that are vulnerable (they are stored in finding.unsaved_endpoints). DefectDojo requires storing endpoints in a specific format (which follow RFCs). Endpoints that do not follow this format can be stored but they will be marked as broken (red flag üö©in UI). To be sure your parse store endpoints in the correct format run the .clean() function for all endpoints in unit tests\nfindings = parser.get_findings(testfile, Test()) for finding in findings: for endpoint in finding.unsaved_endpoints: endpoint.clean()\rTests API Parsers Not only parser but also importer should be tested. patch method from unittest.mock is usualy usefull for simulating API responses. It is highly recommeded to use it.\nOther files that could be involved Change to the model In the event where you\u0026rsquo;d have to change the model, e.g. to increase a database column size to accomodate a longer string of data to be saved\nChange what you need in dojo/models.py\nCreate a new migration file in dojo/db_migrations by running and including as part of your PR\n$ docker compose exec uwsgi bash -c \u0026#39;python manage.py makemigrations -v2\u0026#39; Accept a different type of file to upload If you want to be able to accept a new type of file for your parser, take a look at dojo/forms.py around line 436 (at the time of this writing) or locate the 2 places (for import and re-import) where you find the string attrs={\u0026quot;accept\u0026quot;:.\nFormats currently accepted: .xml, .csv, .nessus, .json, .html, .js, .zip.\nA need for more than just the parser.py Of course, nothing prevents you from having more files than the parser.py file. It\u0026rsquo;s python :-)\nPull request examples If you want to take a look at previous parsers that are now part of DefectDojo, take a look at https://github.com/DefectDojo/django-DefectDojo/pulls?q=is%3Apr+sort%3Aupdated-desc+label%3A%22Import+Scans%22+is%3Aclosed\nUpdate the import page documentation Please add a new .md file in [docs/content/en/integrations/parsers] with the details of your new parser. Include the following content headings:\nAcceptable File Type(s) - please include how to generate this type of file from the related tool, as some tools have multiple methods or require specific commands. An example unit test block, if applicable. A link to the relevant unit tests folder so that users can quickly navigate there from Documentation. A link to the scanner itself - (e.g. GitHub or vendor link) Here is an example of a completed Parser documentation page: https://github.com/DefectDojo/django-DefectDojo/blob/master/docs/content/en/connecting_your_tools/parsers/file/acunetix.md\n","date":"0001-01-01","id":10,"permalink":"/en/open_source/contributing/how-to-write-a-parser/","summary":"All commands assume that you\u0026rsquo;re located at the root of the django-DefectDojo cloned repo.\nPre-requisites You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally.","tags":[],"title":"Contribute to Parsers"},{"content":"The Dashboard is likely the first page you\u0026rsquo;ll see when you open DefectDojo. It summarizes your team‚Äôs performance, and provides tracking tools to monitor specific areas of your vulnerability tracking environment.\nDashboard Components Customizable Dashboard Tiles, which you can use to visualize the metrics which are relevant to you. Pre-built Dashboard Charts, which visualize your team‚Äôs overall performance. Each team member shares a single dashboard, but the results of the dashboard are restricted by their role and Product Membership. Team members will only see calculated stats for the Products, Engagements, Findings or other objects that they have access to. For more information, see our guides on User Permissions and Roles.\nDashboard Tiles Tiles are designed to provide relevant information and speed up navigation within DefectDojo.\nTiles can:\nAct as shortcuts for particular sets of Findings, Products, or other objects Visualize metrics related to your Product Provide alerts on particular activity, track SLA Violations, failing imports or new Critical Findings Tiles are pinned to the top section of your üè† Home page.\nTo learn how to add and use dashboard tiles, see our guide.\nDashboard Charts Located beneath Dashboard Tiles, DefectDojo has five pre-built charts:\nHistorical Finding Severity pie-chart Reported Finding Severity histogram, by month Unassigned Answered Engagement Questionnaires table Top 10 Graded Products table Bottom 10 Graded Products table These charts can be added or removed from the dashboard via Dashboard Configuration.\nHistorical Finding Severity This chart organizes all Findings created in DefectDojo by Severity, so that you can see the overall distribution of vulnerability levels in your environment.\nReported Finding Severity This chart allows you to monitor the volume and severity distribution of incoming Findings per month.\nUnassigned Answered Engagement Questionnaires If you have completed Engagement Questionnaires for review, those will be listed in this table.\nTop 10 / Bottom 10 Graded Products This section summarizes the Graded performance of each Product in your instance, counting the Highest and Lowest scoring Products.\nFinding Counts of each severity are calculated by the tile, but note that Product Grade is only assigned based on Active Findings, so there may be Inactive Findings counted in this table which do not contribute to the Grade.\nTo understand how grades are calculated, see our guide to Product Health Grading.\nDashboard Configuration Superusers can choose which Metrics Charts are displayed on the Dashboard. To do this, select the Edit Dashboard Configuration option from the top-right hand gear menu.\nThis will open the Dashboard Configuration Settings window.\nConfiguration Settings Display Graphs determines whether or not the Historical Finding Severity and Reported Finding Severity charts are visible. Display Surveys determines whether or not the Unassigned Answered Engagement Questionnaires table is visible. Display Data Tables determines whether or not the Top 10 / Bottom 10 Graded Products tables are visible. Reset Dashboard Configuration If you would like to reset your Dashboard to a default state, you can do so by selecting Reset Dashboard Configuration from the top-right hand gear menu.\nNote that this will remove any Custom Dashboard Tiles which have been added to your instance.\n","date":"0001-01-01","id":11,"permalink":"/en/customize_dojo/dashboard_notifications/introduction_dashboard/","summary":"The Dashboard is likely the first page you\u0026rsquo;ll see when you open DefectDojo. It summarizes your team‚Äôs performance, and provides tracking tools to monitor specific areas of your vulnerability tracking environment.","tags":[],"title":"DefectDojo Main Dashboard"},{"content":"If you want to add notes or update the language on a Finding to be more relevant to the current situation, you can do so through the Edit Finding form.\nOpen the Edit Finding Form You can update a Finding by opening the ‚öôÔ∏è Gear Menu in the top and clicking Edit Finding.\nThis will open the Edit Finding form, where you can edit the metadata, change the Finding‚Äôs Status and add additional information.\nEdit Finding Form: Fields \u0026ldquo;Test\u0026rdquo; cannot be edited: Findings always have to be associated with a Test object, and cannot be moved out of that context. However, the Engagement containing a Test can be moved to another Product.\n‚Äã Found By is the scan tool which discovered this Finding. Note that you can add additional scan tools beyond the tool associated with the Test.\n‚Äã Title is created from the scan report, but you can edit this title to be more meaningful if you need to. Note that this may affect Deduplication, as Deduplication generally uses the titles of Findings to identify duplicates.\n‚Äã Date is meant to represent the date the Finding was uncovered by the scanner - not necessarily the date the Finding was imported into DefectDojo. This date is pulled from the scan report, but you can update this date to be more accurate if you need to (for example, if working with historical data, or if using a scanning tool which does not log discovery dates).\n‚Äã Description is the description of a Finding provided by the scan tool. You can add or remove information from the Finding Description if you wish.\n‚Äã Severity is calculated based on several factors. At a base level, this will be the Severity reported by a tool, but a Finding‚Äôs Severity can be affected by EPSS changes. You can also manually adjust the Finding‚Äôs Severity to an appropriate level.\n‚Äã Tags are generic text labels that you can use to organize your Findings via Filters - or they can simply be used as shorthand to identify a specific Finding.\n‚Äã Active / Verified are the primary Finding statuses used by a tool. Active Findings are Findings that are currently active in your network and have been reported by a tool. Verified means that this Finding has been confirmed to exist by a team member.\n‚Äã SAST / DAST are labels used to organize your Findings into the context they were discovered in. Generally, this label is populated based on the scanning tool used, but you can adjust this to a more accurate level (for example, if the Finding was found by both a SAST and a DAST tool). Bulk Edit Findings Findings can be edited in bulk from a Finding List, which can be found either on the Findings page itself, or from within a Test.\nSelecting Findings for Bulk Edit When looking at a table with multiple Findings, such as the ‚ÄòFindings From [tool]‚Äô table on a Test Page or the All Findings list, you can use the checkboxes next to Findings to mark them for Bulk Edit.\nSelecting one or more Findings in this way will open the (hidden) Bulk Edit menu, which contains the following four options:\nBulk Update Actions: apply metadata changes to the selected Findings. Risk Acceptance Actions: create a Full Risk Acceptance to govern the selected Findings, or add the Findings to an existing Full Risk Acceptance Finding Group Actions: create a Finding Group made up of the selected Findings. Note that Finding Groups can only be created within an individual Test. Delete: delete the selected Findings. You will need to confirm this action in a new window. Bulk Update Actions Through the Bulk Update Actions menu, you can apply the following changes to any Findings you have selected:\nUpdate the Severity Apply a new Finding Status Change the Discovery or Planned Remediation Date of the Findings Add a Simple Risk Acceptance, if the option is enabled at the Product level Apply Tags or Notes to all of the selected Findings. Risk Acceptance Actions This page allows you to add a Full Risk Acceptance to the selected Findings. You can either create a new Full Risk Acceptance or add the Findings to one that already exists.\nFinding Group Actions This page allows you to create a new Finding Group from the Selected Findings, or add them to an existing Finding Group.\nHowever, Finding Groups can only be created within an individual Test - Findings from different Tests, Engagements or Products cannot be added to the same Finding Group.\nBulk Delete Findings You can also Delete selected Findings by clicking on the red Delete button. A popup window will appear asking you to confirm this decision.\n","date":"0001-01-01","id":12,"permalink":"/en/working_with_findings/findings_workflows/editing_findings/","summary":"If you want to add notes or update the language on a Finding to be more relevant to the current situation, you can do so through the Edit Finding form.","tags":[],"title":"Editing Findings"},{"content":"Additional Finding filters are available in DefectDojo Pro to more easily triage, filter and prioritize Findings.\nPriority sorts Findings based on the context and importance of the Product they are stored in. Risk considers the Product\u0026rsquo;s context, with a greater emphasis on the exploitability of a Finding. Finding Priority In DefectDojo Pro, Priority is a calculated field on Findings that can be used to sort or filter Findings according to Product-level metadata:\nProduct\u0026rsquo;s Business Criticality Whether the Product has an External Audience Whether the Product is Internet Accessible The Product\u0026rsquo;s estimated revenue or user records count DefectDojo Pro\u0026rsquo;s Finding Priority assigns a numerical rank to each Finding according to this metadata, to provide users with a stronger context on triage and remediation.\nThe range of Priority values is from 0 to 1150. The higher the number, the more urgency the Finding is to triage or remediate.\nPriority numbers can be used with other filters to compare Findings in any context, such as:\nwithin a single Product, Engagement or Test globally in all DefectDojo Products between a few specific Products How Priority is calculated Every Active finding will have a Priority calculated. Inactive or Duplicate Findings will not.\nPriority is set based on the following factors:\nProduct-Level The assigned Criticality for the Product (if defined) The estimated User Records for the Product (if defined) The estimated Revenue for the Product (if defined) If the Product has External Audience defined If the Product has Internet Accessible defined. All of these metadata fields can be set on the Edit Product form for a given Product.\nFinding-Level Whether or not the Finding has an EPSS score, this is automatically kept up to date for Pro customers How many Endpoints in the Product are affected by this Finding Whether or not a Finding is Under Review If no relevant metadata at the Finding or Product level is set, the Priority level will follow the Severity for a given Finding.\nCritical = 90 High = 70 Medium = 50 Low = 30 Info = 10 Currently, Priority calculation and the underlying formula cannot be adjusted. These numbers are meant as a reference only - your team\u0026rsquo;s actual priority for remediation may vary from the DefectDojo calculation.\nFinding Risk The Risk column on a Findings table is another way to quickly prioritize Findings. Risk is calculated using a Finding\u0026rsquo;s Priority level, but also factors in a Finding\u0026rsquo;s exploitability to a greater degree. This is meant as a less granular, more \u0026rsquo;executive-level\u0026rsquo; version of Priority.\nThe four assignable Risk levels are:\nA Finding\u0026rsquo;s EPSS / exploitability is much more emphasized in the Risk calculation. As a result, a Finding can have both a high priority and a low risk value.\nAs with Finding Priority, the Risk calculation cannot currently be adjusted.\n","date":"0001-01-01","id":13,"permalink":"/en/working_with_findings/finding_priority/","summary":"Additional Finding filters are available in DefectDojo Pro to more easily triage, filter and prioritize Findings.\nPriority sorts Findings based on the context and importance of the Product they are stored in.","tags":[],"title":"Finding Priority Enhancement (Pro)"},{"content":"One of the things we understand at DefectDojo is that every company‚Äôs security needs are completely different. There is no ‚Äòone-size-fits-all‚Äô approach. As your organization changes, having a flexible approach is key.\nDefectDojo allows you to connect your security tools in a flexible way to match those changes.\nScan Upload Methods When DefectDojo receives a vulnerability report from a security tool, it will create Findings based on the vulnerabilities contained within that report. DefectDojo acts as the central repository for these Findings where they can be triaged, remediated or otherwise addressed by you and your team.\nThere are two main ways that DefectDojo can upload Finding reports.\nVia direct import through the UI: Import Scan Form Via API endpoint (allowing for automated data ingest): See API Docs DefectDojo Pro Methods DefectDojo Pro users have an additional three methods to handle reports and data:\nVia Universal Importer or DefectDojo CLI, command line tools which leverage the DefectDojo API: See External Tools Via Connectors for certain tools, an ‚Äòout of the box‚Äô data integration: See Connectors Guide Via Smart Upload for certain tools, an importer designed to handle infrastructure scans: See Smart Upload Guide Comparing Upload Methods UI Import API Connectors (Pro) Smart Upload (Pro) Supported Scan Types All: see Supported Tools All: see Supported Tools Snyk, Semgrep, Burp Suite, AWS Security Hub, Probely, Checkmarx, Tenable Nexpose, NMap, OpenVas, Qualys, Tenable Automation? Available via API: /reimport /import endpoints Triggered from CLI Importer or external code Connectors is inherently automated Available via API: /smart_upload_import endpoint Product Hierarchy and organization Each of these methods can create Product Hierarchy on the spot. Product Hierarchy refers to DefectDojo‚Äôs Product Types, Products, Engagements or Tests: objects in DefectDojo which help organize your data into relevant context.\nVulnerability data can be imported into an existing Product Hierarchy. Product Types, Products, Engagements and Tests can all be created in advance, and then data can be imported to that location in DefectDojo. The contextual Product Hierarchy can be created at the time of import. When importing a report, you can create a new Product Type, Product, Engagement and/or Test. This is handled by DefectDojo through the ‚Äòauto-create context‚Äô option. Using Import Methods (Pro UI) In DefectDojo Pro, all of these methods can be accessed from the Import section of the sidebar.\nThe Pro UI allows you to create Product Types, Products and Engagements directly from the Import Scan form, so these objects are not required.\nUsing Import Methods (Classic UI / Open Souce) In DefectDojo OS, you can access the Import Scan Form from two locations:\nThe Tests section of an Engagement: The Findings section of the navigation bar on a Product: DefectDojo OS requires you to set up one or more Products / Product Types before you can import data through the UI. See our article on Product Hierarchy for more information.\n","date":"0001-01-01","id":14,"permalink":"/en/connecting_your_tools/import_intro/","summary":"One of the things we understand at DefectDojo is that every company‚Äôs security needs are completely different. There is no ‚Äòone-size-fits-all‚Äô approach.","tags":[],"title":"Import Method Comparison"},{"content":"If you have a brand new DefectDojo instance, the Import Scan Form is a logical first step to learn the software and set up your environment. From this form, you upload a scan file from a supported tool, which will create Findings to represent those vulnerabilities. While filling out the form, you can decide whether to:\nStore these Findings under an existing Product Type / Product / Engagement or Create a new Product Type / Product / Engagement to store these Findings It‚Äôs easy to reorganize your Product Hierarchy in DefectDojo, so it‚Äôs ok if you‚Äôre not sure how to set things up yet.\nFor now, it‚Äôs good to know that Engagements can store data from multiple tools, which can be useful if you‚Äôre running different tools concurrently as part of a single testing effort.\nAccessing the Import Scan Form (Pro UI) The Import Scan form can be accessed from multiple locations:\nVia the Import \u0026gt; Add Findings menu option on the sidebar From a Product‚Äôs ‚Äò‚ãÆ‚Äô (horizontal dots) Menu, from a Products Table From the ‚öôÔ∏èGear Menu on a Product Page Accessing the Import Scan Form (Classic UI / Open Source) In DefectDojo OS, you can access this form from two locations:\nThe Tests section of an Engagement: The Findings section of the navigation bar on a Product: Completing the Import Scan Form The Import Scan form will create a new Test nested under an Engagement, which will contain a unique Finding for each vulnerability contained within your scan file.\nThe Test will be created with a name that matches the Scan Type: e.g. a Tenable scan will be titled ‚ÄòTenable Scan‚Äô.\nForm Options Scan File: by clicking on the Choose button, you can select a file from your computer to upload. Scan Date (optional): if you want to select a single Scan Date to be applied to all Findings that result from this import, you can select the date in this field.\nIf you do not select a Scan Date, Findings created from this report will use the date specified by the tool. SLAs for each Finding will be calculated based on their date. Scan Type: select the tool used to create this data. Product Type / Product / Engagement Name: select the Product Type, Product, and Engagement Name which you want to create a new Test under. You can also create a new Product Type, Product and/or Engagement at this time if you wish to, by entering the names of the objects that you want to create. Environment: select an Environment that corresponds to the data you‚Äôre uploading. Tags: if you want to use tags to further organize your Test data, you can add Tags using this form. Type in the name of the tag you want to create, and press Enter on your keyboard to add it to the list of tags. Process Findings Asynchronously: this field is enabled by default, but it can be disabled if you wish. See explanation below. Process Findings Asynchronously (Pro) When this field is enabled, DefectDojo will use a background process to populate your Test file with Findings. This allows you to continue working with DefectDojo while Findings are being created from your scan file.\nWhen this field is disabled, DefectDojo will wait until all Findings have been successfully created before you can proceed to the next screen. This could take significant time depending on the size of your file.\nThis option is especially relevant when using the API to import data. If uploading data with Process Findings Asynchronously turned off, DefectDojo will not return a successful response until all Findings have been created successfully,\nOptional Fields Minimum Severity: If you only want to create Findings for a particular Severity level and above, you can select the minimum Severity level here. All vulnerabilities with lower severity than this field will be ignored. Active: if you want to set all of the incoming Findings to either Active or Inactive, you can specify that here. Otherwise, DefectDojo will use the tool‚Äôs vulnerability data to determine whether the Finding is Active or Inactive. This option is relevant if you need your team to manually triage and verify Findings from a particular tool. Verified: as with Active you can set the new set of Findings to either Verified or Unverified by default. This depends on your workflow preferences. For example, if your team prefers to assume Findings are verified unless proven otherwise, you can set this field to True. Version, Branch Tag, Commit Hash, Build ID, Service can all be specified if you want to include these details in the Test. Source Code Management URI can also be specified. This form option must be a valid URI. Group By: if you want to create Finding Groups out of this File, you can specify the grouping method here. Next Steps Once your upload has completed, you should be redirected to the Test Page which contains the Findings found in the scan file. You can start working with those results right away, but feel free to consult the following articles:\nLearn how to organize your Product Hierarchy to manage different contexts for your Findings and Tests: Product Hierarchy Overview. Learn how to extend a Test with additional Findings and reports: Reimport Guide ","date":"0001-01-01","id":15,"permalink":"/en/connecting_your_tools/import_scan_files/import_scan_ui/","summary":"If you have a brand new DefectDojo instance, the Import Scan Form is a logical first step to learn the software and set up your environment.","tags":[],"title":"Import Scan Form"},{"content":"Findings are the main way that DefectDojo standardizes and guides the reporting and remediation process of your security tools. Regardless of whether a vulnerability was reported in SonarQube, Acunetix, or your team‚Äôs custom tool, Findings give you the ability to manage each vulnerability in the same way.\nWhat are Findings? Findings in DefectDojo are made up of the following components:\nThe reported vulnerability data in question The ‚Äòstatus‚Äô of the Finding, used to track remediation, risk acceptance or other decisions made around the vulnerability Other metadata related to the Finding. For example, this could include the location of a Finding in your network, a tool‚Äôs suggestions for remediation, or links to an associated CWE or EPSS score. In addition to storing the vulnerability data and providing a remediation framework, DefectDojo also enhances your Findings in the following ways:\nAutomatically adding related EPSS scores to a Finding to describe exploitability Automatically translating a security tool‚Äôs severity metric into a Severity score for each Finding, which confers an SLA onto the Finding according to your Product‚Äôs SLA Configuration. Overall, DefectDojo Findings are designed to work with the Product Hierarchy to standardize your efforts, and apply a consistent method to each Product.\nA Finding Page The Finding Page contains various components. Each will be populated by the Import process when the Finding is created.\nThe Title of the Finding: Usually this is a descriptive shorthand which identifies the vulnerability or issue detected. This section is also where user-created Tags are displayed if they exist.\n‚Äã\nFinding Overview: This section contains five separate pages of relevant information for the Finding: Description, Mitigation, Impact, References and Notes. These fields can be populated automatically based on the incoming vulnerability data, or they can be edited by a DefectDojo user to provide additional context.\n‚Äã\n‚Äã**- Description** is a more detailed summary and explanation of the Finding in question.\n‚Äã**- Mitigation** is a suggested method for mitigating the Finding so that it is no longer present in your system.\n‚Äã**- Impact** describes the impact of the vulnerability on your security posture. This page might hold descriptive text, or it may include a CVSS Vector String, which is a shorthand way to communicate the vulnerability‚Äôs overall exploitability and with the consequences of an exploitation to your organization. Impact is closely related to a Finding‚Äôs Severity field.\n‚Äã**- References** will list any links or additional information relevant to this Finding if included.\n‚Äã**- Notes** is a page where you can record any other relevant information to this Finding. Notes are ‚ÄòDefectDojo-only‚Äô metadata, and they are not created at the time of import. Use this field to track your mitigation progress or to add more specific detail to the Finding.\n‚Äã\nAdditional Details: This section lists other details related to this Finding, if relevant:\nRequest/Response Pairs associated with the vulnerability Steps To Reproduce the vulnerability Severity Justification where you can record a more detailed explanation of the severity or impact of the Finding.\n‚Äã\n‚Äã Metadata: This section contains filterable metadata related to the Finding:\nID: the ID value of the Finding in DefectDojo Severity: the Severity value of the Finding. Can be Info, Low, Medium, High or Critical. Finding Severities are directly related to the Finding‚Äôs calculated SLA, based on the Product the Finding is stored in. Status: the status of the Finding. Can be either Active or Inactive. In addition to these, Findings can also have a Status of Duplicate, Mitigated, False Positive, Out Of Scope, Risk Accepted or Under Defect Review. These Statuses explain the State of the Finding in more detail. Type: this field describes how the Finding was found, either via a Static (SAST) evaluation of the source code, or through a Dynamic (DAST) evaluation of the Product as it was running. This field is defined by the tool type. Location: this field describes the related File Path to your vulnerability, if relevant. Line: this field describes the line of code containing the vulnerability, if relevant. Date Discovered: this field shows either the date the Finding was imported to DefectDojo, or the date the Finding was discovered by the Tool. Age: this calculated field shows the number of days the Finding has been active. Reporter: this is the username of the DefectDojo account who created this Finding. CWE: this field is a link to the external CWE (Common Weakness Enumeration) definition which applies to this Finding. Vulnerability ID: if there is a particular ID value for this vulnerability within the tool itself, it will be tracked here. EPSS Score / Percentile: if the source data has a CWE value, DefectDojo will automatically pull an EPSS Score and Percentile (Exploit Prediction Scoring System). EPSS represents the likelihood that a software vulnerability can be exploited, based on real-world exploit data. EPSS scores are updated on an ongoing basis, using the latest exploitation data from First. Found By: This will list the scanner used to find this vulnerability.\n‚Äã Example Finding Workflows How you work with Findings in DefectDojo depends on your team‚Äôs responsibilities within your organization. Here are some examples of these processes, and how DefectDojo can help:\nDiscover and Report vulnerabilities If you‚Äôre in charge of security reporting for many different contexts, software Products or teams, DefectDojo can report on those vulnerabilities uncovered. Using the Product Hierarchy, you can organize your Finding data into the appropriate context. For example:\nEach Product in DefectDojo can have a different SLA configuration, so that you can instantly flag Findings that are discovered in Production or other highly sensitive environments. You can create a report directly from a Product Type, Product, Engagement or Test to ‚Äòzoom in and out‚Äô of your security context. Tests contain results from a single tool, Engagements can combine multiple Tests, Products can contain multiple Engagements, Product Types can contain multiple Products. For more information on creating a Report, see our guides to Custom Reporting.\nTriage Vulnerabilities using Finding Status If your team needs to validate the Findings discovered, you can do so by manually applying the Verified status to Findings as you review them. You can also apply other statuses, such as:\nFalse Positive: A tool detected the threat, but the threat is not active in the environment. Out Of Scope: Active, but irrelevant to the current testing effort. Risk Accepted: Active, but determined not to be a priority to address until the Risk Acceptance expires. Under Review: may or may not be Active - your team is still investigating. Mitigated: This issue has been resolved since the Finding was created. If a tool reports a previously triaged Finding on a subsequent import, DefectDojo will remember the Finding‚Äôs previous status and update accordingly. Findings with False Positive, Out Of Scope, Risk Accepted and Under Review statuses will remain as they are, but any Finding that has been Mitigated will be reactivated to let you know that the Finding has returned to the Test environment.\nEnsure Team-wide Consensus and Accountability with Risk Acceptances Part of a security team‚Äôs responsibility is to collaborate with developers to prioritize and deprioritize security issue remediation. This is where Risk Acceptances come in. Adding a Risk Acceptance to a Finding allows you to:\nStore records and ‚Äòartifact‚Äô files on DefectDojo - these could be emails from colleagues acknowledging the Risk Acceptance, meeting notes, or simply a written justification for accepting the risk from your own security team. Add an expiration date to the Risk Acceptance, so that the vulnerability can be re-examined after a given period of time. Any Appsec team member understands that issue mitigation can‚Äôt be prioritized exclusively by developer teams, so Risk Acceptances help you log those sensitive decisions when they are made.\nMonitor current vulnerabilities using CVEs and EPSS scores (Pro Feature) Sometimes, the exploitability and threat posed by a known vulnerability can change based on new data. To keep your work up to date, DefectDojo Pro has partnered with First.org to maintain a database of the latest EPSS scores related to Findings. Any Findings in DefectDojo Pro will be kept up to date automatically according to their EPSS, which is directly based on the CVE of the Finding.\nIf a Finding‚Äôs EPSS score changes (i.e. the related Finding becomes more exploitable or less exploitable), the Severity of the Finding will adjust accordingly.\nNext Steps: Learn how to add or adjust data on your Findings: Editing Findings. Learn how to apply Risk Acceptances to Findings which create a record of sensitive decisions made surrounding risk-accepted vulnerabilities. ","date":"0001-01-01","id":16,"permalink":"/en/working_with_findings/intro_to_findings/","summary":"Findings are the main way that DefectDojo standardizes and guides the reporting and remediation process of your security tools. Regardless of whether a vulnerability was reported in SonarQube, Acunetix, or your team‚Äôs custom tool, Findings give you the ability to manage each vulnerability in the same way.","tags":[],"title":"Introduction to Findings"},{"content":"Webhooks are HTTP requests coming from the DefectDojo instance towards a user-defined webserver which expects this kind of incoming traffic.\nTransition graph: It is not unusual that in some cases a webhook can not be delivered. It is usually connected to network issues, server misconfiguration, or running upgrades on the server. DefectDojo needs to react to these outages. It might temporarily or permanently disable related endpoints. The following graph shows how it might change the status of the webhook definition based on HTTP responses (or manual user interaction).\nNotes:\nTransitions: bold: manual changes by user dotted: automated by celery others: based on responses on webhooks Nodes: Stadium-shaped: Active - following webhook can be sent Rectangles: Inactive - performing of webhook will fail (and not retried) Hexagonal: Initial and final states Rhombus: All states (meta node to make the graph more readable) Body and Headers The body of each request is JSON which contains data about related events like names and IDs of affected elements. Examples of bodies are on pages related to each event (see below).\nEach request contains the following headers. They might be useful for better handling of events by the server receiving them.\nUser-Agent: DefectDojo-\u0026lt;version of DD\u0026gt; X-DefectDojo-Event: \u0026lt;name of the event\u0026gt; X-DefectDojo-Instance: \u0026lt;Base URL for DD instance\u0026gt;\rDisclaimer This functionality is new and in experimental mode. This means functionality might generate breaking changes in following DefectDojo releases and might not be considered final.\nHowever, the community is open to feedback to make this functionality better and get it stable as soon as possible.\nRoadmap There are a couple of known issues that are expected to be resolved as soon as core functionality is considered ready.\nSupport events - Not only adding products, product types, engagements, tests, or upload of new scans but also events around SLA User webhook - right now only admins can define webhooks; in the future, users will also be able to define their own Improvement in UI - add filtering and pagination of webhook endpoints Events product_type_added product_added engagement_added test_added scan_added and scan_added_empty ping ","date":"0001-01-01","id":17,"permalink":"/en/open_source/notification_webhooks/how_to/","summary":"Webhooks are HTTP requests coming from the DefectDojo instance towards a user-defined webserver which expects this kind of incoming traffic.","tags":[],"title":"Notification Webhooks Setup"},{"content":"","date":"0001-01-01","id":18,"permalink":"/en/open_source/installation/","summary":"","tags":[],"title":"Open-Source Installation \u0026 Configuration"},{"content":"This template is designed to document a new or existing parser. Please feel free to improve with any additional information that might help your fellow security professionals.\nCopy this .md file and add it to /docs/content/en/connecting_your_tools/parsers/file in the GitHub repository. Update the title to match the name of your new or existing parser. Fill out all sections listed below. Please remove any instructions or examples found within each section or examples. File Types Specify all file types accepted by your parser (e.g., CSV, JSON, XML). Include instructions on how to create or export the acceptable file format from the related security tool.\nTotal Fields in [File Format] Total data fields: Total number of fields contained in the security tool\u0026rsquo;s export file. Total data fields parsed: Total number of fields parsed into DefectDojo finding. Total data fields NOT parsed: Total number of fields NOT parsed into DefectDojo finding.\nUsing the format below, provide a brief description of each field and how it maps to DefectDojo\u0026rsquo;s data model. Include all fields found in the security tool\u0026rsquo;s export tile, in order of appearance, and noting any fields that are not parsed.\nFields in order of appearance:\nField 1 - Description of how this field is mapped (e.g., maps to finding title, endpoint host.) Field 2 - Description of how this field is mapped / not mapped. Field 3 - Description of how this field is mapped / not mapped. Field 4 - Description of how this field is mapped / not mapped. (continue for every field in the file.) Field Mapping Details For each finding created, include details of how the parser parses specific data. For example:\nHow endpoints are created (e.g., combining IP, Domain, Port, and Protocol fields). How occurrences are handled (e.g., default nb_occurences set to 1, incremented for duplicates). How deduplication is handled (e.g., using a hash of severity + title + description). Describes the default severity if no mapping is matched. Sample Scan Data or Unit Tests Add a link to the unit tests or sample scan data folder in the GitHub repository. For example:\nSample Scan Data Folder Link To Tool Provide a link to the scanner or tool itself (e.g., GitHub repository, vendor website, or documentation). For example:\nTool Name ","date":"0001-01-01","id":19,"permalink":"/en/open_source/contributing/parser-documentation-template/","summary":"This template is designed to document a new or existing parser. Please feel free to improve with any additional information that might help your fellow security professionals.","tags":[],"title":"Parser Documentation Template"},{"content":"DefectDojo uses five main data classes to organize your work: Product Types, Products, Engagements, Tests, and Findings.\nDefectDojo is made to be flexible to conform to your team, rather than making your team conform to the tool. You\u0026rsquo;ll be able to design a robust, adaptable workspace once you understand how these data classes can be used to organize your work.\nProduct Hierarchy Diagram Product Types The first category of data you\u0026rsquo;ll need to set up in DefectDojo is a Product Type. Product Types are intended to categorize Products in a specific way. This could be:\nby business domain by development team by security team Product Types can have Role-Based Access Control rules applied, which limit team members\u0026rsquo; ability to view and interact with their data (including any underlying Products with Engagement, Test and Finding data). For more information on user roles, see our Introduction To Roles article.\nWhat can a Product Type represent? If a particular software project has many distinct deployments or versions, it may be worth creating a single Product Type which covers the scope of the entire project, and having each version exist as individual Products.\n‚Äã You also might consider using Product Types to represent stages in your software development process: one Product Type for \u0026lsquo;In Development\u0026rsquo;, one Product Type for \u0026lsquo;In Production\u0026rsquo;, etc.\n‚Äã Ultimately, it\u0026rsquo;s your decision how you wish to organize your Products, and what you Product Type to represent. Your DefectDojo hierarchy may need to change to fit your security teams\u0026rsquo; needs. Products A Product in DefectDojo is intended to represent any project, program, or product that you are currently testing. The Product hosts all of the security work and testing history related to the underlying goal.\na unique Name a Description a product Type an assigned SLA Configuration Products can be as broad or as specific in scope as you wish. By default, Products are completely separate objects in the hierarchy, but they can be grouped together by Product Type.\nProducts are \u0026lsquo;walled-off\u0026rsquo; and do not interact with other Products. DefectDojo\u0026rsquo;s Smart Features, such as Deduplication, only apply within the context of a single Product.\nLike Product Types, Products can have Role-Based Access Control rules applied, which limit team members\u0026rsquo; ability to view and interact with them (as well as any underlying Engagement, Test and Finding data). For more information on user roles, see our Introduction To Roles article.\nWhat can a Product represent? DefectDojo\u0026rsquo;s concept of a \u0026lsquo;Product\u0026rsquo; will not necessarily correspond 1:1 to what your organization would refer to as a \u0026lsquo;Product\u0026rsquo;. Software development is complex, and security needs can vary greatly even within the scope of a single piece of software.\nThe following scenarios are good reasons to consider creating a separate DefectDojo Product:\n\u0026ldquo;ExampleProduct\u0026rdquo; has a Windows version, a Mac version, and a Cloud version \u0026ldquo;ExampleProduct 1.0\u0026rdquo; uses completely different software components from \u0026ldquo;ExampleProduct 2.0\u0026rdquo;, and both versions are actively supported by your company. The team assigned to work on \u0026ldquo;ExampleProduct version A\u0026rdquo; is different than the product team assigned to work on \u0026ldquo;ExampleProduct version B\u0026rdquo;, and needs to have different security permissions assigned as a result. These variations within a single Product can also be handled at the Engagement level. Note that Engagements don\u0026rsquo;t have access control in the way Products and Product Types do.\nEngagements Once a Product is set up, you can begin creating and scheduling Engagements. Engagements are meant to represent moments in time when testing is taking place, and contain one or more Tests.\nEngagements always have:\na unique Name target Start and End dates Status (Not Started, In Progress, Cancelled, Completed\u0026hellip;) an assigned Testing Lead an associated Product There are two types of Engagement: Interactive and CI/CD.\nAn Interactive Engagement is typically run by an engineer. Interactive Engagements are focused on testing the application while the app is running, using an automated test, human tester, or any activity ‚Äúinteracting‚Äù with the application functionality. See OWASP\u0026rsquo;s definition of IAST. A CI/CD Engagement is for automated integration with a CI/CD pipeline. CI/CD Engagements are meant to import data as an automated action, triggered by a step in the release process. Engagements can be tracked using DefectDojo\u0026rsquo;s Calendar view.\nWhat can an Engagement represent? Engagements are meant to represent groups of related testing efforts. How you wish to group your testing efforts depends on your approach.\nIf you have a planned testing effort scheduled, an Engagement offers you a place to store all of the related results. Here\u0026rsquo;s an example of this kind of Engagement:\nEngagement: ExampleSoftware 1.5.2 - Interactive Testing Effort In this example, a security team runs multiple tests on the same day as part of a software release.\nTest: Nessus Scan Results (March 12) Test: NPM Scan Audit Results (March 12) Test: Snyk Scan Results (March 12)\n‚Äã You can also organize CI/CD Test results within an Engagement. These kinds of Engagements are \u0026lsquo;Open-Ended\u0026rsquo; meaning that they don\u0026rsquo;t have a date, and will instead add additional data each time the associated CI/CD actions are run. Engagement: ExampleSoftware CI/CD Testing In this example, multiple CI/CD scans are automatically imported as Tests every time a new software release is created.\nTest: 1.5.2 Scan Results (March 12) Test: 1.5.1 Scan Results (March 3) Test: 1.5.0 Scan Results (February 14) Engagements can be organized however works best for your team. All Engagements nested under a Product can be viewed by the team assigned to work on the Product.\nTests Tests are a grouping of activities conducted by engineers to attempt to discover flaws in a product.\nTests always have:\na unique Test Title a specific **Test Type (**API Test, Nessus Scan, etc) an associated test Environment an associated Engagement Tests can be created in different ways. Scan data can be directly imported to an Engagement, which will then create a new Test containing that data. Tests can also be created in advance without scan data, as part of planning future Engagements.\nHow do Tests interact with each other? Tests take your testing data and group it into Findings. Generally, security teams will be running the same testing effort repeatedly, and Tests in DefectDojo allow you to handle this process in an elegant way.\nPreviously imported tests can be reimported - If you\u0026rsquo;re running the same type of test within the same Engagement context, you can Reimport the test results after each completed scan. DefectDojo will compare the Reimported data to the existing result, and will not create new Findings if duplicates exist in the scan data.\nTests can be imported separately - If you run the same test on a Product within separate Engagements, DefectDojo will still compare the data with previous Tests to find duplicate Findings. This allows you to keep track of previously mitigated or risk-accepted Findings.\nIf a Test is added directly to a Product without an Engagement, a generic Engagement will be created automatically to contain the Test. This allows for ad-hoc data imports.\nExamples of Tests:\nBurp Scan from Oct. 29, 2015 to Oct. 29, 2015 Nessus Scan from Oct. 31, 2015 to Oct. 31, 2015 API Test from Oct. 15, 2015 to Oct. 20, 2015 Findings Once data has been added uploaded to a Test, the results of that data will be listed in the Test as individual Findings for review.\nA finding represents a specific flaw discovered while testing.\nFindings always have:\na unique Finding Name the Date they were uncovered multiple associated Statuses, such as Active, Verified or False Positive an associated Test a Severity level: Critical, High, Medium, Low, and Informational (Info). Findings can be added through a data import, but they can also be added manually to a Test.\nExamples of Findings:\nOpenSSL ‚ÄòChangeCipherSpec‚Äô MiTM Potential Vulnerability Web Application Potentially Vulnerable to Clickjacking Web Browser XSS Protection Not Enabled Endpoints Scan data generally will contain references to the hosts or endpoints affected by a given Finding. DefectDojo automatically aggregates Findings per-endpoint, so you can use the Endpoint view to look at all Findings that affect a given Endpoint or Hostname.\nExamples:\nhttps://www.example.com https://www.example.com:8080/products 192.168.0.36 ","date":"0001-01-01","id":20,"permalink":"/en/working_with_findings/organizing_engagements_tests/product_hierarchy/","summary":"DefectDojo uses five main data classes to organize your work: Product Types, Products, Engagements, Tests, and Findings.\nDefectDojo is made to be flexible to conform to your team, rather than making your team conform to the tool.","tags":[],"title":"Product Hierarchy: Overview"},{"content":"Note: Rules Engine is a DefectDojo Pro-only feature.\nDefectDojo\u0026rsquo;s Rules Engine allows you to build custom workflows and bulk actions to handle Findings and other objects. Rules Engine allows you to build automated actions that are triggered when an object matches a Rule.\nRules Engine can only be accessed through the Beta UI.\nCurrently, Rules can only be created for Findings, however more object types will be supported in the future.\nRules always need to be manually triggered from the All Rules page. When a rule is triggered, it will be applied to all existing Findings that match the filter conditions set.\nPossible Rule Actions Each Rule can apply one or more of these changes to a Finding when it is triggered successfully (i.e. matches the set Filter conditions).\nModify or append one or more informational fields on a Finding, including Title, Description, Severity, CVSSv3 Vector, Active, Verified, Risk Accepted, False Positive, Mitigated Set a User to Review a Finding Assign a Group as Owners for a Finding Add Tags to a Finding Add a Note to a Finding Create an Alert in DefectDojo with custom text Filter conditions Rules are automatically triggered when a Finding meets specific Filter conditions. For more information on Filters that can be used to create Rule Actions, see the Filter Index page.\nCreating a New Rule Start this process from the New Rule page. In the Beta UI, under Manage Category, Expand the Rules Engine dropdown and click + New Rule.\nStep 1: Label your Rule Enter a Label as the identifier for the new rule, and click Next.\nStep 2: Set trigger conditions with a Filter You will see an All Findings table. Using the All Findings Table, set the Filter conditions to filter the set of Findings that you want your rule to apply to. For more information on applying Filters to a table, see our guide to the Beta UI.\nThe table will preview the list of existing Findings that you have filtered.\nFor example, in this screenshot we are filtering for all Findings that are in \u0026lsquo;Product One\u0026rsquo;. Once we apply this filter (by clicking outside of the Filters menu), it will be added to our list of applicable Filters.\nIn the screenshot above, all Findings that are in the Product \u0026lsquo;Product One\u0026rsquo; will have actions taken on them.\nOnce you have a set of Filters that you want to apply, Click the Next Button.\nStep 3: Set the Rule Actions From the Action dropdown, select the Action that you want to apply to a Finding that matches all filters from Step 2. Multiple Actions can be applied.\nYou can set an additional Conditional Values which allow you to take additional actions, if certain criteria are met.\nFor example, in the screenshot above we have 4 Rule Actions set. Two of these actions are Conditional.\nAll Findings which match the filter conditions will trigger these Non-Conditional Actions:\nThe Finding will be assigned to user group \u0026lsquo;Group 1\u0026rsquo; The Finding will be tagged with all_group_1 Any Findings that match the filter conditions, plus these additional conditions will trigger these Conditional Actions in addition to the two Non-Conditional Actions listed above:\nif the Finding has Critical Severity, it will be tagged with critical_group_1. if the Finding has High Severity, it will be tagged with high_group_1. Step 4 - Preview your Rule The Rule Preview displays all of the Findings that will be changed by this rule once it is run, along with a preview of the Actions taken. Confirm that you are happy with the proposed changes, and Click Submit to save your rule.\nIf you do not believe that this rule was applied correctly, you can Select the Back Button and go back to any of the previous steps.\nFor example, in the screenshot above we have a list of Findings that will be affected by the Rule once it is run. We can see that new Tags and Owners will be applied to each of these Finding from the columns on the right of the Findings list.\nYou will be prompted again to confirm that you want your Rule to be created. Note that the Rule will not be applied immediately, and must be triggered manually.\nRunning a Rule From the All Rules page, you can select a Rule you wish to run. Click on the title of the rule to view it in more detail.\nOn this page, you can see detailed information about this rule under Metadata, including information on when the rule was last triggered. You can also see a preview of any Findings that will be affected by a new run of this Rule, underneath Rule Preview.\nTo run the Rule, click the green Run Rule button. Once you confirm that you want to run the rule, a message will appear that the rule is queued to run. in the background.\nOnce the Rule has successfully finished Running, the number of Items Changed will be updated in the Rule Metadata section of the Rule description.\nRule Metadata Reference Rule For: the objects governed by the Rule. Rule Name: the name of the Rule. Filters: the number of Filters applied by this Rule. Actions: the number of Actions taken by this Rule. Owner: the User who created this Rule. Status: the Status report of the last time this Rule executed.\n\u0026lsquo;E\u0026rsquo; = \u0026lsquo;Error\u0026rsquo;, \u0026lsquo;R\u0026rsquo; = \u0026lsquo;Running\u0026rsquo;, \u0026lsquo;S\u0026rsquo; = \u0026lsquo;Success\u0026rsquo;. Last Run: the timestamp of the last time this Rule was executed. Items Changed: count of objects that were changed on the last rule execution. Items Skipped: count of objects that were skipped by the last rule execution. If a filtered object already matches the \u0026lsquo;result\u0026rsquo; of a Rule Actions applied to it (for example, if it already has the Tags that would be applied by a Rule Action), the object will simply be skipped. ","date":"0001-01-01","id":21,"permalink":"/en/customize_dojo/rules_engine/","summary":"Note: Rules Engine is a DefectDojo Pro-only feature.\nDefectDojo\u0026rsquo;s Rules Engine allows you to build custom workflows and bulk actions to handle Findings and other objects.","tags":[],"title":"Rules Engine Automation"},{"content":"Logging into DefectDojo\u0026rsquo;s Cloud Manager allows you to configure your account settings and manage your subscription with DefectDojo Cloud.\nNew Subscription https://cloud.defectdojo.com/accounts/onboarding/step_1\nThis page allows you to request a new, or additional Cloud instance from DefectDojo.\nManage Subscriptions https://cloud.defectdojo.com/accounts/manage_subscriptions\nThe Subscription Management page shows all of your currently active Cloud instances, and allows you to configure the Firewall settings for each instance.\nChanging your Firewall Settings Once on the Edit Subscription page, enter the IP Address, Mask, and Label for the rule you wish to add. If more than one firewall rule is needed, click Add New Range to create a new empty rule.\nHere, you can also open your firewall to external services (GitHub \u0026amp; Jira Cloud). You can also disable your firewall entirely, if you wish, by selecting Proceed Without Firewall from the menu.\nAdding additional users to the Cloud Portal If you have multiple users who you want to give control over your Cloud Portal / DefectDojo Subscription, you can add them using this form. The users you want to add will have to have created their own Cloud Portal account at cloud.defectdojo.com; having an account on your DefectDojo instance is not sufficient.\nEnter the email associated with the user\u0026rsquo;s Cloud Portal account, and click Submit to add them to your list of linked users. The user will now be able to manage the Cloud Portal and your DefectDojo subscription.\nResources https://cloud.defectdojo.com/resources/\nThe Resources page contains a Contact Us form, which you can use to get in touch with our Support team.\nTools https://cloud.defectdojo.com/external_tools/defectdojo-cli\nThe Tools page is one of the places where you can download external Pro tools, such as Universal Importer or DefectDojo CLI. These tools are external add-ons which can be used to quickly build a command-line import pipeline in your network. For more information about these tools, see the External Tools documentation.\nAccount Settings https://cloud.defectdojo.com/accounts/settings\nThe account settings page has four sections:\nUser Contact allows you to set your Username, Email Address, First Name and Last Name. Email Accounts allows you to add additional email addresses to your accounts. Adding an additional email account will send a verification email to the new address. Manage Social Accounts allows you to connect DefectDojo Cloud to your GitHub or Google credentials, which can be used to log in instead of a username and password. MFA Settings allow you to add an MFA code to Google Authenticator, 1Password or similar apps. Adding an additional step to your login process is a good proactive step to prevent unauthorized access. Add MFA to your Cloud Portal login https://cloud.defectdojo.com/settings/mfa/configure/\nNote that this will only add MFA to your DefectDojo Cloud login, not to the login for your DefectDojo app.\nBegin by installing an Authenticator app which supports QR code authentication on your smartphone or computer. Once you\u0026rsquo;ve done this, click Generate QR Code. Scan the QR code provided in DefectDojo using your Authenticator app, and then enter the six-digit code provided by your app. Click Enable Multi-Factor Authentication. ","date":"0001-01-01","id":22,"permalink":"/en/cloud_management/using-cloud-manager/","summary":"Logging into DefectDojo\u0026rsquo;s Cloud Manager allows you to configure your account settings and manage your subscription with DefectDojo Cloud.\nNew Subscription https://cloud.","tags":[],"title":"Using the Cloud Manager"},{"content":"DefectDojo allows you to create Custom Reports for external audiences, which summarize the Findings or Endpoints that you wish to report on. Custom Reports can include branding and boilerplate text, and can also be used as Templates for future reports.\nOpening the Report Builder The Report Builder can be opened from the üìÑReports page on the sidebar.\nThe report builder page is organized in two columns. The left Report Format column is where you can design your report, using widgets from the right Available Widgets column.\nStep 1: Set Report Options From the Report Options section, you can take the following actions:\nSet a Report Name for the Report or Template Include user-created Finding Notes in the report Include Finding Images in the report Upload a header Image to the report Select a header image for your report To add an image to the top of your report, click the Choose File button and upload an image to DefectDojo.\nThe image will automatically resize to fit the document, and will render directly above your Report Name.\nStep 2: Add content to your report with Widgets Once you have set your Report Options, you can begin to design your report using DefectDojo‚Äôs widgets.\nWidgets are content elements of a report which can be added by dragging and dropping them into the Report Format column. The final Report will be generated based on the position of each Widget, with the Report Name and Header Image rendered at the top.\nThe elements of your report can be reordered by dragging and dropping your widgets into a new order. To remove a widget from a report, click and drag it back to the right column. Widgets can also be collapsed by clicking on the grey header, for ease in navigation through a report builder. The Findings Widget, WYSIWYG Widget and the Endpoints widget can be used more than once. For more information about Report Widgets, see our Report Widget index.\nStep 3: Publish and view your Report Once you have finished building your report, you can generate it by clicking the green ‚ÄòRun‚Äô button at the bottom of the Report Format section.\nThis will automatically take you to the Generated Reports page, and your report will begin to generate in the background. You can check on the Status of your report by reading the Status column next to it, and refreshing the page periodically.\nOnce your report has generated, you can view it by either clicking on the Status (which will be set to ‚ÄòComplete: View Report‚Äô), or by opening the ‚ãÆ menu next to your report and selecting View Report.\nStep 4: Exporting a Report Only DefectDojo users will have access to Reports stored in the software, but Reports are set up in a way where they can be exported or printed easily.\nThe easiest method to use is to Print To PDF - with an HTML Report open, open a Print dialog in your browser and set Save To PDF as the Print Destination.\nReport formatting suggestions WYSIWYG sections can be used to contextualize or summarize Finding lists. We recommend using this widget throughout your report in between Findings or Vulnerable Endpoints widgets. Report Widget Index Cover Page Widget The Cover Page Widget allows you to set a Heading, Sub heading and additional metadata for your report. You can only have a single Cover Page for a given Report.\nExecutive Summary Widget The Executive Summary widget is intended to summarize your report at a glance. It contains a Heading (defaults to Executive Summary), as well as a text box which can contain whatever information you feel is required to summarize the report.\nYou can also Include SLAs in your executive summary. To add images, markup formatting or anything beyond pure text, consider adding a WYSIWYG Content Widget immediately after the executive summary.\nYou can only have a single Executive Summary for a given Report. If your Report contains multiple SLA configurations (I.E. you have Findings from separate Products which each have their own standards for SLA) each SLA configuration will be listed on the Executive Summary as a separate row. Severities Widget As each organization will have different definitions for each severity level, the Severities Widget allows you to define the Severity Levels used in your report for ease of understanding.\nTable Of Contents Widget The Table Of Contents Widget creates a list of each Finding in your report, for quicker access to specific Findings. The table of contents will create a separate heading for each Severity contained within the report. Each Finding listed in the table of contents will have an anchor link attached to quickly jump to the Finding in the report.\nYou can add a section of Custom Content, which will add text underneath the Heading. You can upload an image to the Table Of Contents by clicking the Choose File button next to the Image line. The uploaded image will render directly above the Heading selected. Images will be resized to fit the document. WYSIWYG Content Widget The WYSIWYG (What You See Is What You Get) widget can be used to add a section containing text and images in your report. Multiple copies of this Widget can be added to add context to other sections of your report.\nWYSIWYG Content can include an optional Heading. Images can be added to a WYSIWYG widget by dragging and dropping them directly into the Content box. Images inserted into the Content box will render at their full resolution. You can add multiple WYSIWYG widgets to a report. Findings Widget The Findings Widget provides a list and summary of each Finding you want to include in your report. You can set the scope of the Findings you wish to include with Filters.\nThe Findings Widget is divided into two sections. The upper section contains a list of filters which can be used to determine which Findings you want to include, and the lower section contains the resulting list of Findings after filters are applied.\nTo apply filters to your Findings widget, set the filter parameters and click the Apply Filter button at the bottom. You can preview the results of your filter by checking the Findings list located underneath the Filters section.\nAs with Widgets, the Filters section can be expanded and collapsed by clicking the gret Filters header. You can add multiple separate Findings Widgets to your report with different filter parameters if you want the report to contain more than one list of Findings. Only the Findings you are authorized to view are included in these listings, with respect to Role-Based Access Control. Example Rendered Finding List Vulnerable Endpoints Widget The Vulnerable Endpoints widget is similar to the Findings widget. You can use this widget to list all Findings for specific Endpoints, and sort the Finding list by Endpoint instead of by Severity level.\nThe Vulnerable Endpoints widget will list each active Finding for the Endpoints selected. Rather than creating a single list of unsorted Findings this feature will separate them into their Endpoint context.\nAs with the Findings Widget, the Vulnerable Endpoints Widget is divided into a Filter section and a list of resulting Endpoints from the filter parameters.\nSelect the parameters for the Endpoints you wish to include here and click the Apply Findings button at the bottom. You can preview the results of your filter by checking the Endpoints list located underneath the Filters section.\nYou can add multiple separate Vulnerable Widgets to your report with different filter parameters if you want the report to contain more than one list. Only the Findings you are authorized to view are included in these listings, with respect to Role-Based Access Control. \u0026mdash;- (separator) Widget This Widget will render a light grey horizontal line to divide between sections.\n","date":"0001-01-01","id":23,"permalink":"/en/share_your_findings/pro_reports/using_the_report_builder/","summary":"DefectDojo allows you to create Custom Reports for external audiences, which summarize the Findings or Endpoints that you wish to report on.","tags":[],"title":"Using the Report Builder"},{"content":"This article is based on DefectDojo Inc\u0026rsquo;s February Office Hours: \u0026ldquo;Tackling Common-Use Cases\u0026rdquo;.\nExamples of Use-Cases DefectDojo is designed handle any security implementation: no matter your security team size, IT complexity level, or reporting volume. These stories are intended as jumping-off points for your own needs, but they\u0026rsquo;re based on real examples from our community and DefectDojo Pro team.\nLarge Enterprise: RBAC and Engagements \u0026lsquo;BigCorp\u0026rsquo; is a large multinational enterprise, with a CISO and a centralized IC security group that includes AppSec.\nSecurity at BICORP is highly centralized. Certain things are delegated out to BISOs (Business Information Security Officers).\nThe key concerns for BigCorp are:\nSet and maintain a consistent testing method across all business units in the organization Meet compliance requirements and avoid regulatory issues Testing Model BigCorp handles security data from many sources:\nCI/CD jobs that run SAST, SCA and Secret scanning tools automatically Third-party Pen testing for certain Products PCI compliance auditing for certain Products Each of these report categories can be handled by a separate Engagement, with a separate Test for each kind of test in DefectDojo.\nIf a Product has a CI/CD pipeline, all of the results from that pipeline can be continuously imported into a single open-ended Engagement. Each tool used will create a separate Test within the \u0026lsquo;CI/CD\u0026rsquo; Engagement, which can be continuously updated with new data. Each Pen Test effort can have a separate Engagement created to contain all of the results: e.g. \u0026lsquo;Q1 Pen Test 2024\u0026rsquo;, \u0026lsquo;Q2 Pen Test 2024\u0026rsquo;, etc. BigCorp will likely want to run their own mock PCI Audit so that they\u0026rsquo;re prepared for the real thing when it happens. The results of those audits can also be stored as a separate Engagement. RBAC Model Each BISO has Reader access assigned for each business unit (Product Type) that they\u0026rsquo;re in charge of. Each Product Owner has Writer access for the Product that they\u0026rsquo;re in charge of. Within their Product, these Product Owners can interact with DefectDojo - they can keep notes, set up pipelines, create Risk Acceptances or use other features. Developers at BigCorp have no access to DefectDojo at all, and they don\u0026rsquo;t need it - the Product Owner can push Jira tickets directly from DefectDojo which contain all of the relevant vulnerability information. The developers are already using Jira, so they don\u0026rsquo;t have to track remediation any differently than a different development task. Embedded Systems: Version-Controlled Reporting Cyber Robotics is a company that sells manufacturing hardware that comes with embedded software systems. They have a Chief Product Officer that oversees both their product and cybersecurity as a whole.\nThough they have less diverse security information to manage than BigCorp, it\u0026rsquo;s still essential for them to properly contextualize their security information so that they can proactively respond to any significant Findings.\nKey concerns for Cyber Robotics:\nThey have a limited product line but many versions of each product that they need to properly catalog. Maintenance for their products is complex and costs are high, so unnecessary work needs to be avoided. Testing Model Cyber Robotics has a standardized testing process for all of their embedded systems:\nCI/CD, SAST, and SCA tests are run. Security Control Reviews Network Scans Third Party Code Review However, because each version of their software is isolated, they\u0026rsquo;ll inevitably have a lot of data to organize, much of which is only useful in a single context (the particular version of the software they\u0026rsquo;re running).\nCyber Robotics can solve this problem by using Product Types here to represent a single product line, and individual Products for each separate version. This will allow them to drill down to determine which Products are associated with a single vulnerability.\nAssigning software versions to Products, rather than Engagements allows Cyber Robotics to limit access to a particular software version, if necessary. Field technicians and Support staff can be granted access to a single version of the software without having to give them access to the entire product line.\nRBAC Model The AppSec team here has Global Roles assigned that govern their level of interaction.\nThe Chief Product Officer has Global Reader access to DefectDojo, as with the CISO in BigCorp. Individual Product Owners have Global Reader access to any Product in DefectDojo, as well as Writer access to the Product that they own. On the Support side:\nSupport Personnel are temporarily granted Reader access to specific Products that they\u0026rsquo;re assigned to maintain, but they do not have access to all DefectDojo data. Dynamic IT environments and microservices: Cloud Services company Kate\u0026rsquo;s Cloud Service operates a rapidly changing environment that uses Kubernetes, microservices, and automation. Kate\u0026rsquo;s Cloud Service has a VP of Cloud that oversees Cloud Security issues. They also have a CISO who manages the software development on offer, but for this example we will focus specifically on their Cloud security concerns.\nKate\u0026rsquo;s Cloud Service has fully automated all of their reporting, and ingests data into DefectDojo as soon as reports are produced.\nKey Concerns for Kate\u0026rsquo;s Cloud Service:\nmanaging multi-tenant cloud security, preventing cross-customer interaction while enabling shared service delivery handling rapid changes in their cloud environment Tagging Shared Services Because Kate\u0026rsquo;s model contains many shared services that can impact other Products, the team Tags the results to indicate which cloud offerings rely on those services. This allows any issues with shared services to be traced back to the relevant teams, and reports in DefectDojo. Each of these Shared Services are in a single Product Type that separates them from the main Cloud offerings.\nBecause the company is rapidly growing, with frequently changing tech leads, Kate can use Tags to track which tech lead is currently responsible for each cloud product, avoiding the need for constant manual updates to their DefectDojo system. These Tech Lead associations are tracked by a service that\u0026rsquo;s external to DefectDojo and can govern the import pipelines or call the DefectDojo API.\nRBAC Model On the Security/Compliance side:\nThe Product Security Team that owns DefectDojo has admin access to the entire system. Analysts working for the VP of Cloud are granted read-only access across the system, allowing them to generate the necessary reports and metrics for the VP to assess the security of various cloud offerings. On the development side:\nTech Leads for each specific cloud product (e.g., compute, storage, shared services) have Maintainer access to their assigned Product, to triage the security results related to their specific cloud product offering. They can review Findings and take action within their Product, and can also reorganize their Finding data significantly. Developers working on specific Products are given Writer Access to the Product they\u0026rsquo;re working on, enabling them to comment on Findings, request Peer Reviews, and create Risk Acceptances. Onboarding New Acquisitions: SaaSy Software SaaSy software is a rapidly growing firm which frequently acquires other software companies. Every time a new company is acquired, the Director Of Quality engineering and the AppSec team is suddenly in charge of many new code repos, developers and processes. Their DefectDojo model ensures that they can get up to speed as soon as possible.\nKey Concerns for SaaSy Software:\navoiding public security issues while maintaining compliance programs (such as SOC2) ability to confidently onboard tools and processes from new products ability to report and categorize vulnerabilities on both in-production and in-development branches Testing Model Testing at SaaSy is focused on broad strokes rather than standardized tool use, since each acquisition comes with their own tools and processes for AppSec. SaaSy needs to perform both internal assessments (CI/CD, DAST, Container scans, Threat Modeling) and external assessments (3rd party Pen Tests, Compliance audits.)\nTo assist with onboarding new applications, SaaSy software has a standard approach to their data model. Each time SaaSy onboards a new application, they create a new Product Type for that app, and create sub-products for the repositories that make it up; (Front-End, Backend API, etc.)\nEach of these Products is further subdivided into Engagements, one for the main branch and one for each branch of development. Tests within these Engagements are used to categorize the testing efforts. Development branches have separate Tests which store the results of CI/CD and SCA scans. The Main branch has those as well, but also adds Tests which store Manual Code Review and Threat Model reports.\nAll of these Tests are open-ended and can be updated on a regular basis using Reimport. Deduplication is only handled at the Engagement level, which prevents Findings in one Code branch from closing Findings in another.\nBy applying this model consistently, SaaSy has a model that they can apply to any new software acquisition, and the AppSec team can quickly begin monitoring the data to ensure compliance.\nRBAC Model On the Security/Compliance side:\nThe AppSec team at SaaSy software owns DefectDojo and has full admin access to the software. QE and Compliance teams have read-only access to the entire system, to pull reports and dive into data if required. On the development side:\nEach Product Owner has Writer access to the Product they own in DefectDojo, which allows them to write Risk Acceptances and view metrics for the Product. Developers have read-only access to each Product they work on. They can Request Peer Reviews on Findings or issues they are trying to remediate. ","date":"0001-01-01","id":24,"permalink":"/en/about_defectdojo/examples_of_use/","summary":"This article is based on DefectDojo Inc\u0026rsquo;s February Office Hours: \u0026ldquo;Tackling Common-Use Cases\u0026rdquo;.\nExamples of Use-Cases DefectDojo is designed handle any security implementation: no matter your security team size, IT complexity level, or reporting volume.","tags":[],"title":"üí° Common Use-Cases"},{"content":"When a Test is created in DefectDojo (either in advance or by importing a scan file), the Test can be extended with new Finding data.\nFor example, let‚Äôs say you have a CI/CD pipeline, which is designed to send a new report to DefectDojo every day. Rather than create a new Test or Engagement for each ‚Äòrun‚Äô of the pipeline, you could have each report flow into the same Test using Reimport.\nReimport: Process Summary Reimporting data does not replace any old data in the Test, instead, it compares the incoming scan file with the existing scan data in a test to make informed decisions:\nBased on the latest file, which vulnerabilities are still present? Which vulnerabilities are no longer present? Which vulnerabilities have been previously solved, but have since been reintroduced? The Test will track and separate each scan version via Import History, so that you can check the Finding changes in your Test over time.\nReimport Logic: Create, Ignore, Close or Reopen When using Reimport, DefectDojo will compare the incoming scan data with the existing scan data, and then apply changes to the Findings contained within your Test as follows:\nCreate Findings Any vulnerabilities which were not contained in the previous import will be added to the Test automatically as new Findings.\nIgnore existing Findings If any incoming Findings match Findings that already exist, the incoming Findings will be discarded rather than recorded as Duplicates. These Findings have been recorded already - no need to add a new Finding object. The Test page will show these Findings as Left Untouched.\nClose Findings If there are any Findings that already exist in the Test but which are not present in the incoming report, you can choose to automatically set those Findings to Inactive and Mitigated (on the assumption that those vulnerabilities have been resolved since the previous import). The Test page will show these Findings as Closed.\nIf you don‚Äôt want any Findings to be closed, you can disable this behavior on Reimport:\nUncheck the Close Old Findings checkbox if using the UI Set close_old_findings to False if using the API Reopen Findings If there are any Closed Findings which appear again in a Reimport, they will automatically be Reopened. The assumption is that these vulnerabilities have occurred again, despite previous mitigation. The Test page will track these Findings as Reactivated. If you‚Äôre using a triage-less scanner, or you don‚Äôt otherwise want Closed Findings to reactivate, you can disable this behavior on Reimport:\nSet do_not_reactivate to True if using the API Check the Do Not Reactivate checkbox if using the UI Opening the Reimport form The Re-Import Findings form can be accessed on any Test page, under the ‚öôÔ∏èGear drop-down menu.\nThe Re-import Findings Form will not allow you to import a different scan type, or change the destination of the Findings you‚Äôre trying to upload. If you‚Äôre trying to do one of those things, you‚Äôll need to use the Import Scan Form.\nWorking with Import History Import History for a given test is listed under the Test Overview header on the Test page.\nThis table shows each Import or Reimport as a single line with a Timestamp, along with Branch Tag, Build ID, Commit Hash and Version columns if those were specified.\nActions This header indicates the actions taken by an Import/Reimport.\n# created indicates the number of new Findings created at the time of Import/Reimport # closed shows the number of Findings that were closed by a Reimport (due to not existing in the incoming report). # left untouched shows the count of Open Findings which were unchanged by a Reimport (because they also existed in the incoming report). # reactivated shows any Closed Findings which were reopened by an incoming Reimport. Reimport via API - special note Note that the /reimport API endpoint can both extend an existing Test (apply the method in this article) or create a new Test with new data - an initial call to /import, or setting up a Test in advance is not required.\nTo learn more about creating an automated CI/CD pipeline using DefectDojo, see our guide here.\n","date":"0001-01-01","id":25,"permalink":"/en/connecting_your_tools/import_scan_files/using_reimport/","summary":"When a Test is created in DefectDojo (either in advance or by importing a scan file), the Test can be extended with new Finding data.","tags":[],"title":"Add new Findings to a Test via Reimport"},{"content":"The documentation is built with Hugo and uses the theme Docsy. Static files for the webside are build with github actions and are publish in the gh-pages branch.\nHow to run a local preview Install Hugo. Make sure you have installed the extended version with Sass/SCSS support. Please note there are various Linux packages available on Hugo GitHub Install required theme using Node.js: cd docs and then npm install. To run the Docs local server, cd docs to switch to the docs folder, and start the hugo server by running npm run dev. Hot reloading is supported - pages will automatically update with changes while the server is running. Visit http://localhost:1313. DefectDojo Docs are built using a variation of the Doks theme.\n","date":"0001-01-01","id":26,"permalink":"/en/open_source/contributing/documentation/","summary":"The documentation is built with Hugo and uses the theme Docsy. Static files for the webside are build with github actions and are publish in the gh-pages branch.","tags":[],"title":"Amend Documentation"},{"content":"If you have difficulty accessing your DefectDojo instance, here are some steps you can follow to get reconnected:\nI can access the site, but I can\u0026rsquo;t log in You can reset the password for your account from the login page: yourcompanyinstance.cloud.defectdojo.com/login. Click \u0026lsquo;I forgot my password\u0026rsquo; in order to begin the process.\n‚Äã Enter your email address, and click \u0026ldquo;Reset my password\u0026rdquo;.\n‚Äã You should receive an email with the subject header \u0026ldquo;Password reset on yourcompanyinstance.cloud.defectdojo.com\u0026rdquo;. This email contains a link which you can click to set a new password. If you don\u0026rsquo;t receive an email, please check your Spam folder. Failing that, have your team\u0026rsquo;s DefectDojo admin confirm that you have an account registered on your instance.\nI can\u0026rsquo;t access my company\u0026rsquo;s cloud.defectdojo site If your company\u0026rsquo;s cloud.defectdojo site does not load in your browser, or times out, it may be necessary for your company to change your firewall rules in order to accept your connection.\nFirewall rules can be changed in your Cloud Manager at https://cloud.defectdojo.com/accounts/manage_subscriptions.\nIf your company uses a shared VPN, proxy server or a similar tool, make sure it‚Äôs authorized to connect to DefectDojo and that the IP address is included in DefectDojo\u0026rsquo;s Firewall rules.\nIf the problem persists, please contact support at defectdojo dot com\r.\nI can\u0026rsquo;t log in to the Cloud Manager If you can‚Äôt access the Cloud Manager, navigate to the Login page at https://cloud.defectdojo.com/accounts/login/ and click ‚ÄúForgot your password?‚Äù\nYou‚Äôll be prompted to enter your email address, and our team will send you an email with a link to reset your password and enter a new one.\nPlease note that this login method only works for the Cloud Manager, an admin site which your team members may not all have access to. Directly logging into your instance to use DefectDojo is only possible by directly connecting to yourcompanyinstance.cloud.defectdojo.com/login.\nI\u0026rsquo;ve lost access to my MFA codes For the Cloud Manager: If you lose access to your MFA codes, or Authenticator App, please contact DefectDojo Support at support at defectdojo dot com\r. For a DefectDojo Instance: It is not currently possible to remove MFA access from an account without an MFA code. The best option in this case is to create a new DefectDojo login, and re-grant all necessary permissions to this account. ","date":"0001-01-01","id":27,"permalink":"/en/cloud_management/connectivity-troubleshooting/","summary":"If you have difficulty accessing your DefectDojo instance, here are some steps you can follow to get reconnected:\nI can access the site, but I can\u0026rsquo;t log in You can reset the password for your account from the login page: yourcompanyinstance.","tags":[],"title":"Connectivity Troubleshooting"},{"content":"Normally, most of the Findings in your environment will be imported from other security tools. If you wish, you can add manual Finding entries as well, if you have vulnerabilities or work you wish to manage that was not created from a scan tool.\nFrom the DefectDojo Sidebar, open the New Finding link by clicking Manage \u0026gt; Findings \u0026gt; New Finding.\n‚Äã This opens the New Finding form, which you can fill out with any relevant information surrounding your Finding. You will need to assign this Finding to a previously created Test in DefectDojo.\n","date":"0001-01-01","id":28,"permalink":"/en/working_with_findings/findings_workflows/create_findings_manually/","summary":"Normally, most of the Findings in your environment will be imported from other security tools. If you wish, you can add manual Finding entries as well, if you have vulnerabilities or work you wish to manage that was not created from a scan tool.","tags":[],"title":"Creating Findings Manually"},{"content":"Dashboard Tiles are customizable sets of filters for your DefectDojo instance, which can be added to your üè† Home dashboard. Tiles are designed to provide relevant information and speed up navigation within DefectDojo.\nTiles can:\nAct as shortcuts for particular sets of Findings, Products, or other objects Visualize relevant metrics related a Product, Engagement or other components of the Product Hierarchy Provide alerts on particular activity, track SLA Violations, failing imports or new Critical Findings Tile Filters set a narrower focus for any tile you want to create. Each Tile has a different set of relevant filters which can be selected.\nNote that only Superusers can add or edit Dashboard Tiles.\nTile Components Each Tile contains four main components:\nA count of each object that meets the Tile‚Äôs filter conditions. For example, a Findings Tile will count the number of Findings filtered by the Tile. A customizable Header which can be set to describe the function of the tile. A customizable Footer which brings you to the related list of objects. For example, a Findings Tile‚Äôs footer will bring you to a list of Findings filtered by the Tile. Add / Edit Dashboard Tiles Custom Dashboard Tiles can be added, edited or deleted by any user with Superuser Permissions.\nNew Dashboard tiles can be added by opening the + (plus icon) menu on the Dashboard. New Dashboard tiles will always be created at the bottom of the Dashboard Tiles section.\nSelect the kind of Tile you want to add, which will then bring you to the Add Dashboard Tile form.\nIf you wish to edit a Dashboard Tile, you can click the Header of the Tile, which will also open the Dashboard Tile form.\nDisplay Options From here you can set your Dashboard Tile‚Äôs options:\nSet the Header text for your tile (3) Set the Footer text for your tile (4) Set the Color of your icon (1) Tile Filters Click the Tile Filters + button at the bottom of the form to expand the Tile Filters menu. From here you can apply any relevant filtering to the tile. See the Tile Index for more info on what filters can be applied to which tile.\nDynamic Color Tile If you want to set your tile to change color based on the associated count of Findings, Products or other objects returned by the filter, you can enable Dynamic Color Tile in this menu. The color of the tile Icon will change from Green -\u0026gt; Yellow -\u0026gt; Red as the object count changes.\nDynamic Color Minimum is the bottom of the range. If the Object count is equal to or less than this number, the tile Icon will be set to Green. Dynamic Color Maximum is the top of the range. If the Object count is equal to or greater than this number, the tile Icon will be set to Red. Any number between the Minimum or the Maximum will set the filter to Yellow. Example: Critical Findings Count Say you wanted to set up a Dynamic Color Tile to track our Critical Findings. You can set your Dynamic Color parameters as follows:\nSet Dynamic Color Minimum to 0. As long as you have 0 active Critical Findings, this tile will be Green. Set Dynamic Color Maximum to 5. If you have 5 or more Critical Findings active in our environment, the tile will turn Red to indicate there‚Äôs timely action required to address these Findings. If you have 1-4 Critical Findings in your instance, the filter will be Yellow to indicate that we‚Äôre not in an ‚Äòemergency‚Äô situation but we should be aware of these Findings. Of course, your team‚Äôs standards and acceptable range for this kind of filter may differ from our example.\nInverted Maximum and Minimum If your Maximum is lower than your Minimum, the range will still compute correctly.\nExample 2: Passing Products Count\nSay you wanted to set up a Tile which tracks your Passing Products with a Dynamic Color. An acceptable count of Passing Products for you is 5 or more, and a ‚Äòfailing‚Äô state is 2 or fewer Passing Products.\nYou can set your Dynamic Color Maximum of 2, and a Dynamic Color Minimum of 5, the Tile will apply colors as follows:\nIf the filter returns 2 Objects or fewer , the tile will be Red, indicating that very few of your Products are passing. If the filter returns 5 Objects or greater, the tile will be Green, indicating that a healthy amount of your Products are passing. If the filter returns a value between those two numbers, the tile will be Yellow, indicating that a significant, but non-critical amount of your Products are not passing. Dashboard Tile Index Here is a list summarizing each Dashboard Tile you can add, along with filters that can be applied to the Tile and an example configuration.\nProduct, Engagement or Test Tiles These Tiles allow you to quickly select a list of Products, Engagements or Tests based on the filter parameters you set. You can use this tile for ease in navigation.\nThe number on the tile represents the count of objects (Products, Engagement or Tests) contained within the tile‚Äôs filter parameters. Clicking the footer will take you to a filtered list of those objects.\nExample: Monitoring Engagements In Progress If you want to create a list of your In-Progress Engagements in DefectDojo, you can set up an Engagement tile which filters for that condition.\nCreate an Engagement tile, and from the Tile Filters set Engagement Status to In Progress. To make sure your Tile is accurately labeled, set the Header of your tile to ‚ÄòEngagements In Progress‚Äô. You could also create Engagement tiles for one or more other states, such as Blocked or Completed.\nProduct Tile Filters Product Name Contains: type in one or more partial matches of Product Names, separated by commas Product Name Exact: type in one or more exact matches of Product Names, separated by commas Product Type: Select one or more options from the list Business Criticality: Select one or more options from the list Platform: Select one or more options from the list Lifecycle: Select one or more options from the list Origin: Select one or more options from the list External Audience: Yes/No Internet Accessible: Yes/No Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Outside of SLA: Yes/No Engagement Tile Filters Product Name Contains: type in one or more partial matches of Product Names, separated by commas Product Type: Select one or more options from the list Engagement Name Contains: type in one or more partial matches of Engagements, separated by commas Engagement Lead: Select a single option from the list Engagement Version: type in an Engagement Version Test Version: type in a Test Version Product Lifecycle: Select one or more options from the list Engagement Status: Select one or more options from the list Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Test Tile Filters Test Name Contains: type in one or more partial matches of Test Names, separated by commas Test Type: select a single Test Type from the list Engagement: select a single Engagement from the list Test Version: type in a Test Version Branch/Tag: type in a Branch/Tag Build ID: type in a Build ID Commit Hash: type in a Commit Hash Engagement Tag Contains: type in one or more partial matches of tags, separated by commas Engagement Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Product Tag Contains: type in one or more partial matches of tags, separated by commas Product Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas Finding Tiles Finding tiles provide a count of Findings based on the filter parameters you set. As with other tiles, clicking the Footer will take you to a list of the Findings set by the tile.\nUsing filter parameters you can track Findings in a particular state or time period.\nExample: Monitoring Critical Findings If you wanted to be able to quickly access all of your Critical Findings in DefectDojo, you could do this by creating a tile.\nCreate a Finding tile, and from the Tile Filters set Severity to Critical. To make sure your Tile is accurately labeled, set the Header of the tile to ‚ÄòCritical Findings‚Äô. You can add additional filter parameters to make this tile more functional for your use-case. For example, if you wanted this tile to only track Open Findings (and ignore any Mitigated Findings) you could set the Active filter to Yes.\nFinding Tile Filters Name Contains: enter a partial match of a Finding Name from the menu Component Name Contains: enter a partial match of a Component Name from the menu Date: select an option from the menu CWE: type in an exact match of a CWE Severity: select one or more Severities from the menu Last Reviewed: select an option from the menu Last Status Update: select an option from the menu Mitigated Date: select an option from the menu Reported By: select one or more Users from the menu Product Type: select one or more Product Types from the menu Product: select one or more Products from the menu Product Lifecycle: select one or more Product Lifecycle states from the menu Engagement: select one or more Engagements from the menu Engagement Version: type in an exact match of an Engagement Version Test Type: select one or more Test from the menu Test Version: type in an exact match of a Test Version Active: Yes/No Verified: Yes/No Duplicate: Yes/No Mitigated: Yes/No Out Of Scope: Yes/No False Positive: Yes/No Has Components: Yes/No Has Notes: Yes/No File Path Contains: type in a partial match of a File Path Unique ID From Tool: type in an exact match of a Unique ID From Tool Vulnerability ID From Tool: type in an exact match of a Vulnerability From Tool Vulnerability ID: type in an exact match of a Vulnerability Service Contains: type in a partial match of a Service Parameter Contains: type in a partial match of an Parameter Payload Contains: type in a partial match of an Payload Risk Accepted: Yes/No Has Group: select an option from the list Planned Remediation Date: select an option from the list Planned Remediation Version: type in a Planned Remediation Version Reviewers: select one or more Users from the list Endpoint Host Contains: type in a partial match of an Endpoint Host Outside of SLA: Yes/No Effort For Fixing: select an option from the list Has Tags: Yes/No Tags: type in one or more partial matches of Finding tags, separated by commas Tag Contains: type in one or more partial matches of Finding tags, separated by commas Does Not Have Tags: type in one or more exact matches of Finding tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of Finding tags, separated by commas Test Tags: type in one or more exact matches of tags, separated by commas Test Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Engagement Tags: type in one or more exact matches of tags, separated by commas Engagement Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Product Tags: type in one or more exact matches of tags, separated by commas Product Does Not Have Tags: type in one or more exact matches of tags to ignore, separated by commas Endpoint Tiles If you need to keep track of particular Endpoints, you can set up a Tile to quickly navigate to a filtered list. This tile can be set up to filter by Host, Product, Tags or other parameters that are relevant to the Endpoints you want to track.\nClicking the footer on this tile brings us to a filtered list of Endpoints which displays their status. DefectDojo will only create and track Endpoints with related vulnerabilities, so this will not include any Endpoints which have no vulnerabilities reported.\nExample: Monitor All Endpoints With Same Host If you wanted to use Endpoints to look at vulnerabilities on a certain part of your architecture, regardless of the associated Product, you could use an Endpoint Tile to filter for a particular URL. From there, you could see all Findings associated with that part of your network.\nCreate an Endpoint tile. For this example, we are setting the Host Contains field to ‚Äòcentralaction-items‚Äô, as that string is part of many Endpoint URLs in our infrastructure.‚Äã Set your Header to a title which describes the intended function of your tile. In this example, we used ‚ÄòHost: centralaction-items‚Äô. Endpoint Tile Filters Protocol Contains: type in a partial match of a Protocol from the menu User Info Contains: type in a partial match of User Info from the menu Host Contains: type in a partial match of a Host from the menu Port Contains: type in a partial match of a Port from the menu Path Contains: type in a partial match of a Path from the menu Query Contains: type in a partial match of a Query from the menu Fragment Contains: type in a partial match of a Fragment from the menu Product: select one or more Products from the menu Has Tags: Yes/No Tags: type in one or more exact matches of tags, separated by commas Tag Contains: type in one or more partial matches of tags, separated by commas Does Not Have Tags: type in one or more exact matches tags to ignore, separated by commas Tag Does Not Contain: type in one or more partial matches of tags to ignore, separated by commas SLA Violation Tile This Tile counts Findings which are at risk of violating SLA. It can be set to track all Products, or specific Products chosen from a list.\nExample: Findings Approaching SLA Violation If you want to create a filter for Findings which are within 7 days of SLA expiration, you can set up your filter parameters to track this. When setting the Filter parameters for the SLA Violation tile, set ‚ÄòDays Before Expiration‚Äô to 7. Select either All Products, or a list of specific Products.\nSet the Header to describe the filter you‚Äôre applying, for example ‚ÄòSLA Violation - 3 Days Or Less‚Äô.\nClicking on the footer will bring you to a list of these Findings for you to address. This tile only tracks Active Findings, but will also track Findings with an expired SLA.\nSLA Violation Tile Filters Days Before Expiration: select an option from the menu Include All Products: Yes/No Included Products: select one or more Products from the menu Scan Time Violation Tile This Tile is used to track specific Products to ensure that new scan data is being added on a regular basis.\nIf there are particular Products which you‚Äôre scanning on a regular interval, you can use this tile to ensure your tools and imports are running as expected.\nThis Tile will return a count and related list of Products which have not had new scan data added in the interval you‚Äôve defined.\nExample: Automation Tracking If you have scanning tools set to run on a weekly basis, you can use this tile to make sure those automated processes are working correctly.\nFrom the Tile filters, select the target Products where the scan data will be imported via automation. Set the Days Since Last Scan field to ‚ÄòPast Week‚Äô. Set a descriptive name in the Header which communicates the interval you‚Äôre testing. If you have multiple scanning intervals that you want to monitor, you can set up multiple tiles to track each one.\nScan Time Violation Tile Filters Days Since Last Scan: select an option from the menu Include All Products: Yes/No Included Products: select one or more Products from the menu Product Grade Tile This Tile compares the Product Grade of all Products on your instance, so that you can track any Products which do not meet your grading standard.\nThis tile uses a comparison operator (\u0026lt;, =, \u0026lt;=, \u0026gt;=) to track Products which equal, exceed or fail to meet the Product Grade which you want to monitor.\nFor more information on how Product Grades are calculated, see our article on Product Health Grading.\nExample: Track Failing Products If you want to quickly access Products in your instance which do not meet your Grading standard, you can set up a Tile which handles that calculation. The Grading standard used in this example is ‚ÄòLess Than C‚Äô: we want our tile to flag any Products with a Grade of D or lower.\nCreate a Product Grade Tile. From the Filters list, set the Grade which you consider ‚Äòfailing‚Äô. In this case we‚Äôll select C. In the Filters list, set a Comparison Operator to determine the logic used in counting your failing Products. In this case, we‚Äôll select ‚ÄòLess Than‚Äô. As with other Product related Tiles, you can set the Tile to look at All Products in your instance, or only a specific list of Products.\nProduct Grade Tile Filters Product Grade: select a single Product Grade from the menu Comparison Operator: select a Comparison Operator from the menu, related to Product Grade Include All Products: Yes/No Included Products: select one or more Products from the menu ","date":"0001-01-01","id":29,"permalink":"/en/customize_dojo/dashboard_notifications/about_custom_dashboard_tiles/","summary":"Dashboard Tiles are customizable sets of filters for your DefectDojo instance, which can be added to your üè† Home dashboard. Tiles are designed to provide relevant information and speed up navigation within DefectDojo.","tags":[],"title":"Custom Dashboard Tiles"},{"content":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/oa3/swagger-ui and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.\nThe documentation is generated using drf-spectacular at /api/v2/oa3/swagger-ui/, and is interactive. On the top of API v2 docs is a link that generates an OpenAPI v3 spec.\nTo interact with the documentation, a valid Authorization header value is needed. Visit the /api/key-v2 view to generate your API Key (Token \u0026lt;api_key\u0026gt;) and copy the header value provided.\nEach section allows you to make calls to the API and view the Request URL, Response Body, Response Code and Response Headers.\nIf you\u0026rsquo;re logged in to the Defect Dojo web UI, you do not need to provide the authorization token.\nAuthentication The API uses header authentication with API key. The format of the header should be: :\nAuthorization: Token \u0026lt;api.key\u0026gt; For example: :\nAuthorization: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff Alternative authentication method If you use [an alternative authentication method](en/customize_dojo/user_management/configure_sso/ for users, you may want to disable DefectDojo API tokens because it could bypass your authentication concept. Using of DefectDojo API tokens can be disabled by specifying the environment variable DD_API_TOKENS_ENABLED to False. Or only api/v2/api-token-auth/ endpoint can be disabled by setting DD_API_TOKEN_AUTH_ENDPOINT_ENABLED to False.\nSample Code Here are some simple python examples and their results produced against the /users endpoint: :\nimport requests url = \u0026#39;http://127.0.0.1:8000/api/v2/users\u0026#39; headers = {\u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Token c8572a5adf107a693aa6c72584da31f4d1f1dcff\u0026#39;} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\u0026#34;\u0026#39;{key}\u0026#39;: \u0026#39;{value}\u0026#39;\u0026#34;) print(\u0026#39;------------------\u0026#39;) This code will return the list of all the users defined in DefectDojo. The json object result looks like : :\n[ { \u0026#34;first_name\u0026#34;: \u0026#34;Tyagi\u0026#34;, \u0026#34;id\u0026#34;: 22, \u0026#34;last_login\u0026#34;: \u0026#34;2019-06-18T08:05:51.925743\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Paz\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;dev7958\u0026#34; }, { \u0026#34;first_name\u0026#34;: \u0026#34;saurabh\u0026#34;, \u0026#34;id\u0026#34;: 31, \u0026#34;last_login\u0026#34;: \u0026#34;2019-06-06T11:44:32.533035\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;saurabh.paz\u0026#34; } ] Here is another example against the /users endpoint, this time we will filter the results to include only the users whose user name includes jay:\nimport requests url = \u0026#39;http://127.0.0.1:8000/api/v2/users/?username__contains=jay\u0026#39; headers = {\u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Token c8572a5adf107a693aa6c72584da31f4d1f1dcff\u0026#39;} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\u0026#34;\u0026#39;{key}\u0026#39;: \u0026#39;{value}\u0026#39;\u0026#34;) print(\u0026#39;------------------\u0026#39;) The json object result is: :\n[ { \u0026#34;first_name\u0026#34;: \u0026#34;Jay\u0026#34;, \u0026#34;id\u0026#34;: 22, \u0026#34;last_login\u0026#34;: \u0026#34;2015-10-28T08:05:51.925743\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Paz\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;jay7958\u0026#34; }, { \u0026#34;first_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;id\u0026#34;: 31, \u0026#34;last_login\u0026#34;: \u0026#34;2015-10-13T11:44:32.533035\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;jay.paz\u0026#34; } ] See Django Rest Framework's documentation on interacting with an API for additional examples and tips.\nManually calling the API Tools like Postman can be used for testing the API.\nExample for importing a scan result:\nVerb: POST\nURI: http://localhost:8080/api/v2/import-scan/\nHeaders tab:\nadd the authentication header Key: Authorization Value: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff Body tab\nselect \u0026quot;form-data\u0026quot;, click \u0026quot;bulk edit\u0026quot;. Example for a ZAP scan: engagement:3 verified:true active:true lead:1 tags:test scan_type:ZAP Scan minimum_severity:Info skip_duplicates:true close_old_findings:false Body tab\nClick \u0026quot;Key-value\u0026quot; edit Add a \u0026quot;file\u0026quot; parameter of type \u0026quot;file\u0026quot;. This will trigger multi-part form data for sending the file content Browse for the file to upload Click send\nClients / API Wrappers Wrapper Status Notes Specific python wrapper working (2021-01-21) API Wrapper including scripts for continous CI/CD uploading. Is lagging behind a bit on latest API features as we plan to revamp the API wrapper Openapi python wrapper proof of concept only where we found out the the OpenAPI spec is not perfect yet Java library working (2021-08-30) Created by the kind people of SecureCodeBox Image using the Java library working (2021-08-30) .Net/C# library working (2021-06-08) dd-import working (2021-08-24) dd-import is not directly an API wrapper. It offers some convenience functions to make it easier to import findings and language data from CI/CD pipelines. Some of the api wrappers contain quite a bit of logic to ease scanning and importing in CI/CD environments. We are in the process of simplifying this by making the DefectDojo API smarter (so api wrappers / script can be dumber).\n","date":"0001-01-01","id":30,"permalink":"/en/api/api-v2-docs/","summary":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/oa3/swagger-ui and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.","tags":[],"title":"DefectDojo API v2"},{"content":"Deduplication can be implemented at either a Product level or at a more narrow Engagement level.\nDeduplication for Products Start by navigating to the System Settings page. This is nested under Settings \u0026gt; Pro Settings \u0026gt; ‚öôÔ∏è System Settings on the sidebar. Deduplication and Finding Settings are at the top of the System Settings menu.\n‚Äã Enable Finding Deduplication Enable Finding Deduplication will turn on the Deduplication Algorithm for all Findings. Deduplication will be triggered on all subsequent imports - when this happens, DefectDojo will look at any Findings contained in the destination Product, and deduplicate as per your settings.\nDelete Deduplicate Findings Delete Deduplicate Findings, combined with the Maximum Duplicates field allows DefectDojo to limit the amount of Duplicate Findings stored. When this field is enabled, DefectDojo will only keep a certain number of Duplicate Findings.\nApplying Delete Deduplicate Findings will begin a deletion process immediately. DefectDojo will look at each Finding with Duplicates recorded, and will delete old duplicate Findings until the Maximum Duplicate number has been reached.\nFor more information on how DefectDojo determines what to delete, see our guide to Deleting Deduplicate Findings.\nDeduplication for Engagements Rather than Deduplicating across an entire Product, you can set a deduplication scope to be within a single Engagement exclusively.\nEdit Engagement page To enable Deduplication within a New Engagement, start with the + New Engagement option from the sidebar, which you can find by opening the üì•Engagements sub-menu.\n‚Äã To enable Deduplication within an existing Engagement: from the All Engagements page, select the Edit Engagement option from the ‚ãÆ menu.\n‚Äã You can also open this menu from a specific Engagement Page by clicking the ‚öôÔ∏èGear icon in the top-right hand corner.\n‚Äã Completing the Edit Engagement form Start by opening the Optional Fields + menu at the bottom of the Edit Engagement form. Click the ‚òê Deduplication Within This Engagement box. Submit the form. ","date":"0001-01-01","id":31,"permalink":"/en/working_with_findings/finding_deduplication/enabling_product_deduplication/","summary":"Deduplication can be implemented at either a Product level or at a more narrow Engagement level.\nDeduplication for Products Start by navigating to the System Settings page.","tags":[],"title":"Enabling Deduplication"},{"content":"Note: The following external tools are DefectDojo Pro-only features. These binaries will not work unless they are connected to an instance with a DefectDojo Pro license.\nAbout External Tools defectdojo-cli and universal-importer are command-line tools designed to seamlessly upload scan results into DefectDojo. They streamline both the import and re-import processes of findings and associated objects. These tools are flexible and support importing and re-importing scan results, making it ideal for users who want to quickly set up these interactions with the DefectDojo API.\nDefectDojo-CLI has the same functionality as Universal Importer, but also includes the ability to export Findings from DefectDojo to JSON or CSV.\nInstallation Use the DefectDojo UI to download the appropriate binary for your operating system from the platform.\nLocate ‚ÄúExternal Tools‚Äù from your User Profile menu:\nExtract the downloaded archive within a directory of your choice. Optional: Add the directory containing the extracted binary to your system\u0026rsquo;s $PATH for repeat access. Note that Macintosh users may be blocked from running DefectDojo-CLI or Universal Importer as they are apps from an unidentified developer. See Apple Support for instructions on how to override the block from Apple.\nWindows Users: If you receive the \u0026ldquo;Couldn\u0026rsquo;t download - virus detected\u0026rdquo; error, disabling Smartscreen may work. Otherwise, use a different browser to download the tool from the Cloud portal.\nConfiguration Universal Importer \u0026amp; DefectDojo-CLI can be configured using flags, environment variables, or a configuration file. The most important configuration is the API token, which must be set as an environment variable:\nAdd your API key to your environment variables. You can retrieve your API key from: https://YOUR_INSTANCE.cloud.defectdojo.com/api/key-v2 or\nVia the DefectDojo user interface in the user dropdown in the top-right corner:\nSet your environment variable for the API token. For DefectDojo-CLI: export DD_CLI_API_TOKEN=YOUR_API_KEY\nFor Universal Importer: export DD_IMPORTER_DOJO_API_TOKEN=YOUR_API_KEY\nNote: On Windows, use set instead of export.\nWindows: Using PowerShell Open PowerShell (Windows Key, then search for \u0026ldquo;PowerShell\u0026rdquo;). Set the environment variables: Temporary: $env:DD_IMPORTER_DOJO_API_TOKEN = \u0026#34;[VALUE_FROM_DEFECTDOJO_API]\u0026#34; $env:DD_IMPORTER_DEFECTDOJO_URL=‚Äù[e.g. http://localhost:8080/defectdojo]‚Äù\rPermanent: [Environment]::SetEnvironmentVariable(\u0026#34;DD_IMPORTER_DOJO_API_TOKEN\u0026#34;, \u0026#34;[VALUE_FROM_DEFECTDOJO_API]\u0026#34;, \u0026#34;Machine\u0026#34;)\rRestart your PowerShell session. Verify the setting: echo $env:DD_IMPORTER_DOJO_API_TOKEN echo $env:DD_IMPORTER_DEFECTDOJO_URL\rWindows: Using Command Prompt (Administrative Accounts) Open Command Prompt (Windows Key, then search for \u0026ldquo;Command Prompt\u0026rdquo;). Set the environment variables: Temporary: set DD_IMPORTER_DOJO_API_TOKEN = \u0026#34;[VALUE_FROM_DEFECTDOJO_API]\u0026#34; set DD_IMPORTER_DEFECTDOJO_URL=‚Äù[e.g. http://localhost:8080/defectdojo]‚Äù\rPermanent: setx DD_IMPORTER_DOJO_API_TOKEN = \u0026#34;[VALUE_FROM_DEFECTDOJO_API]\u0026#34; setx DD_IMPORTER_DEFECTDOJO_URL=‚Äù[e.g. http://localhost:8080/defectdojo]‚Äù\rUsing Windows Settings (Non-Administrative Accounts) Press Win + I to open the system settings dialog. In the search box, type \u0026ldquo;environment\u0026rdquo;. Choose \u0026ldquo;Edit Environment variables for your account\u0026rdquo;. Under \u0026ldquo;User variables for [username]\u0026rdquo;, click the \u0026ldquo;New‚Ä¶\u0026rdquo; button. Set the variable: Variable name: DD_IMPORTER_DOJO_API_TOKEN Variable value: [VALUE_FROM_DEFECTDOJO_API] Click \u0026ldquo;OK\u0026rdquo;. Repeat steps 4 through 6 for the DD_IMPORTER_DEFECTDOJO_URL variable Restart any open command windows. Verify the settings: echo %DD_IMPORTER_DOJO_API_TOKEN% echo %DD_IMPORTER_DEFECTDOJO_URL%\rDefectDojo-CLI defectdojo-cli seamlessly integrates scan results into DefectDojo, streamlining the import and reimport processes of Findings and associated objects. Designed for ease of use, the tool supports various endpoints, catering to both initial imports and subsequent reimports ‚Äî ideal for users requiring robust and flexible interaction with the DefectDojo API. DefectDojo-CLI can perform the same functions as universal-importer, and adds export functionality for Findings.\nCommands import Imports findings into DefectDojo. reimport Reimports findings into DefectDojo. export\tExports findings from DefectDojo. interactive Starts an interactive mode to configure the import and reimport process, step by Global Options --help, -h\nshow help --version, -v\nprint the version CLI Formatting --no-color\nDisable color output. (default: false) [$DD_CLI_NO_COLOR] --no-emojis, --no-emoji\nDisable emojis in the output. (default: false) [$DD_CLI_NO_EMOJIS]\n--verbose Enable verbose output. (default: false) [$DD_CLI_VERBOSE]\nImport Use the import command to import new findings into DefectDojo.\nUsage defectdojo-cli [global options] import \u0026lt;required flags\u0026gt; [optional flags] or: defectdojo-cli [global options] import --config ./config-file-path or: defectdojo-cli import [-h | --help] or: defectdojo-cli import example [subcommand options] or: defectdojo-cli import example [-h | --help] \u0026gt;\u0026gt; The API token must be set in the environment variable `DD_CLI_API_TOKEN`.\rimport can import Findings in two ways:\nBy ID:\nCreate a Product (or use an existing product) Create an Engagement inside the product Provide the id of the Engagement in the engagement parameter In this scenario a new Test will be created inside the Engagement.\nBy Name:\nCreate a Product (or use an existing product) Create an Engagement inside the product Provide product-name Provide engagement-name Optionally provide product-type-name In this scenario DefectDojo will look up the Engagement by the provided details.\nWhen using names you can let the importer automatically create Engagements, Products and Product-types by using auto-create-context=true. You can use deduplication-on-engagement to restrict deduplication for imported Findings to the newly created Engagement.\nImport Basic syntax:\ndefectdojo-cli import [options]\rImport Example: defectdojo-cli import \\ --defectdojo-url \u0026#34;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026#34; \\ --scan-type \u0026#34;burp scan\u0026#34; \\ --report-path \u0026#34;./examples/burp_findings.xml\u0026#34; \\ --product-name \u0026#34;dev\u0026#34; \\ --engagement-name \u0026#34;dev\u0026#34; \\ --product-type-name \u0026#34;Research and Development\u0026#34; \\ --test-name \u0026#34;burp-test-dev\u0026#34; \\ --verified \\ --active \\ --minimum-severity \u0026#34;info\u0026#34; \\ --tag \u0026#34;dev\u0026#34; --tag \u0026#34;tools\u0026#34; --tag \u0026#34;burp\u0026#34; --tag \u0026#34;test-dev\u0026#34; \\ --test-version \u0026#34;0.0.1\u0026#34; \\ --auto-create-context\rCommands example, x\nShows an example of required and optional flags for import operation Options --active, -a\nDictates whether findings should be active on import. (default: true) [$DD_CLI_ACTIVE] --api-scan-configuration value, --asc value\nThe ID of the API Scan Configuration object to use when importing or reimporting. (default: 0) [$DD_CLI_API_SCAN_CONFIGURATION] --apply-tags-endpoints, --te\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the endpoints (default: false) [$DD_CLI_APPLY_TAGS_ENDPOINTS] --apply-tags-findings, --tf\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the findings (default: false) [$DD_CLI_APPLY_TAGS_FINDINGS] --auto-create-context, --acc\nIf set to true, the importer automatically creates Engagements, Products, and Product_Types (default: false) [$DD_CLI_AUTO_CREATE_CONTEXT] --deduplication-on-engagement, --doe\nIf set to true, the importer restricts deduplication for imported findings to the newly created Engagement. (default: false) [$DD_CLI_DEDUPLICATION_ON_ENGAGEMENT] --engagement-id value, --ei value\nThe ID of the Engagement to import findings into. (default: 0) [$DD_CLI_ENGAGEMENT_ID] --engagement-name value, -e value\nThe name of the Engagement to import findings into. [$DD_CLI_ENGAGEMENT_NAME] --minimum-severity value, --ms value\nDictates the lowest level severity that should be imported. Valid values are: Critical, High, Medium, Low, Info. (default: \u0026ldquo;Info\u0026rdquo;) [$DD_CLI_MINIMUM_SEVERITY] --product-name value, -p value\nThe name of the Product to import findings into. [$DD_CLI_PRODUCT_NAME] --product-type-name value, --pt value\nThe name of the Product Type to import findings into. [$DD_CLI_PRODUCT_TYPE_NAME] --report-path value, -r value\nThe path to the report to import. (required). [$DD_CLI_REPORT_PATH] --scan-type value, -s value\nThe scan type of the tool (required). [$DD_CLI_SCAN_TYPE] --tag value, -t value [ --tag value, -t value ]\nAny tags to be applied to the Test object [$DD_CLI_TAGS] --test-name value, --tn value\nThe name of the Test to import findings into - Defaults to the name of the scan type. [$DD_CLI_TEST_NAME] --test-version value, -V value\nThe version of the test. [$DD_CLI_TEST_VERSION] --verified, -v\nDictates whether findings should be verified on import. (default: false) [$DD_CLI_VERIFIED] Settings:\n--config value, -c value\nThe path to the TOML configuration file is used to set values for the options. If the option is set in the configuration file and the CLI, the option will take the value set from the CLI. [$DD_CLI_CONFIG_FILE] --defectdojo-url value, -u value The URL of the DefectDojo instance to import findings into. (required). [$DD_CLI_DEFECTDOJO_URL] \u0026ndash;insecure-tls, \u0026ndash;no-tls ignore TLS validation errors when connecting to the provided DefectDojo instance. Most users should not enable this flag. (default: false) [$DD_CLI_INSECURE_TLS] Reimport Use the reimport command to extend an existing Test with Findings from a new report in one of two ways:\nBy ID:\nCreate a Product (or use an existing product) Create an Engagement inside the product Import a scan report and find the id of the Test Provide this in the test-id parameter By Names:\nCreate a Product (or use an existing product) Create an Engagement inside the product Import a report which will create a Test Provide product-name Provide engagement-name Optional: Provide test-name In this scenario DefectDojo will look up the Test by the provided details. If no test-name is provided, the latest test inside the engagement will be chosen based on scan-type.\nWhen using names you can let the importer automatically create Engagements, Products and Product-types by using auto-create-context=true. You can use deduplication-on-engagement to restrict deduplication for imported Findings to the newly created Engagement.\nUsage defectdojo-cli [global options] reimport \u0026lt;required flags\u0026gt; [optional flags] or: defectdojo-cli [global options] reimport --config ./config-file-path or: defectdojo-cli reimport [-h | --help] or: defectdojo-cli reimport example [subcommand options] or: defectdojo-cli reimport example [-h | --help] \u0026gt;\u0026gt; The API token must be set in the environment variable `DD_CLI_API_TOKEN`.\rReimport Example: defectdojo-cli reimport \\ --defectdojo-url \u0026#34;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026#34; \\ --scan-type \u0026#34;Nancy Scan\u0026#34; \\ --report-path \u0026#34;./examples/nancy_findings.json\u0026#34; \\ --test-id 11 \\ --verified \\ --active \\ --minimum-severity \u0026#34;info\u0026#34; \\ --tag \u0026#34;dev\u0026#34; --tag \u0026#34;tools\u0026#34; --tag \u0026#34;nancy\u0026#34; --tag \u0026#34;test-dev\u0026#34; \\ --test-version \u0026#34;1.0\u0026#34; \\ --auto-create-context\rCommands example, x Shows an example of required and optional flags for reimport operation\rOptions --active, -a\nDictates whether findings should be active on import. (default: true) [$DD_CLI_ACTIVE] --api-scan-configuration value, --asc value\nThe ID of the API Scan Configuration object to use when importing or reimporting. (default: 0) [$DD_CLI_API_SCAN_CONFIGURATION] --apply-tags-endpoints, --te\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the endpoints (default: false) [$DD_CLI_APPLY_TAGS_ENDPOINTS] --apply-tags-findings, --tf\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the findings (default: false) [$DD_CLI_APPLY_TAGS_FINDINGS] --auto-create-context, --acc\nIf set to true, the importer automatically creates Engagements, Products, and Product_Types (default: false) [$DD_CLI_AUTO_CREATE_CONTEXT] --deduplication-on-engagement, --doe\nIf set to true, the importer restricts deduplication for imported findings to the newly created Engagement. (default: false) [$DD_CLI_DEDUPLICATION_ON_ENGAGEMENT] --engagement-name value, -e value\nThe name of the Engagement to import findings into. [$DD_CLI_ENGAGEMENT_NAME] --minimum-severity value, --ms value\nDictates the lowest level severity that should be imported. Valid values are: Critical, High, Medium, Low, Info. (default: \u0026ldquo;Info\u0026rdquo;) [$DD_CLI_MINIMUM_SEVERITY] --product-name value, -p value\nThe name of the Product to import findings into. [$DD_CLI_PRODUCT_NAME] --product-type-name value, --pt value\nThe name of the Product Type to import findings into. [$DD_CLI_PRODUCT_TYPE_NAME] --report-path value, -r value\nThe path to the report to import. (required). [$DD_CLI_REPORT_PATH] --scan-type value, -s value\nThe scan type of the tool (required). [$DD_CLI_SCAN_TYPE] --tag value, -t value [ --tag value, -t value ]\nAny tags to be applied to the Test object [$DD_CLI_TAGS] --test-id value, --ti value\nThe ID of the Test to reimport findings into. (default: 0) [$DD_CLI_TEST_ID] --test-name value, --tn value\nThe name of the Test to import findings into - Defaults to the name of the scan type. [$DD_CLI_TEST_NAME] --test-version value, -V value\nThe version of the test. [$DD_CLI_TEST_VERSION] --verified, -v\nDictates whether findings should be set to Verified on import. (default: false) [$DD_CLI_VERIFIED] Settings:\n--config value, -c value\nThe path to the TOML configuration file is used to set values for the options. If the option is set in the configuration file and the CLI, the option will take the value set from the CLI. [$DD_CLI_CONFIG_FILE] --defectdojo-url value, -u value\nThe URL of the DefectDojo instance to import findings into. (required). [$DD_CLI_DEFECTDOJO_URL] --insecure-tls, --no-tls\nignore TLS validation errors when connecting to the provided DefectDojo instance. Most users should not enable this flag. (default: false) [$DD_CLI_INSECURE_TLS] Export Usage defectdojo-cli export \u0026lt;required options\u0026gt; [optional options] or: defectdojo-cli [global options] export --defectdojo-url \u0026lt;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026gt; --json ./output_file_path.json [optional filters] or: defectdojo-cli [global options] export --defectdojo-url \u0026lt;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026gt; --csv ./output_file_path.csv [optional filters] or: defectdojo-cli [global options] export --defectdojo-url \u0026lt;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026gt; --json ./output_file_path.json --csv ./output_file_path.csv [optional filters] or: defectdojo-cli [global options] export --config ./config-file-path or: defectdojo-cli [global options] export --config ./config-file-path --json ./output_file_path.json or: defectdojo-cli [global options] export --config ./config-file-path --csv ./output_file_path.csv or: defectdojo-cli export [-h | --help] or: defectdojo-cli export example [subcommand options] or: defectdojo-cli export example [-h | --help] \u0026gt;\u0026gt; The API token must be set in the environment variable `DD_CLI_API_TOKEN`.\rTo export Findings from DefectDojo-CLI, you will need to supply a configuration file which contains details explaining which Findings you wish to export. This is similar to the GET Findings method via the API.\nFor assistance use defectdojo-cli export --help.\nExport Example This example specifies the URL, export format and a few filter parameters to create a list of Findings.\ndefectdojo-cli export \\ --defectdojo-url \u0026#34;https://your-dojo-instance.cloud.defectdojo.com/\u0026#34; --json \u0026#34;./path/to/findings.json\u0026#34; \\ --active \u0026#34;true\u0026#34; \\ --created \u0026#34;Past 90 days\u0026#34;\rCommands example, x\nShows an example of required and optional flags for export operation help, h\nShows a list of commands or help for one command Options Findings Filters:\n--active true|false, -a true|false\nFindings by active status. [$DD_CLI_FINDINGS_FILTERS_ACTIVE] --created value\nFindings by created date. Supported values: None, Today, Past 7 days, Past 30 days, Past 90 days, Current month, Current year, Past year [$DD_CLI_FINDINGS_FILTERS_CREATED] --cvssv3-score value\nFindings by CVSS v3 score. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_CVSSV3_SCORE] --cwe value\nFindings by CWE ID. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_CWE] --date value\nFindings by date. Supported values: None, Today, Past 7 days, Past 30 days, Past 90 days, Current month, Current year, Past year [$DD_CLI_FINDINGS_FILTERS_DATE] --discovered-after value\nFindings by discovered after the specified date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_DISCOVERED_AFTER] --discovered-before value\nFindings by discovered before the specified date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_DISCOVERED_BEFORE] --discovered-on value\nFindings by discovered date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_DISCOVERED_ON] --duplicate true|false\nFindings by duplicated status. [$DD_CLI_FINDINGS_FILTERS_DUPLICATE] --engagement-ids value [ --engagement-ids value ]\nFindings by engagement IDs. This flag can be used multiple times or as a comma-separated list. [$DD_CLI_FINDINGS_FILTERS_ENGAGEMENT] --epss-percentile value\nFindings by EPSS percentile. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_EPSS_PERCENTILE] --epss-score value\nFindings by EPSS score. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_EPSS_SCORE] --false-positive true|false\nFindings by false positive status. [$DD_CLI_FINDINGS_FILTERS_FALSE_POSITIVE] --is-mitigated true|false\nFindings by mitigation status. [$DD_CLI_FINDINGS_FILTERS_IS_MITIGATED] --mitigated value\nFindings by the date range in which they were marked mitigated Supported values: None, Today, Past 7 days, Past 30 days, Past 90 days, Current month, Current year, Past year [$DD_CLI_FINDINGS_FILTERS_MITIGATED] --mitigated-after value\nFindings by mitigation after the specified date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_MITIGATED_AFTER] --mitigated-before value\nFindings by mitigation before the specified date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_MITIGATED_BEFORE] --mitigated-by-ids value [ --mitigated-by-ids value ]\nFindings by mitigated_by user IDs. This flag can be used multiple times or as a comma-separated list. Could be combined with \u0026ndash;mitigated-by-names. [$DD_CLI_FINDINGS_FILTERS_MITIGATED_BY_IDS] --mitigated-by-names value [ --mitigated-by-names value ]\nFindings by mitigated_by user names. This flag can be used multiple times or as a comma-separated list. Could be combined with \u0026ndash;mitigated-by-ids. [$DD_CLI_FINDINGS_FILTERS_MITIGATED_BY_NAMES] --mitigated-on value\nFindings by mitigation date. Format: YYYY-MM-DD [$DD_CLI_FINDINGS_FILTERS_MITIGATED_ON] --not-tags value [ --not-tags value ]\nFindings by tags that should not be present. This flag can be used multiple times or as a comma-separated list. [$DD_CLI_FINDINGS_FILTERS_NOT_TAGS] --out-of-scope true|false\nFindings by out of scope or in scope status. [$DD_CLI_FINDINGS_FILTERS_OUT_OF_SCOPE] --out-of-sla true|false\nFindings by outside or inside SLA status. [$DD_CLI_FINDINGS_FILTERS_OUT_OF_SLA] --product-name value\nFindings by product name. [$DD_CLI_FINDINGS_FILTERS_PRODUCT_NAME] --product-name-contains value\nFindings by product name contains. [$DD_CLI_FINDINGS_FILTERS_PRODUCT_NAME_CONTAINS] --product-type-ids value [ --product-type-ids value ]\nFindings by product type IDs. This flag can be used multiple times or as a comma-separated list. Could be combined with \u0026ndash;product-type-names [$DD_CLI_FINDINGS_FILTERS_PRODUCT_TYPE_IDS] --product-type-names value [ --product-type-names value ]\nFindings by product type names. This flag can be used multiple times or as a comma-separated list. Could be combined with \u0026ndash;product-type-ids [$DD_CLI_FINDINGS_FILTERS_PRODUCT_TYPE_NAMES] --risk-accepted true|false\nFindings by risk accepted status. [$DD_CLI_FINDINGS_FILTERS_RISK_ACCEPTED] --severity value [ --severity value ]\nFindings by severity. Valid values are: Critical, High, Medium, Low, Info. This flag can be used multiple times or as a comma-separated list. [$DD_CLI_FINDINGS_FILTERS_SEVERITY] --tags value [ --tags value ]\nFindings by tags that should be present. This flag can be used multiple times or as a comma-separated list. [$DD_CLI_FINDINGS_FILTERS_TAGS] --test-id value\nFindings by test ID. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_TEST_ID] --title-contains value\nFindings by containing the given string in their title. [$DD_CLI_FINDINGS_FILTERS_TITLE_CONTAINS] --under-review true|false\nFindings by under review status. [$DD_CLI_FINDINGS_FILTERS_UNDER_REVIEW] --verified true|false\nFindings by verified status. (default: ignored) [$DD_CLI_FINDINGS_FILTERS_VERIFIED] --vulnerability-id value [ --vulnerability-id value ]\nFindings by vulnerability ID. This flag can be used multiple times or as a comma-separated list. [$DD_CLI_FINDINGS_FILTERS_VULNERABILITY_ID] Findings Output\n--csv value\nPath of the file where the CSV file of the findings will be written. [$DD_CLI_FINDINGS_OUTPUT_CSV_PATH_FILE] --json value Path of the file where the JSON file of the findings will be written. [$DD_CLI_FINDINGS_OUTPUT_JSON_PATH_FILE]\nSettings\n--config value, -c value The path to the TOML configuration file is used to set values for the options. If the option is set in the configuration file and the CLI, the option will take the value set from the CLI. [$DD_CLI_CONFIG_FILE]\n--defectdojo-url value, -u value The URL of the DefectDojo instance to import findings into. (required). [$DD_CLI_DEFECTDOJO_URL]\n--insecure-tls, --no-tls ignore TLS validation errors when connecting to the provided DefectDojo instance. Most users should not enable this flag. (default: false) [$DD_CLI_INSECURE_TLS]\nExport Example: defectdojo-cli export \\ --defectdojo-url \u0026#34;https://your-dojo-instance.cloud.defectdojo.com/\u0026#34;\rInteractive Interactive mode allows you to configure import and reimport process, step-by-step.\nUsage defectdojo-cli interactive or: defectdojo-cli interactive [--skip-intro] [--no-full-screen] [--log-path] or: defectdojo-cli interactive [-h | --help]\rOptions --skip-intro Skip the intro screen (default: false) --no-full-screen\nDisable full screen mode (default: false) --log-path value\nPath to the log file --help, -h\nshow help Universal Importer universal-importer seamlessly integrates scan results into DefectDojo, streamlining both the import and reimport processes of findings and associated objects. Designed for ease of use, the tool supports various endpoints, catering to both initial imports and subsequent reimports ‚Äî ideal for users requiring robust and flexible interaction with the DefectDojo API.\nUsage of Universal Importer is similar to DefectDojo-CLI, however Universal Importer does not have the Export functionality, and environment variables are encoded differently.\nCommands import Imports findings into DefectDojo. reimport Reimports findings into DefectDojo. interactive Starts an interactive mode to configure the import and reimport process, step by Global Options --help, -h\nshow help --version, -v\nprint the version CLI Formatting --no-color\nDisable color output. (default: false) [$DD_IMPORTER_NO_COLOR] --no-emojis, --no-emoji\nDisable emojis in the output. (default: false) [$DD_IMPORTER_NO_EMOJIS] --verbose\nEnable verbose output. (default: false) [$DD_IMPORTER_VERBOSE] Import Use the import command to import new findings into DefectDojo.\nUsage defectdojo-cli [global options] import \u0026lt;required flags\u0026gt; [optional flags] or: defectdojo-cli [global options] import --config ./config-file-path or: defectdojo-cli import [-h | --help] or: defectdojo-cli import example [subcommand options] or: defectdojo-cli import example [-h | --help] \u0026gt;\u0026gt; The API token must be set in the environment variable `DD_IMPORTER_DOJO_API_TOKEN`.\rimport can import Findings in two ways:\nBy ID:\nCreate a Product (or use an existing product) Create an Engagement inside the product Provide the id of the Engagement in the engagement parameter In this scenario a new Test will be created inside the Engagement.\nBy Name:\nCreate a Product (or use an existing product) Create an Engagement inside the product Provide product-name Provide engagement-name Optionally provide product-type-name In this scenario DefectDojo will look up the Engagement by the provided details.\nWhen using names you can let the importer automatically create Engagements, Products and Product-types by using auto-create-context=true. You can use deduplication-on-engagement to restrict deduplication for imported Findings to the newly created Engagement.\nImport Basic syntax:\ndefectdojo-cli import [options]\rImport Example: defectdojo-cli import \\ --defectdojo-url \u0026#34;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026#34; \\ --scan-type \u0026#34;burp scan\u0026#34; \\ --report-path \u0026#34;./examples/burp_findings.xml\u0026#34; \\ --product-name \u0026#34;dev\u0026#34; \\ --engagement-name \u0026#34;dev\u0026#34; \\ --product-type-name \u0026#34;Research and Development\u0026#34; \\ --test-name \u0026#34;burp-test-dev\u0026#34; \\ --verified \\ --active \\ --minimum-severity \u0026#34;info\u0026#34; \\ --tag \u0026#34;dev\u0026#34; --tag \u0026#34;tools\u0026#34; --tag \u0026#34;burp\u0026#34; --tag \u0026#34;test-dev\u0026#34; \\ --test-version \u0026#34;0.0.1\u0026#34; \\ --auto-create-context\rCommands example, x\nShows an example of required and optional flags for import operation Options --active, -a\nDictates whether findings should be active on import. (default: true) [$DD_IMPORTER_ACTIVE] --api-scan-configuration value, --asc value\nThe ID of the API Scan Configuration object to use when importing or reimporting. (default: 0) [$DD_IMPORTER_API_SCAN_CONFIGURATION] --apply-tags-endpoints, --te\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the endpoints (default: false) [$DD_IMPORTER_APPLY_TAGS_ENDPOINTS] --apply-tags-findings, --tf\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the findings (default: false) [$DD_IMPORTER_APPLY_TAGS_FINDINGS] --auto-create-context, --acc\nIf set to true, the importer automatically creates Engagements, Products, and Product_Types (default: false) [$DD_IMPORTER_AUTO_CREATE_CONTEXT] --deduplication-on-engagement, --doe\nIf set to true, the importer restricts deduplication for imported findings to the newly created Engagement. (default: false) [$DD_IMPORTER_DEDUPLICATION_ON_ENGAGEMENT] --engagement-id value, --ei value\nThe ID of the Engagement to import findings into. (default: 0) [$DD_IMPORTER_ENGAGEMENT_ID] --engagement-name value, -e value\nThe name of the Engagement to import findings into. [$DD_IMPORTER_ENGAGEMENT_NAME] --minimum-severity value, --ms value\nDictates the lowest level severity that should be imported. Valid values are: Critical, High, Medium, Low, Info. (default: \u0026ldquo;Info\u0026rdquo;) [$DD_IMPORTER_MINIMUM_SEVERITY] --product-name value, -p value\nThe name of the Product to import findings into. [$DD_IMPORTER_PRODUCT_NAME] --product-type-name value, --pt value\nThe name of the Product Type to import findings into. [$DD_IMPORTER_PRODUCT_TYPE_NAME] --report-path value, -r value\nThe path to the report to import. (required). [$DD_IMPORTER_REPORT_PATH] --scan-type value, -s value\nThe scan type of the tool (required). [$DD_IMPORTER_SCAN_TYPE] --tag value, -t value [ --tag value, -t value ]\nAny tags to be applied to the Test object [$DD_IMPORTER_TAGS] --test-name value, --tn value\nThe name of the Test to import findings into - Defaults to the name of the scan type. [$DD_IMPORTER_TEST_NAME] --test-version value, -V value\nThe version of the test. [$DD_IMPORTER_TEST_VERSION] --verified, -v\nDictates whether findings should be verified on import. (default: false) [$DD_IMPORTER_VERIFIED] Settings:\n--config value, -c value\nThe path to the TOML configuration file is used to set values for the options. If the option is set in the configuration file and the CLI, the option will take the value set from the CLI. [$DD_IMPORTER_CONFIG_FILE] --defectdojo-url value, -u value The URL of the DefectDojo instance to import findings into. (required). [$DD_IMPORTER_DEFECTDOJO_URL] \u0026ndash;insecure-tls, \u0026ndash;no-tls ignore TLS validation errors when connecting to the provided DefectDojo instance. Most users should not enable this flag. (default: false) [$DD_IMPORTER_INSECURE_TLS] Reimport Use the reimport command to extend an existing Test with Findings from a new report in one of two ways:\nBy ID:\nCreate a Product (or use an existing product) Create an Engagement inside the product Import a scan report and find the id of the Test Provide this in the test-id parameter By Names:\nCreate a Product (or use an existing product) Create an Engagement inside the product Import a report which will create a Test Provide product-name Provide engagement-name Optional: Provide test-name In this scenario DefectDojo will look up the Test by the provided details. If no test-name is provided, the latest test inside the engagement will be chosen based on scan-type.\nWhen using names you can let the importer automatically create Engagements, Products and Product-types by using auto-create-context=true. You can use deduplication-on-engagement to restrict deduplication for imported Findings to the newly created Engagement.\nUsage defectdojo-cli [global options] reimport \u0026lt;required flags\u0026gt; [optional flags] or: defectdojo-cli [global options] reimport --config ./config-file-path or: defectdojo-cli reimport [-h | --help] or: defectdojo-cli reimport example [subcommand options] or: defectdojo-cli reimport example [-h | --help] \u0026gt;\u0026gt; The API token must be set in the environment variable `DD_IMPORTER_DOJO_API_TOKEN`.\rReimport Example: defectdojo-cli reimport \\ --defectdojo-url \u0026#34;https://YOUR_INSTANCE.cloud.defectdojo.com/\u0026#34; \\ --scan-type \u0026#34;Nancy Scan\u0026#34; \\ --report-path \u0026#34;./examples/nancy_findings.json\u0026#34; \\ --test-id 11 \\ --verified \\ --active \\ --minimum-severity \u0026#34;info\u0026#34; \\ --tag \u0026#34;dev\u0026#34; --tag \u0026#34;tools\u0026#34; --tag \u0026#34;nancy\u0026#34; --tag \u0026#34;test-dev\u0026#34; \\ --test-version \u0026#34;1.0\u0026#34; \\ --auto-create-context\rCommands example, x Shows an example of required and optional flags for reimport operation\rOptions --active, -a\nDictates whether findings should be active on import. (default: true) [$DD_IMPORTER_ACTIVE] --api-scan-configuration value, --asc value\nThe ID of the API Scan Configuration object to use when importing or reimporting. (default: 0) [$DD_IMPORTER_API_SCAN_CONFIGURATION] --apply-tags-endpoints, --te\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the endpoints (default: false) [$DD_IMPORTER_APPLY_TAGS_ENDPOINTS] --apply-tags-findings, --tf\nIf set to true, the tags (from the option \u0026ndash;tag) will be applied to the findings (default: false) [$DD_IMPORTER_APPLY_TAGS_FINDINGS] --auto-create-context, --acc\nIf set to true, the importer automatically creates Engagements, Products, and Product_Types (default: false) [$DD_IMPORTER_AUTO_CREATE_CONTEXT] --deduplication-on-engagement, --doe\nIf set to true, the importer restricts deduplication for imported findings to the newly created Engagement. (default: false) [$DD_IMPORTER_DEDUPLICATION_ON_ENGAGEMENT] --engagement-name value, -e value\nThe name of the Engagement to import findings into. [$DD_IMPORTER_ENGAGEMENT_NAME] --minimum-severity value, --ms value\nDictates the lowest level severity that should be imported. Valid values are: Critical, High, Medium, Low, Info. (default: \u0026ldquo;Info\u0026rdquo;) [$DD_IMPORTER_MINIMUM_SEVERITY] --product-name value, -p value\nThe name of the Product to import findings into. [$DD_IMPORTER_PRODUCT_NAME] --product-type-name value, --pt value\nThe name of the Product Type to import findings into. [$DD_IMPORTER_PRODUCT_TYPE_NAME] --report-path value, -r value\nThe path to the report to import. (required). [$DD_IMPORTER_REPORT_PATH] --scan-type value, -s value\nThe scan type of the tool (required). [$DD_IMPORTER_SCAN_TYPE] --tag value, -t value [ --tag value, -t value ]\nAny tags to be applied to the Test object [$DD_IMPORTER_TAGS] --test-id value, --ti value\nThe ID of the Test to reimport findings into. (default: 0) [$DD_IMPORTER_TEST_ID] --test-name value, --tn value\nThe name of the Test to import findings into - Defaults to the name of the scan type. [$DD_IMPORTER_TEST_NAME] --test-version value, -V value\nThe version of the test. [$DD_IMPORTER_TEST_VERSION] --verified, -v\nDictates whether findings should be set to Verified on import. (default: false) [$DD_IMPORTER_VERIFIED] Settings:\n--config value, -c value\nThe path to the TOML configuration file is used to set values for the options. If the option is set in the configuration file and the CLI, the option will take the value set from the CLI. [$DD_IMPORTER_CONFIG_FILE] --defectdojo-url value, -u value\nThe URL of the DefectDojo instance to import findings into. (required). [$DD_IMPORTER_DEFECTDOJO_URL] --insecure-tls, --no-tls\nignore TLS validation errors when connecting to the provided DefectDojo instance. Most users should not enable this flag. (default: false) [$DD_IMPORTER_INSECURE_TLS] Interactive Interactive mode allows you to configure import and reimport process, step-by-step.\nUsage defectdojo-cli interactive or: defectdojo-cli interactive [--skip-intro] [--no-full-screen] [--log-path] or: defectdojo-cli interactive [-h | --help]\rOptions --skip-intro Skip the intro screen (default: false) --no-full-screen\nDisable full screen mode (default: false) --log-path value Path to the log file --help, -h show help Troubleshooting If you encounter any issues with these tools, please check the following:\nEnsure you\u0026rsquo;re using the correct binary for your operating system and CPU architecture. Verify that the API key is set correctly in your environment variables. Check that the DefectDojo URL is correct and accessible. When importing, confirm that the report file exists and is in the supported format for the specified scan type. You can review the supported scanners for DefectDojo on our supported tools list. ","date":"0001-01-01","id":32,"permalink":"/en/connecting_your_tools/external_tools/","summary":"Note: The following external tools are DefectDojo Pro-only features. These binaries will not work unless they are connected to an instance with a DefectDojo Pro license.","tags":[],"title":"External Tools: Universal Importer \u0026 DefectDojo-CLI (Pro)"},{"content":"Tags In DefectDojo, tags are a first class citizen and are recognized as the facilitators of organization within each level of the data model. Tags are ideal for grouping objects in a manner that can be filtered out into smaller, more digestible chunks.\nHere is an example with a product with two tags and four findings each with a single tag\nFormat of tag Tags can be formatted in any of the following ways:\nStringWithNoSpaces string-with-hyphens string_with_underscores colons:acceptable \u0026ldquo;quoted string with spaces\u0026rdquo; Adding and Removing Tags can be managed in the following ways\nCreating or Editing new objects\nWhen a new object is created or edited through the UI or API, there is a field for specifying the tags to be set on a given object. This field is a multiselect field that also has auto completion to make searching and adding existing tags a breeze. Here is what the field looks like on the product from the screenshot in the previous section:\nImport and Reimport\nTags can also be applied to a given test at the time of import or reimport. This is a very handy use case when importing via the API with automation as it provides an opportunity to append automation run details and tool information that may not be captured in the test or finding object directly.\nThe field looks and behaves exactly as it does on a given object\nBulk Edit Menu (Findings only)\nWhen needing to update many findings with the same set of tags, the bulk edit menu can be used to ease the burden.\nIn the following example, lets say I want to update the tags of the two findings with the tag \u0026ldquo;tag-group-alpha\u0026rdquo; to be a new tag list like this [\u0026ldquo;tag-group-charlie\u0026rdquo;, \u0026ldquo;tag-group-delta\u0026rdquo;]. First I would select the tags to be updated:\nOnce a finding is selected, a new button appears with the name \u0026ldquo;Bulk Edit\u0026rdquo;. Clicking this button produces a dropdown menu with many options, but the focus is just on tags for now. Update the field to have the desired tag list as follows, and click submit\nThe tags on the selected Findings will be updated to whatever was specified in the tags field within the bulk edit menu\nFiltering Tags can be filtered in many ways through both the UI and the API. For example, here is a snippet of the Finding filters:\nThere are ten fields related to tags:\nTags: filter on any tags that are attached to a given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;B\u0026rdquo; Finding Will not be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;F\u0026rdquo; Not Tags: filter on any tags that are not attached to a given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;F\u0026rdquo; Finding Will not be returned Finding Tags: [\u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;] Filter Query: \u0026ldquo;B\u0026rdquo; Tag Name Contains: filter on any tags that contain part or all of the query in the given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;et\u0026rdquo; (part of \u0026ldquo;Beta\u0026rdquo;) Finding Will not be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;meg\u0026rdquo; (part of \u0026ldquo;Omega\u0026rdquo;) Not Tags: filter on any tags that do not contain part or all of the query in the given Finding Examples: Finding will be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;meg\u0026rdquo; (part of \u0026ldquo;Omega\u0026rdquo;) Finding Will not be returned Finding Tags: [\u0026ldquo;Alpha\u0026rdquo;, \u0026ldquo;Beta\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;] Filter Query: \u0026ldquo;et\u0026rdquo; (part of \u0026ldquo;Beta\u0026rdquo;) For the other six tag filters, they follow the same rules as \u0026ldquo;Tags\u0026rdquo; and \u0026ldquo;Not Tags\u0026rdquo; as above, but at different levels in the data model:\nTags (Test): filter on any tags that are attached to the Test of a given Finding is part of Not Tags (Test): filter on any tags that are not attached to the Test of a given Finding is part of Tags (Engagement): filter on any tags that are attached to the Engagement of a given Finding is part of Not Tags (Engagement): filter on any tags that are not attached to the Engagement of a given Finding is part of Tags (Product): filter on any tags that are attached to the Product of a given Finding is part of Not Tags (Product): filter on any tags that are not attached to the Product of a given Finding is part of Tag Inheritance When enabled, tags applied to a given product will automatically be applied to all objects under Products in the Product Hierarchy.\nConfiguration Tag Inheritance can be enabled at the following scope levels:\nGlobal Scope Every product system wide will begin applying tags to all children objects This is set within the System Settings Product Scope Only the selected product will begin applying tags to all children objects This is set at the product creation/edit page Behaviors Tags can be added and removed to other objects the same as when tag inheritance is disabled. The only exception to that rule being inherited tags as they cannot be removed from an object. See the following example of adding a tag \u0026ldquo;test_only_tag\u0026rdquo; to the Test object and a tag \u0026ldquo;engagement_only_tag\u0026rdquo; to the Engagement.\nWhen updates are made to the tag list on a product, the same changes are made to all objects within the product asynchronously. The duration of this task directly correlates to the number the objects contained within a finding. If the results are not observed within a reasonable time period, consult the celery worker logs to identify where any problems might have arisen.\nRisk Acceptance Findings cannot always be remediated or addressed for various reasons. A finding 'status' can be change to 'accepted' by doing the following: Findings are accepted in the engagement view. To locate the engagement from the finding click the link to engagement as shown below.\nThen, in the engagement view click the plus icon in the 'Risk Acceptance' box and fill in the details to support the risk acceptance.\nThe engagement view is now updated with the risk.\nThe finding status changes to 'Accepted' with a link to the risk acceptance.\nDeduplication Deduplication is a feature that when enabled will compare findings to automatically identify duplicates. When deduplication is enabled, a list of deduplicated findings is added to the engagement view. The following image illustrates the option deduplication on engagement and deduplication on product level:\nUpon saving a finding, DefectDojo will look at the other findings in the product or the engagement (depending on the configuration) to find duplicates\nWhen a duplicate is found:\nThe newly imported finding takes status: inactive, duplicate An \u0026quot;Original\u0026quot; link is displayed after the finding status, leading to the original finding There are two ways to use the deduplication:\nDeduplicate vulnerabilities in the same build/release. The vulnerabilities may be found by the same scanner (same scanner deduplication) or by different scanners (cross-scanner deduplication). this helps analysis and assessment of the technical debt, especially if using many different scanners; although detecting duplicates across scanners is not trivial as it requires a certain standardization. Track unique vulnerabilities across builds/releases so that DefectDojo knows when it finds a vulnerability that has seen it before. this allows you keep information attached to a given finding in a unique place: all further duplicate findings will point to the original one.\nDeduplication configuration Global configuration The deduplication can be activated in \u0026quot;System Settings\u0026quot; by ticking \u0026quot;Deduplicate findings\u0026quot;.\nAn option to delete duplicates can be found in the same menu, and the maximum number of duplicates to keep for the same finding can be configured.\nEngagement configuration When creating or editing an engagement, the \u0026quot;Deduplication within engagement only\u0026quot; checkbox can be ticked.\nIf activated: Findings are only deduplicated within the same engagement. Findings present in different engagements cannot be duplicates Otherwise: Findings are deduplicated across the whole product Note that currently deduplication does not occur across different products.\nDeduplication algorithms The behavior of the deduplication can be configured for each parser in settings.dist.py (or settings.py after install) by configuring the DEDUPLICATION_ALGORITHM_PER_PARSER variable, or via the env variable (useful for Kubernetes deployments) DD_DEDUPLICATION_ALGORITHM_PER_PARSER with a JSON string like\n{\u0026#34;ScannerName\u0026#34;:\u0026#34;algorithm\u0026#34;}\rThe environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe available algorithms are:\nDEDUPE_ALGO_UNIQUE_ID_FROM_TOOL (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: unique_id_from_tool) The deduplication occurs based on finding.unique_id_from_tool which is a unique technical id existing in the source tool. Few scanners populate this field currently. If you want to use this algorithm, you may need to update the scanner code beforehand. Advantages: If your source tool has a reliable means of tracking a unique vulnerability across scans, this configuration will allow defectDojo to use this ability. Drawbacks: Using this algorithm will not allow cross-scanner deduplication as other tools will have a different technical id. When the tool evolves, it may change the way the unique id is generated. In that case you won't be able to recognise that findings found in previous scans are actually the same as the new findings. DEDUPE_ALGO_HASH_CODE (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: hash_code) The deduplication occurs based on finding.hash_code. The hash_code itself is configurable for each scanner in parameter HASHCODE_FIELDS_PER_SCANNER. DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: unique_id_from_tool_or_hash_code) A finding is a duplicate with another if they have the same unique_id_from_tool OR the same hash_code. Allows to use both a technical deduplication (based on unique_id_from_tool) for a reliable same-parser deduplication and a functional one (based on hash_code configured on CWE+severity+file_path for example) for cross-parser deduplication DEDUPE_ALGO_LEGACY (value for DD_DEDUPLICATION_ALGORITHM_PER_PARSER: legacy) This is algorithm that was in place before the configuration per parser was made possible, and also the default one for backward compatibility reasons. Legacy algorithm basically deduplicates based on: For static scanner: ['title', 'cwe', 'line', 'file_path', 'description'] For dynamic scanner: ['title', 'cwe', 'line', 'file_path', 'description', 'endpoints'] Note that there are some subtleties that may give unexpected results. Switch dojo.specific-loggers.deduplication to debug in settings.py to get more info in case of trouble.\nHash_code computation configuration The hash_code computation can be configured for each parser using the parameter HASHCODE_FIELDS_PER_SCANNER in settings.dist.py, or via the env variable (useful for Kubernetes deployments) DD_HASHCODE_FIELDS_PER_SCANNER with a JSON string like\n{\u0026#34;ScannerName\u0026#34;:[\u0026#34;field1\u0026#34;, \u0026#34;field2\u0026#34;]}\rThe environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe parameter HASHCODE_ALLOWED_FIELDS list the fields from finding table that were tested and are known to be working when used as a hash_code. Don't hesitate to enrich this list when required (the code is generic and allows adding new fields by configuration only)\nNote that endpoints isn't a field from finding table but rather a meta value that will trigger a computation based on all the endpoints.\nWhen populating HASHCODE_FIELDS_PER_SCANNER, please respect the order of declaration of the fields: use the same order as in HASHCODE_ALLOWED_FIELDS: that will allow cross-scanner deduplication to function because the hash_code is computed as a sha-256 of concatenated values of the configured fields.\nTips:\nIt's advised to use fields that are standardized for a reliable deduplication, especially if aiming at cross-scanner deduplication. For example title and description tend to change when the tools evolve and don't allow cross-scanner deduplication\nGood candidates are cwe or cve Adding the severity will make sure the deduplication won't be to aggressive (there are several families of XSS and sql injection for example, with various severities but the same cwe). Adding the file_path or endpoints is advised too. The parameter HASHCODE_ALLOWS_NULL_CWE will allow switching to legacy algorithm when a null cwe is found for a given finding: this is to avoid getting many duplicates when the tool fails to give a cwe while we are expecting it.\nHashcode generation / regeneration When you change the hashcode configuration, it is needed to regenerated the hashcodes for all findings, or at least those findings found by scanners for which the configuration was updated.\nThis is sometimes also needed after an upgrade to a new DefectDojo version, for example when we made changes to the hashcode configuration or calculation logic. We will mention this in the upgrade notes.\nTo regenerate the hashcodes, use the dedupe management command:\ndocker compose exec uwsgi ./manage.py dedupe --hash_code_only This will only regenerated the hashcodes, but will not run any deduplication logic on existing findings. If you want to run deduplication again on existing findings to make sure any duplicates found by the new hashcode config are marked as such, run:\ndocker compose exec uwsgi ./manage.py dedupe The deduplication part of this command will run the deduplication for each finding in a celery task. If you want to run the deduplication in the foreground process, use:\ndocker compose exec uwsgi ./manage.py dedupe --dedupe_sync Please note the deduplication process is resource intensive and can take a long time to complete (estimated ~7500 findings per minute when run in the foreground)\nDebugging deduplication There is a specific logger that can be activated in order to have details about the deduplication process : switch dojo.specific-loggers.deduplication to debug in settings.dist.py.\nDeduplication - APIv2 parameters close_old_findings : if true, findings that are not duplicates and that were in the previous scan of the same type (example ZAP) for the same engagement (or product in case of \u0026quot;close_old_findings_product_scope\u0026quot;) and that are not present in the new scan are closed (Inactive, Verified, Mitigated). close_old_findings_product_scope : if true, close_old_findings applies to all findings of the same type in the product. Note that \u0026quot;Deduplication on engagement\u0026quot; is no longer used to determine the scope of close_old_findings. Deduplication / Similar findings Similar Findings Visualization:\nSimilar Findings While viewing a finding, similar findings within the same product are listed along with buttons to mark one finding a duplicate of the other. Clicking the \u0026quot;Use as original\u0026quot; button on a similar finding will mark that finding as the original while marking the viewed finding as a duplicate. Clicking the \u0026quot;Mark as duplicate\u0026quot; button on a similar finding will mark that finding as a duplicate of the viewed finding. If a similar finding is already marked as a duplicate, then a \u0026quot;Reset duplicate status\u0026quot; button is shown instead which will remove the duplicate status on that finding along with marking it active again. Service Level Agreement (SLA) DefectDojo allows you to maintain your security SLAs and automatically remind teams whenever a SLA is about to get breached, or is breached.\nTo apply SLAs to Findings, open the System Settings page and check \u0026lsquo;Enable Finding SLAs\u0026rsquo;.\nYou will then need to create one or more SLA Configurations, from the SLA Configuration menu (your-defectdojo.com/sla_config).\nSLA notification configuration There are 3 variables in the system settings that can be set for notifications of SLA breaches. By default notifications are disabled. You can either choose to notify about breaches for findings that are only in \u0026lsquo;Active\u0026rsquo; or for any findings across the instance that are in Active, Verified. Furthermore, it is possible choose to only consider findings that have a JIRA issue linked to them.\nThere are 2 variables in the settings.py file that you can configure, to act on the global behavior.\nSLA_NOTIFY_PRE_BREACH = 3 SLA_NOTIFY_POST_BREACH = 7 The SLA_NOTIFY_PRE_BREACH is expressed in days. Whenever a finding's \u0026quot;SLA countdown\u0026quot; (time to remediate) drops to this number, a notification would be sent everyday, as scheduled by the crontab in settings.py, until the day it breaches.\nThe SLA_NOTIFY_POST_BREACH lets you define in days how long you want to be kept notified about findings that have breached the SLA. Passed that number, notifications will cease.\nBe mindful of performance if you choose to have SLA notifications on non-verified findings, especially if you import a lot of findings through CI in 'active' state.\nWhat notification channels for SLA notifications? You will notice that an extra SLA breach option is now present on the Notification page and also in the Product view.\nSLA notification with JIRA You can choose to also send SLA notification as JIRA comments, if your product is configured with JIRA. You can enable this at the Product level in the Product specific JIRA settings.\nThe Product level JIRA notification configuration takes precendence over the global JIRA notification configuration.\nWhen is the SLA notification job run? The default setup will trigger the SLA notification code at 7:30am on a daily basis, as defined in the settings.py file. You can of course modify this schedule to your context.\n\u0026#39;compute-sla-age-and-notify\u0026#39;: { \u0026#39;task\u0026#39;: \u0026#39;dojo.tasks.async_sla_compute_and_notify\u0026#39;, \u0026#39;schedule\u0026#39;: crontab(hour=7, minute=30), } The celery containers are the ones concerned with this configuration. If you suspect things are not working as expected, make sure they have the latest version of your settings.py file.\nYou can of course change this default by modifying that stanza.\nLaunching from the CLI You can also invoke the SLA¬†notification function from the CLI. For example, if run from docker compose:\n$ docker compose exec uwsgi /bin/bash -c \u0026#39;python manage.py sla_notifications\u0026#39; Reports Instant reports Instant reports can be generated for:\nProduct types Products Engagements Tests List of Findings Endpoints Filtering is available on all report generation views to aid in focusing the report for the appropriate need.\nCustom reports Custom reports, generated with the Report Builder, allow you to select specific components to be added to the report. These include:\nCover Page Table of Contents WYSIWYG Content Findings Vulnerable Endpoints Page Breaks DefectDojo\u0026rsquo;s reports can be generated in HTML.\nMetrics DefectDojo provides a number of metrics visualization in order to help with reporting, awareness and to be able to quickly communicate a products/product type's security stance.\nThe following metric views are provided:\nProduct Type Metrics This view provides graphs displaying Open Bug Count by Month, Accepted Bug Count by Month, Open Bug Count by Week, Accepted Bug Count by Week as well as tabular data on Top 10 Products by bug severity, Detail Breakdown of all reported findings, Opened Findings, Accepted Findings, Closed Findings, Trending Open Bug Count, Trending Accepted Bug Count, and Age of Issues. Product Type Counts This view provides tabular data of Total Current Security Bug Count, Total Security Bugs Opened In Period, Total Security Bugs Closed In Period, Trending Total Bug Count By Month, Top 10 By Bug Severity, and Open Findings. This view works great for communication with stakeholders as it is a snapshot in time of the product. Product Tag Counts Same as above, but for a group of products sharing a tag. Simple Metrics Provides tabular data for all Product Types. The data displayed in this view is the total number of S0, S1, S2, S3, S4, Opened This Month, and Closed This Month. Engineer Metrics Provides graphs displaying information about a tester's activity. Metrics Dashboard Provides a full screen, auto scroll view with many metrics in graph format. This view is great for large displays or \u0026quot;Dashboards.\u0026quot; Users DefectDojo users inherit from django.contrib.auth.models.User.\nA username, first name, last name, and email address can be associated with each user. Additionally the following attributes describe the type of users:\nActive Designates whether this user should be treated as active and can login to DefectDojo. Unselect this instead of deleting accounts. Superuser status Designates that this user can configure the system and has all permissions for objects without explicitly assigning them. A superuser may force a password reset for any user at any given time. This can be set when creating a new user, or when editing an existing one, requiring the user to change their password upon their next login.\nDefectDojo enforces the following password rules for all users:\nMust meet a length requirement of 9 characters Must be unique (not commonly used) Must contain one of each of the following: a number (0-9), uppercase letter (A-Z), lowercase letter (a-z), and symbol ()[]{}|~!@#$%^\u0026amp;*_-+=;:`\u0026rsquo;\u0026quot;,\u0026lt;\u0026gt;./? Calendar The calendar view provides a look at all the engagements and tests occurring during the month d, week or day displayed. Each entry is a direct link to the respective engagement or test view page.\nBenchmarks DefectDojo utilizes the OWASP ASVS Benchmarks to benchmark a product to ensure the product meets your application technical security controls. Benchmarks can be defined per the organizations policy for secure development and multiple benchmarks can be applied to a product.\nBenchmarks are available from the Product view. To view the configured benchmarks select the dropdown menu from the right hand drop down menu. You will find the selection near the bottom of the menu entitled: 'OWASP ASVS v.3.1'.\nIn the Benchmarks view for each product, the default level is ASVS Level\nOn the top right hand side the drop down can be changed to the desired ASVS level (Level 1, Level 2 or Level 3). The publish checkbox will display the ASVS score on the product page and in the future this will be applied to reporting. On the left hand side the ASVS score is displayed with the desired score, the % of benchmarks passed to achieve the score and the total enabled benchmarks for that AVSV level.\nAdditional benchmarks can be added/updated in the Django admin site. In a future release this will be brought out to the UI.\nEndpoint Meta Importer For heavy infrastructure scanning organizations, endpoints need to be as flexible as possible to get the most of DefectDojo. This flexibility comes in the form of Tags and custom fields. Tags allow users to filter, sort, and report objects in ways the base object is not totally proficient in doing.\nEndpoint Meta Importer provides a means to apply arbitrary tags and custom fields to endpoints in mass via a CSV file. Tags and customs fields are stored in the format of column:row.\nHere is a very simple example with only two columns:\nhostname | team | public_facing ------------------------------------------------------------------ sheets.google.com | data analytics | yes docs.google.com | language processing | yes feedback.internal.google.com | human resources | no\rThe three endpoints hosts will be used to find existing endpoints with matching hosts, or create new endpoints, and then apply meta as follows:\nsheets.google.com (endpoint) -\u0026gt; [ team:data analytics, public_facing:yes ] (tags) docs.google.com (endpoint) -\u0026gt; [ team:language processing, public_facing:yes ] (tags) feedback.internal.google.com (endpoint) -\u0026gt; [ team:human resources, public_facing:no ] (tags)\rEndpoint Meta Importer can be found in the Endpoint tab when viewing a Product\nNote: The field \u0026ldquo;hostname\u0026rdquo; is required as it is used to query/create endpoints.\nFindings Image Upload You can add images (.png, .jpeg, .gif) to your findings. In order to achieve this, you have to click on \u0026ldquo;Manage Files\u0026rdquo; within the finding: There, you can upload a png file to attach it to a finding: The following picture shows the result: ","date":"0001-01-01","id":33,"permalink":"/en/open_source/archived_docs/usage/features/","summary":"Tags In DefectDojo, tags are a first class citizen and are recognized as the facilitators of organization within each level of the data model.","tags":[],"title":"Features"},{"content":"Each Finding created in DefectDojo has a Status which communicates relevant information. Statuses help your team keep track of their progress in resolving issues.\nEach Finding status has a context-specific meaning which will need to be defined by your own team. These are our suggestions, but your team\u0026rsquo;s usage may vary.\nActive Findings ‚ÄòThis Finding has been discovered by a scanning tool.‚Äô\nBy default, any new Finding created in DefectDojo will be labeled as Active. Active in this case means ‚Äòthis is a new Finding that DefectDojo has not recorded on a past import‚Äô. If a Finding has been Mitigated in the past, but appears in a scan again in the future, the status of that Finding will reopen to reflect that the vulnerability has returned.\nVerified Findings ‚ÄòThis Finding has been confirmed by our team to exist.‚Äô\nJust because a tool records a problem does not necessarily mean the Finding requires engineering attention. Therefore, new Findings are also labeled as Unverified by default.\nIf you‚Äôre able to confirm that the Finding does exist, you can mark it as Verified.\nIf you don‚Äôt need to manually verify each Finding, you can automatically mark them as Verified during import, or disregard this Status.\nOpen Findings ‚ÄòThere is work to be done on these Findings.‚Äô\nOnce a Finding is Active, it will be labeled as an Open Finding, regardless of whether or not it has been Verified.\nOpen Findings can be seen from the Findings \u0026gt; Open Findings view of DefectDojo.\nClosed Findings \u0026lsquo;The Vulnerability recorded here is no longer active‚Äô.\nOnce the work on a Finding is complete, you can manually Close it from the Close Findings option. Alternatively, if a scan is re-imported into DefectDojo which does not contain a previously-recorded Finding, the previously-recorded Finding will automatically close.\nUnder Review ‚ÄòI have sent this Finding to one or more team members to look at.‚Äô\nWhen a Finding is Under Review, it needs to be reviewed by a team member. You can put a Finding under review by Selecting Request Peer Review from the Finding‚Äôs drop-down menu.\nRisk Accepted ‚ÄòOur team has evaluated the risk associated with this Finding, and we‚Äôve agreed that we can safely delay fixing it.‚Äô\nFindings cannot always be remediated or addressed for various reasons. You can add a Risk Acceptance to a Finding with the Add Risk Acceptance option. Risk Acceptances allow you to upload files and enter notes to support a Risk Acceptance decision.\nRisk Acceptances have expiry dates, at which time you can reevaluate the impact of the Finding and decide what to do next.\nFor more information on Risk Acceptances, see our Guide.\nOut Of Scope ‚ÄòThis Finding was discovered by our scanning tool, but detecting this kind of vulnerability was not the direct goal of our test.‚Äô\nWhen you mark a Finding as Out Of Scope, you are indicating that it is not directly relevant to the Engagement or Test it is contained within.\nIf you have a testing and remediation effort related to a specific aspect of your software, you can use this Status to indicate that this Finding is not part of your effort.\nFalse Positive ‚ÄòThis Finding was discovered by our scanning tool, but after reviewing the Finding we have discovered that this reported vulnerability does not exist.‚Äô\nOnce you‚Äôve reviewed a Finding, you might discover that the vulnerability reported does not actually exist. The False Positive status allows DefectDojo to keep track of this information, and future imports will also apply the False Positive status to this Finding.\nIf a different scanning tool finds a similar Finding, it will not be recorded as a False Positive. DefectDojo can only compare Findings within the same tool to determine if a Finding has already been recorded.\nInactive ‚ÄòThis Finding was discovered previously but it was either mediated or does not require immediate attention.‚Äô\nIf a Finding is marked as Inactive, this means that the issue currently has no impact on the software environment and does not need to be addressed. This status does not necessarily mean that the issue has been resolved.\n","date":"0001-01-01","id":34,"permalink":"/en/working_with_findings/findings_workflows/finding_status_definitions/","summary":"Each Finding created in DefectDojo has a Status which communicates relevant information. Statuses help your team keep track of their progress in resolving issues.","tags":[],"title":"Finding Status Definitions"},{"content":"You can use Generic Findings Import as a method to ingest JSON or CSV files into DefectDojo which are not already in the supported parsers list.\nFiles uploaded using Generic Findings Import must conform to the accepted format with respect to CSV column headers / JSON attributes.\nThese attributes are supported for CSV:\nDate: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value. epss_score: The probability of exploitation in the next 30 days, must be a float value between 0 and 1.0. epss_percentile: The proportion of all scored vulnerabilities with the same or a lower EPSS score, must be a float value between 0 and 1.0. Url: Url associated with the finding. Severity: Severity of the finding. Must be one of Info, Low, Medium, High, or Critical. Description: Description of the finding. Can be multiple lines if enclosed in double quotes. Mitigation: Possible Mitigations for the finding. Can be multiple lines if enclosed in double quotes. Impact: Detailed impact of the finding. Can be multiple lines if enclosed in double quotes. References: References associated with the finding. Can be multiple lines if enclosed in double quotes. Active: Indicator if the finding is active. Must be empty, TRUE or FALSE Verified: Indicator if the finding has been verified. Must be empty, TRUE, or FALSE FalsePositive: Indicator if the finding is a false positive. Must be TRUE, or FALSE. Duplicate: Indicator if the finding is a duplicate. Must be TRUE, or FALSE The CSV expects a header row with the names of the attributes.\nExample of JSON format:\n{ \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as dict\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36234\u0026#34;, \u0026#34;cwe\u0026#34;: 261, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/first.cpp\u0026#34;, \u0026#34;line\u0026#34;: 13, \u0026#34;endpoints\u0026#34;: [ { \u0026#34;host\u0026#34;: \u0026#34;exemple.com\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as strings\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36235\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/two.cpp\u0026#34;, \u0026#34;line\u0026#34;: 135, \u0026#34;endpoints\u0026#34;: [ \u0026#34;http://urlfiltering.paloaltonetworks.com/test-command-and-control\u0026#34;, \u0026#34;https://urlfiltering.paloaltonetworks.com:2345/test-pest\u0026#34; ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36236\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/threeeeeeeeee.cpp\u0026#34;, \u0026#34;line\u0026#34;: 1353 } ] }\rThis parser supports an attributes that accept files as Base64 strings. These files are attached to the respective findings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Vuln with image\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;files\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Screenshot from 2017-04-10 16-54-19.png\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;iVBORw0KGgoAAAANSUhEUgAABWgAAAK0CAIAAAARSkPJAAAAA3N\u0026lt;...\u0026gt;TkSuQmCC\u0026#34; } ] } ] }\rThis parser supports an attribute name and type to be able to define TestType. Based on this, you can define custom HASHCODE_FIELDS or DEDUPLICATION_ALGORITHM in the settings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;My custom Test type\u0026#34;, \u0026#34;findings\u0026#34;: [ ] }\rSample Scan Data Sample Generic Findings Import scans can be found here.\n","date":"0001-01-01","id":35,"permalink":"/en/connecting_your_tools/parsers/generic_findings_import/","summary":"You can use Generic Findings Import as a method to ingest JSON or CSV files into DefectDojo which are not already in the supported parsers list.","tags":[],"title":"Generic Findings Import"},{"content":"Recommended Options Docker Compose See instructions in DOCKER.md\nSaaS (Includes Support \u0026amp; Supports the Project) SaaS link\nOptions for the brave (not officially supported) Kubernetes See instructions in KUBERNETES.md\nLocal install with godojo See instructions in README.md in the godojo repository\nCustomizing of settings See Configuration\n","date":"0001-01-01","id":36,"permalink":"/en/open_source/installation/installation/","summary":"Recommended Options Docker Compose See instructions in DOCKER.md\nSaaS (Includes Support \u0026amp; Supports the Project) SaaS link\nOptions for the brave (not officially supported) Kubernetes See instructions in KUBERNETES.","tags":[],"title":"Installation (Open-Source)"},{"content":"If you have a team of users working in DefectDojo, it\u0026rsquo;s important to set up Role-Based Access Control (RBAC) appropriately so that users can only access specific data. Security data is highly sensitive, and DefectDojo\u0026rsquo;s options for access control allow you to be specific about each team member‚Äôs access to information.\nThis article is an overview of how permissions in DefectDojo work. If you would prefer to see a detailed breakdown of each action that can be controlled by Permissions, see our Permissions Chart article.\nTypes of Permissions DefectDojo manages four different kinds of permissions:\nUsers can be assigned as Members to Products or Product Types. A Product Membership comes with a Role which allows your users to view and interact with Data Types (Product Types, Products, Engagements, Tests and Findings) in DefectDojo. Users can have multiple Product or Product Type memberships, with different levels of access.\n‚Äã Users can also have Configuration Permissions assigned, which allow them to access configuration pages in DefectDojo. Configuration Permissions are not related to Products or Product Types, and are not associated with Roles.\n‚Äã Users can be assigned Global Roles, which give them a standardized level of access to all Products and Product Types.\n‚Äã Users can be set up as Superusers: administrator level roles which give them control and access to all DefectDojo data and configuration. Each of these Permission types can also be assigned to User Group. If you have a large number of users in DefectDojo, such as a dedicated testing team for a particular Product, Groups allow you to set up and maintain permissions quickly.\nProduct/Product Type Membership \u0026amp; Roles When users are assigned as members to a Product or Product Type, they also receive a role which controls how they interact with the associated Finding data.\nRole Summaries Users can be assigned a role of Reader, Writer, Maintainer, Owner or API Importer, either globally or within a Product / Product Type.\n‚ÄòUnderlying data‚Äô refers to all Products, Engagements, Tests, Findings or Endpoints nested under a Product, or Product Type.\nReader Users can view underlying data on any Product or Product Type they are assigned to, and add comments. They cannot edit, add or otherwise modify any of the underlying data, but they can export Reports and add Notes to data.\n‚Äã Writer Users have all Reader abilities, plus the ability to Add or Edit Engagements, Tests and Findings. They cannot add new Products, and they cannot Delete any underlying data.\n‚Äã Maintainer Users have all Writer abilities, plus the ability to edit Product or Product Types. They can add new Members with Roles to the Product or Product Type, and they can also Delete Engagements, Tests, and Findings.\n‚Äã Owner Users have the greatest amount of control over a Product or Product Type. They can designate other Owners, and can also Delete the Products or Product Types they‚Äôre assigned to.\n‚Äã API Importer Users have limited abilities. This Role allows limited API access without exposing the majority of the API endpoints, so is useful for automation or users who are meant to be ‚Äòexternal‚Äô to DefectDojo. They can view underlying data, Add / Edit Engagements, and Import Scan Data. For detailed information on Roles, please see our Role Permission Chart.\nGlobal Roles Users with Global Roles can view and interact with any Data Type (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on their assigned Role.\nGroup Memberships User Groups can be added as Members of a Product or Product Type. Users who are part of the Group will inherit access to all associated Products or Product Types, and will inherit the Role assigned to the Group.\nUsers with multiple roles If a User is assigned as a member of a Product, they are not granted any associated Product Type permissions by default.\nA User\u0026rsquo;s Product Role always supersedes their \u0026lsquo;default\u0026rsquo; Product Type Role.\n‚Äã\nA User\u0026rsquo;s Product / Product Type Role always supersedes their Global Role within the underlying Product or Product Type. For example, if a User has a Product Type Role of Reader, but is also assigned as an Owner on a Product nested under that Product Type, they will have additional Owner permissions added for that Product only.\n‚Äã\nRoles cannot take away permissions, they can only add additional ones. For example, If a User has a Product Type Role or Global Role of Owner, assigning them a Reader role on a particular Product will not take away their Owner permissions on that Product.\n‚Äã\nSuperuser status always supersedes any Roles assigned.\nSuperusers Superusers (Admins) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. They can also change access rules for all users in DefectDojo. Superusers will also receive notifications for all system issues and alerts.\nBy default, the first account created on a new DefectDojo instance will have Superuser permissions. That user will be able to edit permissions for all subsequent DefectDojo users. Only an existing Superuser can add another superuser, or add a Global Role to a user.\nConfiguration Permissions Configuration Permissions, although similar, are not related to Products or Roles. They must be assigned separately from Roles. Regular users do not have any Configuration Permissions by default, and assigning these configuration permissions should be done carefully.\nUsers can have Configuration Permissions assigned in different ways:\nUsers can be assigned Configuration Permissions directly. Specific permissions can be configured directly on a User page.\nUser Groups can be assigned Configuration Permissions. As with Roles, specific Configuration Permissions can be added to Groups, which will give all Group members these permissions.\nSuperusers have all Configuration Permissions, so they do not have a Configuration Permission section on their User page.\nGroup Configuration Permissions If users are part of a Group, they also have Group Configuration Permissions which control their level of access to a Group‚Äôs configuration. Group Permissions do not correspond to the Group‚Äôs Product or Product Type membership.\nIf users create a new Group, they will be given the Owner role of the new Group by default.\nFor more information on Configuration Permissions, see our Configuration Permissions Chart.\n","date":"0001-01-01","id":37,"permalink":"/en/customize_dojo/user_management/about_perms_and_roles/","summary":"If you have a team of users working in DefectDojo, it\u0026rsquo;s important to set up Role-Based Access Control (RBAC) appropriately so that users can only access specific data.","tags":[],"title":"Permissions in DefectDojo"},{"content":"Product Health Grading Within DefectDojo\u0026rsquo;s system settings, you have the opportunity to enable a grading system for your products. For that you have to enable (\u0026ldquo;Enable Product Grading\u0026rdquo;). Then, the products are graded with the following possible grades:\nGrade A Grade B Grade C Grade D Grade F The best grade is A going down to the worst grade F. By default the grades stick to the achieved percentage mentioned in grade converation here.\nCalculation of the grades The code that performs the grade calculations can be found here.\nThe highest health score is 100 and it decreases based on the number of findings for each severity (critical, high, medium, low) within the product. In the following code snippet you can see the rules. Note that the following abbreviations were used:\ncrit: amount of critical findings within the product high: amount of high findings within the product med: amount of medium findings within the product low: amount of low findings within the product health=100 if crit \u0026gt; 0: health = 40 health = health - ((crit - 1) * 5) if high \u0026gt; 0: if health == 100: health = 60 health = health - ((high - 1) * 3) if med \u0026gt; 0: if health == 100: health = 80 health = health - ((med - 1) * 2) if low \u0026gt; 0: if health == 100: health = 95 health = health - low if health \u0026lt; 5: health = 5 return health\r","date":"0001-01-01","id":38,"permalink":"/en/open_source/archived_docs/usage/productgrading/","summary":"Product Health Grading Within DefectDojo\u0026rsquo;s system settings, you have the opportunity to enable a grading system for your products. For that you have to enable (\u0026ldquo;Enable Product Grading\u0026rdquo;).","tags":[],"title":"Product Health Grading"},{"content":"Introduction to Permission Types Individual users have four different kinds of permission that they can be assigned:\nUsers can be assigned as Members to Products or Product Types. This allows them to view and interact with Data Types (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on the role they are assigned on the specific Product. Users can have multiple Product or Product Type memberships, with different levels of access.\n‚Äã Users can also have Configuration Permissions assigned, which allow them to access configuration pages in DefectDojo. Configuration Permissions are not related to Products or Product Types.\n‚Äã Users can be assigned Global Roles, which give them a standardized level of access to all Products and Product Types.\n‚Äã Users can be set up as Superusers: administrator level roles which give them control and access to all DefectDojo data and configuration. You can also create Groups if you want to assign Product Membership, Configuration Permissions or Global Roles to a group of users at the same time. If you have a large number of users in DefectDojo, such as a dedicated testing team for a particular Product, Groups may be a more helpful feature.\nSuperusers \u0026amp; Global Roles Part of your Role-Based Access Control (RBAC) configuration may require you to create additional Superusers, or users with Global Roles.\nSuperusers (Admins) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. They can also change access rules for all users in DefectDojo. Superusers will also receive notifications for all system issues and alerts. Users with Global Roles can view and interact with any Data Type (Product Types, Products, Engagements, Tests and Findings) in DefectDojo depending on their assigned Role. For more information about each Role and associated privileges, please refer to our Introduction to Roles article. Users can also have specific Configuration Permissions assigned, allowing them to access certain DefectDojo configuration pages. Users have no Configuration Permissions by default. By default, the first account created on a new DefectDojo instance will have Superuser permissions. That user will be able to edit permissions for all subsequent DefectDojo users. Only an existing Superuser can add another superuser, or add a Global Role to a user.\nAdd Superuser or Global Role status to an existing user Navigate to the üë§ Users \u0026gt; Users page on the sidebar. You will see a list of all registered accounts on DefectDojo, along with each account\u0026rsquo;s Active status, Global Roles, and other relevant User data.\n‚Äã ‚Äã\nClick the name of the account that you wish to give Superuser privileges to. This will bring you to their User Page.\n‚Äã\nFrom the Default Information section of their User Page, open the ‚ò∞ menu and select Edit.\n‚Äã From the Edit User page:\n‚Äã\nFor Superuser Status, check off the ‚òëÔ∏èSuperuser Status box, located in the user\u0026rsquo;s Default Information.\n‚Äã\nTo assign a Global Role, select one from the dropdown Global Role menu at the bottom of the page.\n‚Äã ‚Äã\nClick Submit to accept these changes.\nProduct \u0026amp; Product Type Membership By default, any new account created on DefectDojo will not have permission to view any Product Level Data. They will need to be assigned membership to each Product they want to view and interact with.\nProduct \u0026amp; Product Type membership can only be configured by Superusers, Maintainers or Owners. Maintainers \u0026amp; Owners can only configure membership on Products / Product Types that they are already assigned to. Global Maintainers \u0026amp; Owners can configure membership on any Product or Product Type, as can Superusers. Users can have two kinds of membership simultaneously at the Product level:\nThe Role conferred by their underlying Product Type membership, if applicable Their Product-specific Role, if one exists. If a user has already been added as a Product Type member, and does not require an additional level of permissions on a specific Product, there is no need to add them as a Product Member.\nAdding a new Member Navigate to the Product or Product Type which you want to assign a user to. You can select the Product from the list under Products \u0026gt; All Products. Locate the Members heading, click the ‚ò∞ menu, and select + Add Users. This will take you to a page where you can Register new Members. Select a User from the dropdown Users menu. Select the Role that you want that User to have on this Product or Product Type: API Importer, Reader, Writer, Maintainer or Owner.\n‚Äã Users cannot be assigned as Members on a Product or Product Type without also having a Role. If you\u0026rsquo;re not sure which Role you want a new user to have, Reader is a good \u0026lsquo;default\u0026rsquo; option. This will keep your Product state secure until you make your final decision about their Role.\nEdit Or Delete a Member Members can have their Role changed within a Product or Product Type.\nWithin the Product or Product Type page, navigate to the Members heading and click the ‚ãÆ button next to the User who you want to Edit or Delete.\nüìù Edit will take you to the Edit Member screen, where you can change this user\u0026rsquo;s Role (from API Importer, Reader, Writer, Maintainer or Owner to a different choice).\nüóëÔ∏è Delete removes a User\u0026rsquo;s Membership altogether. It will not remove any contributions or changes the User has made to the Product or Product Type.\nIf you can\u0026rsquo;t Edit or Delete a user\u0026rsquo;s Membership (the ‚ãÆ is not visible) it\u0026rsquo;s because they have this Membership conferred at a Product Type level. A user can have two levels of membership within a Product - one assigned at the Product Type level and another assigned at the Product level. Add an additional Product role to a user with a related Product Type role If a User has a Product Type-level Role, they will also be assigned Membership with this Role to every underlying Product within the category. However, if you want this User to have a special Role on a specific Product within that Product Type, you can give them an additional Role on the Product level.\nFrom the Product page, navigate to the Members heading, click the ‚ò∞ menu, and select + Add Users (as if you were adding a new User to the Product). Select the User\u0026rsquo;s name from the drop-down menu, and select the Product Role you want that User to be assigned. A Product Role will supersede a user‚Äôs standard Product Type Role or Global Role. For example, if a User has a Product Type Role of Reader, but is also assigned as an Owner on a Product nested under that Product Type, they will have additional Owner permissions added for that Product only.\nHowever, this does not work in reverse. If a User has a Product Type Role or Global Role of Owner, assigning them a Reader role on a particular Product will not take away their Owner permissions. Roles cannot take away permissions granted to a User by other Roles, they can only add additional permissions.\nConfiguration Permissions Many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their superuser status. These Configuration Permissions allow regular users to access and contribute to parts of DefectDojo outside of their standard Product or Product Role assignment.\nConfiguration Permissions are not related to a specific Product or Product Type - users can have configuration permissions assigned without the need for other statuses or Product / Product Type Membership.\n‚Äã\nList of Configuration Permissions Credential Manager: Access to the ‚öôÔ∏èConfiguration \u0026gt; Credential Manager page Development Environments: Manage the Engagements \u0026gt; Environments list Finding Templates: Access to the Findings \u0026gt; Finding Templates page Groups: Access the üë§Users \u0026gt; Groups page Jira Instances: Access the ‚öôÔ∏èConfiguration \u0026gt; JIRA page Language Types:Access the Language Types API endpoint Login Banner: Edit the ‚öôÔ∏èConfiguration \u0026gt; Login Banner page Announcements: Access ‚öôÔ∏èConfiguration \u0026gt; Announcements Note Types: Access the ‚öôÔ∏èConfiguration \u0026gt; Note Types page Product Types: n/a Questionnaires: Access the Questionnaires \u0026gt; All Questionnaires page Questions: Access the Questionnaires \u0026gt; Questions page Regulations: Access the ‚öôÔ∏èConfiguration \u0026gt; Regulations page SLA Configuration: Access the ‚öôÔ∏èConfiguration \u0026gt; SLA Configuration page Test Types: Add or edit a Test Type (under Engagements \u0026gt; Test Types) Tool Configuration: Access the ‚öôÔ∏èConfiguration \u0026gt; Tool Types page Tool Types: Access the ‚öôÔ∏èConfiguration \u0026gt; Tool Types page Users: Access the üë§Users \u0026gt; Users page Add Configuration Permissions to a User Only Superusers can add Configuration Permissions to a User.\nNavigate to the üë§ Users \u0026gt; Users page on the sidebar. You will see a list of all registered accounts on DefectDojo, along with each account\u0026rsquo;s Active status, Global Roles, and other relevant User data.\n‚Äã Click the name of the account that you wish to edit.\n‚Äã\nNavigate to the Configuration Permissions List. This is located on the right-hand side of the User Page.\n‚Äã\nSelect the User Configuration Permissions you wish to add.\n‚Äã For a detailed breakdown of User Configuration Permissions, please refer to our Permission Chart.\n","date":"0001-01-01","id":39,"permalink":"/en/customize_dojo/user_management/set_user_permissions/","summary":"Introduction to Permission Types Individual users have four different kinds of permission that they can be assigned:\nUsers can be assigned as Members to Products or Product Types.","tags":[],"title":"Set a User's permissions"},{"content":"The process for adding a second Cloud instance is more or less the same as adding your first instance. This guide assumes you\u0026rsquo;ve already set up your initial DefectDojo server, and have an agreement with our Sales team to add another instance.\nIf you have not already requested an additional Cloud instance, please contact info at defectdojo dot com\rbefore proceeding.\nStep 1: Open the New Subscription process You can start this process from the following link: https://cloud.defectdojo.com/accounts/onboarding/step_1, or by clicking üõí New Subscription from the Cloud Manager page (cloud.defectdojo.com).\nStep 2: Set your Server Label Enter your company\u0026rsquo;s Name and the Server Label you want to use with DefectDojo. You will then have a custom domain created for your DefectDojo instance on our servers.\nKeep your company name the same as before, but create a new Server Label and check the \u0026ldquo;Use Server Label in Domain\u0026rdquo; button, so that you can easily differentiate between your servers.\nStep 3: Select a Server Location Select a Server Location from the drop-down menu. As before, we recommend selecting a server that is geographically closest to your users to reduce server latency.\nStep 4: Configure your Firewall Rules Enter the IP address ranges, subnet mask and labels that you want to allow to access DefectDojo. Additional IP addresses and rules can be added or changed by your team after your instance is up and running.\nIf you wish, these firewall rules can be different from the rules on your main DefectDojo instance.\nIf you want to use external services with this instance (GitHub or JIRA), check the appropriate boxes listed under Select External Services.\nYou can also proceed without a firewall by selecting Proceed Without Firewall. Your firewall can be re-enabled later.\nStep 5: Confirm your Plan type and Billing Frequency At the end of our process, you\u0026rsquo;ll be put in touch with our sales team, who can accurately quote your new server. We recommend you select the Plan Type which has the server specifications you require for the new instance.\nA second server may not require the same storage, CPU and RAM requirements as your \u0026lsquo;main\u0026rsquo; instance, but this will depend on your team\u0026rsquo;s technical requirements.\nStep 6: Review and Submit your Request We\u0026rsquo;ll prompt you to look over your request one more time. Once submitted, only Firewall rules can be changed by your team without assistance from Support.\nAfter reviewing and accepting DefectDojo\u0026rsquo;s License and Support Agreement, you can proceed to Checkout With Stripe, or if you have an existing billing arrangement you can click Contact Sales.\nOur Support team will reach out to you with login credentials when your server has been approved and provisioned.\n","date":"0001-01-01","id":40,"permalink":"/en/cloud_management/additional-cloud-instance/","summary":"The process for adding a second Cloud instance is more or less the same as adding your first instance. This guide assumes you\u0026rsquo;ve already set up your initial DefectDojo server, and have an agreement with our Sales team to add another instance.","tags":[],"title":"Set up an additional Cloud instance"},{"content":"Once you have created one or more Reports in DefectDojo you can take further actions, including:\nUsing a report as a template for subsequent reports\nRe-running a report with updated data\nDeleting an old or unused report\nUse a report as a Template DefectDojo allows you to easily create Report templates with your team logo, boilerplate text and a standardized content order.\nIf you want to change the way a report is set up, or create a new one with a similar layout, you can re-open the Report Builder by selecting View Template from the ‚ãÆ menu next to the report you wish to use as a template.\nThere are two places where you can find a Report Template to use:\nFrom the Generated Reports page, where you can see a list of completed reports From the Report Templates page, where you can see a list of previously run reports, including reports which were deleted from the Generated Reports page. Both of these pages can be found in the üìÑ Reports tab on the sidebar.\nTo access the Report Templates page, open üìÑReports \u0026gt; Report Templates from the sidebar. From that table, you can open the report builder by clicking the ‚ãÆ menu next to the report you wish to use as a template.\nEvery time you make changes to a template or previous report, the result will be saved as a new report under Generated Reports so that you don\u0026rsquo;t lose the older version. If you like, the older version can be deleted.\nRe-Running a Report DefectDojo Reports are ‚Äòfrozen in time‚Äô - to keep your records consistent, they do not update automatically when DefectDojo experiences data changes.\nHowever, if you want to create an updated version of a previously created report, you can do so by selecting Re-run Report from the ‚ãÆ menu next to the report you wish to generate.\nSelecting this option will create a new report in the Generated Reports list, with a different Created timestamp to indicate that the report was run at a separate time.\nDeleting a Report If you no longer need a report, you can delete it by selecting Delete Report from the ‚ãÆ menu next to the report you wish to delete. Note that this will only remove the report from the Generated Reports list - a record of the report will still exist under Report Templates if you want to re-run it.\n","date":"0001-01-01","id":41,"permalink":"/en/share_your_findings/pro_reports/working_with_generated_reports/","summary":"Once you have created one or more Reports in DefectDojo you can take further actions, including:\nUsing a report as a template for subsequent reports","tags":[],"title":"Templates and Historical Reports"},{"content":"Here are some common issues with the Jira integration, and ways to address them.\nUnable to setup Jira configuration in DefectDojo due to 404, 401 or 403 errors Jira Cloud:\nConsult the Jira Cloud REST API documentation on authentication: https://developer.atlassian.com/cloud/jira/software/basic-auth-for-rest-apis/ Verify on the command line that the provided credentials can access the necessary issues in Jira: curl -D- \\ -u \u0026lt;emailaddress\u0026gt;:\u0026lt;personal_access_token\u0026gt; \\ -X GET \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ https://\u0026lt;COMPANY\u0026gt;.atlassian.net/rest/api/latest/issue/\u0026lt;JIRA_ISSUE_KEY\u0026gt;/transitions?expand=transitions.fields\rFor example:\ncurl -D- \\ -u defectdojo@example.com:ATATT1234567890abcdefghijklmnopqrstuvwxyz \\ -X GET \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ https://defectdojo.atlassian.net/rest/api/latest/issue/VULNERABILITY-1/transitions?expand=transitions.fields\rJira Data Center or Server:\nConsult the Jira Data Center REST API documentation on authentication: https://developer.atlassian.com/server/jira/platform/basic-authentication/ (username + password) https://confluence.atlassian.com/enterprise/using-personal-access-tokens-1026032365.html (personal access token) Verify on the command line that the provided credentials can access the necessary issues in Jira: curl -u username:password -X GET -H \u0026#34;Content-Type: application/json\u0026#34; https://\u0026lt;COMPANY\u0026gt;.atlassian.net/rest/api/latest/issue/\u0026lt;JIRA_ISSUE_KEY\u0026gt;/transitions?expand=transitions.fields\rFor example:\ncurl -u defectdojo@example.com:123456 -X GET -H \u0026#34;Content-Type: application/json\u0026#34; https://defectdojo.atlassian.net/rest/api/latest/issue/VULNERABILITY-1/transitions?expand=transitions.fields\rWhen using personal access tokens:\ncurl -H \u0026#34;Authorization: Bearer \u0026lt;personal_access_token\u0026gt;\u0026#34; https://\u0026lt;COMPANY\u0026gt;.atlassian.net/rest/api/latest/issue/\u0026lt;JIRA_ISSUE_KEY\u0026gt;/transitions?expand=transitions.fields\rFor example:\ncurl -H \u0026#34;Authorization: Bearer ATATT1234567890abcdefghijklmnopqrstuvwxyz\u0026#34; https://\u0026lt;COMPANY\u0026gt;.atlassian.net/rest/api/latest/issue/\u0026lt;JIRA_ISSUE_KEY\u0026gt;/transitions?expand=transitions.fields\rFindings that I \u0026lsquo;Push To Jira\u0026rsquo; do not appear in Jira Using the \u0026lsquo;Push To Jira\u0026rsquo; workflow triggers an asynchronous process, however an Issue should be created in Jira fairly quickly after \u0026lsquo;Push To Jira\u0026rsquo; is triggered.\nCheck your DefectDojo notifications to see if the process was successful. If the push failed, you will get an error response from Jira in your notifications. Common reasons issues are not created:\nThe Default Issue Type you have selected is not usable with the Jira Project Issues in the Project have required attributes that prevent them from being created via DefectDojo (see our guide to Custom Fields) Error: Product Misconfigured or no permissions in Jira? This error message can appear when attempting to add a created Jira configuration to a Product. DefectDojo will attempt to validate a connection to Jira, and if that connection fails, it will raise this error message.\nCheck to see if your Jira credentials are allowed to create issues in the given Jira Project you have selected. The \u0026ldquo;Project Key\u0026rdquo; field needs to be a valid Jira Project. Jira issues can use many different Keys within a single Project; the easiest way to confirm your Project Key is to look at the URL for that particular Jira Project: generally this will look like https://xyz.atlassian.net/jira/core/projects/JTV/board. In this case JTV is the Project Key. Changes made to Jira issues are not updating Findings in DefectDojo Start by confirming that the DefectDojo webhook receiver is configured correctly and can successfully receive updates.\nEnsure the SSL certificate used by Defect Dojo is trusted by JIRA. For JIRA Cloud you must use a valid SSL/TLS certificate, signed by a globally trusted certificate authority\nIf you\u0026rsquo;re trying to push status changes, confirm that Jira transition mappings are set up correctly (Reopen / Close Transition IDs).\nTest your JIRA webhook using a public endpoint such as Pipedream or Beeceptor:\nJira Epics aren\u0026rsquo;t being created \u0026quot;Field 'customfield_xyz' cannot be set. It is not on the appropriate screen, or unknown.\u0026quot;\nDefectDojo\u0026rsquo;s Jira integration needs a customfield value for \u0026lsquo;Epic Name\u0026rsquo;. However, your Project settings might not actually use \u0026lsquo;Epic Name\u0026rsquo; as a field when creating Epics. Atlassian made a change in August 2023 which combined the \u0026lsquo;Epic Name\u0026rsquo; and \u0026lsquo;Epic Summary\u0026rsquo; fields.\nNewer Jira Projects might not use this field when creating Epics by default, which results in this error message.\nTo correct this issue, you can add the \u0026lsquo;Epic Name\u0026rsquo; field to your Project\u0026rsquo;s issue creation screen:\nAttempt to create an Epic in Jira manually (through Jira UI). Open the \u0026ldquo;\u0026hellip;\u0026rdquo; menu Click \u0026lsquo;Find Your Field\u0026rsquo; Type in \u0026lsquo;Epic Name\u0026rsquo; Add Epic Name as a field to this particular screen by following Jira\u0026rsquo;s instructions. ","date":"0001-01-01","id":42,"permalink":"/en/share_your_findings/troubleshooting_jira/","summary":"Here are some common issues with the Jira integration, and ways to address them.\nUnable to setup Jira configuration in DefectDojo due to 404, 401 or 403 errors Jira Cloud:","tags":[],"title":"Troubleshooting Jira errors"},{"content":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.\nUsing docker images provided in DockerHub If you're using latest, then you need to pre pull the latest from DockerHub to update.\nThe generic upgrade method for docker compose are as follows:\nPull the latest version\ndocker pull defectdojo/defectdojo-django:latest docker pull defectdojo/defectdojo-nginx:latest\rIf you would like to use a version other than the latest, specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2 docker pull defectdojo/defectdojo-nginx:1.10.2\rIf you would like to use alpine based images, you specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2-alpine docker pull defectdojo/defectdojo-nginx:1.10.2-alpine\rGo to the directory where your docker-compose.yml file lives\nStop DefectDojo: docker compose stop\nRe-start DefectDojo, allowing for container recreation: docker compose up -d\nDatabase migrations will be run automatically by the initializer. Check the output via docker compose logs initializer or relevant k8s command\nIf you have the initializer disabled (or if you want to be on the safe side), run the migration command: docker compose exec uwsgi /bin/bash -c \u0026quot;python manage.py migrate\u0026quot;\nBuilding your local images If you build your images locally and do not use the ones from DockerHub, the instructions are the same, with the caveat that you must build your images first.\nPull the latest DefectDojo changes\ngit fetch git pull git merge origin/master\rThen replace the first step of the above generic upgrade method for docker compose with: docker compose build\ngodojo installations If you have installed DefectDojo on \u0026ldquo;iron\u0026rdquo; and wish to upgrade the installation, please see the instructions in the repo.\nUpgrade notes for each release ","date":"0001-01-01","id":43,"permalink":"/en/open_source/upgrading/","summary":"Docker compose When you deploy a vanilla docker compose, it will create a persistent volume for your Postgres database. As long as your volume is there, you should not lose any data.","tags":[],"title":"Upgrading"},{"content":"","date":"0001-01-01","id":44,"permalink":"/en/open_source/archived_docs/usage/","summary":"","tags":[],"title":"Usage"},{"content":"Here\u0026rsquo;s a quick reference you can use to ensure successful implementation - from a blank canvas to a fully functional app.\nThe Basics Start by importing a file using the UI. This is generally the quickest way to see how your data fits into the DefectDojo model. (note: OS users will need to set up a Product Type and Product before they can import data)\nNow that you have data in DefectDojo, learn more about how to organize it with the Product Hierarchy Overview. The Product Hierarchy creates a working inventory of your apps, which helps you divide your data up into logical categories. These categories can be used to apply access control rules, or to segement your reports to the correct team.\nTry creating a Report to summarize the data you\u0026rsquo;ve imported. Reports can be used to quickly share Findings with stakeholders such as Product Owners.\nThis is the essence of DefectDojo - import security data, organize it, and present it to the folks who need to know.\nAll of these features can be automated, and because DefectDojo can handle over 190 tools (at time of writing) you should be all set to create a functional security inventory of your entire organizational output.\nOther guides Does your organization use Jira? Learn how to use our Jira integration to create Jira tickets from the data you ingest. Are you expecting to share DefectDojo with many users in your organization? Check out our guides to user management and set up role-based access control (RBAC). Ready to dive into automation? Learn how to use the DefectDojo API to automatically import new data, and build a robust CI / CD pipeline. ","date":"0001-01-01","id":45,"permalink":"/en/about_defectdojo/new_user_checklist/","summary":"Here\u0026rsquo;s a quick reference you can use to ensure successful implementation - from a blank canvas to a fully functional app.","tags":[],"title":"‚òëÔ∏è New User Checklist"},{"content":"Regular releases The DefectDojo team aims to maintain the following cadence:\nMinor releases: at least once a month on the first Monday of the month. Patch/Bugfix: releases every week on Monday. Security releases: will be performed outside of our regular cadence depending on severity. GitHub Actions are the source of truth. The releases are semi-automated. The steps for a regular release are:\nCreate the release branch from dev or bugfix and prepare a PR against master (details) \u0026ndash;\u0026gt; A maintainer verifies and manually merges the PR Tag, issue draft release and docker build+push (details) \u0026ndash;\u0026gt; A maintainer massages the release-drafter notes and publishes the release A PR to merge master back to dev and bugfix is created to re-align the branches (details) Security releases PRs that relate to security issues are done through security advisories which provide a way to work privately on code without prematurely disclosing vulnerabilities.\nRelease and hotfix model Diagrams created with plantUML. Find a web-based editor for PlantUML at https://www.planttext.com.\nDocumentation A dev version of the documentation built from the dev branch is available at DefectDojo Documentation - dev branch.\n``` @startuml participant \u0026ldquo;Dev Branch\u0026rdquo; as dev #LightBlue participant \u0026ldquo;BugFix Branch\u0026rdquo; as bugfix #LightGreen participant \u0026ldquo;Release Branch\u0026rdquo; as release #LightGoldenRodYellow participant \u0026ldquo;Master Branch\u0026rdquo; as master #LightSalmon\n== Minor Release (Monthly) ==\ndev -\u0026gt; release: Create branch \u0026ldquo;release/2.x.0\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.0\\n - Push 2.x.0 to DockerHub master \u0026ndash;\u0026gt; bugfix: Merge master into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master back into dev\n== Patch/BugFix Release (Weekly) ==\nbugfix -\u0026gt; release: Create branch \u0026ldquo;release/2.x.y\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master -\u0026gt; bugfix: Merge master back into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master into dev to realign\n== Security Release (As Needed) ==\nmaster -\u0026gt; release: Create branch \u0026ldquo;release/2.x.y\u0026rdquo; release -\u0026gt; master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master \u0026ndash;\u0026gt; bugfix: Merge master into bugfix to realign master \u0026ndash;\u0026gt; dev: Merge master into dev to realign\n@enduml\n\u0026lt;/div\u0026gt;\r","date":"0001-01-01","id":46,"permalink":"/en/open_source/contributing/branching-model/","summary":"Regular releases The DefectDojo team aims to maintain the following cadence:\nMinor releases: at least once a month on the first Monday of the month.","tags":[],"title":"Branching model"},{"content":"dojo/settings/settings.dist.py The main settings are stored in dojo/settings/settings.dist.py. It is great to use this file as a reference for what can be configured, but it shouldn't be edited directly, because changes will be overwritten when updating DefectDojo. There are several methods to change the default settings:\nEnvironment variables Most parameters can be set by environment variables.\nWhen you deploy DefectDojo via Docker Compose, you can set environment variables in docker-compose.yml. Be aware you have to set the variables for three services: uwsgi, celerybeat and celeryworker.\nWhen you deploy DefectDojo in a Kubernetes cluster, you can set environment variables as extraConfigs and extraSecrets in helm/defectdojo/values.yaml.\nEnvironment file (not with Docker Compose or Kubernetes) settings.dist.py reads environment variables from a file whose name is specified in the environment variable DD_ENV_PATH. If this variable is not set, the default .env.prod is used. The file must be located in the dojo/settings directory.\nAn example can be found in template_env.\nlocal_settings.py local_settings.py can contain more complex customizations such as adding MIDDLEWARE or INSTALLED_APP entries. This file is processed after settings.dist.py is processed, so you can modify settings delivered by DefectDojo out of the box. The file must be located in the dojo/settings directory. Environment variables in this file must not have the DD_ prefix. If the file is missing feel free to create it. Do not edit settings.dist.py directly.\nAn example can be found in dojo/settings/template-local_settings.\nIn Docker Compose release mode, files in docker/extra_settings/ (relative to the file docker-compose.yml) will be copied into dojo/settings/ in the docker container on startup.\nlocal_settings.py can be used in Kubernetes as well. Variable localsettingspy will be stored as ConfigMap and mounted to responsible location of containers.\nConfiguration in the UI Users with the superuser status can configure more options via the UI under Configuration / System Settings.\n","date":"0001-01-01","id":47,"permalink":"/en/open_source/installation/configuration/","summary":"dojo/settings/settings.dist.py The main settings are stored in dojo/settings/settings.dist.py. It is great to use this file as a reference for what can be configured, but it shouldn't be edited directly, because changes will be overwritten when updating DefectDojo.","tags":[],"title":"Configuration (Open Source)"},{"content":"If you have an excessive amount of duplicate Findings which you want to delete, you can set Delete Deduplicate Findings as an option in the System Settings.\nDelete Deduplicate Findings, combined with the Maximum Duplicates field allows DefectDojo to limit the amount of Duplicate Findings stored. When this field is enabled, DefectDojo will only keep a certain number of Duplicate Findings.\nWhich duplicates will be deleted? The original Finding will never be deleted automatically from DefectDojo, but once the threshold for Maximum Duplicates is crossed, DefectDojo will automatically delete the oldest Duplicate Finding.\nFor example, let‚Äôs say that you had your Maximum Duplicates field set to ‚Äò1‚Äô.\nFirst, you import Test 1. Your report contains a vulnerability which is recorded as Finding A. Later, you import Test 2 contains the same vulnerability. This will be recorded as Finding B, and Finding B will be marked as a duplicate of Finding A. Later still, you import Test 3 which also contains that vulnerability. This will be recorded as Finding C, which will be marked as a duplicate of Finding A. At this time, Finding B will be deleted from DefectDojo as the threshold for maximum duplicates has been crossed. Applying this setting Applying Delete Deduplicate Findings will begin a deletion process immediately. This setting can be applied on the System Settings page. See Enabling Deduplication for more information.\n","date":"0001-01-01","id":48,"permalink":"/en/working_with_findings/finding_deduplication/delete_deduplicates/","summary":"If you have an excessive amount of duplicate Findings which you want to delete, you can set Delete Deduplicate Findings as an option in the System Settings.","tags":[],"title":"Delete Deduplicate Findings"},{"content":"","date":"0001-01-01","id":49,"permalink":"/en/open_source/archived_docs/integrations/","summary":"","tags":[],"title":"Integrations"},{"content":"One of DefectDojo‚Äôs strengths is that the data model can accommodate many different use-cases and applications. You‚Äôll likely change your approach as you master the software and discover ways to optimize your workflow.\nBy default, DefectDojo does not delete any duplicate Findings that are created. Each Finding is considered to be a separate instance of a vulnerability. So in this case, Duplicate Findings can be an indicator that a process change is required to your workflow.\nStep 1: Clean up your excess Duplicates Fortunately, DefectDojo‚Äôs Deduplication settings allow you to mass-delete duplicates once a certain threshold has been crossed. This feature makes the cleanup process easier. To learn more about this process, see our article on Finding Deduplication \u0026lt;-link will go here.\nStep 2: Evaluate your Engagements for redundancies Once you‚Äôve cleaned up your duplicate Findings, it‚Äôs a good practice to look at the Product which contained them to see if there‚Äôs a clear culprit. You might find that there are Engagements contained within which have a redundant context.\nDuplicate or Reused Engagements Engagements store one or more Tests for a particular testing context. That context is ultimately up to you to define for yourself, but if you see a few Engagements within your Product which should share the same context, consider combining them into a single engagement.\n‚Äã\nQuestions to ask when defining Engagement context: If I wanted to make a report on this work, would the Engagement contain all of the relevant information I need? Are we proactively creating Engagements ahead of time or are they being created ‚Äòad-hoc‚Äô by my import process? Are we using the right kind of Engagement - Interactive or CI/CD? What section of the codebase is being worked on by tests: is each repository a separate context or could multiple repositories make up a shared context for testing? Who are the stakeholders involved with the Productt, and how will I share results with them? Step 3: Check for redundant Tests If you discover that separate Tests have been created which capture the same testing context, this may be an indicator that these tests can be consolidated into a single Reimport.\nDefectDojo has two methods for importing test data to create Findings: Import and Reimport. Both of these methods are very similar, but the key difference between the two is that Import always creates a new Test, while Reimport can add new data to an existing Test. It‚Äôs also worth noting that Reimport does not create duplicate Findings within that Test.\nEach time you import new vulnerability reports into DefectDojo, those reports will be stored in a Test object. A Test object can be created by a user ahead of time to hold a future Import. If a user wants to import data without specifying a Test destination, a new Test will be created to store the incoming report.\nTests are flexible objects, and although they can only hold one kind of report, they can handle multiple instances of that same report through the Reimport method. To learn more about Reimport, see our article on this topic.\nWhen are Duplicate Findings acceptable? Duplicate Findings are not always indicative of a problem. There are many cases where keeping duplicates is the preferred approach. For example:\nIf your team uses and reports on Interactive Engagements. If you want to create a discrete report on a single Test specifically, you would want to know if there‚Äôs an occurrence of a Finding that was already uncovered earlier. If you have Engagements which are contextually separated (for example, because they cover different repositories) you would want to be able to flag Findings which are occurring in both places. ","date":"0001-01-01","id":50,"permalink":"/en/working_with_findings/findings_workflows/manage_duplicate_findings/","summary":"One of DefectDojo‚Äôs strengths is that the data model can accommodate many different use-cases and applications. You‚Äôll likely change your approach as you master the software and discover ways to optimize your workflow.","tags":[],"title":"Manage Duplicate Findings"},{"content":"System-wide permissions Administrators (aka superusers) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. Staff users can add Product Types, and have access to data according to their role in a Product or Product Type. Regular users have limited functionality available. They cannot add Product Types but have access to data according to their role in a Product or Product Type Product and Product Type permissions Users can be assigned as members to Products and Product Types, giving them one out of five predefined roles. The role defines what kind of access a user has to functions for interacting with data of that Product or Product Type:\nProduct / Product Type roles:\nReader Writer Maintainer Owner API Importer Add Product Type 1) 1) View Product Type x x x x x Remove yourself as a member x x x x Manage Product Type members x x Edit Product Type x x Add Product x x Add Product Type member as Owner x Delete Product Type x View Product x x x x x Remove yourself as a member x x x x Manage Product members x x Edit Product x x Add Product member as Owner x Delete Product x View Engagement x x x x x Add Engagement x x x x Edit Engagement x x x x Risk Acceptance x x x Delete Engagement x x View Test x x x x x Add Test x x x Edit Test x x x x Delete Test x x View Finding x x x x x Add Finding x x x Edit Finding x x x (Re-)Import Scan Result x x x x Delete Finding x x View Finding Group x x x x x Add Finding Group x x x Edit Finding Group x x x Delete Finding Group x x x View Endpoint x x x x x Add Endpoint x x x Edit Endpoint x x x Delete Endpoint x x Edit Benchmark x x x Delete Benchmark x x View Components x x x x x View Note History x x x x Add Note x x x x Edit Note (x) 2) x x x Delete Note (x) 2) (x) 2) x x 1) Every superuser can add Product Types. Regular users are not allowed to add Product Types, unless they are a Global Owner or Maintainer.\n2) Every user is allowed to edit and delete his own notes.\nThe role of a user within a Product Type is inherited by all Products of that Product Type, unless the user is explicitly defined as a member of a Product with a different role. In that case, if a user doesn\u0026rsquo;t have a certain right for the Product Type, it is then checked if he has the right for the Product.\nA Product Type needs to have at least one owner. The last owner cannot be removed.\nGlobal permissions Users can be assigned a global role in the Edit User dialog. A global role gives a user access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nA use case for a global role could be the Chief Information Security Officer of a company who needs an overview of all systems. If he gets the global role Reader, he can see the findings for all products and also all metrics.\nSince global roles give users access to all data, only superusers are allowed to edit it.\nGroups If you have a number of users who should all have the same permissions for some Products or Product Types, you can put them together in a group. The group defines the roles for Products and Product Types that are applied to all members of the group.\nThe membership of a group itself has a role that determines what permissions the member has to manage the group:\nReader Maintainer Owner Add Group 1) View Group x x x Remove yourself as a member x x x Manage Group members x x Edit Group x x Add Group member as Owner x Delete Group x 1) Every superuser can add groups. Regular users are not allowed to add groups.\nThe permissions to manage the roles of Products and Product types for a group is defined by the role of the user in the respective Product or Product Type.\nGroups can have a global role too. This global role gives all members of the group access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nConfiguration permissions Many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their superuser status:\n3 configurations can still only be changed by superusers:\nSystem settings Notifications on system level Configuration permissions for users and groups These configuration settings are a powerful tool and should be used with great care.\n","date":"0001-01-01","id":51,"permalink":"/en/open_source/archived_docs/usage/permissions/","summary":"System-wide permissions Administrators (aka superusers) have no limitations in the system. They can change all settings, manage users and have read / write access to all data.","tags":[],"title":"Permissions"},{"content":"Questionnaires Questionnaires provide a means for collecting information from developers and respective stakeholders. DefectDojo includes functionality to create new questionnaires with custom questions, open questionnaires to receive responses for certain time periods from insiders or outsiders, and connect questionnaires with new or existing engagements.\nCreating a New Questionnaire To access, create, or modify new/existing questionnaires, navigate to the All Questionnaires dashboard from the sidebar.\nOn the questionnaire dashboard, all existing questionnaires are displayed. To quickly find a questionnaire, the filters may be used to search for snippets within the questionnaire name and/or description, as well as by active/inactive status.\nWhen questionnaires are open for responses, they will be displayed in the General Questionnaires block towards the bottom of the page.\nTo begin the process of creating a new questionnaire, select the Create Questionnaire button located in the top right of the questionnaire dashboard.\nQuestionnaires have a name and description, as well as an activity status, which are initially set on questionnaire creation, but can be modified in the future if necessary. Once these fields are filled in appropriately, the user can create the questionnaire without any questions (by selecting Create Questionnaire), or with questions (by selecting Create Questionnaire and Add Questions).\nTo add questions to a questionnaire, select the dropdown titled Select as many Questions as applicable, which will open all of the existing questions within DefectDojo. Once the desired questions are selected from the list, the dropdown can be closed, and the Update Questionnaire Questions can be selected to save the newly created questionnaire.\nNote: New questions may also be added at the time of questionnaire creation by selecting the plus located next to the questions dropdown.\nCreating New Questions The questions dashboard displays all of the questions that may exist as part of questionnaires within DefectDojo. Similar to questionnaires, to quickly find a question, the filters may be used to search for optional status, or snippets within the question name and/or description. Two types of questions exist within DefectDojo questionnaires: Text Questions and Multiple Choice Questions. To add a new question, select the Create Question button located in the top right of the questions dashboard.\nAdding Text Questions To add a text question (open-ended), fill out the add question form, where:\nType - The type of question being created, in this case Text. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Question Text - The text that is displayed to prompt a user for their answer (e.g. What is your favorite color?). Adding Multiple Choice Questions Similar to the process of adding a text question, choice questions (non-open-ended) allow the user to pick from a given list of choices. To add a choice question, fill out the add question form, where:\nType - The type of question being created, in this case Choice. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Multichoice - When the multichoice box is checked, multiple choices from the list of choices may be selected by the user. Answer Choices - The possible answer choices that may be selected by a user. Publishing a Questionnaire Once a questionnaire has been successfully created, it can be published to accept responses. To publish a questionnaire, select the plus located to the right of General Questionnaires.\nThis will prompt for a specific questionnaire to be selected, as well as a date the questionnaire response window should close. The response window sets a due date for recipients. Once these two options have been selected, publish the questionnaire by selecting Add Questionnaire.\nOnce a questionnaire is published, a link to share it can be retrieved by selecting the Share Questionnaire action. To ensure the newly created questionnaire has been constructed as expected, open the share link and view the newly created questionnaire.\nUnassigned Questionnaires When a questionnaire\u0026rsquo;s response window has closed, all of the responses will be saved, and the questionnaire will be listed as an Unassigned Answered Engagement Questionnaire on the DefectDojo dashboard.\nThere are three actions that may be taken when a questionnaire\u0026rsquo;s response window has closed: View Responses, Create Engagement, and Assign User.\nView Questionnaire Responses To view the questionnaire responses, select the View Responses action. All of the responses from the questionnaire will be displayed.\nCreate an Engagement From a Questionnaire To link the questionnaire to a product via an engagement, select the Create Engagement action. Once a product is selected from the dropdown, select Create Engagement. This will link the questionnaire results with a new engagement under the selected product, which can then be given specific details similar to other engagements in DefectDojo, such as Description, Version, Status, Tags, etc.\nTo view a questionnaire at the engagement level, navigate to the engagement linked with the desired questionnaire. Expand the Additional Features menu to reveal a Questionnaires dropdown, which will contain all of the linked questionnaires.\nAssign a Questionnaire to a User To assign a questionnaire to a user, select the Assign User action. This will prompt for a user to be selected from the dropdown of available users. Once a user is selected, assign the questionnaire to the specified user by selecting Assign Questionnaire.\nCreating Questionnaires From Engagements While questionnaires are commonly created from the questionnaire dashboard, they can also be created at the engagement level. To create a new questionnaire from within an engagement, expand the Additional Features dropdown to reveal the Questionnaires dropdown. In the right side header of the Questionnaires dropdown, select the plus to link a new questionnaire.\nOnce prompted, select a questionnaire from the available surveys list to link it with the engagement. If the user wishes to leave a response at the time of linking the questionnaire with the engagement, the Add Questionnaire and Repond option may be selected. To simply link the questionnaire with the engagement, select Add Questionnaire.\nAnonymous Questionnaires Questionnaires, by default, are only accessible by DefectDojo users. To allow outside responses to DefectDojo questionnaires, ensure the Allow Anonymous Survey Reponses option within the System Settings is selected. To share a questionnaire with anonymous users, use the questionnaire\u0026rsquo;s Share Link.\n","date":"0001-01-01","id":52,"permalink":"/en/open_source/archived_docs/usage/questionnaires/","summary":"Questionnaires Questionnaires provide a means for collecting information from developers and respective stakeholders. DefectDojo includes functionality to create new questionnaires with custom questions, open questionnaires to receive responses for certain time periods from insiders or outsiders, and connect questionnaires with new or existing engagements.","tags":[],"title":"Questionnaires"},{"content":"If you have a significant number of DefectDojo users, you may want to create one or more Groups, in order to set the same Role-Based Access Control (RBAC) rules for many users simultaneously. Only Superusers can create User Groups.\nGroups can work in multiple ways:\nSet one, or many different Product or Product Type level Roles for all Group Members, allowing specific control over which Products or Product Types can be accessed and edited by the Group. Set a Global Role for all Group Members, giving them visibility and access to all Product or Product Types. Set Configuration Permissions for a Group, allowing them to change specific functionality around DefectDojo. For more information on Roles, please refer to our Introduction To Roles article.\nThe All Groups page From the sidebar, navigate to üë§Users \u0026gt; Groups to see a list of all active and inactive user groups.\nFrom here, you can create, delete or view your individual Group pages.\nFor DefectDojo Pro users, the Beta UI\u0026rsquo;s All Groups has a few additional options.\nYou can filter this table by Group Name, Description, E-mail Address, Global Role, as well as the total number of Users, Product Types, and Products associated with the Group. You can also adjust a Group\u0026rsquo;s Permissions or other settings by clicking the \u0026ldquo;‚ãÆ\u0026rdquo; button next to the Group you wish to edit. Viewing A Group Viewing a group displays all Group information, such as ID, name, description, global role, etc. The Group Members, Product Types, and Products associated with the group are also displayed. Additionally, configuration permissions tied to a Group can be updated directly from the ‚ÄúView Group‚Äù page.\nFor DefectDojo Pro users, the Beta UI\u0026rsquo;s Group View allows you to assign Configuration Permission adjustments in a slightly different way.\nAll configuration permissions are displayed in a dropdown which is grouped into subcategories. If the selection of configuration permissions is different from their current value, an ‚ÄúUpdate Configuration Permissions‚Äù button is displayed. Once a few additional permissions have been selected, the user will be asked to confirm they would like to update the permissions for the selected group before an update is made. Create / Edit a User Group Navigate to the üë§Users \u0026gt; Groups page on the sidebar. You will see a list of all existing User Groups, including their Name, Description, Number of Users, Global Role (if applicable) and Email.\n‚Äã Click the üõ†Ô∏è button next to the All Groups heading, and select + New Group.\n‚Äã This will take you to a page where you can create a new Group. Set the Name for this Group, and add a Description if you wish.\nYou can also select a Global Role that you wish to apply to this Group, if you wish. Adding a Global Role to the Group will give all Group Members access to all DefectDojo data, along with a limited amount of edit access depending on the Global Role you choose. See our Introduction To Roles article for more information.\nThe account that initially creates a Group will have an Owner Role for the Group by Default.\nSet an email address to receive reports The Weekly Digest is a report on all Group-assigned Products / Product Types. To have a weekly Digest sent out, enter the destination email address you wish to use on the Create / Edit Group form. Group members will still receive notifications as usual.\nViewing a Group Page Once you have created a Group, you can access it by selecting it in the menu listed under Users \u0026gt; Groups.\nThe Group Page can be customized with a Description.It features a list of all Group Members, as well as the assigned Products, Product Types, and the associated Role associated with each of these**.**\nYou can also see the Group‚Äôs Configuration Permissions listed here.\nManage a Group‚Äôs Users Group Membership is managed from the individual Group page, which you can select from the list in the Users \u0026gt; Groups page. Click the highlighted Group Name to access the Group page that you wish to edit.\nIn order to view or edit a Group‚Äôs Membership, a User must have the appropriate Configuration permissions enabled as well as Membership in the Group (or Superuser status).\nAdd a User to a Group User Groups can have as many Users assigned as you wish. All Users in a Group will be given the associated Role on each Product or Product Type listed, but Users may also have Individual Roles which supersede the Group role.\nFrom the Group page, select + Add Users from the ‚ò∞ button at the edge of the Members heading.\n‚Äã This will take you to the Add Some Group Members screen. Open the Users drop-down menu, and then check off each user that you wish to add to the Group.\n‚Äã .Select the Group Role that you wish to assign these Users. This determines their ability to configure the Group.\nNote that adding a member to a Group will not allow them access to their own Group page by default. This is a separate Configuration permission which must be enabled first.\nEdit or Delete a Member from a User Group From the Group page, select the ‚ãÆ next to the Name of the User you wish to Edit or Delete from the Group. üìù Edit will take you to the Edit Member screen, where you can change this user\u0026rsquo;s Role (from Reader, Maintainer or Owner to a different choice).\nüóëÔ∏è Delete removes a User\u0026rsquo;s Membership altogether. It will not remove any contributions or changes the User has made to the Product or Product Type.\nManage a Group‚Äôs Permissions Group Permissions are managed from the individual Group page, which you can select from the list in the Users \u0026gt; Groups page. Click the highlighted Group Name to access the Group page that you wish to edit.\nNote that only Superusers can edit a Group‚Äôs permissions (Product / Product Type, or Configuration).\n‚Äã\nAdd Product Roles or Product Type Roles for a Group You can register as many Product Roles or Product Type Roles as you wish in each Group.\nFrom the Group page, select + Add Product Types, or + Add Product from the relevant heading (Product Type Groups or Product Groups).\n‚Äã This will take you to a Register New Products / Product Types Page, where you can select a Product or Product Type to add from the drop-down menu.\nSelect the Role that you want all Group members to have regarding this particular Product or Product Type. Groups cannot be assigned to Products or Product Types without a Role. If you\u0026rsquo;re not sure which Role you want a Group to have, Reader is a good \u0026lsquo;default\u0026rsquo; option. This will keep your Product state secure until you make your final decision about the Group Role.\nAssign Configuration Permissions to a Group If you want the Members in your Group to access Configuration functions, and control certain aspects of DefectDojo, you can assign these responsibilities from the Group page.\nAssign View, Add, Edit or Delete roles from the menu in the bottom-right hand corner. Checking off a Configuration Permission will immediately give the Group access to this particular function.\n","date":"0001-01-01","id":53,"permalink":"/en/customize_dojo/user_management/create_user_group/","summary":"If you have a significant number of DefectDojo users, you may want to create one or more Groups, in order to set the same Role-Based Access Control (RBAC) rules for many users simultaneously.","tags":[],"title":"Share permissions: User Groups"},{"content":"Note: Smart Upload is only available in DefectDojo Pro.\nSmart upload is a specialized importer that ingests reports from infrastructure scanning tools, including:\nNexpose NMap OpenVas Qualys Tenable Smart Upload is unique in that it can split Findings from a scan file into separate Products. This is relevant in an Infrastructure scanning context, where the Findings may apply to many different teams, have different implicit SLAs, or need to be included in separate reports due to where they were discovered in your infrastructure.\nSmart Upload handles this by sorting incoming findings based on the Endpoints discovered in the scan. At first, those Findings will need to be manually assigned, or directed into the correct Product from an Unassigned Findings list. However, once a Finding has been assigned to a Product, all subsequent Findings that share an Endpoint or Host will be sent to the same Product.\nSmart Upload menu options The Smart Upload menu is stored in a collapsible section of the sidebar.\nAdd Findings allows you to import a new scan file, similar to DefectDojo‚Äôs Import Scan method Unassigned Findings lists all Findings from Smart Upload which have yet to be assigned to a Product. The Smart Upload Form The Smart Upload Import Scan form is essentially the same as the Import Scan form. See our notes on the Import Scan Form for more details.\nUnassigned Findings Once a Smart Upload has been completed, any Findings which are not automatically assigned to a Product (based on their Endpoint) will be placed in the Unassigned Findings list. The first Smart Upload for a given tool does not yet have any method to Assign Findings, so each Finding from this file will be sent to this page for sorting.\nUnassigned Findings are not included in the Product Hierarchy and will not appear in reports, filters or metrics until they have been assigned.\nWorking with Unassigned Findings You can select one or more Unassigned Findings for sorting with the checkbox, and perform one of the following actions:\nAssign to New Product, which will create a new Product Assign to Existing Product which will move the Finding into an existing Product Disregard Selected Findings, which will remove the Finding from the list Whenever a Finding is assigned to a New or Existing Product, it will be placed in a dedicated Engagement called ‚ÄòSmart Upload‚Äô. This Engagement will contain a Test named according to the Scan Type (e.g. Tenable Scan). Subsequent Findings uploaded via Smart Upload which match those Endpoints will be placed under that Engagement \u0026gt; Test.\nDisregarded Findings If a Finding is Disregarded it will be removed from the Unassigned Findings list. However, the Finding will not be recorded in memory, so subsequent scan uploads may cause the Finding to appear in the Unassigned Findings list again.\n","date":"0001-01-01","id":54,"permalink":"/en/connecting_your_tools/import_scan_files/smart_upload/","summary":"Note: Smart Upload is only available in DefectDojo Pro.\nSmart upload is a specialized importer that ingests reports from infrastructure scanning tools, including:","tags":[],"title":"Smart Upload for infrastructure scans (Pro)"},{"content":"Permissions in DefectDojo Pro have been simplified, to make it easier to assign object access. This feature can be accessed through the Beta UI.\nOpening the Permissions window When looking at Product Type or Product, you can open the Permissions window to set permissions quickly. This menu can be found in a Table by clicking the horizontal dots \u0026quot;‚ãÆ\u0026quot;. IF looking at an individual Product or Product Type page, this menu can be found under the blue gear ‚Äò‚öôÔ∏è‚Äô.\nSetting Permissions through the permissions window At the top of this window, you can choose to manage permissions for an individual user or for a user group. Here, you can select a user or group to add to the Product, and select the Role that you want that user to have. On the lower table, you can see a list of all users or groups who have access to this object. You can also quickly assign a new role for one of these users or groups from the drop-down menu. Setting Configuration Permissions through the User view A user\u0026rsquo;s configuration permissions can now be set in a more user-friendly approach. From the Users View, all configuration permissions are displayed in a dropdown, then grouped by the permission type. If the selection of configuration permissions is different from their current value, an ‚ÄúUpdate Configuration Permissions‚Äù button is displayed. When clicked, the user will be asked to confirm they would like to update the permissions for the selected group before an update is made.\n","date":"0001-01-01","id":55,"permalink":"/en/customize_dojo/user_management/pro_permissions_overhaul/","summary":"Permissions in DefectDojo Pro have been simplified, to make it easier to assign object access. This feature can be accessed through the Beta UI.","tags":[],"title":"üüß Set Permissions in Pro"},{"content":"Role Permission Chart This chart is intended to list all permissions related to a Product or Product Type, as well as which permissions are available to each role.\nSection Permission Reader Writer Maintainer Owner API Importer Product / Product Type Access View assigned Product or Product Type ¬π ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è View nested Products, Engagements, Tests, Findings, Endpoints ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Add new Products (within assigned Product Type) ¬≤ ‚òëÔ∏è ‚òëÔ∏è Delete assigned Products or Product Types ‚òëÔ∏è Product / Product Type Membership Add Users as Members (excluding Owner Role) ‚òëÔ∏è ‚òëÔ∏è Edit member Roles (excluding Owner Role) ‚òëÔ∏è ‚òëÔ∏è Edit member Roles (including Owner Role) ‚òëÔ∏è Remove self from Product / Product Type membership ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Add an Owner Role to another User ‚òëÔ∏è Edit an associated Product/Product Type Membership within a Group¬≥ ‚òëÔ∏è Delete an associated Product/Product Type Membership within a Group¬≥ Engagements (Within a Product) Add, Edit Engagements ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Add, Edit Risk Acceptances ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Engagements ‚òëÔ∏è ‚òëÔ∏è Tests (Within a Product) Add Tests ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Edit Tests ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Tests ‚òëÔ∏è ‚òëÔ∏è Findings (Within a Product) Add Findings ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Edit Findings ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Import, Reimport Scan Results ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Findings ‚òëÔ∏è ‚òëÔ∏è Add, Edit, Delete Finding Groups ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Other Data (Within a Product) Add, Edit Endpoints ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Endpoints ‚òëÔ∏è ‚òëÔ∏è Edit Benchmarks ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Benchmarks ‚òëÔ∏è ‚òëÔ∏è View Note History ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Add, Edit, Delete Own Notes ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Edit Other Notes ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Delete Other Notes ‚òëÔ∏è ‚òëÔ∏è A user who is assigned permissions at the Product level only cannot view the Product Type it is contained in. When a new Product is added underneath a Product Type, all Product Type-level Users will be added as Members of the new Product with their Product Type-level Role. The user who wishes to make changes to a Group must also have Edit Group Configuration Permissions, and a Maintainer or Owner Group Configuration Role in the Group they wish to edit. Configuration Permission Chart Each Configuration Permission refers to a particular function in the software, and has an associated set of actions a user can perform related to this function.\nThe majority of Configuration Permissions give users access to certain pages in the UI.\nConfiguration Permission View ‚òëÔ∏è Add ‚òëÔ∏è Edit ‚òëÔ∏è Delete ‚òëÔ∏è Credential Manager Access the ‚öôÔ∏èConfiguration \u0026gt; Credential Manager page Add new entries to the Credential Manager Edit Credential Manager entries Delete Credential Manager entries Development Environments n/a Add new Development Environments to the üóìÔ∏èEngagements \u0026gt; Environments list Edit Development Environments in the üóìÔ∏èEngagements \u0026gt; Environments list Delete Development Environments from the üóìÔ∏èEngagements \u0026gt; Environments list Finding Templates¬π Access the Findings \u0026gt; Finding Templates page Add a Finding Template Edit a Finding Template Delete a Finding Template Groups Access the üë§Users \u0026gt; Groups page Add a new User Group Superuser only Superuser only Jira Instances Access the ‚öôÔ∏èConfiguration \u0026gt; JIRA page Add a new JIRA Configuration Edit an existing JIRA Configuration Delete a JIRA Configuration Language Types Login Banner n/a n/a Edit the login banner, located under ‚öôÔ∏èConfiguration \u0026gt; Login Banner n/a Announcements n/a n/a Configure Announcements, located under ‚öôÔ∏èConfiguration \u0026gt; Announcements n/a Note Types Access the ‚öôÔ∏èConfiguration \u0026gt; Note Types page Add a Note Type Edit a Note Type Delete a Note Type Product Types n/a Add a new Product Type (under Products \u0026gt; Product Type) n/a n/a Questionnaires Access the Questionnaires \u0026gt; All Questionnaires page Add a new Questionnaire Edit an existing Questionnaire Delete a Questionnaire Questions Access the Questionnaires \u0026gt; Questions page Add a new Question Edit an existing Question n/a Regulations n/a Add a Regulation to the ‚öôÔ∏èConfiguration \u0026gt; Regulations page Edit an existing Regulation Delete a Regulation SLA Configuration Access the ‚öôÔ∏èConfiguration \u0026gt; SLA Configuration page Add a new SLA Configuration Edit an existing SLA Configuration Delete an SLA Configuration Test Types n/a Add a new Test Type (under Engagements \u0026gt; Test Types) Edit an existing Test Type n/a Tool Configuration Access the ‚öôÔ∏èConfiguration \u0026gt; Tool Configuration page Add a new Tool Configuration Edit an existing Tool Configuration Delete a Tool Configuration Tool Types Access the ‚öôÔ∏èConfiguration \u0026gt; Tool Types page Add a new Tool Type Edit an existing Tool Type Delete a Tool Type Users Access the üë§Users \u0026gt; Users page Add a new User to DefectDojo Edit an existing User Delete a User Access to the Finding Templates page also requires the Writer, Maintainer or Owner Global Role for this user. Group Configuration Permissions Configuration Permission Reader Maintainer Owner View Group ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Remove self from Group ‚òëÔ∏è ‚òëÔ∏è ‚òëÔ∏è Edit a Member‚Äôs role in a Group ‚òëÔ∏è ‚òëÔ∏è Edit or Delete a Product or Product Type Membership from a Group¬π ‚òëÔ∏è ‚òëÔ∏è Change a Group Member‚Äôs role to Owner ‚òëÔ∏è Delete Group ‚òëÔ∏è This also requires the User to have at least a Maintainer Role on the Product or Product Type which they wish to edit. ","date":"0001-01-01","id":56,"permalink":"/en/customize_dojo/user_management/user_permission_chart/","summary":"Role Permission Chart This chart is intended to list all permissions related to a Product or Product Type, as well as which permissions are available to each role.","tags":[],"title":"Action permission charts"},{"content":"LDAP Authentication Out of the box Defect Dojo does not support LDAP authentication.\nHowever, since Defect Dojo is built using Django, it isn\u0026rsquo;t too difficult to add support for LDAP. So long as you don\u0026rsquo;t mind building your own Docker images\u0026hellip;\nWe will need to modify a grand total of 4-5 files, depending on how you want to pass Dojo your LDAP secrets.\nDockerfile.django-* Dockerfile.nginx-* requirements.txt local_settings.py docker-compose.yml (Optional) Dockerfile modifications In both Dockerfile.django and Dockerfile.nginx, you want to add the following lines to the apt-get install layers:\nlibldap2-dev \\ libsasl2-dev \\ ldap-utils \\\rrequirements.txt Please check for the latest version of these requirements at the time of implementation on pypi.org and use those if you can.\npython-ldap django-auth-ldap Otherwise add the following to requirements.txt:\npython-ldap==3.4.2 django-auth-ldap==4.1.0\rlocal_settings.py Find the settings file (hint: check in /dojo/settings/settings.py for instructions for how to use /dojo/settings/local_settings.py, if the file does not already exist) and add the following:\nAt the top of the file:\nimport ldap from django_auth_ldap.config import LDAPSearch, GroupOfNamesType\rThen further down add LDAP settings to the env dict:\n# LDAP DD_LDAP_SERVER_URI=(str, \u0026#39;ldap://ldap.example.com\u0026#39;), DD_LDAP_BIND_DN=(str, \u0026#39;\u0026#39;), DD_LDAP_BIND_PASSWORD=(str, \u0026#39;\u0026#39;),\rThen under the env dict add:\nAUTH_LDAP_SERVER_URI = env(\u0026#39;DD_LDAP_SERVER_URI\u0026#39;) AUTH_LDAP_BIND_DN = env(\u0026#39;DD_LDAP_BIND_DN\u0026#39;) AUTH_LDAP_BIND_PASSWORD = env(\u0026#39;DD_LDAP_BIND_PASSWORD\u0026#39;) AUTH_LDAP_USER_SEARCH = LDAPSearch( \u0026#34;ou=Groups,dc=example,dc=com\u0026#34;, ldap.SCOPE_SUBTREE, \u0026#34;(uid=%(user)s)\u0026#34; ) AUTH_LDAP_USER_ATTR_MAP = { \u0026#34;first_name\u0026#34;: \u0026#34;givenName\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;sn\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;mail\u0026#34;, }\rPlease make sure to customise all of the LDAP search variables to match your company\u0026rsquo;s configuration.\nFor additional group controls you can add:\n# Set up the basic group parameters. AUTH_LDAP_GROUP_SEARCH = LDAPSearch( \u0026#34;dc=example,dc=com\u0026#34;, ldap.SCOPE_SUBTREE, \u0026#34;(objectClass=groupOfNames)\u0026#34;, ) AUTH_LDAP_GROUP_TYPE = GroupOfNamesType(name_attr=\u0026#34;cn\u0026#34;) # Simple group restrictions AUTH_LDAP_REQUIRE_GROUP = \u0026#34;cn=DD_USER_ACTIVE,ou=Groups,dc=example,dc=com\u0026#34; AUTH_LDAP_USER_FLAGS_BY_GROUP = { \u0026#34;is_active\u0026#34;: \u0026#34;cn=DD_USER_ACTIVE,ou=Groups,dc=example,dc=com\u0026#34;, \u0026#34;is_staff\u0026#34;: \u0026#34;cn=DD_USER_STAFF,ou=Groups,dc=example,dc=com\u0026#34;, \u0026#34;is_superuser\u0026#34;: \u0026#34;cn=DD_USER_ADMIN,ou=Groups,dc=example,dc=com\u0026#34;, }\rThen also add 'django_auth_ldap.backend.LDAPBackend' to the AUTHENTICATION_BACKENDS variable, for example:\nAUTHENTICATION_BACKENDS = ( \u0026#39;django_auth_ldap.backend.LDAPBackend\u0026#39;, \u0026#39;django.contrib.auth.backends.RemoteUserBackend\u0026#39;, \u0026#39;django.contrib.auth.backends.ModelBackend\u0026#39;, )\rRead the docs for Django Authentication with LDAP here: https://django-auth-ldap.readthedocs.io/en/latest/\ndocker-compose.yml In order to pass the variables to the local_settings.py file via docker, it\u0026rsquo;s a good idea to add these to the docker compose file.\nYou can do this by adding the following variables to the environment section for the uwsgi image:\nDD_LDAP_SERVER_URI: \u0026#34;${DD_LDAP_SERVER_URI:-ldap://ldap.example.com}\u0026#34; DD_LDAP_BIND_DN: \u0026#34;${DD_LDAP_BIND_DN:-}\u0026#34; DD_LDAP_BIND_PASSWORD: \u0026#34;${DD_LDAP_BIND_PASSWORD:-}\u0026#34;\rAlternatively you can set these values in a local_settings.py file.\n","date":"0001-01-01","id":57,"permalink":"/en/open_source/ldap-authentication/","summary":"LDAP Authentication Out of the box Defect Dojo does not support LDAP authentication.\nHowever, since Defect Dojo is built using Django, it isn\u0026rsquo;t too difficult to add support for LDAP.","tags":[],"title":"Authentication via LDAP"},{"content":"If you have a CI/CD pipeline, a daily scan process or any kind of repeated incoming report, setting up a Reimport process in advance is key to avoiding excessive duplicates. Reimport collapses the context and Findings associated with a recurring test into a single Test page, where you can review import history and track vulnerability changes across scans.\nCreate an Engagement to store the CI/CD results for the object you‚Äôre running CI/CD on. This could be a code repository where you have CI/CD actions set up to run. Generally, you want a separate Engagement set up for each pipeline so that you can quickly understand where the Finding results are coming from.\n‚Äã Each CI/CD action will import data to DefectDojo in a separate step, so each of those should be mapped to a separate Test. For example, if each pipeline execution runs an NPM-audit as well as a dependency scan, each scan result will need to flow into a Test (nested under the Engagement).\n‚Äã You do not need to create a new Test each time the CI/CD action runs. Instead, you can Reimport data to the same test location. Reimport in action DefectDojo will compare the incoming scan data with the existing scan data, and then apply changes to the Findings contained within your Test as follows:\n‚Äã\nCreate Findings Any vulnerabilities which were not contained in the previous import will be added to the Test automatically as new Findings.\n‚Äã\nIgnore existing Findings If any incoming Findings match Findings that already exist, the incoming Findings will be discarded rather than recorded as Duplicates. These Findings have been recorded already - no need to add a new Finding object. The Test page will show these Findings as Left Untouched.\n‚Äã\nClose Findings If there are any Findings that already exist in the Test but which are not present in the incoming report, you can choose to automatically set those Findings to Inactive and Mitigated (on the assumption that those vulnerabilities have been resolved since the previous import). The Test page will show these Findings as Closed.\nIf you don‚Äôt want any Findings to be closed, you can disable this behavior on Reimport:\nUncheck the Close Old Findings checkbox if using the UI Set close_old_findings to False if using the API ‚Äã Reopen Findings If there are any Closed Findings which appear again in a Reimport, they will automatically be Reopened. The assumption is that these vulnerabilities have occurred again, despite previous mitigation. The Test page will track these Findings as Reactivated. If you‚Äôre using a triage-less scanner, or you don‚Äôt otherwise want Closed Findings to reactivate, you can disable this behavior on Reimport:\nSet do_not_reactivate to True if using the API Check the Do Not Reactivate checkbox if using the UI Working with Import History Import History for a given test is listed under the Test Overview header on the Test page.\nThis table shows each Import or Reimport as a single line with a Timestamp, along with Branch Tag, Build ID, Commit Hash and Version columns if those were specified.\nActions This header indicates the actions taken by an Import/Reimport.\n# created indicates the number of new Findings created at the time of Import/Reimport # closed shows the number of Findings that were closed by a Reimport (due to not existing in the incoming report). # left untouched shows the count of Open Findings which were unchanged by a Reimport (because they also existed in the incoming report). # reactivated shows any Closed Findings which were reopened by an incoming Reimport. Why not simply use Import? Although both methods are possible, Import should be reserved for new occurrences of Findings and Data, while Reimport should be applied for further iterations of the same data.\nIf your CI/CD pipeline runs an Import and creates a new Test object each time, each Import will give you a collection of discrete Findings which you will then need to manage as separate objects. Using Reimport alleviates this problem and eliminates the amount of ‚Äòcleanup‚Äô you‚Äôll need to do when a vulnerability is resolved.\nUsing Reimport allows you to store each recurring report on the same page, and maintains a continuity of each time new data was added to the Test.\nHowever, if you‚Äôre using the same scanning tool in multiple locations or contexts, it may be more appropriate to create a separate Test for each location or context. This depends on your preferred method of organization.\n","date":"0001-01-01","id":58,"permalink":"/en/working_with_findings/finding_deduplication/avoiding_duplicates_via_reimport/","summary":"If you have a CI/CD pipeline, a daily scan process or any kind of repeated incoming report, setting up a Reimport process in advance is key to avoiding excessive duplicates.","tags":[],"title":"Avoid Duplicates: Reimport Recurring Tests"},{"content":"You can find further information in the contributing guidelines.\n","date":"0001-01-01","id":59,"permalink":"/en/open_source/contributing/","summary":"You can find further information in the contributing guidelines.","tags":[],"title":"Contributing"},{"content":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.\nWhen he is asked to audit an application, Bill registers a new Product in DefectDojo, and creates a new Engagement. Here he sets some basic information, like how long he expects the Engagement will take, who will be leading the testing (himself), what Product he will be working on, and what tests he will be doing.\nNext, he can add a Test to the Engagement, or upload a Nessus scan and start picking out the real vulnerabilities from the false positives (Nessus scan Findings are imported as inactive by default).\nWithin the Test section, Bill can add Findings for any issues that he has uncovered during his audit. He can assign a severity to the Findings, describe replication steps, mitigation strategies, and impact on the system. This will come in handy when he wants to generate a report to send to the development team responsible for this Product, or his manager.\nOnce Bill has completed his Engagement, he can close the Engagement on the main Engagement page. He can then view the results of his Tests, and generate a report to send to the development team.\nIf Bill hears back from the development team that they won't be able to fix the issue for a while, he can make a note of this on the Engagement page. Bill will also receive Alerts for any bugs that persist longer than they are supposed to based on their severity.\nExample 2 - John the QE manager John wants to keep tabs on what his team members are up to, and find issues that are taking a long time to get fixed. He creates his own DefectDojo account with superuser privileges so that he can view other team members' metrics.\nTo get a better idea of what his team members are currently working on, he can start by checking the Calendar. This will show him any active Engagements that his team is involved in, based on the dates assigned to those Engagements.\nHe can view metrics for a Product Type, such as \u0026quot;Third Party Apps\u0026quot; to track his team's activity and follow up with Product teams who have long-lived bugs. He can also look at all the Findings for which there is a Risk Acceptance associated, and ensure that the proper documentation or timeline has been provided for the Findings in question.\nIf he wants to check on a particular team member's progress, he can look at the Engineer Metrics dashboard under \u0026quot;Additional Metrics\u0026quot; for that user.\n","date":"0001-01-01","id":60,"permalink":"/en/open_source/archived_docs/usage/workflows/","summary":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.","tags":[],"title":"Example workflows"},{"content":"Filter String Matching Optimization IN the UI, many of the filters for a given object will also query related objects for an easy visual match of an item to filter on. For instances with many objects, this could lead to a considerable performance hit. To alleviate this constriction, enable the \u0026ldquo;Filter String Matching Optimization\u0026rdquo; setting in the System Settings to change many filters to only search on names, rather than the objects themselves. This change will save many large queries, and will improve the performance of UI based interactions.\nAsynchronous Import DefectDojo offers an experimental feature to aynschronously import security reports. This feature works in most use cases, but struggles when doing things such as pushing to Jira during the import process. Because Endpoints are still being processed and created even after the import procedure is completed, pushing Findings to Jira can result in incomplete Jira tickets. It is advised to wait until after import has been completed (reaches 100%).\nTo enable this feature, set ASYNC_FINDING_IMPORT to True in local_settings.py\nAsynchronous Delete For larger instances, deleting an object can take minutes for all related objects to be expanded into memory, rendered on the page, and then removing all objects from the database. To combat this issue, two settings can be set in local_settings.py:\nASYNC_OBJECT_DELETE Deleting an object asynchronously changes the way an object is deleted under the hood. By removing the need to expand into memory, a lot of time (and memory) can be saved by offloading the lookups and removals onto celery processes. This process works by starting at the bottom of a given object, and walking the tree upwards rather than downwards. This way, objects can be seperated into buckets, and then deleted.\nDELETE_PREVIEW Previewing all the objects to be deleted takes almost as much time as deleting the objects itself. This is a safety feature intended to warn users of what they are about to delete, as well as educating users of how the delete functionality works by cascade deleting all related objects. With this feature enabled, the user will only see the following text in the delete preview (without any database lookups)\nPreviewing the relationships has been disabled.\n","date":"0001-01-01","id":61,"permalink":"/en/open_source/performance/","summary":"Filter String Matching Optimization IN the UI, many of the filters for a given object will also query related objects for an easy visual match of an item to filter on.","tags":[],"title":"Performance Enhancements"},{"content":"Production Use (with Docker compose) The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.\nAlthough Docker Compose is one of the supported installation methods to deploy a containerized DefectDojo in a production environment, the docker-compose.yml file is not intended for production use without first customizing it to your particular situation.\nSee Running with Docker Compose for more information how to run DefectDojo with Docker Compose.\nSystem Requirements It is recommended to use a dedicated database server and not the preconfigured PostgreSQL database. This will improve the performance of DefectDojo significantly.\nInstance Size With a separate database, the minimum recommendations to run DefectDojo are:\n2 vCPUs 8 GB of RAM 10 GB of disk space (remember, your database is not here -- so what you have for your O/S should do). You could allocate a different disk than your OS's for potential performance improvements. Security Verify the nginx configuration and other run-time aspects such as security headers to comply with your compliance requirements. Change the AES256 encryption key \u0026amp;91a*agLqesc*0DJ+2*bAbsUZfR*4nLw in docker-compose.yml to something unique for your instance. This encryption key is used to encrypt API keys and other credentials stored in Defect Dojo to connect to external tools such as SonarQube. A key can be generated in various ways for example using a password manager or openssl:\nopenssl rand -base64 32\rDD_CREDENTIAL_AES_256_KEY: \u0026#34;${DD_CREDENTIAL_AES_256_KEY:-\u0026lt;PUT THE GENERATED KEY HERE\u0026gt;o}\u0026#34;\rFile Backup In both cases (dedicated DB or containerized), if you are self-hosting, it is recommended that you implement and create periodic backups of your data.\nMedia files Media files for uploaded files, including threat models and risk acceptance, are stored in a docker volume. This volume needs to be backed up regularly.\nPerformance Adjustments uWSGI By default (except in ptvsd mode for debug purposes), uWSGI will handle 4 concurrent connections.\nBased on your resource settings, you can tweak:\nDD_UWSGI_NUM_OF_PROCESSES for the number of spawned processes. (default 2) DD_UWSGI_NUM_OF_THREADS for the number of threads in these processes. (default 2) For example, you may have 4 processes with 6 threads each, yielding 24 concurrent connections.\nCelery worker By default, a single mono-process celery worker is spawned. When storing a large amount of findings or running large imports it might be helpful to adjust these parameters to prevent resource starvation.\nThe following variables can be changed to increase worker performance, while keeping a single celery container.\nDD_CELERY_WORKER_POOL_TYPE will let you switch to prefork. (default solo) When you enable prefork, the variables below have to be used. see the Dockerfile.django-* for in-file references.\nDD_CELERY_WORKER_AUTOSCALE_MIN defaults to 2. DD_CELERY_WORKER_AUTOSCALE_MAX defaults to 8. DD_CELERY_WORKER_CONCURRENCY defaults to 8. DD_CELERY_WORKER_PREFETCH_MULTIPLIER defaults to 128. You can execute the following command to see the configuration:\ndocker compose exec celerybeat bash -c \u0026quot;celery -A dojo inspect stats\u0026quot; and see what is in effect.\nAsynchronous Import This experimental feature has been deprecated as of DefectDojo 2.44.0 (March release). Please exercise caution if using this feature with an older version of DefectDojo, as results may be inconsistent.\nImport and Re-Import can also be configured to handle uploads asynchronously to aid in processing especially large scans. It works by batching Findings and Endpoints by a configurable amount. Each batch will be be processed in separate celery tasks.\nThe following variables impact async imports.\nDD_ASYNC_FINDING_IMPORT defaults to False DD_ASYNC_FINDING_IMPORT_CHUNK_SIZE defaults to 100 When using asynchronous imports with dynamic scanners, Endpoints will continue to \u0026ldquo;trickle\u0026rdquo; in even after the import has returned a successful response. This is because processing continues to occur after the Findings have already been imported.\nTo determine if an import has been fully completed, please see the progress bar in the appropriate test.\n","date":"0001-01-01","id":62,"permalink":"/en/open_source/installation/running-in-production/","summary":"Production Use (with Docker compose) The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.","tags":[],"title":"Running in Production (Open Source)"},{"content":"Note: The Beta UI and associated features are only available in DefectDojo Pro.\nIn late 2023, DefectDojo Inc. released a new UI for DefectDojo Pro, which has since been in Beta for Pro customers to test and experiment with.\nThe Beta UI brings the following enhancements to DefectDojo:\nModern and sleek design, built using Vue.js Optimized data delivery and load times, especially for large datasets Access to new Pro features, including API Connectors, Universal Importer, and Pro Metrics views Improved UI workflows: better filtering, dashboards, and navigation Switching To The Beta UI To access the Beta UI, open your User Options menu from the top-right hand corner. You can also switch back to the Classic UI from the same menu.\nNavigational Changes The Sidebar has been reorganized: Pro Metrics and the Homepage can be found in the first section.\nImport methods can be found in the Import section: set up API Connectors, use the Import Scan form to Add Findings, or use Smart Upload to handle infrastructure scanning tools.\nThe Manage section allows you to view different objects in the Product Hierarchy, with views for Product Types, Products, Engagements, Tests, Findings, Risk Acceptances, Endpoints and Components.\nThe Settings section allows you to configure your DefectDojo instance, including your License, Cloud Settings, Users, Feature Configuration and admin-level Enterprise Settings.\nThe Enterprise settings section contains the System Settings, Jira Instances, Deduplication Settings, SAML, OAuth, Login and MFA forms.\nThe beta UI also has a new table format to help with navigation. This table is used with all Product Hierarchy. Each column can be clicked on to apply a relevant filter, and columns can be reordered to present data however you like.\nThe table also has a \u0026ldquo;Toggle Columns\u0026rdquo; menu which can add or remove columns from the table.\nFiltering the Table In this screenshot we are filtering for all Findings that are in \u0026lsquo;Product One\u0026rsquo;. Once we apply this filter (by clicking outside of the Filters menu), the contents of this Finding list will automatically update to reflect the filter applied.\nNew Dashboards New metrics visualizations are included in the Beta UI. All of these reports can be filtered and exported as PDF to share them with a wider audience.\nThe Executive Insights dashboard displays the current state of your Products and Product Types. Program Insights dashboard displays the effectiveness of your security team and the cost savings associated with separating duplicates and false positives from actionable Findings. Remediation Insights displays your effectiveness at remediating Findings. Tool Insights displays the effectiveness of your tool suite (and Connectors pipelines) at detecting and reporting vulnerabilities. ","date":"0001-01-01","id":63,"permalink":"/en/about_defectdojo/ui_pro_vs_os/","summary":"Note: The Beta UI and associated features are only available in DefectDojo Pro.\nIn late 2023, DefectDojo Inc. released a new UI for DefectDojo Pro, which has since been in Beta for Pro customers to test and experiment with.","tags":[],"title":"üé® Pro UI Changes"},{"content":"Note: Currently this article only covers Finding Filters available in the DefectDojo Pro Beta UI, but this article will be expanded in the future to govern more object types, along with Open-Source filters.\nHere is a list of filters that can be applied in the DefectDojo Beta UI to sort lists of Findings. DefectDojo Filters can be used to assist with navigating through lists of Objects, creating custom Dashboard Tiles, or creating automation via Rules Engine.\nFindings These fields are specific to DefectDojo Findings and are used to organize a Finding. Each of these filters is a separate column in the All Findings table.\nFindings in DefectDojo can be filtered by:\nDefectDojo Metadata These Filters are related directly to DefectDojo core functionality.\nCannot be modified These Filters are assigned at the time of issue creation, and cannot be directly modified via Edit Finding.\nFinding Severity (any of Info, Low, Medium, High, Critical) Product Product Type Engagement Engagement Version Test Test Type Test Version Date Created Age (Finding age in days) SLA Expiration Date Mitigated Within SLA (True or False value: was the Finding Mitigated within SLA or not?) Reporter (user or service who created the Finding) Found by (refers to the Tool) Can be modified These fields are set when an issue is created, but can be modified as an issue progresses.\nStatus Last Status Update (Timestamp) Mitigated (True or False) Additional Model Functions These DefectDojo functions can be used to further organize your Findings or track remediation.\nFinding Tags Reviewers (Assigned User) Has Notes (True/False) Group (refers to the Finding Group, if one exists) Risk Acceptance (select one or more existing Risk Acceptances from the list) Tool-Specific Metadata These fields have no direct impact on the functionality of DefectDojo, but provide additional information to help explain and mitigate issues. They can be set when a Finding is initially created (using information in an incoming report), or they can be changed by a user.\nCWE Value Vulnerability ID (usually a CVE) EPSS Score EPSS Percentile Service Planned Remediation Date Planned Remediation Version Has Component (True/False) Component Name Component Version File Path Effort for Fixing Jira Metadata If using the Jira integration, these filters track updates to linked Jira Issues.\nJira Issue (Can filter by whether the Finding has one, or not) Jira Age (Age of Jira Issue) Jira Change (Last time changes were pushed to Jira) ","date":"0001-01-01","id":64,"permalink":"/en/working_with_findings/organizing_engagements_tests/filter_index/","summary":"Note: Currently this article only covers Finding Filters available in the DefectDojo Pro Beta UI, but this article will be expanded in the future to govern more object types, along with Open-Source filters.","tags":[],"title":"Filter Index"},{"content":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool. If the repository of the source code is specified in the Engagement, DefectDojo will present the filepath as a link and the user can navigate directly to the location of the vulnerability.\nSetting the repository in the Engagement and Test Engagement While editing the Engagement, users can set the URL of the specific SCM repo. For Interactive Engagement it needs to be the URL including the branch:\nfor GitHub - like https://github.com/DefectDojo/django-DefectDojo/tree/dev for GitLab - like https://gitlab.com/gitlab-org/gitlab/-/tree/master for public BitBucket - like (like git clone url) for standalone/onpremise BitBucket https://bb.example.com/scm/some-project/some-repo.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url) For CI/CD Engagement, where user could set commit hash, branch/tag and code line it should look like examples below:\nfor GitHub - like https://github.com/DefectDojo/django-DefectDojo for GitLab - like https://gitlab.com/gitlab-org/gitlab for public BitBucket, Gitea and Codeberg - like https://bitbucket.org/some-user/some-project.git (like git clone url) for standalone/onpremise BitBucket https://bb.example.com/scm/some-project.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url) If user does not set commit hash or branch/tag in appropriate fields of CI/CD Engagement edit form, the URL should look like in Interactive Engagement edit form.\nSCM navigation URL is composed from Repo URL using SCM Type. A specific SCM type can be set in Product custom field \u0026ldquo;scm-type\u0026rdquo;. If no \u0026ldquo;scm-type\u0026rdquo; is set and the URL contains \u0026ldquo;https://github.com\u0026rdquo;, a \u0026ldquo;github\u0026rdquo; SCM type is assumed.\nProduct custom fields:\nProduct SCM type add:\nPossible SCM types could be \u0026lsquo;github\u0026rsquo;, \u0026lsquo;gitlab\u0026rsquo;, \u0026lsquo;bitbucket\u0026rsquo;, \u0026lsquo;bitbucket-standalone\u0026rsquo;, \u0026lsquo;gitea\u0026rsquo;, \u0026lsquo;codeberg\u0026rsquo; or nothing (for default github).\nLink in Finding When viewing a finding, the location will be presented as a link, if the repository of the source code has been set in the Engagement:\nClicking on this link will open a new tab in the browser, with the source file of the vulnerability at the corresponding line number:\n","date":"0001-01-01","id":65,"permalink":"/en/open_source/archived_docs/integrations/source-code-repositories/","summary":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool.","tags":[],"title":"Source code repositories"},{"content":"Demo Try out the demo sever at demo.defectdojo.org\nLog in with admin / 1Defectdojo@demo#appsec. Please note that the demo is publicly accessable and regularly reset. Do not put sensitive data in the demo.\n","date":"0001-01-01","id":66,"permalink":"/en/open_source/installation/demo/","summary":"Demo Try out the demo sever at demo.defectdojo.org\nLog in with admin / 1Defectdojo@demo#appsec. Please note that the demo is publicly accessable and regularly reset.","tags":[],"title":"Demo"},{"content":"If your team requires an on-premise DefectDojo installation, please connect with our Sales team by emailing -\u0026gt; info at defectdojo dot com\r. This trial setup process only applies to DefectDojo Cloud users.\nAll DefectDojo plans include a free 2-week trial, which you can use to evaluate our software. DefectDojo Trial instances are fully-featured and can be immediately converted to our team into paid instances - no need to set everything up again, or reupload any data when your trial period ends.\nAt the end of this process, you\u0026rsquo;ll be put in touch with our Sales team, who will follow up to receive your billing information, and authorize and set up your company\u0026rsquo;s trial instance.\nRequesting your Trial In order to sign up for a trial, you\u0026rsquo;ll need to create an account on our Cloud Portal, and then click the New Subscription menu option from the sidebar.\nStep 1: Welcome Click Continue to begin setting up your instance.\nStep 2: Enter your Company Information \u0026amp; create your Domain Enter your company\u0026rsquo;s Name and the Server Label you want to use with DefectDojo. You will then have a custom domain created for your DefectDojo instance on our servers.\nNormally, DefectDojo will name your domain according to your Company Name., but if you select \u0026ldquo;Use Server Label in Domain\u0026rdquo;, DefectDojo will instead label your domain according to the Server Label you chose. This approach may be preferred if you plan to use multiple DefectDojo instances (such as a Production instance and a Test instance, for example). Please contact our Sales team -\u0026gt; info at defectdojo dot com\rif you require multiple instances.\nStep 3: Select a Server Location Select a Server Location from the drop-down menu. We recommend selecting a server that is geographically closest to the main DefectDojo team to reduce server latency.\nStep 4: Configure your Firewall Rules Enter the IP address ranges, subnet mask and labels that you want to allow to access DefectDojo. Additional IP addresses and rules can be added or changed by your team after your instance is up and running.\nIf you want to use external services with DefectDojo (GitHub or JIRA), check the appropriate boxes listed under Select External Services.\nStep 5: Confirm your Plan type and Billing Frequency Before you complete the process, please confirm the plan you want to use along with your billing frequency - monthly or annually.\nStep 6: Review and Submit your Request We\u0026rsquo;ll prompt you to look over your request one more time. Once submitted, only Firewall rules can be changed by your team without assistance from Support. To contact Support, please email support at defectdojo dot com\ror follow the instructions in this article.\nAfter reviewing and accepting DefectDojo\u0026rsquo;s License and Support Agreement, you can click Checkout With Stripe or Contact Sales.\nCheckout With Stripe will take you to a Stripe page where you can enter your billing information. If you do not wish to enter your billing info at this time, you can click Contact Sales - our Sales team will be in touch to set up your trial. Once your trial has been approved Our Support team will send you a Welcome email with links and an initial password to access your DefectDojo instance. You can always reach out to support at defectdojo dot com\rfor product assistance once your trial begins.\n","date":"0001-01-01","id":67,"permalink":"/en/about_defectdojo/request_a_trial/","summary":"If your team requires an on-premise DefectDojo installation, please connect with our Sales team by emailing -\u0026gt; info at defectdojo dot com\r.","tags":[],"title":"Request a DefectDojo Pro Trial"},{"content":"Need help with DefectDojo? Here are some ways to get assistance.\nOpen-Source Support Open-Source users can receive help and advice through our community channels.\nFor Open-Source users, the quickest way to get help is through the OWASP Slack Channel. Our community members are active on the # defectdojo channel and can help you with issues you\u0026rsquo;re facing.\nTo report a bug, issues can be raised on our GitHub.\nSee our Community Site for more information.\nDefectDojo Pro Support DefectDojo Pro subscriptions come with full support from the DefectDojo Inc team during the initial trial period and beyond.\nEmail Customers / Pro Users can always email our team directly at support at defectdojo dot com\rfor assistance.\nWithin DefectDojo You can contact us through the DefectDojo App:\nby opening Cloud Manager \u0026gt; Contact Support from the left sidebar or through {your-instance}.defectdojo.com/cloud_portal/support. Through the Cloud Portal You can also contact our support team through your Cloud Portal:\nby clicking on Contact Us (on the left sidebar) or via https://cloud.defectdojo.com/resources/contact. ","date":"0001-01-01","id":68,"permalink":"/en/about_defectdojo/contact_defectdojo_support/","summary":"Need help with DefectDojo? Here are some ways to get assistance.\nOpen-Source Support Open-Source users can receive help and advice through our community channels.","tags":[],"title":"Get Support"},{"content":"Import of languages for a project You can import JSON reports generated by the cloc tool via the API:\nWhen importing a file, all language information for the respective project will be deleted first and then populated with the content of the file. Please make sure to use the --json parameter when invoking the cloc command, to get the correct file format.\nDisplay The results of the import are shown on the left side of the product details page.\nThe colors are defined by entries in the table Language_Type, which has been prepopulated with data from GitHub.\nImport of language types GitHub updates its language colors from time to time, when new languages emerge. The management command\n./manage.py import_github_languages\nreads data from a JSON file hosted in https://github.com/ozh/github-colors to add new languages and update colors.\n","date":"0001-01-01","id":69,"permalink":"/en/open_source/languages/","summary":"Import of languages for a project You can import JSON reports generated by the cloc tool via the API:\nWhen importing a file, all language information for the respective project will be deleted first and then populated with the content of the file.","tags":[],"title":"Languages and lines of code"},{"content":"DefectDojo has protection against brute force attacks through rate limiting\nConfiguration For further information, please visit the package documentation Django Ratelimit\nEnable Rate Limiting To enable and configure rate limiting, edit the settings (see Configuration and edit/replace the following information:\nDD_RATE_LIMITER_ENABLED=(bool, True), DD_RATE_LIMITER_RATE=(str, \u0026#39;5/m\u0026#39;), DD_RATE_LIMITER_BLOCK=(bool, True), DD_RATE_LIMITER_ACCOUNT_LOCKOUT=(bool, True), Rate Limit The frequency at which the request will be limited can be set to\nseconds - 1s minutes - 5m hours - 100h days - 2400d Extended configuration can be found here\nBlock Requests By default, rate limiting is set to record offenses, but does not actually block requests and enforce the limit.\nSetting DD_RATE_LIMITER_BLOCK will block all incoming requests at the configured frequncy once that frequency has been exceeded.\nAccount Lockout In the event of a brute force attack, a users credentials could potentially be comprimised.\nIn an attempt to circumvent that event, setting DD_RATE_LIMITER_ACCOUNT_LOCKOUT will force a user to reset their password upon the next attempted login.\nMulti-Process Behavior When using configurations with multiple uwsgi processes, the rate limiting package uses the default cache that is memory based and local to a process.\nExtra Configuation For further information, please visit the package documentation Django Ratelimit\n","date":"0001-01-01","id":70,"permalink":"/en/open_source/rate_limiting/","summary":"DefectDojo has protection against brute force attacks through rate limiting\nConfiguration For further information, please visit the package documentation Django Ratelimit","tags":[],"title":"Rate Limiting"},{"content":"Export Findings Pages that show a list of findings or a list of engagements have a CSV and Excel Export functionality in the top right dropdown menu.\nThe list of engagements can be exported as CSV/Excel.\n","date":"0001-01-01","id":71,"permalink":"/en/open_source/exporting/","summary":"Export Findings Pages that show a list of findings or a list of engagements have a CSV and Excel Export functionality in the top right dropdown menu.","tags":[],"title":"Exporting"},{"content":"","date":"2023-09-07","id":72,"permalink":"/en/open_source/","summary":"","tags":[],"title":"Open Source DefectDojo"},{"content":"","date":"2023-09-07","id":73,"permalink":"/","summary":"","tags":[],"title":"DefectDojo Documentation"},{"content":"Note: Connectors are a DefectDojo Pro-only feature.\nDefectDojo allows users to build sophisticated API integrations, and gives users full control over how their vulnerability data is organized.\nBut everyone needs a starting point, and that\u0026rsquo;s where Connectors come in. Connectors are designed to get your security tools connected and importing data to DefectDojo as quickly as possible.\nWe currently support Connectors for the following tools, with more on the way:\nAWS Security Hub BurpSuite Checkmarx ONE Dependency-Track Probely Semgrep SonarQube Snyk Tenable Wiz These Connectors provide an API-speed integration with DefectDojo, and can be used to automatically ingest and organize vulnerability data from the tool.\nConnectors Quick-Start If you\u0026rsquo;re using DefectDojo\u0026rsquo;s Auto-Map settings, you can have your first Connector up and running in no time.\nSet up a Connector from a supported tool. Discover your tool\u0026rsquo;s data hierarchy. Sync the vulnerabilities found with your tool into DefectDojo. That\u0026rsquo;s all, really! And remember, even if you create your Connector the \u0026rsquo;easy\u0026rsquo; way, you can easily change the way things are set up later, without losing any of your work.\nHow Connectors Work As long as you have the API key from the tool you\u0026rsquo;re trying to connect, a connector can be added in just a few minutes. Once the connection is working, DefectDojo will Discover your tool\u0026rsquo;s environment to see how you\u0026rsquo;re organizing your scan data.\nLet\u0026rsquo;s say you have a BurpSuite tool, which is set up to scan five different repositories for vulnerabilities. Your Connector will take note of this organizational structure and set up Records to help you translate those separate repositories into DefectDojo\u0026rsquo;s Product / Engagement / Test hierarchy. If you have \u0026lsquo;Auto-Map Records\u0026rsquo; enabled, DefectDojo will learn and copy that structure automatically.\nOnce your Record mappings are set up, DefectDojo will start importing scan data on a regular basis. You\u0026rsquo;ll be kept up to date on any new vulnerabilities detected by the tool, and you can start working with existing vulnerabilities immediately, using DefectDojo\u0026rsquo;s Findings system.\nWhen you\u0026rsquo;re ready to add more tools to DefectDojo, you can easily rearrange your import mappings to something else. Multiple tools can be set up to import vulnerabilities to the same destination, and you can always reorganize your setup for a better fit without losing any work.\nMy Connector isn\u0026rsquo;t supported Fortunately, DefectDojo can still handle manual import for a wide range of security tools. Please see our Supported Tool List, as well as our guide to Importing data.\nNext Steps Check out the Connectors page by switching to DefectDojo\u0026rsquo;s Beta UI. Follow our guide to create your first Connector. Check out the process of Running Operations with your Connected security tools and see how they can be configured to import data. ","date":"2023-09-07","id":74,"permalink":"/en/connecting_your_tools/connectors/about_connectors/","summary":"Note: Connectors are a DefectDojo Pro-only feature.\nDefectDojo allows users to build sophisticated API integrations, and gives users full control over how their vulnerability data is organized.","tags":[],"title":"About Connectors"},{"content":"DefectDojo keeps you up to date in a variety of ways. Notifications can be sent for upcoming Engagements, user Mentions, SLA expiry, and other events in the software.\nThis article contains an overview of notifications at both System-wide and Personal levels.\nNotification Types DefectDojo handles notifications in two different ways::\nSystem-Wide Notifications are sent to all users. Personal Notifications are set by individual users, and will be received in addition to any System-Wide Notifications. In both cases, Role-Based Access Control rules apply, so users will not receive activity notifications for Products or Product Types (or their related objects) which they don‚Äôt have access to.\nNotification Delivery Methods There are four delivery methods for DefectDojo notifications:\nDefectDojo can share üîî Alerts, stored as a list in the DefectDojo interface DefectDojo can send notifications to an Email address DefectDojo can send notifications to Slack, in either a shared or individual channel DefectDojo can also send notifications to Microsoft Teams in a shared channel Notifications can be sent to multiple destinations simultaneously.\nReceiving Slack and Teams notifications will require you to have a working integration. For more info on setting this integration up, see our Guide.\nIn-App Alerts DefectDojo‚Äôs Alerts system keeps you up to date with all Product or system activity.\nThe Alerts List The Alerts List is always visible in the top-right hand corner of DefectDojo, and contains a compact list of notifications. Clicking on each Alert will take you directly to the relevant page in DefectDojo.\nYou can open your Alerts List by clicking on the üîî‚ñº icon on the top right hand corner:\nTo see all of your notifications, along with additional detail, you can click the See All Alerts \u0026gt; button, which will open the Alerts Page.\nYou can also Clear All Alerts \u0026gt; from the Alerts List.\nThe Alerts Page The Alerts Page stores all of your Alerts in DefectDojo with additional detail. On this page, you can read descriptions of each Alert in DefectDojo, and remove them from the Alerts queue once you no longer need them.\nTo remove one or more Alerts from the Alerts Page, check the empty box next to it, and then click the Remove selected button in the bottom-right corner of the Page.\nNotes On Alerts Reading an Alert, or opening the Alerts Page will not remove any Alerts from the count next to the bell icon. This is so that you can easily access past alerts to use them as reminders or a personal activity log. Using the Clear All Alerts \u0026gt; function in the Alerts Menu will also completely clear the Alerts Page, so use this feature with care. Removing an Alert only affects your own Alerts List - it will not affect any other user‚Äôs Alerts. Removing an Alert does not remove any import history or activity logs from DefectDojo. ","date":"0001-01-01","id":75,"permalink":"/en/customize_dojo/notifications/about_notifications/","summary":"DefectDojo keeps you up to date in a variety of ways. Notifications can be sent for upcoming Engagements, user Mentions, SLA expiry, and other events in the software.","tags":[],"title":"About Notifications \u0026 üîî Alerts"},{"content":"This parser imports the Acunetix Scanner with xml output or Acunetix 360 Scanner with JSON output.\nSample Scan Data Sample Acunetix Scanner scans can be found here.\n","date":"0001-01-01","id":76,"permalink":"/en/connecting_your_tools/parsers/file/acunetix/","summary":"This parser imports the Acunetix Scanner with xml output or Acunetix 360 Scanner with JSON output.\nSample Scan Data Sample Acunetix Scanner scans can be found here.","tags":[],"title":"Acunetix Scanner"},{"content":"Note: Connectors are a DefectDojo Pro-only feature.\nThe process for adding and configuring a connector is similar, regardless of the tool you‚Äôre trying to connect. However, certain tools may require you to create API keys or complete additional steps.\nBefore you begin this process, we recommend checking our Tool-Specific Reference to find the API resources for the tool you\u0026rsquo;re trying to connect.\nIf you haven\u0026rsquo;t already, start by switching to the Beta UI in DefectDojo.\nFrom the left-side menu, click on the API Connectors menu item. This is nested under the Import header. ‚Äã Choose a new Connector you want to add to DefectDojo in Available Connections, and click the Add Configuration underneath the tool.\n‚Äã\nYou can also edit an existing Connection under the Configured Connections header. Click Manage Configuration \u0026gt; Edit Configuration for the Configured Connection you want to Edit.\n‚Äã You will need an accessible URL Location for the tool, along with an API Secret key. The location of the API key will depend on the tool you are trying to configure. See our Tool-Specific Reference for more details.\n‚Äã\nSet a Label for this connection to help you identify it in DefectDojo.\n‚Äã\nSchedule the Connector‚Äôs automatic Discovery and Synchronization activities. These can be changed later.\n‚Äã\nSelect whether you wish to Enable Auto-Mapping. Enable Auto-Mapping will create a new Product in DefectDojo to store the data from this connector. Auto-Mapping can be turned on or off at any time.\n‚Äã\nClick Submit.\nNext Steps Now that you\u0026rsquo;ve added a connector, you can confirm everything is set up correctly by running a Discover operation. ","date":"0001-01-01","id":77,"permalink":"/en/connecting_your_tools/connectors/add_edit_connectors/","summary":"Note: Connectors are a DefectDojo Pro-only feature.\nThe process for adding and configuring a connector is similar, regardless of the tool you‚Äôre trying to connect.","tags":[],"title":"Add or Edit a Connector"},{"content":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample Anchore Enterprise Policy Check scans can be found here.\n","date":"0001-01-01","id":78,"permalink":"/en/connecting_your_tools/parsers/file/anchore_enterprise/","summary":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample Anchore Enterprise Policy Check scans can be found here.","tags":[],"title":"Anchore Enterprise Policy Check"},{"content":"File Types DefectDojo parser accepts a .json file.\nYou can generate vulnerability data using the Anchore Enterprise CLI tool, Anchorectl, or through the Enterprise UI.\nGenerating a Vulnerability Report: Using Anchorectl: Run the following command to generate a vulnerability report in JSON format\nanchorectl image vulnerabilities ubuntu:latest -o json Using the Anchore UI: Navigate to the desired image in the Anchore Enterprise UI, click on the Vulnerabilities tab, and download the report in JSON format.\nAcceptable JSON Format All properties are strings and are required by the parser. As the parser evolved, two anchore engine parser JSON formats are present till now. Both (old / new) are supported.\n{ \u0026#34;vulnerabilityId\u0026#34;: \u0026#34;CVE-2023-24531\u0026#34;, \u0026#34;cves\u0026#34;: \u0026#34;CVE-2023-24531\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;detectedAt\u0026#34;: \u0026#34;2025-03-18T08:09:03Z\u0026#34;, \u0026#34;packageType\u0026#34;: \u0026#34;Go\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/usr/local/bin/gosu\u0026#34;, \u0026#34;package\u0026#34;: \u0026#34;stdlib-go1.18.2\u0026#34;, \u0026#34;fixAvailable\u0026#34;: \u0026#34;1.21.0-0\u0026#34;, \u0026#34;fixObservedAt\u0026#34;: \u0026#34;2025-03-18T08:09:03Z\u0026#34;, \u0026#34;link\u0026#34;: \u0026#34;https://nvd.nist.gov/vuln/detail/CVE-2023-24531\u0026#34;, \u0026#34;nvdCvssBaseScore\u0026#34;: 9.8 }\rSample Scan Data Sample Anchore-Engine scans can be found here\n","date":"0001-01-01","id":79,"permalink":"/en/connecting_your_tools/parsers/file/anchore_engine/","summary":"File Types DefectDojo parser accepts a .json file.\nYou can generate vulnerability data using the Anchore Enterprise CLI tool, Anchorectl, or through the Enterprise UI.","tags":[],"title":"Anchore Enterprise Vulnerability"},{"content":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON files are created using the Grype CLI, using the \u0026lsquo;-o json\u0026rsquo; option. See: https://github.com/anchore/grype\nExample: grype yourApp/example-page -o json \u0026gt; example_vulns.json\nAcceptable JSON Format All properties are expected as strings and are required by the parser.\n{ \u0026#34;matches\u0026#34;: [ { \u0026#34;vulnerability\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;example-id\u0026#34;, \u0026#34;dataSource\u0026#34;: \u0026#34;https://example.org/.../example-id\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;exampleName\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;exampleSeverity\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;https://example.org/.../example-id\u0026#34;, ... ], \u0026#34;cvss\u0026#34;: [], \u0026#34;fix\u0026#34;: { \u0026#34;versions\u0026#34;: [], \u0026#34;state\u0026#34;: \u0026#34;not-fixed\u0026#34; }, \u0026#34;advisories\u0026#34;: [] }, \u0026#34;relatedVulnerabilities\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;first-related-example-id\u0026#34;, \u0026#34;dataSource\u0026#34;: \u0026#34;https://example.org/.../related-example-id\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;first-related-exampleName\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;first-related-exampleSeverity\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;https://example.org/.../related-example-id\u0026#34;, ... ], \u0026#34;description\u0026#34;: \u0026#34;first-example-description\u0026#34;, \u0026#34;cvss\u0026#34;: [ { \u0026#34;version\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;vector\u0026#34;: \u0026#34;AV:L/AC:L/Au:N/C:N/I:P/A:N\u0026#34;, \u0026#34;metrics\u0026#34;: { \u0026#34;baseScore\u0026#34;: 2.1, \u0026#34;exploitabilityScore\u0026#34;: 3.9, \u0026#34;impactScore\u0026#34;: 2.9 }, \u0026#34;vendorMetadata\u0026#34;: {} } ] }, ... ], \u0026#34;matchDetails\u0026#34;: [ { \u0026#34;matcher\u0026#34;: \u0026#34;example-matcher\u0026#34;, \u0026#34;searchedBy\u0026#34;: { \u0026#34;distro\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;example-distrotype\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;namespace\u0026#34;: \u0026#34;exampleName\u0026#34;, \u0026#34;package\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;example-package\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.17-3+deb10u3\u0026#34; } }, \u0026#34;found\u0026#34;: { \u0026#34;versionConstraint\u0026#34;: \u0026#34;none (deb)\u0026#34; } } ], \u0026#34;artifact\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;example-artifact\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;example-artifact-version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;example-type\u0026#34;, \u0026#34;locations\u0026#34;: [ { \u0026#34;path\u0026#34;: \u0026#34;.../examplePath/\u0026#34;, \u0026#34;layerID\u0026#34;: \u0026#34;exampleLayerID\u0026#34; }, { \u0026#34;path\u0026#34;: \u0026#34;.../examplePath-2/\u0026#34;, \u0026#34;layerID\u0026#34;: \u0026#34;exampleLayerID\u0026#34; }, ... ], \u0026#34;language\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;licenses\u0026#34;: [ \u0026#34;GPL-2\u0026#34; ], \u0026#34;cpes\u0026#34;: [ \u0026#34;example-cpe\u0026#34;, ... ], \u0026#34;purl\u0026#34;: \u0026#34;pkg:deb/debian/libgssapi-krb5-2@1.17-3+deb10u3?arch=amd64\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;Source\u0026#34;: \u0026#34;krb5\u0026#34; } } }, ... ], \u0026#34;source\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, \u0026#34;target\u0026#34;: { \u0026#34;userInput\u0026#34;: \u0026#34;vulnerable-image:latest\u0026#34;, \u0026#34;imageID\u0026#34;: \u0026#34;sha256:ce9898fd214aef9c994a42624b09056bdce3ff4a8e3f68dc242d967b80fcbeee\u0026#34;, \u0026#34;manifestDigest\u0026#34;: \u0026#34;sha256:9d8825ab20ac86b40eb71495bece1608a302fb180384740697a28c2b0a5a0fc6\u0026#34;, \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.distribution.manifest.v2+json\u0026#34;, \u0026#34;tags\u0026#34;: [ \u0026#34;vulnerable-image:latest\u0026#34; ], \u0026#34;imageSize\u0026#34;: 707381791, \u0026#34;layers\u0026#34;: [ { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.image.rootfs.diff.tar.gzip\u0026#34;, \u0026#34;digest\u0026#34;: \u0026#34;sha256:d000633a56813933cb0ac5ee3246cf7a4c0205db6290018a169d7cb096581046\u0026#34;, \u0026#34;size\u0026#34;: 69238554 }, ... ], \u0026#34;manifest\u0026#34;: \u0026#34;exampleManifestString==\u0026#34;, \u0026#34;config\u0026#34;: \u0026#34;exampleConfigString\u0026#34;, \u0026#34;repoDigests\u0026#34;: [] } }, \u0026#34;distro\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;debian\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;idLike\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;descriptor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;grype\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.28.0\u0026#34;, \u0026#34;configuration\u0026#34;: { \u0026#34;configPath\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;output-template-file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;quiet\u0026#34;: false, \u0026#34;check-for-app-update\u0026#34;: true, \u0026#34;only-fixed\u0026#34;: false, \u0026#34;scope\u0026#34;: \u0026#34;Squashed\u0026#34;, \u0026#34;log\u0026#34;: { \u0026#34;structured\u0026#34;: false, \u0026#34;level\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;file\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;db\u0026#34;: { \u0026#34;cache-dir\u0026#34;: \u0026#34;/home/user/.cache/grype/db\u0026#34;, \u0026#34;update-url\u0026#34;: \u0026#34;https://toolbox-data.anchore.io/grype/databases/listing.json\u0026#34;, \u0026#34;ca-cert\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;auto-update\u0026#34;: true, \u0026#34;validate-by-hash-on-start\u0026#34;: false }, \u0026#34;dev\u0026#34;: { \u0026#34;profile-cpu\u0026#34;: false, \u0026#34;profile-mem\u0026#34;: false }, \u0026#34;fail-on-severity\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;registry\u0026#34;: { \u0026#34;insecure-skip-tls-verify\u0026#34;: false, \u0026#34;insecure-use-http\u0026#34;: false, \u0026#34;auth\u0026#34;: [] }, \u0026#34;ignore\u0026#34;: null, \u0026#34;exclude\u0026#34;: [] }, \u0026#34;db\u0026#34;: { \u0026#34;built\u0026#34;: \u0026#34;2021-12-24T08:14:02Z\u0026#34;, \u0026#34;schemaVersion\u0026#34;: 3, \u0026#34;location\u0026#34;: \u0026#34;/home/user/.cache/grype/db/3\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;sha256:6c4777e1acea787e5335ccee6b5e4562cd1767b9cca138c07e0802efb2a74162\u0026#34;, \u0026#34;error\u0026#34;: null } } }\rSample Scan Data Sample Grype scans can be found here.\n","date":"0001-01-01","id":80,"permalink":"/en/connecting_your_tools/parsers/file/anchore_grype/","summary":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON files are created using the Grype CLI, using the \u0026lsquo;-o json\u0026rsquo; option.","tags":[],"title":"Anchore Grype"},{"content":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample AnchoreCTL Policies Report scans can be found here.\n","date":"0001-01-01","id":81,"permalink":"/en/connecting_your_tools/parsers/file/anchorectl_policies/","summary":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample AnchoreCTL Policies Report scans can be found here.","tags":[],"title":"AnchoreCTL Policies Report"},{"content":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample AnchoreCTL Vuln Report scans can be found here.\n","date":"0001-01-01","id":82,"permalink":"/en/connecting_your_tools/parsers/file/anchorectl_vulns/","summary":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample AnchoreCTL Vuln Report scans can be found here.","tags":[],"title":"AnchoreCTL Vuln Report"},{"content":"Accepts AppCheck Web Application Scanner output in .json format.\nSample Scan Data Sample AppCheck Web Application Scanner scans can be found here.\n","date":"0001-01-01","id":83,"permalink":"/en/connecting_your_tools/parsers/file/appcheck_web_application_scanner/","summary":"Accepts AppCheck Web Application Scanner output in .json format.\nSample Scan Data Sample AppCheck Web Application Scanner scans can be found here.","tags":[],"title":"AppCheck Web Application Scanner"},{"content":"Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nSample Scan Data Sample AppSpider (Rapid7) scans can be found here.\n","date":"0001-01-01","id":84,"permalink":"/en/connecting_your_tools/parsers/file/appspider/","summary":"Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nSample Scan Data Sample AppSpider (Rapid7) scans can be found here.","tags":[],"title":"AppSpider (Rapid7)"},{"content":"File Types DefectDojo parser accepts JSON report format.\nSee Aqua documention: https://docs.aquasec.com\nCI/CD Scans Aqua scanning can be integrated with several types of third-party CI/CD systems.\nIf there is no plugin available for a particular development tool, Aqua can be integrated with the CI/CD pipeline using Scanner CLI.\nCI/CD scans produces JSON scan reports that are supported by the parser. With this kind of report, the parser is able to retrieve vulnerabilities as well as sensitive datas.\nREST API You can also retrieve the JSON directly from Aqua if you use one of the following endpoint:\n/api/v1/scanner/registry/\u0026lt;registryName\u0026gt;/image/\u0026lt;imageName\u0026gt;/scan_result\n/api/v2/risks/vulnerabilities\nExample\ncurl -X GET \u0026lt;aquaseceurl\u0026gt;/api/v1/scanner/registry/\u0026lt;registryName\u0026gt;/image/\u0026lt;imageName\u0026gt;/scan_result \u0026gt; report.json\rcurl -X GET \u0026lt;aquaseceurl\u0026gt;/api/v2/risks/vulnerabilities?show_negligible=true\u0026amp;image_name_exact_match=true\u0026amp;registry_name=\u0026lt;registryName\u0026gt;\u0026amp;image_name=\u0026lt;imageName\u0026gt; \u0026gt; report.json\rThose JSON files will only list vulnerabilities. Thus, DefectDojo parser will not retrieve findings such as sensitive datas.\nSample Scan Data Sample Aqua scans can be found here.\n","date":"0001-01-01","id":85,"permalink":"/en/connecting_your_tools/parsers/file/aqua/","summary":"File Types DefectDojo parser accepts JSON report format.\nSee Aqua documention: https://docs.aquasec.com\nCI/CD Scans Aqua scanning can be integrated with several types of third-party CI/CD systems.","tags":[],"title":"Aqua"},{"content":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter \u0026#39;json\u0026#39; js.com.afr Sample Scan Data Sample Arachni Scanner scans can be found here.\n","date":"0001-01-01","id":86,"permalink":"/en/connecting_your_tools/parsers/file/arachni/","summary":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter \u0026#39;json\u0026#39; js.com.afr Sample Scan Data Sample Arachni Scanner scans can be found here.","tags":[],"title":"Arachni Scanner"},{"content":"AuditJS scanning tool using OSSIndex database and generated with --json or -j option (https://www.npmjs.com/package/auditjs).\nauditjs ossi --json \u0026gt; auditjs_report.json Sample Scan Data Sample AuditJS (OSSIndex) scans can be found here.\n","date":"0001-01-01","id":87,"permalink":"/en/connecting_your_tools/parsers/file/auditjs/","summary":"AuditJS scanning tool using OSSIndex database and generated with --json or -j option (https://www.npmjs.com/package/auditjs).\nauditjs ossi --json \u0026gt; auditjs_report.json Sample Scan Data Sample AuditJS (OSSIndex) scans can be found here.","tags":[],"title":"AuditJS (OSSIndex)"},{"content":"File Types AWS Inspector2 report can be imported in json format. Inspector2 name comes from API calls to \u0026ldquo;modern\u0026rdquo; Inspector API - aws inspector2 as opposite to Classic Inspector (previous version of the service), this is an example of how such report can be generated: aws inspector2 list-findings --filter-criteria '{\u0026quot;resourceId\u0026quot;:[{\u0026quot;comparison\u0026quot;:\u0026quot;EQUALS\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;i-instance_id_here\u0026quot;}]}' --region us-east-1 \u0026gt; inspector2_findings.json\nThis parser can help to get findings in a delegated admin account for AWS Inspector or in a standalone AWS account. The parser is developed mostly for a scenario where findings are obtained for a specific resource like an ECR image or an instance, and uploaded to a test in a DefectDojo engagement that represents a branch from a git repository.\nA minimal valid json file with no findings:\n{ \u0026#34;findings\u0026#34;: [] }\rDetailed API response format can be obtained here\nSample Scan Data Sample AWS Inspector2 findings can be found here.\n","date":"0001-01-01","id":88,"permalink":"/en/connecting_your_tools/parsers/file/aws_inspector2/","summary":"File Types AWS Inspector2 report can be imported in json format. Inspector2 name comes from API calls to \u0026ldquo;modern\u0026rdquo; Inspector API - aws inspector2 as opposite to Classic Inspector (previous version of the service), this is an example of how such report can be generated: aws inspector2 list-findings --filter-criteria '{\u0026quot;resourceId\u0026quot;:[{\u0026quot;comparison\u0026quot;:\u0026quot;EQUALS\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;i-instance_id_here\u0026quot;}]}' --region us-east-1 \u0026gt; inspector2_findings.","tags":[],"title":"AWS Inspector2 Scanner"},{"content":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file.\nSample Scan Data Sample AWS Prowler Scanner scans can be found here.\n","date":"0001-01-01","id":89,"permalink":"/en/connecting_your_tools/parsers/file/aws_prowler/","summary":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file.\nSample Scan Data Sample AWS Prowler Scanner scans can be found here.","tags":[],"title":"AWS Prowler Scanner"},{"content":"File Types DefectDojo parser accepts a native json file produced by prowler v3 with file extension .json or a ocsf-json file produced by prowler v4 with file extension .ocsf.json. Please note: earlier versions of AWS Prowler create output data in a different format. See our other prowler parser documentation if you are using an earlier version of AWS Prowler.\nJSON reports can be created from the AWS Prowler v3 CLI using the following command: prowler \u0026lt;provider\u0026gt; -M json\nJSON-OCSF reports can be created from the AWS Prowler v4 CLI using the following command: prowler \u0026lt;provider\u0026gt; -M json-ocsf\nAcceptable Prowler v3 JSON format Parser expects an array of assessments. All properties are strings and are required by the parser.\n[ { \u0026#34;AssessmentStartTime\u0026#34;: \u0026#34;example_timestamp\u0026#34;, \u0026#34;FindingUniqueId\u0026#34;: \u0026#34;example_uniqueIdFromTool\u0026#34;, \u0026#34;Provider\u0026#34;: \u0026#34;example_provider\u0026#34;, \u0026#34;CheckID\u0026#34;: \u0026#34;acm_certificates_expiration_check\u0026#34;, \u0026#34;CheckTitle\u0026#34;: \u0026#34;Check if ACM Certificates are about to expire in specific days or less\u0026#34;, \u0026#34;CheckType\u0026#34;: [ \u0026#34;Example ASFF-Compliant Finding Type\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;example_awsServiceName\u0026#34;, \u0026#34;SubServiceName\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;FAIL\u0026#34;, \u0026#34;StatusExtended\u0026#34;: \u0026#34;Example status description\u0026#34;, \u0026#34;Severity\u0026#34;: \u0026#34;example_severity\u0026#34;, \u0026#34;ResourceType\u0026#34;: \u0026#34;AwsCertificateManagerCertificate\u0026#34;, \u0026#34;ResourceDetails\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Example general test description.\u0026#34;, \u0026#34;Risk\u0026#34;: \u0026#34;Example test impact description.\u0026#34;, \u0026#34;RelatedUrl\u0026#34;: \u0026#34;https://docs.aws.amazon.com/config/latest/developerguide/acm-certificate-expiration-check.html\u0026#34;, \u0026#34;Remediation\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;NativeIaC\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Terraform\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;CLI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Other\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;Recommendation\u0026#34;: { \u0026#34;Text\u0026#34;: \u0026#34;Example recommendation.\u0026#34;, \u0026#34;Url\u0026#34;: \u0026#34;https://docs.aws.amazon.com/config/latest/developerguide/example_related_documentation.html\u0026#34; } }, \u0026#34;Compliance\u0026#34;: { \u0026#34;GDPR\u0026#34;: [ \u0026#34;article_32\u0026#34; ], ... }, \u0026#34;Categories\u0026#34;: [], \u0026#34;DependsOn\u0026#34;: [], \u0026#34;RelatedTo\u0026#34;: [], \u0026#34;Notes\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Profile\u0026#34;: null, \u0026#34;AccountId\u0026#34;: \u0026#34;example_accountId\u0026#34;, \u0026#34;OrganizationsInfo\u0026#34;: null, \u0026#34;Region\u0026#34;: \u0026#34;example_region\u0026#34;, \u0026#34;ResourceId\u0026#34;: \u0026#34;example.resource.id.com\u0026#34;, \u0026#34;ResourceArn\u0026#34;: \u0026#34;arn:aws:acm:us-east-1:999999999999:certificate/ffffffff-0000-0000-0000-000000000000\u0026#34;, \u0026#34;ResourceTags\u0026#34;: {} } ... ]\rAcceptable Prowler v4 JSON-OCSF format The parser expects an array of assessments. All properties are strings and are required by the parser.\n[{ \u0026#34;metadata\u0026#34;: { \u0026#34;event_code\u0026#34;: \u0026#34;iam_role_administratoraccess_policy_permissive_trust_relationship\u0026#34;, \u0026#34;product\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Prowler\u0026#34;, \u0026#34;vendor_name\u0026#34;: \u0026#34;Prowler\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;4.2.1\u0026#34; }, \u0026#34;version\u0026#34;: \u0026#34;1.2.0\u0026#34; }, \u0026#34;severity_id\u0026#34;: 4, \u0026#34;severity\u0026#34;: \u0026#34;High\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Suppressed\u0026#34;, \u0026#34;status_code\u0026#34;: \u0026#34;FAIL\u0026#34;, \u0026#34;status_detail\u0026#34;: \u0026#34;IAM Role myAdministratorExecutionRole has AdministratorAccess policy attached that has too permissive trust relationship.\u0026#34;, \u0026#34;status_id\u0026#34;: 3, \u0026#34;unmapped\u0026#34;: { \u0026#34;check_type\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;related_url\u0026#34;: \u0026#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_job-functions.html#jf_administrator\u0026#34;, \u0026#34;categories\u0026#34;: \u0026#34;trustboundaries\u0026#34;, \u0026#34;depends_on\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;related_to\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;notes\u0026#34;: \u0026#34;CAF Security Epic: IAM\u0026#34;, \u0026#34;compliance\u0026#34;: {} }, \u0026#34;activity_name\u0026#34;: \u0026#34;Create\u0026#34;, \u0026#34;activity_id\u0026#34;: 1, \u0026#34;finding_info\u0026#34;: { \u0026#34;created_time\u0026#34;: \u0026#34;2024-06-03T14:15:19.382075\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\u0026#34;, \u0026#34;product_uid\u0026#34;: \u0026#34;prowler\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;prowler-aws-iam_role_administratoraccess_policy_permissive_trust_relationship-123456789012-us-east-1-myAdministratorExecutionRole\u0026#34; }, \u0026#34;resources\u0026#34;: [ { \u0026#34;cloud_partition\u0026#34;: \u0026#34;aws\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;details\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;iam\u0026#34; }, \u0026#34;labels\u0026#34;: [], \u0026#34;name\u0026#34;: \u0026#34;myAdministratorExecutionRole\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AwsIamRole\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/myAdministratorExecutionRole\u0026#34; } ], \u0026#34;category_name\u0026#34;: \u0026#34;Findings\u0026#34;, \u0026#34;category_uid\u0026#34;: 2, \u0026#34;class_name\u0026#34;: \u0026#34;DetectionFinding\u0026#34;, \u0026#34;class_uid\u0026#34;: 2004, \u0026#34;cloud\u0026#34;: { \u0026#34;account\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AWS_Account\u0026#34;, \u0026#34;type_id\u0026#34;: 10, \u0026#34;uid\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;labels\u0026#34;: [] }, \u0026#34;org\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;provider\u0026#34;: \u0026#34;aws\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34; }, \u0026#34;event_time\u0026#34;: \u0026#34;2024-06-03T14:15:19.382075\u0026#34;, \u0026#34;remediation\u0026#34;: { \u0026#34;desc\u0026#34;: \u0026#34;Apply the principle of least privilege. Instead of AdministratorAccess, assign only the permissions necessary for specific roles and tasks. Create custom IAM policies with minimal permissions based on the principle of least privilege. If a role really needs AdministratorAccess, the trust relationship must be well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\u0026#34;, \u0026#34;references\u0026#34;: [ \u0026#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\u0026#34; ] }, \u0026#34;risk_details\u0026#34;: \u0026#34;The AWS-managed AdministratorAccess policy grants all actions for all AWS services and for all resources in the account and as such exposes the customer to a significant data leakage threat. It is therefore particularly important that the trust relationship is well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\u0026#34;, \u0026#34;type_uid\u0026#34;: 200401, \u0026#34;type_name\u0026#34;: \u0026#34;Create\u0026#34; }]\rSample Scan Data Unit tests of AWS Prowler v3 JSON and Prowler v4 JSON-OCSF can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/aws_prowler_v3.\n","date":"0001-01-01","id":90,"permalink":"/en/connecting_your_tools/parsers/file/aws_prowler_v3plus/","summary":"File Types DefectDojo parser accepts a native json file produced by prowler v3 with file extension .json or a ocsf-json file produced by prowler v4 with file extension .","tags":[],"title":"AWS Prowler V3"},{"content":"AWS Security Hub consumes, aggregates, organizes, and prioritizes findings from AWS security services and from the third-party product integrations. Security Hub processes these findings using a standard findings format called the AWS Security Finding Format (ASFF), which eliminates the need for time-consuming data conversion efforts. Then it correlates ingested findings across products to prioritize the most important ones.\nReference: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-findings-format.html\nProwler tool can generate this format with option -M json-asff.\nSample Scan Data Sample AWS Security Finding Format (ASFF) scans can be found here.\n","date":"0001-01-01","id":91,"permalink":"/en/connecting_your_tools/parsers/file/asff/","summary":"AWS Security Hub consumes, aggregates, organizes, and prioritizes findings from AWS security services and from the third-party product integrations. Security Hub processes these findings using a standard findings format called the AWS Security Finding Format (ASFF), which eliminates the need for time-consuming data conversion efforts.","tags":[],"title":"AWS Security Finding Format (ASFF)"},{"content":"File Types This DefectDojo parser accepts JSON files from AWS Security Hub. The JSON reports can be created from the AWS Security Hub CLI using the following command: aws securityhub get-findings.\nAWS Security Hub integrates with multiple AWS Tools. Thus, you can retrieve findings from various AWS sources through AWS Security Hub. This parser is able to handle the following findings retrieved over AWS Security Hub:\nAWS Security Hub Compliance Checks AWS Security Hub GuardDuty AWS Security Hub Inspector Example Commands to retrieve JSON output AWS Security Hub Compliance Checks: aws securityhub get-findings --filters ComplianceStatus=\u0026quot;[{Comparison=EQUALS,Value=FAILED}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json AWS Security Hub GuardDuty: aws securityhub get-findings --filters ProductName=\u0026quot;[{Value=GuardDuty,Comparison=EQUALS}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json AWS Security Hub Inspector: aws securityhub get-findings --filters ProductName=\u0026quot;[{Value=Inspector,Comparison=EQUALS}]\u0026quot; | jq \u0026quot;.\u0026quot; \u0026gt; output.json Important note AWS Security Hub Parser does import the affected service ARNs as hosts to DefectDojo. However, as ARNs contain invalid digits for hosts, the ARN is changed slightly. \u0026ldquo;:\u0026rdquo;, \u0026quot; \u0026quot; \u0026amp; \u0026ldquo;/\u0026rdquo; are replaced by \u0026ldquo;_\u0026rdquo;.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":92,"permalink":"/en/connecting_your_tools/parsers/file/awssecurityhub/","summary":"File Types This DefectDojo parser accepts JSON files from AWS Security Hub. The JSON reports can be created from the AWS Security Hub CLI using the following command: aws securityhub get-findings.","tags":[],"title":"AWS Security Hub"},{"content":"Azure Security Center recommendations can be exported from the user interface in CSV format.\nSample Scan Data Sample Azure Security Center Recommendations Scan scans can be found here.\n","date":"0001-01-01","id":93,"permalink":"/en/connecting_your_tools/parsers/file/azure_security_center_recommendations/","summary":"Azure Security Center recommendations can be exported from the user interface in CSV format.\nSample Scan Data Sample Azure Security Center Recommendations Scan scans can be found here.","tags":[],"title":"Azure Security Center Recommendations Scan"},{"content":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bandit, you will need to install and run the .json report formatter from your Bandit instance.\nSee Bandit documentation: https://bandit.readthedocs.io/en/latest/formatters/index.html\nAcceptable JSON Format All properties are expected as strings, except \u0026ldquo;metrics\u0026rdquo; properties, which are expected as numbers. All properties are required by the parser.\n{ \u0026#34;errors\u0026#34;: [], \u0026#34;generated_at\u0026#34;: \u0026#34;example-timestamp\u0026#34;, \u0026#34;metrics\u0026#34;: { \u0026#34;_totals\u0026#34;: { \u0026#34;CONFIDENCE.HIGH\u0026#34;: 1.0, \u0026#34;CONFIDENCE.LOW\u0026#34;: 0.0, \u0026#34;CONFIDENCE.MEDIUM\u0026#34;: 0.0, \u0026#34;CONFIDENCE.UNDEFINED\u0026#34;: 0.0, \u0026#34;SEVERITY.HIGH\u0026#34;: 0.0, \u0026#34;SEVERITY.LOW\u0026#34;: 1.0, \u0026#34;SEVERITY.MEDIUM\u0026#34;: 0.0, \u0026#34;SEVERITY.UNDEFINED\u0026#34;: 0.0, \u0026#34;loc\u0026#34;: 2, \u0026#34;nosec\u0026#34;: 0 }, \u0026#34;one/one.py\u0026#34;: { \u0026#34;CONFIDENCE.HIGH\u0026#34;: 1.0, \u0026#34;CONFIDENCE.LOW\u0026#34;: 0.0, \u0026#34;CONFIDENCE.MEDIUM\u0026#34;: 0.0, \u0026#34;CONFIDENCE.UNDEFINED\u0026#34;: 0.0, \u0026#34;SEVERITY.HIGH\u0026#34;: 0.0, \u0026#34;SEVERITY.LOW\u0026#34;: 1.0, \u0026#34;SEVERITY.MEDIUM\u0026#34;: 0.0, \u0026#34;SEVERITY.UNDEFINED\u0026#34;: 0.0, \u0026#34;loc\u0026#34;: 2, \u0026#34;nosec\u0026#34;: 0 } ... }, \u0026#34;results\u0026#34;: [ { \u0026#34;code\u0026#34;: \u0026#34;1 import os\\n2 assert False\\n\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;example.filename\u0026#34;, \u0026#34;issue_confidence\u0026#34;: \u0026#34;example_confidence\u0026#34;, \u0026#34;issue_severity\u0026#34;: \u0026#34;example_severity\u0026#34;, \u0026#34;issue_text\u0026#34;: \u0026#34;Example issue description.\u0026#34;, \u0026#34;line_number\u0026#34;: 2, \u0026#34;line_range\u0026#34;: [ 2 ], \u0026#34;more_info\u0026#34;: \u0026#34;https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\u0026#34;, \u0026#34;test_id\u0026#34;: \u0026#34;B101\u0026#34;, \u0026#34;test_name\u0026#34;: \u0026#34;assert_used\u0026#34; } ... ] }\rSample Scan Data Sample Bandit scans can be found here.\n","date":"0001-01-01","id":94,"permalink":"/en/connecting_your_tools/parsers/file/bandit/","summary":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bandit, you will need to install and run the .","tags":[],"title":"Bandit"},{"content":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bearer CLI, pass \u0026ldquo;-f json\u0026rdquo; to your Bearer command\nSee Bearer documentation: https://docs.bearer.com/reference/commands/\nSample Scan Data Sample Bearer scans can be found here\n","date":"0001-01-01","id":95,"permalink":"/en/connecting_your_tools/parsers/file/bearer_cli/","summary":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bearer CLI, pass \u0026ldquo;-f json\u0026rdquo; to your Bearer command","tags":[],"title":"Bearer CLI"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;BlackDuck API\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your BlackDuck API token in the API Key field.\nIn Add API Scan Configuration provide the ID of the project from which to import findings in the field Service key 1. Provide the version of the project from which to import findings in the field Service key 2.\n","date":"0001-01-01","id":96,"permalink":"/en/connecting_your_tools/parsers/api/blackduck/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Blackduck API"},{"content":"What Black Duck Binary Analysis gives you visibility into open source and third-party dependencies that have been compiled into executables, libraries, containers, and firmware. You can analyze individual files using an intuitive user interface or Black Duck multifactor open source detection, which automates the scanning of binary artifacts.\nUsing a combination of static and string analysis techniques coupled with fuzzy matching against the Black Duck KnowledgeBase, Black Duck Binary Analysis quickly and reliably identifies components, even if they\u0026rsquo;ve been modified.\nFor more info, check out Black Duck Binary Analysis here.\nWhy Open source vulnerabilities aren\u0026rsquo;t the only security issues that might be lurking in application binaries.\nBlack Duck Binary Analysis can also detect if sensitive information like email addresses, authorization tokens, compiler switches, and passwords are exposed, and it identifies when mobile applications request excessive permissions‚Äîall of which puts your organization and users\u0026rsquo; personal data at risk.\nHow Initiate Black Duck Binary Analysis scans using the UI, REST API, or drivers such as pwn_bdba_scan found within the security automation framework, PWN Import a single BDBA vulnerabilty csv results file into DefectDojo leveraging the UI, REST API, or drivers such as pwn_defectdojo_importscan or pwn_defectdojo_reimportscan. Sample Scan Data Sample Blackduck Binary Analysis scans can be found here.\n","date":"0001-01-01","id":97,"permalink":"/en/connecting_your_tools/parsers/file/blackduck_binary_analysis/","summary":"What Black Duck Binary Analysis gives you visibility into open source and third-party dependencies that have been compiled into executables, libraries, containers, and firmware.","tags":[],"title":"Blackduck Binary Analysis"},{"content":"Upload the zip file containing the security.csv and files.csv.\nSample Scan Data Sample Blackduck Component Risk scans can be found here.\n","date":"0001-01-01","id":98,"permalink":"/en/connecting_your_tools/parsers/file/blackduck_component_risk/","summary":"Upload the zip file containing the security.csv and files.csv.\nSample Scan Data Sample Blackduck Component Risk scans can be found here.","tags":[],"title":"Blackduck Component Risk"},{"content":"2 options:\nImport the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.csv in order to produce findings that bear file locations information. Import a single security.csv file. Findings will not have any file location information. Sample Scan Data Sample Blackduck Hub scans can be found here.\n","date":"0001-01-01","id":99,"permalink":"/en/connecting_your_tools/parsers/file/blackduck/","summary":"2 options:\nImport the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.","tags":[],"title":"Blackduck Hub"},{"content":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data Sample Brakeman Scan scans can be found here.\n","date":"0001-01-01","id":100,"permalink":"/en/connecting_your_tools/parsers/file/brakeman/","summary":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data Sample Brakeman Scan scans can be found here.","tags":[],"title":"Brakeman Scan"},{"content":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample Bugcrowd scans can be found here.\n","date":"0001-01-01","id":101,"permalink":"/en/connecting_your_tools/parsers/file/bugcrowd/","summary":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample Bugcrowd scans can be found here.","tags":[],"title":"Bugcrowd"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Bugcrowd API\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your BlackDuck API token in the API Key field. Set your API key directly in the format username:password in the API Token input, it will be added to the header 'Authorization': 'Token {}'.format(self.api_token),\nFor each product, you can configure 2 things:\nService key 1: the bugcrowd program code (it\u0026rsquo;s the slug name in the url for the program, url safe) Service key 2: the bugcrowd target name (the full name, it will be url-encoded, you can find it in https://tracker.bugcrowd.com//settings/scope/target_groups) It can be left empty so that all program submissions are imported That way, per product, you can use the same program but separate by target, which is a fairly common way of filtering/grouping Bugcrowd. Adding support for a 3rd filtering would be possible with Service Key 3, feel free to make a PR.\n","date":"0001-01-01","id":102,"permalink":"/en/connecting_your_tools/parsers/api/bugcrowd/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Bugcrowd API"},{"content":"Import the text output generated with bundle-audit check\nSample Scan Data Sample Bundler-Audit scans can be found here.\n","date":"0001-01-01","id":103,"permalink":"/en/connecting_your_tools/parsers/file/bundler_audit/","summary":"Import the text output generated with bundle-audit check\nSample Scan Data Sample Bundler-Audit scans can be found here.","tags":[],"title":"Bundler-Audit"},{"content":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML output.\nDastardly is a free, lightweight web application security scanner for your CI/CD pipeline. It is designed specifically for web developers, and checks your application for seven security issues that are likely to interest you during software development. Dastardly is based on the same scanner as Burp Suite (Burp Scanner).\nSample Scan Data Sample Burp Dastardly scans can be found here.\n","date":"0001-01-01","id":104,"permalink":"/en/connecting_your_tools/parsers/file/burp_dastardly/","summary":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML output.\nDastardly is a free, lightweight web application security scanner for your CI/CD pipeline.","tags":[],"title":"Burp Dastardly"},{"content":"File Types DefectDojo parser accepts a Standard Report as an HTML file. To parse an XML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp/\nSee also Burp documentation for info on how to export a Standard Report: https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nSample Scan Data Sample Burp Enterprise Scan scans can be found here.\n","date":"0001-01-01","id":105,"permalink":"/en/connecting_your_tools/parsers/file/burp_enterprise/","summary":"File Types DefectDojo parser accepts a Standard Report as an HTML file. To parse an XML file instead, use this method: https://documentation.","tags":[],"title":"Burp Enterprise Scan"},{"content":"Import the JSON data returned from the BurpSuite Enterprise GraphQL API. Append all the issues returned to a list and save it as the value for the key \u0026ldquo;Issues\u0026rdquo;. There is no need to filter duplicates, the parser will automatically combine issues with the same name.\nExample:\n{ \u0026#34;Issues\u0026#34;: [ { \u0026#34;issue_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Cross-site scripting (reflected)\u0026#34;, \u0026#34;description_html\u0026#34;: \u0026#34;Issue Description\u0026#34;, \u0026#34;remediation_html\u0026#34;: \u0026#34;Issue Remediation\u0026#34;, \u0026#34;vulnerability_classifications_html\u0026#34;: \u0026#34;\u0026lt;li\u0026gt;\u0026lt;a href=\\\u0026#34;https://cwe.mitre.org/data/definitions/79.html\\\u0026#34;\u0026gt;CWE-79: Improper Neutralization of Input During Web Page Generation (\u0026#39;Cross-site Scripting\u0026#39;)\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026#34;, \u0026#34;references_html\u0026#34;: \u0026#34;\u0026lt;li\u0026gt;\u0026lt;a href=\\\u0026#34;https://portswigger.net/web-security/cross-site-scripting\\\u0026#34;\u0026gt;Cross-site scripting\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026#34; }, \u0026#34;description_html\u0026#34;: \u0026#34;Details\u0026#34;, \u0026#34;remediation_html\u0026#34;: \u0026#34;Remediation Details\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;high\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/burp\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;https://portswigger.net\u0026#34;, \u0026#34;evidence\u0026#34;: [ { \u0026#34;request_index\u0026#34;: 0, \u0026#34;request_segments\u0026#34;: [ { \u0026#34;data_html\u0026#34;: \u0026#34;GET\u0026#34; }, { \u0026#34;highlight_html\u0026#34;: \u0026#34;data\u0026#34; }, { \u0026#34;data_html\u0026#34;: \u0026#34; HTTP More data\u0026#34; } ] }, { \u0026#34;response_index\u0026#34;: 0, \u0026#34;response_segments\u0026#34;: [ { \u0026#34;data_html\u0026#34;: \u0026#34;HTTP/2 200 OK \u0026#34; }, { \u0026#34;highlight_html\u0026#34;: \u0026#34;data\u0026#34; }, { \u0026#34;data_html\u0026#34;: \u0026#34;More data\u0026#34; } ] } ] } ] } Example GraphQL query to get issue details:\nquery Issue ($id: ID!, $serial_num: ID!) { issue(scan_id: $id, serial_number: $serial_num) { issue_type { name description_html remediation_html vulnerability_classifications_html references_html } description_html remediation_html severity path origin evidence { ... on Request { request_index request_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } ... on Response { response_index response_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } } } } Sample Scan Data Sample Burp GraphQL scans can be found here.\n","date":"0001-01-01","id":106,"permalink":"/en/connecting_your_tools/parsers/file/burp_graphql/","summary":"Import the JSON data returned from the BurpSuite Enterprise GraphQL API. Append all the issues returned to a list and save it as the value for the key \u0026ldquo;Issues\u0026rdquo;.","tags":[],"title":"Burp GraphQL"},{"content":"Import Burp REST API scan data in JSON format (/scan/[task_id] endpoint).\nSample Scan Data Sample Burp REST API scans can be found here.\n","date":"0001-01-01","id":107,"permalink":"/en/connecting_your_tools/parsers/file/burp_api/","summary":"Import Burp REST API scan data in JSON format (/scan/[task_id] endpoint).\nSample Scan Data Sample Burp REST API scans can be found here.","tags":[],"title":"Burp REST API"},{"content":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. To parse an HTML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp_enterprise/\nWhen the Burp report is generated, the recommended option is Base64 encoding both the request and response fields - e.g. check the box that says \u0026quot;Base64-encode requests and responses\u0026quot;. These fields will be processed and made available in the 'Finding View' page.\nSee also: Burp documentation - XML export is described under \u0026ldquo;Export Issue data\u0026rdquo;. https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nAcceptable XML Format All XML elements are required and will be parsed as strings.\n\u0026lt;issues burpVersion=\u0026#34;1.6.05\u0026#34; exportTime=\u0026#34;Sat Sep 13 22:39:44 CEST 2014\u0026#34;\u0026gt; \u0026lt;issue\u0026gt; \u0026lt;serialNumber\u0026gt;exampleSerialNumber\u0026lt;/serialNumber\u0026gt; \u0026lt;type\u0026gt;exampleTypeNumber\u0026lt;/type\u0026gt; \u0026lt;name\u0026gt;Example Issue Name\u0026lt;/name\u0026gt; \u0026lt;host ip=\u0026#34;192.168.187.137\u0026#34;\u0026gt;http://bwa\u0026lt;/host\u0026gt; \u0026lt;path\u0026gt;\u0026lt;![CDATA[/bodgeit/basket.jsp]]\u0026gt;\u0026lt;/path\u0026gt; \u0026lt;location\u0026gt;\u0026lt;![CDATA[/bodgeit/basket.jsp [b_id cookie]]]\u0026gt;\u0026lt;/location\u0026gt; \u0026lt;severity\u0026gt;Example Severity\u0026lt;/severity\u0026gt; \u0026lt;confidence\u0026gt;Firm\u0026lt;/confidence\u0026gt; \u0026lt;issueBackground\u0026gt;\u0026lt;![CDATA[Example issue background.]]\u0026gt;\u0026lt;/issueBackground\u0026gt; \u0026lt;remediationBackground\u0026gt;\u0026lt;![CDATA[Example remediation info.]]\u0026gt;\u0026lt;/issueDetail\u0026gt; \u0026lt;remediationDetail\u0026gt;\u0026lt;![CDATA[Example remediation details.]]\u0026gt;\u0026lt;/remediationDetail\u0026gt; \u0026lt;requestresponse\u0026gt; \u0026lt;request method=\u0026#34;POST\u0026#34; base64=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;![CDATA[exampleDataString=]]\u0026gt;\u0026lt;/request\u0026gt; \u0026lt;response base64=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;![CDATA[exampleBase64DataString]]\u0026gt;\u0026lt;/response\u0026gt; \u0026lt;responseRedirected\u0026gt;false\u0026lt;/responseRedirected\u0026gt; \u0026lt;/requestresponse\u0026gt; \u0026lt;/issue\u0026gt; ... \u0026lt;/issues\u0026gt;\rSample Scan Data Sample Burp scans can be found here.\n","date":"0001-01-01","id":108,"permalink":"/en/connecting_your_tools/parsers/file/burp/","summary":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. To parse an HTML file instead, use this method: https://documentation.","tags":[],"title":"Burp XML"},{"content":"Import JSON output of cargo-audit scan report https://crates.io/crates/cargo-audit\nSample Scan Data Sample CargoAudit Scan scans can be found here.\n","date":"0001-01-01","id":109,"permalink":"/en/connecting_your_tools/parsers/file/cargo_audit/","summary":"Import JSON output of cargo-audit scan report https://crates.io/crates/cargo-audit\nSample Scan Data Sample CargoAudit Scan scans can be found here.","tags":[],"title":"CargoAudit Scan"},{"content":" Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis) To generate the OSA report using Checkmarx CLI: ./runCxConsole.sh OsaScan -v -CxServer \u0026lt;...\u0026gt; -CxToken \u0026lt;..\u0026gt; -projectName \u0026lt;...\u0026gt; -enableOsa -OsaLocationPath \u0026lt;lib_folder\u0026gt; -OsaJson \u0026lt;output_folder\u0026gt;\nThat will generate three files, two of which are needed for defectdojo. Build the file for defectdojo with the jq utility: jq -s . CxOSAVulnerabilities.json CxOSALibraries.json\nData for SAST, SCA and KICS are supported.\nSample Scan Data Sample Checkmarx scans can be found here.\n","date":"0001-01-01","id":110,"permalink":"/en/connecting_your_tools/parsers/file/checkmarx/","summary":"Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis) To generate the OSA report using Checkmarx CLI: .","tags":[],"title":"Checkmarx"},{"content":"CxFlow is a Spring Boot application written by Checkmarx that enables initiations of scans and result orchestration. CxFlow support interactive with various Checkmarx product. This parser support JSON format export by bug tracker.\n#YAML cx-flow: bug-tracker:Json #CLI --cx-flow.bug-tracker=json Checkmarx CxFlow SAST: JSON report from Checkmarx Cxflow. Sample Scan Data Sample Checkmarx CxFlow SAST scans can be found here.\n","date":"0001-01-01","id":111,"permalink":"/en/connecting_your_tools/parsers/file/checkmarx_cxflow_sast/","summary":"CxFlow is a Spring Boot application written by Checkmarx that enables initiations of scans and result orchestration. CxFlow support interactive with various Checkmarx product.","tags":[],"title":"Checkmarx CxFlow SAST"},{"content":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample Checkmarx One scans can be found here.\n","date":"0001-01-01","id":112,"permalink":"/en/connecting_your_tools/parsers/file/checkmarx_one/","summary":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample Checkmarx One scans can be found here.","tags":[],"title":"Checkmarx One Scan"},{"content":"File Types DefectDojo parser accepts Checkov scan data as a .JSON file.\nJSON files can be created from the Checkov CLI: https://www.checkov.io/2.Basics/CLI%20Command%20Reference.html\nAcceptable JSON Format { \u0026#34;check_type\u0026#34;: \u0026#34;terraform\u0026#34;, \u0026#34;results\u0026#34;: { \u0026#34;passed_checks\u0026#34;: [ ], \u0026#34;failed_checks\u0026#34;: [ { \u0026#34;check_id\u0026#34;: \u0026#34;CKV_AZURE_41\u0026#34;, \u0026#34;check_name\u0026#34;: \u0026#34;Ensure the key vault is recoverable\u0026#34;, \u0026#34;check_result\u0026#34;: { \u0026#34;result\u0026#34;: \u0026#34;FAILED\u0026#34; }, \u0026#34;code_block\u0026#34;: [ ], \u0026#34;file_path\u0026#34;: \u0026#34;file_path\u0026#34;, \u0026#34;file_line_range\u0026#34;: [ 1, 16 ], \u0026#34;resource\u0026#34;: \u0026#34;azurerm_key_vault.main\u0026#34;, \u0026#34;check_class\u0026#34;: \u0026#34;checkov.terraform.checks.resource.azure.KeyvaultRecoveryEnabled\u0026#34;, \u0026#34;guideline\u0026#34;: \u0026#34;https://docs.bridgecrew.io/docs/ensure-the-key-vault-is-recoverable\u0026#34; }, ... ], \u0026#34;skipped_checks\u0026#34;: [], \u0026#34;parsing_errors\u0026#34;: [] }, \u0026#34;summary\u0026#34;: { \u0026#34;passed\u0026#34;: 0, \u0026#34;failed\u0026#34;: 2, \u0026#34;skipped\u0026#34;: 0, \u0026#34;parsing_errors\u0026#34;: 0, \u0026#34;checkov_version\u0026#34;: \u0026#34;1.0.467\u0026#34; } }\rSample Scan Data Sample Checkov scans can be found here.\n","date":"0001-01-01","id":113,"permalink":"/en/connecting_your_tools/parsers/file/checkov/","summary":"File Types DefectDojo parser accepts Checkov scan data as a .JSON file.\nJSON files can be created from the Checkov CLI: https://www.","tags":[],"title":"Checkov Report"},{"content":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile Types DefectDojo parser accepts Chef Inspect log scan data as a .log or .txt file.\nSample Scan Data Sample Chef Inspect logs can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/chefinspect\n","date":"0001-01-01","id":114,"permalink":"/en/connecting_your_tools/parsers/file/chefinspect/","summary":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile Types DefectDojo parser accepts Chef Inspect log scan data as a .log or .","tags":[],"title":"Chef Inspect Log"},{"content":"You can import JSON reports of Docker image vulnerabilities found by a Clair scan or the Clair Klar client.\nSample Scan Data Sample Clair Scan scans can be found here.\n","date":"0001-01-01","id":115,"permalink":"/en/connecting_your_tools/parsers/file/clair/","summary":"You can import JSON reports of Docker image vulnerabilities found by a Clair scan or the Clair Klar client.\nSample Scan Data Sample Clair Scan scans can be found here.","tags":[],"title":"Clair Scan"},{"content":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON output.\nSample Scan Data Sample Cloudsploit (AquaSecurity) scans can be found here.\n","date":"0001-01-01","id":116,"permalink":"/en/connecting_your_tools/parsers/file/cloudsploit/","summary":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON output.\nSample Scan Data Sample Cloudsploit (AquaSecurity) scans can be found here.","tags":[],"title":"Cloudsploit (AquaSecurity)"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Cobalt.io\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Paste your Cobalt.io API token in the API Key field and the desired org token in the Extras field.\nIn Add API Scan Configuration provide the ID of the asset from which to import findings in the field Service key 1. The ID can be found at the end of the URL when viewing the asset in your browser.\nIf you have more than one asset configured, you must also select which Cobalt.io API Scan Configuratio to use.\n","date":"0001-01-01","id":117,"permalink":"/en/connecting_your_tools/parsers/api/cobalt/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Cobalt.io API Import "},{"content":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found here.\n","date":"0001-01-01","id":118,"permalink":"/en/connecting_your_tools/parsers/file/cobalt/","summary":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found here.","tags":[],"title":"Cobalt.io Scan"},{"content":"Import Codechecker static analyzer report in JSON format: https://codechecker.readthedocs.io/en/latest/ Report format described here: https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#parse\nOne could make Codechecker JSON report using command like this:\nCodeChecker parse /path/to/codechecker/analyzer/output/directory -e json -o /path/to/output/file.json\rBefore this step you should build your project with Codechecker build process interception,\nodeChecker log -b \u0026#34;make -j8\u0026#34; -o ./my.project.codechecker.log\rthen analyze it\nCodeChecker analyze ./codechecker.log -o /path/to/codechecker/analyzer/output/directory\rSample Scan Data Sample Codechecker Report native scans can be found here.\n","date":"0001-01-01","id":119,"permalink":"/en/connecting_your_tools/parsers/file/codechecker/","summary":"Import Codechecker static analyzer report in JSON format: https://codechecker.readthedocs.io/en/latest/ Report format described here: https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#parse\nOne could make Codechecker JSON report using command like this:","tags":[],"title":"Codechecker Report native"},{"content":"CodeQL can be used to generate a SARIF report, that can be imported into Defect Dojo:\ncodeql database analyze db python-security-and-quality.qls --sarif-add-snippets --format=sarif-latest --output=security-extended.sarif\rThe same can be achieved by running the CodeQL GitHub action with the add-snippet property set to true.\n","date":"0001-01-01","id":120,"permalink":"/en/connecting_your_tools/parsers/file/codeql/","summary":"CodeQL can be used to generate a SARIF report, that can be imported into Defect Dojo:\ncodeql database analyze db python-security-and-quality.","tags":[],"title":"CodeQL"},{"content":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found here.\n","date":"0001-01-01","id":121,"permalink":"/en/connecting_your_tools/parsers/file/contrast/","summary":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found here.","tags":[],"title":"Contrast Scanner"},{"content":"Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\ndisplayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI) Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected\nSample Scan Data Sample Coverity API scans can be found here.\n","date":"0001-01-01","id":122,"permalink":"/en/connecting_your_tools/parsers/file/coverity_api/","summary":"Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\ndisplayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI) Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected","tags":[],"title":"Coverity API"},{"content":"File Types This DefectDojo parser accepts JSON files created from the Synopsys Coverity CLI using the following command: coverity scan.\nDocumentation for CLI can be found here.\nExample Commands to retrieve JSON output Run coverity scan --project-dir \u0026lt;project_dir\u0026gt; --local \u0026lt;result_file\u0026gt; --local-format json to create the JSON report.\nSample Scan Data Sample Coverity scans can be found here.\n","date":"0001-01-01","id":123,"permalink":"/en/connecting_your_tools/parsers/file/coverity_scan/","summary":"File Types This DefectDojo parser accepts JSON files created from the Synopsys Coverity CLI using the following command: coverity scan.","tags":[],"title":"Coverity Scan JSON Report"},{"content":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data Sample Crashtest Security scans can be found here.\n","date":"0001-01-01","id":124,"permalink":"/en/connecting_your_tools/parsers/file/crashtest_security/","summary":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data Sample Crashtest Security scans can be found here.","tags":[],"title":"Crashtest Security"},{"content":"DefectDojo‚Äôs API allows for robust pipeline solutions, which automatically ingest new scans to your instance. Automation like this can take a few different forms:\nA daily import which scans your environment on a daily basis, and then imports the results of the scan to DefectDojo (similar to our Connectors feature) A CI/CD pipeline which scans new code as it is deployed, and imports the results to DefectDojo as a triggered action These pipelines can be created by directly calling our API /reimport endpoint with an attached scan file in a way that closely resembles our Import Scan Form.\nUniversal Importer: out of the box automation DefectDojo Inc. maintains a Universal Importer which can be set up with existing CI/CD pipelines, triggered via GitHub actions, or run in any other automated context.\nThis external tool is a useful way to build a pipeline directly from the command line: a much faster solution than writing your own code.\nSee our guide to external tools to learn more. External tools are available for DefectDojo Pro users only.\nDefectDojo‚Äôs API DefectDojo‚Äôs API is documented in-app using the OpenAPI framework. You can access this documentation from the User Menu in the top right-hand corner, under ‚ÄòAPI v2 OpenAPI3‚Äô.\n- The documentation can be used to test API calls with various parameters, and does so using your own user‚Äôs API Token.\nIf you need to access an API token for a script or another integration, you can find that information under the API v2 Token option from the same menu.\nGeneral API Considerations Although our OpenAPI documentation is detailed regarding the parameters that can be used with each endpoint, it assumes that the reader has a solid understanding of DefectDojo‚Äôs key concepts. (Product Hierarchy, Findings, Deduplication, etc). Users who want a working import integration but are less familiar with DefectDojo as a whole should consider our Universal Importer. DefectDojo‚Äôs API can sometimes create unintended data objects, particularly if ‚ÄòAuto-Create Context‚Äô is used on the /import or /reimport endpoint. Fortunately, it is very difficult to accidentally delete data using the API. Most objects can only be removed using a dedicated DELETE call to the relevant endpoint. Specific notes on /import and /reimport endpoints The /reimport endpoint can be used for both an initial Import, or a ‚ÄúReimport‚Äù which extends a Test with additional Findings. You do not need to first create a Test with /import before you can use the /reimport endpoint. As long as ‚ÄòAuto Create Context‚Äô is enabled, the /reimport endpoint can create a new Test, Engagement, Product or Product Type. In almost all cases, you can use the /reimport endpoint exclusively when adding data via API.\nHowever, the /import endpoint can instead be used for a pipeline where you always want to store each scan result in a discrete Test object, rather than using /reimport to handle the diff within a single Test object. Either option is acceptable, and the endpoint you choose depends on your reporting structure, or whether you need to inspect an isolated run of a Pipeline.\nUsing the Scan Completion Date (API: scan_date) field DefectDojo offers a plethora of supported scanner reports, but not reports them contain the information most important to a user. The scan_date field is a flexible smart feature that allows users to set the completion date of the a given scan report, and have it propagate down to all the findings imported.\nThis field is not mandatory, but the default value for this field is the date of import (whenever the request is processed and a successful response is returned).\nHere are the following use cases for this field, and the results applied to the Test:\nIf the report does not set the date, and scan_date is not set at import Finding date will be the default value of scan_date If the report sets the date, and the scan_date is not set at import Finding date will be whatever the report sets If the report does not set the date, and the scan_date is set at import Finding date will be whatever the user set for scan_date If the report sets the date, and the scan_date is set at import Finding date will be whatever the user set for scan_date ","date":"0001-01-01","id":125,"permalink":"/en/connecting_your_tools/import_scan_files/api_pipeline_modelling/","summary":"DefectDojo‚Äôs API allows for robust pipeline solutions, which automatically ingest new scans to your instance. Automation like this can take a few different forms:","tags":[],"title":"Create an automated import pipeline via API"},{"content":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan Report scans can be found here.\n","date":"0001-01-01","id":126,"permalink":"/en/connecting_your_tools/parsers/file/cred_scan/","summary":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan Report scans can be found here.","tags":[],"title":"CredScan Report"},{"content":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample Scan Data Sample Crunch42 Scan scans can be found here.\n","date":"0001-01-01","id":127,"permalink":"/en/connecting_your_tools/parsers/file/crunch42/","summary":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample Scan Data Sample Crunch42 Scan scans can be found here.","tags":[],"title":"Crunch42 Scan"},{"content":"CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.\nFrom: https://www.cyclonedx.org/\nExample with Anchore Grype:\n./grype defectdojo/defectdojo-django:1.13.1 -o cyclonedx \u0026gt; report.xml Example with cyclonedx-bom tool:\npip install cyclonedx-bom cyclonedx-py Usage: cyclonedx-py [OPTIONS] Options: -i \u0026lt;path\u0026gt; - the alternate filename to a frozen requirements.txt -o \u0026lt;path\u0026gt; - the bom file to create -j - generate JSON instead of XML Sample Scan Data Sample CycloneDX scans can be found here.\n","date":"0001-01-01","id":128,"permalink":"/en/connecting_your_tools/parsers/file/cyclonedx/","summary":"CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.","tags":[],"title":"CycloneDX"},{"content":"Import report in JSON generated with -j option\nSample Scan Data Sample DawnScanner scans can be found here.\n","date":"0001-01-01","id":129,"permalink":"/en/connecting_your_tools/parsers/file/dawnscanner/","summary":"Import report in JSON generated with -j option\nSample Scan Data Sample DawnScanner scans can be found here.","tags":[],"title":"DawnScanner"},{"content":"Import compliance, malware, secret, vulnerability reports from Deepfence Threatmapper in XLSX file format.\nSample Scan Data Sample Threatmapper scans can be found here. In this link are both .xlsx and .csv listed. They contain the same content, but csv can be read in the Browser, but only xlsx is supported by the parser.\n","date":"0001-01-01","id":130,"permalink":"/en/connecting_your_tools/parsers/file/deepfence_threatmapper/","summary":"Import compliance, malware, secret, vulnerability reports from Deepfence Threatmapper in XLSX file format.\nSample Scan Data Sample Threatmapper scans can be found here.","tags":[],"title":"Deepfence Threatmapper"},{"content":"OWASP Dependency Check output can be imported in Xml format. This parser ingests the vulnerable dependencies and inherits the suppressions.\nSuppressed vulnerabilities are tagged with the tag: suppressed. Suppressed vulnerabilities are marked as mitigated. If the suppression is missing any \u0026lt;notes\u0026gt; tag, it tags them as no_suppression_document. Related vulnerable dependencies are tagged with related tag. Sample Scan Data Sample Dependency Check scans can be found here.\n","date":"0001-01-01","id":131,"permalink":"/en/connecting_your_tools/parsers/file/dependency_check/","summary":"OWASP Dependency Check output can be imported in Xml format. This parser ingests the vulnerable dependencies and inherits the suppressions.","tags":[],"title":"Dependency Check"},{"content":"Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format. See here for more info on this JSON format: https://docs.dependencytrack.org/integrations/file-formats/\nSample Scan Data Sample Dependency Track scans can be found here.\n","date":"0001-01-01","id":132,"permalink":"/en/connecting_your_tools/parsers/file/dependency_track/","summary":"Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format.","tags":[],"title":"Dependency Track"},{"content":"Import of JSON report from https://github.com/Yelp/detect-secrets\nSample Scan Data Sample Detect-secrets scans can be found here.\n","date":"0001-01-01","id":133,"permalink":"/en/connecting_your_tools/parsers/file/detect_secrets/","summary":"Import of JSON report from https://github.com/Yelp/detect-secrets\nSample Scan Data Sample Detect-secrets scans can be found here.","tags":[],"title":"Detect-secrets"},{"content":"Import JSON reports of OWASP docker-bench-security. docker-bench-security is a script that make tests based on CIS Docker Benchmark.\nSample Scan Data Sample docker-bench-security Scanner scans can be found here.\n","date":"0001-01-01","id":134,"permalink":"/en/connecting_your_tools/parsers/file/dockerbench/","summary":"Import JSON reports of OWASP docker-bench-security. docker-bench-security is a script that make tests based on CIS Docker Benchmark.\nSample Scan Data Sample docker-bench-security Scanner scans can be found here.","tags":[],"title":"docker-bench-security Scanner"},{"content":"Import JSON container image linter reports https://github.com/goodwithtech/dockle\nSample Scan Data Sample Dockle Report scans can be found here.\n","date":"0001-01-01","id":135,"permalink":"/en/connecting_your_tools/parsers/file/dockle/","summary":"Import JSON container image linter reports https://github.com/goodwithtech/dockle\nSample Scan Data Sample Dockle Report scans can be found here.","tags":[],"title":"Dockle Report"},{"content":"Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nSample Scan Data Sample DrHeader scans can be found here.\n","date":"0001-01-01","id":136,"permalink":"/en/connecting_your_tools/parsers/file/drheader/","summary":"Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nSample Scan Data Sample DrHeader scans can be found here.","tags":[],"title":"DrHeader"},{"content":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample Scan Data Sample DSOP Scan scans can be found here.\n","date":"0001-01-01","id":137,"permalink":"/en/connecting_your_tools/parsers/file/dsop/","summary":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample Scan Data Sample DSOP Scan scans can be found here.","tags":[],"title":"DSOP Scan"},{"content":"Import Edgescan vulnerabilities by API or JSON file.\nAll parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nStep 1: Add tool configuration\nSelect the gear icon from the left hand side of the page. Click on the Tool Configuration option and then + Add Tool Configuration from the dropdown menu. Once presented with a series of fields, set Tool Type to \u0026ldquo;Edgescan\u0026rdquo; and Authentication Type to \u0026ldquo;API Key\u0026rdquo;. Paste your Edgescan API key in the API Key field. Click on the Submit button. Step 2: Add and configure a product\nSelect the hamburger menu icon from the left hand side of the page. Click on the All Products option and then + Add Product. Fill in the fields presented. Once the product is added, click on the Settings option then Add API Scan Configuration. Select the previously added Edgescan Tool Configuration. Provide the edgescan asset ID(s) that you wish to import the findings for in the field Service key 1. Note that multiple asset IDs should be comma separated with no spacing. If you want to import vulnerabilities for all assets, simply leave the Service key 1 field empty. Step 3: Importing scan results\nAfter the previous steps are complete, you can import the findings by selecting the Findings option on the product\u0026rsquo;s page and then Import Scan Results. Once you are presented with a series of fields, select Edgescan Scan as the scan type. If you have more than one asset configured, you must also select which Edgescan API Scan Configuration to use. Click on the Import button. Important Reminder:\nTo ensure you\u0026rsquo;re not introducing duplicate vulnerabilities, always use the \u0026ldquo;Re-Upload Scan\u0026rdquo; option when re-importing findings from Edgescan. This can be found within the engagement\u0026rsquo;s options by clicking on Engagements , then the active engagement in question, then Edgescan Scan and selecting \u0026ldquo;Re-Upload Scan\u0026rdquo; from the dropdown menu located on the right. ","date":"0001-01-01","id":138,"permalink":"/en/connecting_your_tools/parsers/api/edgescan/","summary":"Import Edgescan vulnerabilities by API or JSON file.\nAll parsers which using API have common basic configuration step but with different values.","tags":[],"title":"Edgescan"},{"content":"Import Edgescan vulnerabilities by JSON file or API - no file required\n","date":"0001-01-01","id":139,"permalink":"/en/connecting_your_tools/parsers/file/edgescan/","summary":"Import Edgescan vulnerabilities by JSON file or API - no file required","tags":[],"title":"Edgescan"},{"content":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint scans can be found here.\n","date":"0001-01-01","id":140,"permalink":"/en/connecting_your_tools/parsers/file/eslint/","summary":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint scans can be found here.","tags":[],"title":"ESLint"},{"content":"You can either import the findings in .xml or in .fpr file format. If you import a .fpr file, the parser will look for the file \u0026lsquo;audit.fvdl\u0026rsquo; and analyze it. An extracted example can be found here. The optional audit.xml is also parsed. All vulnerabilities marked with suppressed=\u0026quot;true\u0026quot; will be marked as false positive.\nSample Scan Data Sample Fortify scans can be found here.\nFortify Webinspect report formats. Fortify Webinspect released in version 24.2 a new xml report format. This parser is able to handle both report formats. See this issue for further information.\nGenerate XML Output from Foritfy This section describes how to import XML generated from a Fortify FPR. It assumes you already have, or know how to acquire, an FPR file. Once you have the FPR file you will need use Fortify\u0026rsquo;s ReportGenerator tool (located in the bin directory of your fortify install). FORTIFY_INSTALL_ROOT/bin/ReportGenerator\nBy default, the Report Generator tool does not display all issues, it will only display one per category. To get all issues, copy the DefaultReportDefinitionAllIssues.xml to: FORTIFY_INSTALL_ROOT/Core/config/reports\nOnce this is complete, you can run the following command on your .fpr file to generate the required XML:\n./path/to/ReportGenerator -format xml -f /path/to/output.xml -source /path/to/downloaded/artifact.fpr -template DefaultReportDefinitionAllIssues.xml\r","date":"0001-01-01","id":141,"permalink":"/en/connecting_your_tools/parsers/file/fortify/","summary":"You can either import the findings in .xml or in .fpr file format. If you import a .fpr file, the parser will look for the file \u0026lsquo;audit.","tags":[],"title":"Fortify"},{"content":"Import Generic findings in CSV or JSON format.\nAttributes supported for CSV:\nDate: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value. Url: Url associated with the finding. Severity: Severity of the finding. Must be one of Info, Low, Medium, High, or Critical. Description: Description of the finding. Can be multiple lines if enclosed in double quotes. Mitigation: Possible Mitigations for the finding. Can be multiple lines if enclosed in double quotes. Impact: Detailed impact of the finding. Can be multiple lines if enclosed in double quotes. References: References associated with the finding. Can be multiple lines if enclosed in double quotes. Active: Indicator if the finding is active. Must be empty, TRUE or FALSE Verified: Indicator if the finding has been verified. Must be empty, TRUE, or FALSE FalsePositive: Indicator if the finding is a false positive. Must be TRUE, or FALSE. Duplicate:Indicator if the finding is a duplicate. Must be TRUE, or FALSE IsMitigated: Indicator if the finding is mitigated. Must be TRUE, or FALSE MitigatedDate: Date the finding was mitigated in mm/dd/yyyy format or ISO format The CSV expects a header row with the names of the attributes.\nDate fields are parsed using dateutil.parse supporting a variety of formats such a YYYY-MM-DD or ISO-8601.\nExample of JSON format:\n{ \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as dict\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36234\u0026#34;, \u0026#34;cwe\u0026#34;: 261, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/first.cpp\u0026#34;, \u0026#34;line\u0026#34;: 13, \u0026#34;endpoints\u0026#34;: [ { \u0026#34;host\u0026#34;: \u0026#34;exemple.com\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title with endpoints as strings\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36235\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/two.cpp\u0026#34;, \u0026#34;line\u0026#34;: 135, \u0026#34;endpoints\u0026#34;: [ \u0026#34;http://urlfiltering.paloaltonetworks.com/test-command-and-control\u0026#34;, \u0026#34;https://urlfiltering.paloaltonetworks.com:2345/test-pest\u0026#34; ] }, { \u0026#34;title\u0026#34;: \u0026#34;test title\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36236\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/threeeeeeeeee.cpp\u0026#34;, \u0026#34;line\u0026#34;: 1353 }, { \u0026#34;title\u0026#34;: \u0026#34;test title mitigated\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2021-01-06\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36236\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/threeeeeeeeee.cpp\u0026#34;, \u0026#34;line\u0026#34;: 1353, \u0026#34;is_mitigated\u0026#34;: true, \u0026#34;mitigated\u0026#34;: \u0026#34;2021-01-16\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;test title mitigated ISO\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description with\\n\\n some UTF-8 chars √† qu\u0026#39;il est beau2\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;mitigation\u0026#34;: \u0026#34;Some mitigation\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2024-01-04T11:02:11Z\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-2020-36236\u0026#34;, \u0026#34;cwe\u0026#34;: 287, \u0026#34;cvssv3\u0026#34;: \u0026#34;CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\u0026#34;, \u0026#34;file_path\u0026#34;: \u0026#34;src/threeeeeeeeee.cpp\u0026#34;, \u0026#34;line\u0026#34;: 1353, \u0026#34;is_mitigated\u0026#34;: true, \u0026#34;mitigated\u0026#34;: \u0026#34;2024-01-24T11:02:11Z\u0026#34; } ] }\rThis parser supports an attributes that accept files as Base64 strings. These files are attached to the respective findings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;findings\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Vuln with image\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Some very long description\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;files\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Screenshot from 2017-04-10 16-54-19.png\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;iVBORw0KGgoAAAANSUhEUgAABWgAAAK0CAIAAAARSkPJAAAAA3N\u0026lt;...\u0026gt;TkSuQmCC\u0026#34; } ] } ] }\rThis parser supports an attribute name and type to be able to define TestType. Based on this, you can define custom HASHCODE_FIELDS or DEDUPLICATION_ALGORITHM in the settings.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;My wonderful report\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;My custom Test type\u0026#34;, \u0026#34;findings\u0026#34;: [ ] }\rSample Scan Data Sample Generic Findings Import scans can be found here.\n","date":"0001-01-01","id":142,"permalink":"/en/connecting_your_tools/parsers/file/generic/","summary":"Import Generic findings in CSV or JSON format.\nAttributes supported for CSV:\nDate: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value.","tags":[],"title":"Generic Findings Import"},{"content":"Import Ggshield findings in JSON format.\nSample Scan Data Sample Ggshield scans can be found here.\n","date":"0001-01-01","id":143,"permalink":"/en/connecting_your_tools/parsers/file/ggshield/","summary":"Import Ggshield findings in JSON format.\nSample Scan Data Sample Ggshield scans can be found here.","tags":[],"title":"Ggshield"},{"content":"Import findings from Github vulnerability scan (GraphQL Query): https://help.github.com/en/github/managing-security-vulnerabilities\nCurrently the parser is able to manage only RepositoryVulnerabilityAlert object. The parser has some kind of search feature which detect the data in the report.\nHere is the mandatory objects and attributes:\nvulnerabilityAlerts (RepositoryVulnerabilityAlert object) + id + createdAt (optional) + vulnerableManifestPath + state (optional) + securityVulnerability (SecurityVulnerability object) + severity (CRITICAL/HIGH/LOW/MODERATE) + package (optional) + name (optional) + advisory (SecurityAdvisory object) + description + summary + description + identifiers + value + references (optional) + url (optional) + cvss (optional) + score (optional) + vectorString (optional) + cwes (optional)\rReferences:\nhttps://docs.github.com/en/graphql/reference/objects#repositoryvulnerabilityalert https://docs.github.com/en/graphql/reference/objects#securityvulnerability Github v4 graphql query to fetch data, with extended information like the repository name and url, alert number.\nquery getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } Another example of Python script, to have a function that queries any repository, with support for paginated responses and get all findings. Has a filter to only get OPEN dependabot alerts but this can be removed in the GraphQL query\ndef make_query(after_cursor=None): return \u0026#34;\u0026#34;\u0026#34; query getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } \u0026#34;\u0026#34;\u0026#34;.replace( \u0026#34;AFTER\u0026#34;, \u0026#39;\u0026#34;{}\u0026#34;\u0026#39;.format(after_cursor) if after_cursor else \u0026#34;null\u0026#34; ) # accumulates all pages data into a single object def get_dependabot_alerts_repository(repo, owner): keep_fetching = True after_cursor = None output_result = {\u0026#34;data\u0026#34;: {\u0026#34;repository\u0026#34;: {\u0026#34;vulnerabilityAlerts\u0026#34;: {\u0026#34;nodes\u0026#34;: []}}}} while keep_fetching: headers = {\u0026#34;Authorization\u0026#34;: AUTH_TOKEN} request = requests.post( url=\u0026#34;https://api.github.com/graphql\u0026#34;, json={ \u0026#34;operationName\u0026#34;: \u0026#34;getVulnerabilitiesByRepoAndOwner\u0026#34;, \u0026#34;query\u0026#34;: make_query(after_cursor), \u0026#34;variables\u0026#34;: {\u0026#34;name\u0026#34;: repo, \u0026#34;owner\u0026#34;: owner}, }, headers=headers, ) result = request.json() output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;name\u0026#34;] = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][ \u0026#34;name\u0026#34; ] output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;url\u0026#34;] = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;url\u0026#34;] if result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;totalCount\u0026#34;] == 0: return None output_result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;nodes\u0026#34;] += result[ \u0026#34;data\u0026#34; ][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;nodes\u0026#34;] keep_fetching = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;pageInfo\u0026#34;][ \u0026#34;hasNextPage\u0026#34; ] after_cursor = result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;pageInfo\u0026#34;][ \u0026#34;endCursor\u0026#34; ] print( \u0026#34;Fetched {} alerts for repo {}/{}\u0026#34;.format( result[\u0026#34;data\u0026#34;][\u0026#34;repository\u0026#34;][\u0026#34;vulnerabilityAlerts\u0026#34;][\u0026#34;totalCount\u0026#34;], owner, repo, ) ) return json.dumps(output_result, indent=2)\rSample Scan Data Sample Github Vulnerability scans can be found here.\n","date":"0001-01-01","id":144,"permalink":"/en/connecting_your_tools/parsers/file/github_vulnerability/","summary":"Import findings from Github vulnerability scan (GraphQL Query): https://help.github.com/en/github/managing-security-vulnerabilities\nCurrently the parser is able to manage only RepositoryVulnerabilityAlert object. The parser has some kind of search feature which detect the data in the report.","tags":[],"title":"Github Vulnerability"},{"content":"GitLab API Fuzzing Report report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab API Fuzzing Report Scan scans can be found here.\n","date":"0001-01-01","id":145,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_api_fuzzing/","summary":"GitLab API Fuzzing Report report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab API Fuzzing Report Scan scans can be found here.","tags":[],"title":"GitLab API Fuzzing Report Scan"},{"content":"GitLab Container Scan report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab Container Scan scans can be found here.\n","date":"0001-01-01","id":146,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_container_scan/","summary":"GitLab Container Scan report file can be imported in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab Container Scan scans can be found here.","tags":[],"title":"GitLab Container Scan"},{"content":"GitLab DAST Report in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab DAST Report scans can be found here.\n","date":"0001-01-01","id":147,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_dast/","summary":"GitLab DAST Report in JSON format (option \u0026ndash;json)\nSample Scan Data Sample GitLab DAST Report scans can be found here.","tags":[],"title":"GitLab DAST Report"},{"content":"Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nSample Scan Data Sample GitLab Dependency Scanning Report scans can be found here.\n","date":"0001-01-01","id":148,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_dep_scan/","summary":"Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nSample Scan Data Sample GitLab Dependency Scanning Report scans can be found here.","tags":[],"title":"GitLab Dependency Scanning Report"},{"content":"Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nSample Scan Data Sample GitLab SAST Report scans can be found here.\n","date":"0001-01-01","id":149,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_sast/","summary":"Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nSample Scan Data Sample GitLab SAST Report scans can be found here.","tags":[],"title":"GitLab SAST Report"},{"content":"GitLab Secret Detection Report file can be imported in JSON format (option \u0026ndash;json).\nSample Scan Data Sample GitLab Secret Detection Report scans can be found here.\n","date":"0001-01-01","id":150,"permalink":"/en/connecting_your_tools/parsers/file/gitlab_secret_detection_report/","summary":"GitLab Secret Detection Report file can be imported in JSON format (option \u0026ndash;json).\nSample Scan Data Sample GitLab Secret Detection Report scans can be found here.","tags":[],"title":"GitLab Secret Detection Report"},{"content":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample Gitleaks scans can be found here.\n","date":"0001-01-01","id":151,"permalink":"/en/connecting_your_tools/parsers/file/gitleaks/","summary":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample Gitleaks scans can be found here.","tags":[],"title":"Gitleaks"},{"content":"Google Cloud has a Artifact Registry that you can enable security scans https://cloud.google.com/artifact-registry/docs/analysis Once a scan is completed, results can be pulled via API/gcloud https://cloud.google.com/artifact-analysis/docs/metadata-storage and exported to JSON\nFile Types DefectDojo parser accepts Google Cloud Artifact Vulnerability Scan data as a .json file.\nSample Scan Data Sample reports can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/gcloud_artifact_scan\n","date":"0001-01-01","id":152,"permalink":"/en/connecting_your_tools/parsers/file/gcloud_artifact_scan/","summary":"Google Cloud has a Artifact Registry that you can enable security scans https://cloud.google.com/artifact-registry/docs/analysis Once a scan is completed, results can be pulled via API/gcloud https://cloud.","tags":[],"title":"Google Cloud Artifact Vulnerability Scan"},{"content":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample Gosec Scanner scans can be found here.\n","date":"0001-01-01","id":153,"permalink":"/en/connecting_your_tools/parsers/file/gosec/","summary":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample Gosec Scanner scans can be found here.","tags":[],"title":"Gosec Scanner"},{"content":"JSON vulnerability report generated by govulncheck tool, using a command like govulncheck -json . \u0026gt;\u0026gt; report.json\nSample Scan Data Sample Govulncheck scans can be found here.\n","date":"0001-01-01","id":154,"permalink":"/en/connecting_your_tools/parsers/file/govulncheck/","summary":"JSON vulnerability report generated by govulncheck tool, using a command like govulncheck -json . \u0026gt;\u0026gt; report.json\nSample Scan Data Sample Govulncheck scans can be found here.","tags":[],"title":"Govulncheck"},{"content":"Import HackerOne cases findings in JSON format (vulnerability disclosure parser) or Bug Bounties in JSON or CSV format (bug bounty parser)\nSample Scan Data Sample HackerOne Cases scans can be found here.\n","date":"0001-01-01","id":155,"permalink":"/en/connecting_your_tools/parsers/file/h1/","summary":"Import HackerOne cases findings in JSON format (vulnerability disclosure parser) or Bug Bounties in JSON or CSV format (bug bounty parser)","tags":[],"title":"HackerOne Cases"},{"content":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample Hadolint scans can be found here.\n","date":"0001-01-01","id":156,"permalink":"/en/connecting_your_tools/parsers/file/hadolint/","summary":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample Hadolint scans can be found here.","tags":[],"title":"Hadolint"},{"content":"Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nSample Scan Data Sample Harbor Vulnerability scans can be found here.\n","date":"0001-01-01","id":157,"permalink":"/en/connecting_your_tools/parsers/file/harbor_vulnerability/","summary":"Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nSample Scan Data Sample Harbor Vulnerability scans can be found here.","tags":[],"title":"Harbor Vulnerability"},{"content":"The HCL Appscan has the possibility to export the results in PDF, XML and CSV formats within the portal. However, this parser only supports the import of XML generated from HCL Appscan on cloud.\nSample Scan Data Sample HCL Appscan scans can be found here.\n","date":"0001-01-01","id":158,"permalink":"/en/connecting_your_tools/parsers/file/hcl_appscan/","summary":"The HCL Appscan has the possibility to export the results in PDF, XML and CSV formats within the portal. However, this parser only supports the import of XML generated from HCL Appscan on cloud.","tags":[],"title":"HCL Appscan"},{"content":"HCL Appscan on Cloud can export the results in PDF, XML and CSV formats but this parser only supports the import of XML generated from HCL Appscan on Cloud for SAST scans.\nSample Scan Data Sample HCL AppScan on Cloud SAST scans can be found here.\n","date":"0001-01-01","id":159,"permalink":"/en/connecting_your_tools/parsers/file/hcl_asoc_sast/","summary":"HCL Appscan on Cloud can export the results in PDF, XML and CSV formats but this parser only supports the import of XML generated from HCL Appscan on Cloud for SAST scans.","tags":[],"title":"HCL AppScan on Cloud SAST"},{"content":"Import findings from Horusec scan.\n./horusec_linux_x64 start -O=report.json -o json -i=\u0026#34;tests/\u0026#34;\rReferences:\nGitHub repository Sample Scan Data Sample Horusec scans can be found here.\n","date":"0001-01-01","id":160,"permalink":"/en/connecting_your_tools/parsers/file/horusec/","summary":"Import findings from Horusec scan.\n./horusec_linux_x64 start -O=report.json -o json -i=\u0026#34;tests/\u0026#34;\rReferences:\nGitHub repository Sample Scan Data Sample Horusec scans can be found here.","tags":[],"title":"Horusec"},{"content":"Import JSON report of the Humble scanner https://github.com/rfc-st/humble\nSample Scan Data Sample Humble Report scans can be found here.\n","date":"0001-01-01","id":161,"permalink":"/en/connecting_your_tools/parsers/file/humble/","summary":"Import JSON report of the Humble scanner https://github.com/rfc-st/humble\nSample Scan Data Sample Humble Report scans can be found here.","tags":[],"title":"Humble Report"},{"content":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI Report scans can be found here.\n","date":"0001-01-01","id":162,"permalink":"/en/connecting_your_tools/parsers/file/huskyci/","summary":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI Report scans can be found here.","tags":[],"title":"HuskyCI Report"},{"content":"Import JSON reports from THC Hydra.\nHydra can discover weak login credentials on different types of services (e.g. RDP).\nAs Hydra cannot provide a severity rating (as it doesn\u0026rsquo;t know how severe a weak login is at this scanned service), all imported findings will be rated \u0026lsquo;High\u0026rsquo;.\nSample JSON report:\n{ \u0026#34;errormessages\u0026#34;: [ \u0026#34;[ERROR] Error Message of Something\u0026#34;, \u0026#34;[ERROR] Another Message\u0026#34;, \u0026#34;These are very free form\u0026#34; ], \u0026#34;generator\u0026#34;: { \u0026#34;built\u0026#34;: \u0026#34;2019-03-01 14:44:22\u0026#34;, \u0026#34;commandline\u0026#34;: \u0026#34;hydra -b jsonv1 -o results.json ... ...\u0026#34;, \u0026#34;jsonoutputversion\u0026#34;: \u0026#34;1.00\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;http-post-form\u0026#34;, \u0026#34;software\u0026#34;: \u0026#34;Hydra\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;v8.5\u0026#34; }, \u0026#34;quantityfound\u0026#34;: 1, \u0026#34;results\u0026#34;: [ { \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;login\u0026#34;: \u0026#34;bill@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;bill\u0026#34;, \u0026#34;port\u0026#34;: 9999, \u0026#34;service\u0026#34;: \u0026#34;http-post-form\u0026#34; } ], \u0026#34;success\u0026#34;: false }\rSample Scan Data Sample Hydra scans can be found here.\n","date":"0001-01-01","id":163,"permalink":"/en/connecting_your_tools/parsers/file/hydra/","summary":"Import JSON reports from THC Hydra.\nHydra can discover weak login credentials on different types of services (e.g. RDP).\nAs Hydra cannot provide a severity rating (as it doesn\u0026rsquo;t know how severe a weak login is at this scanned service), all imported findings will be rated \u0026lsquo;High\u0026rsquo;.","tags":[],"title":"Hydra"},{"content":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan DAST scans can be found here.\n","date":"0001-01-01","id":164,"permalink":"/en/connecting_your_tools/parsers/file/ibm_app/","summary":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan DAST scans can be found here.","tags":[],"title":"IBM AppScan DAST"},{"content":"XML or JSON Scan Result File from Immuniweb Scan.\nSample Scan Data Sample Immuniweb Scan scans can be found here.\n","date":"0001-01-01","id":165,"permalink":"/en/connecting_your_tools/parsers/file/immuniweb/","summary":"XML or JSON Scan Result File from Immuniweb Scan.\nSample Scan Data Sample Immuniweb Scan scans can be found here.","tags":[],"title":"Immuniweb Scan"},{"content":"IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.).\nManual Import Use the Export CSV feature in the IntSights Threat Command GUI to create an IntSights Alerts.csv file. This CSV file can then be imported into Defect Dojo.\nAutomated Import The IntSights get-complete-alert API only returns details for a single alert. To automate the process, individually fetch details for each alert and append to a list. The list is then saved as the value for the key \u0026ldquo;Alerts\u0026rdquo;. This JSON object can then be imported into Defect Dojo.\nExample:\n{ \u0026quot;Alerts\u0026quot;:[ { \u0026quot;_id\u0026quot;:\u0026quot;5c80egf83b4a3900078b6be6\u0026quot;, \u0026quot;Details\u0026quot;:{ \u0026quot;Source\u0026quot;:{ \u0026quot;URL\u0026quot;:\u0026quot;https://www.htbridge.com/websec/?id=ABCDEF\u0026quot;, \u0026quot;Date\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;Type\u0026quot;:\u0026quot;Other\u0026quot;, \u0026quot;NetworkType\u0026quot;:\u0026quot;ClearWeb\u0026quot; }, \u0026quot;Images\u0026quot;:[ \u0026quot;5c80egf833963a40007e01e8d\u0026quot;, \u0026quot;5c80egf833b4a3900078b6bea\u0026quot;, \u0026quot;5c80egf834626bd0007bd64db\u0026quot; ], \u0026quot;Title\u0026quot;:\u0026quot;HTTP headers weakness in example.com web server\u0026quot;, \u0026quot;Tags\u0026quot;:[], \u0026quot;Type\u0026quot;:\u0026quot;ExploitableData\u0026quot;, \u0026quot;Severity\u0026quot;:\u0026quot;Critical\u0026quot;, \u0026quot;SubType\u0026quot;:\u0026quot;VulnerabilityInTechnologyInUse\u0026quot;, \u0026quot;Description\u0026quot;:\u0026quot;X-XSS-PROTECTION and CONTENT-SECURITY-POLICY headers were not sent by the server, which makes it vulnerable for various attack vectors\u0026quot; }, \u0026quot;Assignees\u0026quot;:[ \u0026quot;5c3c8f99903dfd0006ge5e61\u0026quot; ], \u0026quot;FoundDate\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;Assets\u0026quot;:[ { \u0026quot;Type\u0026quot;:\u0026quot;Domains\u0026quot;, \u0026quot;Value\u0026quot;:\u0026quot;example.com\u0026quot; } ], \u0026quot;TakedownStatus\u0026quot;:\u0026quot;NotSent\u0026quot;, \u0026quot;IsFlagged\u0026quot;:false, \u0026quot;UpdateDate\u0026quot;:\u0026quot;2018-03-08T00:01:02.622Z\u0026quot;, \u0026quot;RelatedIocs\u0026quot;:[], \u0026quot;RelatedThreatIDs\u0026quot;:[], \u0026quot;Closed\u0026quot;:{ \u0026quot;IsClosed\u0026quot;:false } } ] } Sample Scan Data Sample IntSights Report scans can be found here.\n","date":"0001-01-01","id":166,"permalink":"/en/connecting_your_tools/parsers/file/intsights/","summary":"IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.","tags":[],"title":"IntSights Report"},{"content":"Vulnerabilities List - JSON report\nSample Scan Data Sample Invicti scans can be found here.\n","date":"0001-01-01","id":167,"permalink":"/en/connecting_your_tools/parsers/file/invicti/","summary":"Vulnerabilities List - JSON report\nSample Scan Data Sample Invicti scans can be found here.","tags":[],"title":"Invicti"},{"content":"File Types Accepts a JSON File, generated from the JFrog Artifact Summary API Call.\nSample Scan Data / Unit Tests Sample JFrog Xray API Summary Artifact Scans can be found here.\nLink To Tool See JFrog Documentation: https://jfrog.com/help/r/jfrog-rest-apis/summary\n","date":"0001-01-01","id":168,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_api_summary_artifact/","summary":"File Types Accepts a JSON File, generated from the JFrog Artifact Summary API Call.\nSample Scan Data / Unit Tests Sample JFrog Xray API Summary Artifact Scans can be found here.","tags":[],"title":"JFrog Xray API Summary Artifact Scan"},{"content":"Import the JSON format for the \u0026quot;JFrog Xray On Demand Binary Scan\u0026quot; file. Use this importer for Xray version 3.X\nJFrog file documentation:\nhttps://jfrog.com/help/r/jfrog-cli/on-demand-binary-scan\nSample Scan Data Sample JFrog Xray On Demand Binary Scan scans can be found here.\n","date":"0001-01-01","id":169,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_on_demand_binary_scan/","summary":"Import the JSON format for the \u0026quot;JFrog Xray On Demand Binary Scan\u0026quot; file. Use this importer for Xray version 3.X","tags":[],"title":"JFrog Xray On Demand Binary Scan"},{"content":"Import the JSON format for the \u0026quot;Security \u0026amp; Compliance | Reports\u0026quot; export. Jfrog\u0026rsquo;s Xray tool is an add-on to their Artifactory repository that does Software Composition Analysis, see https://www.jfrog.com/confluence/display/JFROG/JFrog+Xray for more information. \u0026quot;Xray Unified\u0026quot; refers to Xray Version 3.0 and later.\nSample Scan Data Sample JFrog XRay Unified scans can be found here.\n","date":"0001-01-01","id":170,"permalink":"/en/connecting_your_tools/parsers/file/jfrog_xray_unified/","summary":"Import the JSON format for the \u0026quot;Security \u0026amp; Compliance | Reports\u0026quot; export. Jfrog\u0026rsquo;s Xray tool is an add-on to their Artifactory repository that does Software Composition Analysis, see https://www.","tags":[],"title":"JFrog XRay Unified"},{"content":"Import the JSON format for the \u0026quot;Security Export\u0026quot; file. Use this importer for Xray version 2.X\nSample Scan Data Sample JFrogXRay scans can be found here.\n","date":"0001-01-01","id":171,"permalink":"/en/connecting_your_tools/parsers/file/jfrogxray/","summary":"Import the JSON format for the \u0026quot;Security Export\u0026quot; file. Use this importer for Xray version 2.X\nSample Scan Data Sample JFrogXRay scans can be found here.","tags":[],"title":"JFrogXRay"},{"content":"Import of JSON report from https://github.com/Checkmarx/kics\nSample Scan Data Sample KICS Scanner scans can be found here.\n","date":"0001-01-01","id":172,"permalink":"/en/connecting_your_tools/parsers/file/kics/","summary":"Import of JSON report from https://github.com/Checkmarx/kics\nSample Scan Data Sample KICS Scanner scans can be found here.","tags":[],"title":"KICS Scanner"},{"content":"Import Kiuwan SAST Scan in CSV format. Export as CSV Results on Kiuwan, or via the Kiuwan REST API endpoint vulnerabilities/export (type=csv).\nSample Scan Data Sample Kiuwan Scanner scans can be found here.\n","date":"0001-01-01","id":173,"permalink":"/en/connecting_your_tools/parsers/file/kiuwan/","summary":"Import Kiuwan SAST Scan in CSV format. Export as CSV Results on Kiuwan, or via the Kiuwan REST API endpoint vulnerabilities/export (type=csv).","tags":[],"title":"Kiuwan Scanner (SAST)"},{"content":"Import Kiuwan Insights Scan in JSON format. Export via API endpoint insights/analysis/security as json and create a file for importing to DefectDojo.\nExample Code Data can be fetched from the Kiuwan REST API like this:\nimport requests, json headers = {\u0026#39;Authorization\u0026#39;: \u0026#39;Basic $KIUWAN_TOKEN\u0026#39;, \u0026#39;Accept\u0026#39; : \u0026#39;application/json\u0026#39;} appName = \u0026#34;Test\u0026#34; analysisCode = \u0026#34;A-111-1111111111\u0026#34; URL = \u0026#34;https://api.kiuwan.com/insights/analysis/security?analysisCode=\u0026#34; + analysisCode + \u0026#34;\u0026amp;application=\u0026#34; + appName response = requests.get(url = URL, headers = headers) jsonResponse = r.json() data = jsonResponse[\u0026#34;data\u0026#34;] saveFile(\u0026#34;result.json\u0026#34;, json.dumps(data, indent=2))\rSample Scan Data Sample Kiuwan Scanner scans can be found here.\n","date":"0001-01-01","id":174,"permalink":"/en/connecting_your_tools/parsers/file/kiuwan_sca/","summary":"Import Kiuwan Insights Scan in JSON format. Export via API endpoint insights/analysis/security as json and create a file for importing to DefectDojo.","tags":[],"title":"Kiuwan Scanner (SCA i.e. \"Insights\")"},{"content":"Import KrakenD Audit Scan results in JSON format. You can use the following command to audit the KrakenD configuration which then can be uploaded to DefectDojo:\nkrakend audit -c krakend.json -f \u0026#34;{{ marshal . }}\u0026#34; \u0026gt;\u0026gt; recommendations.json\rSample Scan Data Sample KrakenD Audit scans can be found here.\n","date":"0001-01-01","id":175,"permalink":"/en/connecting_your_tools/parsers/file/krakend_audit/","summary":"Import KrakenD Audit Scan results in JSON format. You can use the following command to audit the KrakenD configuration which then can be uploaded to DefectDojo:","tags":[],"title":"KrakenD Audit Scan"},{"content":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan Data Sample kube-bench Scanner scans can be found here.\n","date":"0001-01-01","id":176,"permalink":"/en/connecting_your_tools/parsers/file/kubebench/","summary":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan Data Sample kube-bench Scanner scans can be found here.","tags":[],"title":"kube-bench Scanner"},{"content":"Kubeaudit is a command line tool and a Go package to audit Kubernetes clusters for various different security concerns. The output of of Kubeaudit which is supported within this parser is JSON. The tool can be found here\nSample Scan Data Sample Kubeaudit scans can be found here.\n","date":"0001-01-01","id":177,"permalink":"/en/connecting_your_tools/parsers/file/kubeaudit/","summary":"Kubeaudit is a command line tool and a Go package to audit Kubernetes clusters for various different security concerns. The output of of Kubeaudit which is supported within this parser is JSON.","tags":[],"title":"Kubeaudit Scan"},{"content":"Import JSON reports of kube-hunter scans. Use \u0026ldquo;kube-hunter \u0026ndash;report json\u0026rdquo; to produce the report in json format.\nSample Scan Data Sample kubeHunter Scanner scans can be found here.\n","date":"0001-01-01","id":178,"permalink":"/en/connecting_your_tools/parsers/file/kubehunter/","summary":"Import JSON reports of kube-hunter scans. Use \u0026ldquo;kube-hunter \u0026ndash;report json\u0026rdquo; to produce the report in json format.\nSample Scan Data Sample kubeHunter Scanner scans can be found here.","tags":[],"title":"kubeHunter Scanner"},{"content":"Kubescape is a K8s open-source tool providing a Kubernetes single pane of glass, including risk analysis, security compliance, RBAC visualizer, and image vulnerability scanning. Kubescape scans K8s clusters, YAML files, and HELM charts, detecting misconfigurations according to multiple frameworks (such as the NSA-CISA, MITRE ATT\u0026amp;CK¬Æ), software vulnerabilities, and RBAC (role-based-access-control) violations at early stages of the CI/CD pipeline, calculates risk score instantly and shows risk trends over time.\nThe parser supports json output files\nSample Scan Data Sample Kubescape scans can be found here.\n","date":"0001-01-01","id":179,"permalink":"/en/connecting_your_tools/parsers/file/kubescape/","summary":"Kubescape is a K8s open-source tool providing a Kubernetes single pane of glass, including risk analysis, security compliance, RBAC visualizer, and image vulnerability scanning.","tags":[],"title":"Kubescape Scanner"},{"content":"File Types This DefectDojo parser accepts JSON files (in flattened format) from Legitify. For further details regarding the results, please consult the relevant documentation.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":180,"permalink":"/en/connecting_your_tools/parsers/file/legitify/","summary":"File Types This DefectDojo parser accepts JSON files (in flattened format) from Legitify. For further details regarding the results, please consult the relevant documentation.","tags":[],"title":"Legitify"},{"content":"Note: Connectors are a DefectDojo Pro-only feature.\nOnce an API connector is set up, it will run two Operations on a recurring basis:\nDiscover will learn the connected tool\u0026rsquo;s structure, and will create records in DefectDojo of any unmapped data; Sync will import new Findings from the tool based on your mappings. Both of these Operations are managed on the Operations page of a Connector. The table will also track past runs of these Operations so that you can ensure your Connector is up to date.\nTo access a Connector\u0026rsquo;s Operations Page, open Manage Records \u0026amp; Operations for the Connector you wish to work with, and then switch to the \u0026lt;/\u0026gt; Operations From (tool) tab.\nThe Manage Records \u0026amp; Operations page can also be used to handle Records; which are the individual Product mappings of your connected tool. See Managing Records for more information.\nThe Operations Page Each entry on the Operations Page\u0026rsquo;s table is a record of an operation event, with the following traits:\nType describes whether the event was a Sync or a Discover operation. Status describes whether the event ran successfully. Trigger describes how the event was triggered - was it a Scheduled operation which ran automatically, or a Manual operation which was triggered by a DefectDojo user? The Start \u0026amp; End Time of each operation is recorded here, along with the Duration. Discover Operations The first step a DefectDojo Connector needs to take is to Discover your tool\u0026rsquo;s environment to see how you\u0026rsquo;re organizing your scan data.\nLet\u0026rsquo;s say you have a BurpSuite tool, which is set up to scan five different repositories for vulnerabilities. Your Connector will take note of this organizational structure and set up Records to help you translate those separate repositories into DefectDojos Product/Engagement/Test hierarchy.\nCreating New Records Each time your Connector runs a Discover operation, it will look for new Vendor-Equivalent-Products (VEPs). DefectDojo looks at the way the Vendor tool is set up and will create Records of VEPs based on how your tool is organized.\nRun Discover Manually Discover operations will automatically run on a regular basis, but they can also be run manually. If you\u0026rsquo;re setting up this Connector for the first time, you can click the Discover button next to the Unmapped Records header. After you refresh the page, you will see your initial list of Records.\nTo learn more about working with records and setting up mappings to Products, see our guide to Managing Records.\nSync Operations On a daily basis, DefectDojo will look at each Mapped Record for new scan data. DefectDojo will then run a Reimport, which compares the state of existing scan data to an incoming report.\nWhere is vulnerability data stored? DefectDojo will create an Engagement nested under the Product specified in the Record Mapping. This Engagement will be called Global Connectors. The Global Connectors Engagement will track each separate Connection associated with the Product as a Test. On this sync, and each subsequent sync, the Test will store each vulnerability found by the tool as a Finding. How Sync handles new vulnerability data Whenever Sync runs, it will compare the latest scan data against the existing list of Findings for changes.\nIf there are new Findings detected, they will be added to the Test as new Findings. If there are any Findings which aren‚Äôt detected in the latest scan, they will be marked as Inactive in the Test. To learn more about Products, Engagements, Tests and Findings, see our Product Hierarchy Overview.\nRunning Sync Manually To have DefectDojo run a Sync operation off-schedule:\nNavigate to the Manage Records \u0026amp; Operations page for the connector you want to use. From the API Connectors page, click the drop-down menu on the Connector you wish to work with, and select Manage Records \u0026amp; Operations.\n‚Äã From this page, click the Sync button. This button is located next to the Mapped Records header. ","date":"0001-01-01","id":181,"permalink":"/en/connecting_your_tools/connectors/manage_operations/","summary":"Note: Connectors are a DefectDojo Pro-only feature.\nOnce an API connector is set up, it will run two Operations on a recurring basis:","tags":[],"title":"Managing Operations"},{"content":"Note: Connectors are a DefectDojo Pro-only feature.\nOnce you have run your first Discover operation, you should see a list of Mapped or Unmapped records on the Manage Records and Operations page.\nWhat\u0026rsquo;s a Record? A Record is a connection between a DefectDojo Product and a Vendor-Equivalent-Product. You can use your Records list to control the flow of data between your tool and DefectDojo.\nRecords are created and updated during the Discover operation, which DefectDojo runs daily to look for new Vendor-Equivalent Products.\nRecords have various attributes, including:\nThe State of the Record The Product the Record imports data to When the Record was First and Last Discovered (by the Discover process) When the Record mapping was Finalized by a user A link to the DefectDojo Product How Records are Mapped Each Record needs to have a Mapping assigned. The Mapping tells DefectDojo where to store the scan data from the tool. A Mapped Record assigns the Vendor-Equivalent Product to a DefectDojo Product, and tells the Connector to start importing scan data to that location (as Engagements and Tests).\nYou can assign Mappings yourself, or you can have DefectDojo assign them automatically.\nAuto-Mapping If you have Auto-Mapping enabled, new Records will be Mapped to Products automatically. Each time DefectDojo Discovers a new Record, a matching DefectDojo Product will be automatically created for each Record**.** That Record will be stored under Mapped Records to indicate that it is ready to import data to DefectDojo.\nIf you don\u0026rsquo;t have Auto-Mapping enabled, you can make your own decisions about where you want data to flow. Each time the Connector finds a new Vendor-Equivalent Product (via Discover), it will add a new Record to your Unmapped Records list, and you can then manually assign that Record to a new or existing Product in DefectDojo.\nMapping - Example Workflow: David has just finished setting up a connector for his BurpSuite tool, and runs a Discover operation. David has Burp set up to scan 4 different \u0026lsquo;Sites\u0026rsquo;, and DefectDojo creates a new Record for each of those Sites.\nIf David decides to use Auto-Mapping, DefectDojo will create a new Product for each Site. From now on, when DefectDojo runs a Synchronize operation, the Connector will import scan data directly from the Site into the Product (via the Record mapping)\n‚Äã If David leaves Auto-Mapping off, DefectDojo will still discover those 4 Sites and create Records, but it won\u0026rsquo;t import any data until David creates the Mappings himself.\n‚Äã David can always change how these mappings are set up later. Maybe he wants to consolidate the output of a few different Burp Sites into a single Product. Or maybe he\u0026rsquo;s looking to have a Product which records scan data from a few different tools - including Burp. It\u0026rsquo;s easy for David to change where Burp scan data is stored into DefectDojo by changing the Mapping of these Records. How Records interact with Products Once a Record is Mapped, DefectDojo will be ready to import your tool‚Äôs scans through a Sync Operation. Connectors can work alongside other DefectDojo import processes or interactive testing.\nRecord Mappings are designed to be non-invasive. If you map a Product to a Record which contains existing Engagements or Findings, those existing Engagements and Findings will not be affected or overwritten by the data sync process.\n‚Äã All data created via a connector will be stored under a single Engagement called Global Connectors. That Engagement will create a separate Test for each Connector mapped to the Product. This makes it possible to send scan data from multiple Connectors to the same Product. All of the data will be stored in the same Engagement, but each Connector will store data in a separate Test.\nTo learn more about Products, Engagements and Tests, see our Product Hierarchy Overview.\nRecord States - Glossary Each Record has an associated state to communicate how the Record is working.\nNew A New Record is an Unmapped Record which DefectDojo has Discovered. It can be Mapped to a Product or Ignored. To Map a new Record to a Product, see our guide on Editing Records.\nGood \u0026lsquo;Good\u0026rsquo; indicates that a Record is Mapped and operating correctly. Future Discover Operations check to see if the underlying Vendor-Equivalent Product still exists, to ensure that the Sync operation will run correctly.\nIgnored \u0026lsquo;Ignored\u0026rsquo; Records have been successfully Discovered, but a DefectDojo user has decided not to map the data to a Product.\nWarning States: Stale or Missing If the connection between tool and DefectDojo changes, the state of a Record will change to let you know.\nStale A Mapping is moved to ‚ÄòStale‚Äô when a related Product, Engagement or Test has been deleted from DefectDojo. The mapping still exists, but there isn‚Äôt anywhere in DefectDojo for the Tool‚Äôs data to import to.\nStale records can be remapped to an existing Product, or Ignored if the scan data is no longer relevant.\nMissing If a Record has been Mapped, but the source data (or Vendor-Equivalent Product) is not being detected by DefectDojo, the Record will be labeled as Missing.\nDefectDojo Connectors will adapt to name changes, directory changes and other data shifts, so this is possibly because the related Vendor-Equivalent Product was deleted from the Tool you‚Äôre using.\nIf you intended to remove the Vendor Equivalent Product from your tool, you can Delete a Missing Record. If not, you\u0026rsquo;ll need to troubleshoot the problem within the Tool so that the source data can be Discovered correctly.\nEdit Records: Remap, Ignore or Delete Records can be Edited, Ignored or Deleted from the Manage Records \u0026amp; Operations Page.\nAlthough Mapped and Unmapped records are located in separate tables, they can both be edited in the same way.\nFrom the Records table, click the blue ‚ñº Arrow next to the State column on a given Record. From there, you can select Edit Record, or Delete Record.\nChange the Mapping of a Record Clicking Edit Record will open a window which allows you to change the destination product in DefectDojo. You can either select an existing Product from the drop-down menu, or you can type in the name of a new Product you wish to create.\nThe scan data associated with a Record can be directed to flow into a different Product by changing the mapping.\nSelect, or type in the name of a new Product from the drop-down menu to the right.\nEdit the State of a Record The State of a Record can be changed from this menu as well. Records can be switched from Good to Ignored (or vice versa) by choosing an option from the State dropdown list.\nIgnoring a Record If you wish to ‚Äòswitch off‚Äô one of the records or disregard the data it‚Äôs sending to DefectDojo, you can choose to ‚ÄòIgnore‚Äô the record. An ‚ÄòIgnored‚Äô record will move to the Unmapped Records list and will not push any new data to DefectDojo.\nYou can Ignore a Mapped Record (which will remove the mapping), or a New Record (from the unmapped Records list).\nRestoring an Ignored Record If you would like to remove the Ignored status from a record, you can change it back to New with the same State dropdown menu.\nIf Auto-Map Records is enabled, the Record will return to its original mapping once the Discover operation runs again. If Auto-Map Records is not enabled, DefectDojo will not automatically restore a previous mapping, so you‚Äôll need to set up the mapping for this Record again. Delete a Record You can also Delete Records, which will remove them from the Unmapped or Mapped Records table.\nKeep in mind that the Discover function will always import all records from a tool - meaning that even if a Record is deleted from DefectDojo, it will become re-discovered later (and will return to the list of Records to be mapped again).\nIf you plan on removing the underlying Vendor-Equivalent Product from your scan tool, then Deleting the Record is a good option. Otherwise, the next Discover operation will see that the associated data is missing, and this Record will change state to \u0026lsquo;Missing\u0026rsquo;.\n‚Äã However, if the underlying Vendor-Equivalent Product still exists, it will be Discovered again on a future Discover operation. To prevent this behaviour, you can instead Ignore the Record. Does this affect any imported data? No. All Findings, Tests and Engagements created by a sync record will remain in DefectDojo even after a Record is deleted. Deleting a record or a configuration will only remove the data-flow process, and won‚Äôt delete any vulnerability data from DefectDojo or your tool.\n","date":"0001-01-01","id":182,"permalink":"/en/connecting_your_tools/connectors/manage_records/","summary":"Note: Connectors are a DefectDojo Pro-only feature.\nOnce you have run your first Discover operation, you should see a list of Mapped or Unmapped records on the Manage Records and Operations page.","tags":[],"title":"Managing Records"},{"content":"File Types Accepts a JSON file, generated from the Mend* Unified Agent.\nSample Scan Data / Unit Tests Unit tests for Mend JSON files can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/mend\nLink To Tool See documentation: https://docs.mend.io/bundle/unified_agent/page/example_of_a_unified_agent_json_report.html\nFormerly known as Whitesource.\n","date":"0001-01-01","id":183,"permalink":"/en/connecting_your_tools/parsers/file/mend/","summary":"File Types Accepts a JSON file, generated from the Mend* Unified Agent.\nSample Scan Data / Unit Tests Unit tests for Mend JSON files can be found at https://github.","tags":[],"title":"Mend Scan"},{"content":"The Meterian JSON report output file can be imported.\nSample Scan Data Sample Meterian Scanner scans can be found here.\n","date":"0001-01-01","id":184,"permalink":"/en/connecting_your_tools/parsers/file/meterian/","summary":"The Meterian JSON report output file can be imported.\nSample Scan Data Sample Meterian Scanner scans can be found here.","tags":[],"title":"Meterian Scanner"},{"content":"Import XML report\nSample Scan Data Sample Microfocus Webinspect Scanner scans can be found here.\n","date":"0001-01-01","id":185,"permalink":"/en/connecting_your_tools/parsers/file/microfocus_webinspect/","summary":"Import XML report\nSample Scan Data Sample Microfocus Webinspect Scanner scans can be found here.","tags":[],"title":"Microfocus Webinspect Scanner"},{"content":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scanner scans can be found here.\n","date":"0001-01-01","id":186,"permalink":"/en/connecting_your_tools/parsers/file/mobsf/","summary":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scanner scans can be found here.","tags":[],"title":"MobSF Scanner"},{"content":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scorecard Scanner scans can be found here.\n","date":"0001-01-01","id":187,"permalink":"/en/connecting_your_tools/parsers/file/mobsf_scorecard/","summary":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scorecard Scanner scans can be found here.","tags":[],"title":"MobSF Scorecard Scanner"},{"content":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan Data Sample Mobsfscan scans can be found here.\n","date":"0001-01-01","id":188,"permalink":"/en/connecting_your_tools/parsers/file/mobsfscan/","summary":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan Data Sample Mobsfscan scans can be found here.","tags":[],"title":"Mobsfscan"},{"content":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory Scanner scans can be found here.\n","date":"0001-01-01","id":189,"permalink":"/en/connecting_your_tools/parsers/file/mozilla_observatory/","summary":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory Scanner scans can be found here.","tags":[],"title":"Mozilla Observatory Scanner"},{"content":"This parser helps to parse Microsoft Defender Findings and supports two types of imports:\nYou can import a JSON output file from the api/vulnerabilities/machinesVulnerabilities endpoint of Microsoft defender. You can upload a custom zip file which include multiple JSON files from two Microsoft Defender Endpoints. For that you have to make your own zip file and include two folders (machines/ and vulnerabilities/) within the zip file. For vulnerabilities/ you can attach multiple JSON files from the api/vulnerabilities/machinesVulnerabilities REST API endpoint of Microsoft Defender. Furthermore, in machines/ you can attach the JSON output from the api/machines REST API endpoint of Microsoft Defender. Then, the parser uses the information in both folders to add more specific information like the affected IP Address to the finding. However, if you have a fast changing environment with a huge number of vulnerabilities and endpoints, it is recommended to leave the folder machines/ empty. Then, for stability reasons the machine info is skipped and only the machineID is added to the finding. Sample Scan Data Sample MS Defender Parser scans can be found here.\n","date":"0001-01-01","id":190,"permalink":"/en/connecting_your_tools/parsers/file/ms_defender/","summary":"This parser helps to parse Microsoft Defender Findings and supports two types of imports:\nYou can import a JSON output file from the api/vulnerabilities/machinesVulnerabilities endpoint of Microsoft defender.","tags":[],"title":"MS Defender Parser"},{"content":"Nancy output file (go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json) can be imported in JSON format.\nFile Types This parser expects a JSON file.\nCommand Used To Generate Output `go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json` Sample Scan Data Sample Nancy scans can be found here.\nLink To Tool See Nancy on GitHub: https://github.com/sonatype-nexus-community/nancy\n","date":"0001-01-01","id":191,"permalink":"/en/connecting_your_tools/parsers/file/nancy/","summary":"Nancy output file (go list -json -deps ./\u0026hellip; | nancy sleuth \u0026gt; nancy.json) can be imported in JSON format.\nFile Types This parser expects a JSON file.","tags":[],"title":"Nancy Scan"},{"content":"Netsparker has now become Invicti. Please plan to migrate automation scripts to use the Invicti Scan type.\nVulnerabilities List - JSON report\nSample Scan Data Sample Netsparker scans can be found here.\n","date":"0001-01-01","id":192,"permalink":"/en/connecting_your_tools/parsers/file/netsparker/","summary":"Netsparker has now become Invicti. Please plan to migrate automation scripts to use the Invicti Scan type.\nVulnerabilities List - JSON report","tags":[],"title":"Netsparker"},{"content":"Imports compliance scans returned by REST API.\nSample Scan Data Sample NeuVector (compliance) scans can be found here.\n","date":"0001-01-01","id":193,"permalink":"/en/connecting_your_tools/parsers/file/neuvector/","summary":"Imports compliance scans returned by REST API.\nSample Scan Data Sample NeuVector (compliance) scans can be found here.","tags":[],"title":"NeuVector (compliance)"},{"content":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample NeuVector (REST) scans can be found here.\n","date":"0001-01-01","id":194,"permalink":"/en/connecting_your_tools/parsers/file/neuvector_compliance/","summary":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample NeuVector (REST) scans can be found here.","tags":[],"title":"NeuVector (REST)"},{"content":"Use the full XML export template from Nexpose.\nSample Scan Data Sample Nexpose XML 2.0 (Rapid7) scans can be found here.\n","date":"0001-01-01","id":195,"permalink":"/en/connecting_your_tools/parsers/file/nexpose/","summary":"Use the full XML export template from Nexpose.\nSample Scan Data Sample Nexpose XML 2.0 (Rapid7) scans can be found here.","tags":[],"title":"Nexpose XML 2.0 (Rapid7)"},{"content":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\nXML output (old) new XML output (with nxvmlversion=\u0026quot;1.2\u0026quot; type) JSON output See: https://github.com/sullo/nikto\nSample Scan Data Sample Nikto scans can be found here.\n","date":"0001-01-01","id":196,"permalink":"/en/connecting_your_tools/parsers/file/nikto/","summary":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\nXML output (old) new XML output (with nxvmlversion=\u0026quot;1.2\u0026quot; type) JSON output See: https://github.","tags":[],"title":"Nikto"},{"content":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found here.\n","date":"0001-01-01","id":197,"permalink":"/en/connecting_your_tools/parsers/file/nmap/","summary":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found here.","tags":[],"title":"Nmap"},{"content":"Node Security Platform (NSP) output file can be imported in JSON format.\nSample Scan Data Sample Node Security Platform scans can be found here.\n","date":"0001-01-01","id":198,"permalink":"/en/connecting_your_tools/parsers/file/nsp/","summary":"Node Security Platform (NSP) output file can be imported in JSON format.\nSample Scan Data Sample Node Security Platform scans can be found here.","tags":[],"title":"Node Security Platform"},{"content":"Input Type: This parser takes JSON Lines Output from Nosey Parker: https://github.com/praetorian-inc/noseyparkerSupports\nSupports versions 0.16.0 and 0.22.0\nThings to note about the Nosey Parker Parser: All findings are marked with a severity of \u0026lsquo;High\u0026rsquo; The deduplication algorithm marks a unique finding by the secret, filepath, and line number all together The Nosey Parker tool allows for both full history scans of a repo and targeted branch scans The Parser does NOT differentiate between the 2 scan types (may be future functionality)\nFor full history scans:\nThe scan will pick up secrets committed in the past that have since been removed If a secret is removed from source code, it will still show up in the next scan When importing findings via the Dojo API, make sure to use the parameter do_not_reactivate which will keep existing findings closed, without reactivating them For targeted branch scans:\nKeep in mind there may be active secrets that are either in the git history or not in the current branch JSON Lines Format: The parser only accepts .jsonl reports. Each line of the JSON Lines file from NoseyParker corresponds to a unique secret found with metadata for every match.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":199,"permalink":"/en/connecting_your_tools/parsers/file/noseyparker/","summary":"Input Type: This parser takes JSON Lines Output from Nosey Parker: https://github.com/praetorian-inc/noseyparkerSupports\nSupports versions 0.16.0 and 0.22.0\nThings to note about the Nosey Parker Parser: All findings are marked with a severity of \u0026lsquo;High\u0026rsquo; The deduplication algorithm marks a unique finding by the secret, filepath, and line number all together The Nosey Parker tool allows for both full history scans of a repo and targeted branch scans The Parser does NOT differentiate between the 2 scan types (may be future functionality)","tags":[],"title":"Nosey Parker"},{"content":"Note: This parser only supports import from NPM Audit v6 or older.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'advisories' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v6 or older due to missing relevant fields, including:\nFinding created / updated dates Relevant CVE number Finding overview (description Field) Recommendation Issue reference CWE Exploitability See NPM\u0026rsquo;s issue on GitHub for more information. https://github.com/npm/npm-audit-report/issues/45\nAttempting to import a file from a later version of NPM Audit will raise an error message.\nSample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","date":"0001-01-01","id":200,"permalink":"/en/connecting_your_tools/parsers/file/npm_audit/","summary":"Note: This parser only supports import from NPM Audit v6 or older.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format.","tags":[],"title":"NPM Audit"},{"content":"Note: This parser only supports import from NPM Audit v7 or newer.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'vulnerabilities' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v7 or newer. It aims to provide the same information as the non-JSON formatted output.\nAttempting to import a file from a version less than 7 of NPM Audit will raise an error message.\nCommand Used To Generate Output Either of these commands will work:\n`npm audit \u0026ndash;json` `npm audit fix \u0026ndash;dry-run \u0026ndash;json` Sample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","date":"0001-01-01","id":201,"permalink":"/en/connecting_your_tools/parsers/file/npm_audit_7_plus/","summary":"Note: This parser only supports import from NPM Audit v7 or newer.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format.","tags":[],"title":"NPM Audit Version 7+"},{"content":"Import JSON output of nuclei scan report https://github.com/projectdiscovery/nuclei\nSample Scan Data Sample Nuclei scans can be found here.\n","date":"0001-01-01","id":202,"permalink":"/en/connecting_your_tools/parsers/file/nuclei/","summary":"Import JSON output of nuclei scan report https://github.com/projectdiscovery/nuclei\nSample Scan Data Sample Nuclei scans can be found here.","tags":[],"title":"Nuclei"},{"content":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data Sample Openscap Vulnerability Scan scans can be found here.\n","date":"0001-01-01","id":203,"permalink":"/en/connecting_your_tools/parsers/file/openscap/","summary":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data Sample Openscap Vulnerability Scan scans can be found here.","tags":[],"title":"Openscap Vulnerability Scan"},{"content":"You can either upload the exported results of an OpenVAS Scan in a .csv or .xml format.\nSample Scan Data Sample OpenVAS scans can be found here.\n","date":"0001-01-01","id":204,"permalink":"/en/connecting_your_tools/parsers/file/openvas/","summary":"You can either upload the exported results of an OpenVAS Scan in a .csv or .xml format.\nSample Scan Data Sample OpenVAS scans can be found here.","tags":[],"title":"OpenVAS Parser"},{"content":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample ORT evaluated model Importer scans can be found here.\n","date":"0001-01-01","id":205,"permalink":"/en/connecting_your_tools/parsers/file/ort/","summary":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample ORT evaluated model Importer scans can be found here.","tags":[],"title":"ORT evaluated model Importer"},{"content":"Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nSample Scan Data Sample OssIndex Devaudit scans can be found here.\n","date":"0001-01-01","id":206,"permalink":"/en/connecting_your_tools/parsers/file/ossindex_devaudit/","summary":"Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nSample Scan Data Sample OssIndex Devaudit scans can be found here.","tags":[],"title":"OssIndex Devaudit"},{"content":"Use OSV-Scanner to find existing vulnerabilities affecting your project\u0026rsquo;s dependencies.\nSample Scan Data Sample OSV Scanner output can be found here.\n","date":"0001-01-01","id":207,"permalink":"/en/connecting_your_tools/parsers/file/osv_scanner/","summary":"Use OSV-Scanner to find existing vulnerabilities affecting your project\u0026rsquo;s dependencies.\nSample Scan Data Sample OSV Scanner output can be found here.","tags":[],"title":"OSV Scanner"},{"content":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample Outpost24 Scan scans can be found here.\n","date":"0001-01-01","id":208,"permalink":"/en/connecting_your_tools/parsers/file/outpost24/","summary":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample Outpost24 Scan scans can be found here.","tags":[],"title":"Outpost24 Scan"},{"content":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data Sample PHP Security Audit v2 scans can be found here.\n","date":"0001-01-01","id":209,"permalink":"/en/connecting_your_tools/parsers/file/php_security_audit_v2/","summary":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data Sample PHP Security Audit v2 scans can be found here.","tags":[],"title":"PHP Security Audit v2"},{"content":"Import results from the PHP Symfony Security Checker.\nSample Scan Data Sample PHP Symfony Security Checker scans can be found here.\n","date":"0001-01-01","id":210,"permalink":"/en/connecting_your_tools/parsers/file/php_symfony_security_check/","summary":"Import results from the PHP Symfony Security Checker.\nSample Scan Data Sample PHP Symfony Security Checker scans can be found here.","tags":[],"title":"PHP Symfony Security Checker"},{"content":"Import pip-audit JSON scan report.\nFile Types This parser expects a JSON file.\nThe parser can handle legacy and current JSON format.\nThe current format has added a dependencies element:\n{ \u0026quot;dependencies\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;pyopenssl\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;23.1.0\u0026quot;, \u0026quot;vulns\u0026quot;: [] }, ... ] ... } The legacy format does not include the dependencies key:\n[ { \u0026quot;name\u0026quot;: \u0026quot;adal\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;1.2.2\u0026quot;, \u0026quot;vulns\u0026quot;: [] }, ... ] Sample Scan Data Sample pip-audit Scan scans can be found here.\nLink To Tool pip-audit\n","date":"0001-01-01","id":211,"permalink":"/en/connecting_your_tools/parsers/file/pip_audit/","summary":"Import pip-audit JSON scan report.\nFile Types This parser expects a JSON file.\nThe parser can handle legacy and current JSON format.","tags":[],"title":"pip-audit Scan"},{"content":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.\n","date":"0001-01-01","id":212,"permalink":"/en/connecting_your_tools/parsers/file/pmd/","summary":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.","tags":[],"title":"PMD Scan"},{"content":"Popeye Parser documentation. Popeye is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations. For more information about the tool, please visit the public repository https://github.com/derailed/popeye.\nPopeye reports. Popeye offer different format to export their reports, in this case for the parser we have selected to be done with JSON option for simplicity. Support for other report types planned for future.\nJSON reports have the following structure:\n{ \u0026#34;popeye\u0026#34;: { \u0026#34;score\u0026#34;: 100, \u0026#34;grade\u0026#34;: \u0026#34;B\u0026#34;, \u0026#34;sanitizers\u0026#34;: [ { \u0026#34;sanitizer\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;gvr\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;tally\u0026#34;: { \u0026#34;ok\u0026#34;: 1, \u0026#34;info\u0026#34;: 0, \u0026#34;warning\u0026#34;: 0, \u0026#34;error\u0026#34;: 0, \u0026#34;score\u0026#34;: 100 }, \u0026#34;issues\u0026#34;: { \u0026#34;Version\u0026#34;: [ { \u0026#34;group\u0026#34;: \u0026#34;__root__\u0026#34;, \u0026#34;gvr\u0026#34;: \u0026#34;cluster\u0026#34;, \u0026#34;level\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;[POP-406] K8s version OK\u0026#34; } ] } } ] } }\rThey offer a list of \u0026ldquo;sanitizers\u0026rdquo; that is the list of scanned resources in the cluster. At the same time, each sanitizer will have a list of issues, in this case the issues names will match to specific resources of the cluster (pods, roles, clusterroles, etc.) where each one will have inside a list of specific findings for that resource (issue in the report).\nThis parser goes through every finding inside the issues of every sanitizer looking for the ones with level 1 (Info), 2 (Warning) or 3 (Error) to be created as findings in DefectDojo.\nFindings severity matching. Popeye scan findings don\u0026rsquo;t match to public vulnerabilities, it just looks for possible informational topic, warnings or errors in kubernetes resources definition or configuraiton, so they categorize their findings the following way:\nSeverity 0: Ok Severity 1: Info Severity 2: Warning Severity 3: Error To match it to DefectDojo severity formula, Secerity 0 (Ok) findings from Popeye will be ignored as those are checks that does not need an action to be resolved. For the rest:\nSeverity 1 (Info) Popeye findings will be created as Severity \u0026ldquo;Info\u0026rdquo; findings in DefectDojo. Severity 2 (Warning) Popeye findings will be created as Severity \u0026ldquo;Low\u0026rdquo; findings in DefectDojo. Severity 3 (Errors) Popeye findings will be created as Severity \u0026ldquo;High\u0026rdquo; findingsi in DefectDojo. Sample Scan Data Sample Popeye scans can be found here.\n","date":"0001-01-01","id":213,"permalink":"/en/connecting_your_tools/parsers/file/popeye/","summary":"Popeye Parser documentation. Popeye is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations.","tags":[],"title":"Popeye"},{"content":"DefectDojo can calculate a grade for your Products based on the amount of Findings contained within. Grades are ranked from A - F.\nNote that only Active \u0026amp; Verified Findings contribute to a Product Grade - unverified Findings will not have an impact.\nProduct Grade Calculation Every Product Grade starts at 100 (with no Findings).\nGrade calculation starts by looking at the highest Severity level of a Finding in a Product, and reducing the Product Health to a base level.\nHighest Severity Level of a Finding Maximum Grade Critical 40 High 60 Medium 80 Low 95 Further points are then deducted from the Grade for each additional Finding:\nSeverity Level of an additional Finding Grade Reduced by Critical 5 High 3 Medium 2 Low 1 ","date":"0001-01-01","id":214,"permalink":"/en/working_with_findings/organizing_engagements_tests/product_health_grade/","summary":"DefectDojo can calculate a grade for your Products based on the amount of Findings contained within. Grades are ranked from A - F.","tags":[],"title":"Product Health Grade"},{"content":"This parser imports the Progpilot SAST JSON output. The scanner can be found here.\nSample Scan Data Sample Progpilot Parser scans can be found here.\n","date":"0001-01-01","id":215,"permalink":"/en/connecting_your_tools/parsers/file/progpilot/","summary":"This parser imports the Progpilot SAST JSON output. The scanner can be found here.\nSample Scan Data Sample Progpilot Parser scans can be found here.","tags":[],"title":"Progpilot"},{"content":"What is PTART? PTART is a Pentest and Security Auditing Reporting Tool developed by the Michelin CERT (https://github.com/certmichelin/PTART)\nImporting Reports Reports can be exported to JSON format from the PTART web UI, and imported into DefectDojo by using the \u0026ldquo;PTART Report\u0026rdquo; importer.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":216,"permalink":"/en/connecting_your_tools/parsers/file/ptart/","summary":"What is PTART? PTART is a Pentest and Security Auditing Reporting Tool developed by the Michelin CERT (https://github.com/certmichelin/PTART)\nImporting Reports Reports can be exported to JSON format from the PTART web UI, and imported into DefectDojo by using the \u0026ldquo;PTART Report\u0026rdquo; importer.","tags":[],"title":"PTART Reports"},{"content":" (Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON results generated by the pwn_sast Driver. This driver scans source code repositories for security anti-patterns that may result in vulnerability identification. More driver results coming soon\u0026hellip; Sample Scan Data Sample PWN Security Automation Framework scans can be found here.\n","date":"0001-01-01","id":217,"permalink":"/en/connecting_your_tools/parsers/file/pwn_sast/","summary":"(Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON results generated by the pwn_sast Driver. This driver scans source code repositories for security anti-patterns that may result in vulnerability identification.","tags":[],"title":"PWN Security Automation Framework"},{"content":"Qualys Hacker Guardian CSV export\nSample Scan Data Sample Qualys Scan scans can be found here.\n","date":"0001-01-01","id":218,"permalink":"/en/connecting_your_tools/parsers/file/qualys_hacker_guardian/","summary":"Qualys Hacker Guardian CSV export\nSample Scan Data Sample Qualys Scan scans can be found here.","tags":[],"title":"Qualys Hacker Guardian Scan"},{"content":"Qualys WebGUI output files can be imported in XML format.\nSample Scan Data Sample Qualys Infrastructure Scan (WebGUI XML) scans can be found here.\n","date":"0001-01-01","id":219,"permalink":"/en/connecting_your_tools/parsers/file/qualys_infrascan_webgui/","summary":"Qualys WebGUI output files can be imported in XML format.\nSample Scan Data Sample Qualys Infrastructure Scan (WebGUI XML) scans can be found here.","tags":[],"title":"Qualys Infrastructure Scan (WebGUI XML)"},{"content":"Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.\nA CSV formatted Qualys Scan Report can also be used. Ensure the following values are checked in the Scan Report Template config:\nCVSS Version = CVSSv3\nVulnerability Details Threat Impact Solution Patches and Workarounds Virtual Patches and Mitigating Controls Results Sample Scan Data Sample Qualys Scan scans can be found here.\n","date":"0001-01-01","id":220,"permalink":"/en/connecting_your_tools/parsers/file/qualys/","summary":"Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.","tags":[],"title":"Qualys Scan"},{"content":"Qualys WebScan output files can be imported in XML format.\nSample Scan Data Sample Qualys Webapp Scan scans can be found here.\n","date":"0001-01-01","id":221,"permalink":"/en/connecting_your_tools/parsers/file/qualys_webapp/","summary":"Qualys WebScan output files can be imported in XML format.\nSample Scan Data Sample Qualys Webapp Scan scans can be found here.","tags":[],"title":"Qualys Webapp Scan"},{"content":"Import JSON report of Rapplex - Web Application Security Scanner\nSample Scan Data Sample Rapplex scans can be found here.\n","date":"0001-01-01","id":222,"permalink":"/en/connecting_your_tools/parsers/file/rapplex/","summary":"Import JSON report of Rapplex - Web Application Security Scanner\nSample Scan Data Sample Rapplex scans can be found here.","tags":[],"title":"Rapplex Scan"},{"content":"You can import a JSON report which was retrieved through the REST API of Red Hat Satellite. The scanner can be found here.\nSample Scan Data Sample Red Hat Satellite scans can be found here.\n","date":"0001-01-01","id":223,"permalink":"/en/connecting_your_tools/parsers/file/redhatsatellite/","summary":"You can import a JSON report which was retrieved through the REST API of Red Hat Satellite. The scanner can be found here.","tags":[],"title":"Red Hat Satellite"},{"content":"Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nSample Scan Data Sample Retire.js scans can be found here.\n","date":"0001-01-01","id":224,"permalink":"/en/connecting_your_tools/parsers/file/retirejs/","summary":"Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nSample Scan Data Sample Retire.js scans can be found here.","tags":[],"title":"Retire.js"},{"content":"Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \u0026#34;url_endpoint\u0026#34;: \u0026#34;https://api.riskrecon.com/v1\u0026#34;, \u0026#34;api_key\u0026#34;: \u0026#34;you-api-key\u0026#34;, \u0026#34;companies\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Company 1\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [\u0026#34;127.0.0.1\u0026#34;], \u0026#34;host_name\u0026#34;: [\u0026#34;localhost\u0026#34;], \u0026#34;asset_value\u0026#34;: [], \u0026#34;severity\u0026#34;: [\u0026#34;critical\u0026#34;, \u0026#34;high\u0026#34;], \u0026#34;priority\u0026#34;: [], \u0026#34;hosting_provider\u0026#34;: [], \u0026#34;country_name\u0026#34;: [] } }, { \u0026#34;name\u0026#34;: \u0026#34;Company 2\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;ip_address\u0026#34;: [\u0026#34;0.0.0.0\u0026#34;] } } ], \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [], \u0026#34;host_name\u0026#34;: [], \u0026#34;asset_value\u0026#34;: [], \u0026#34;severity\u0026#34;: [\u0026#34;critical\u0026#34;], \u0026#34;priority\u0026#34;: [], \u0026#34;hosting_provider\u0026#34;: [], \u0026#34;country_name\u0026#34;: [] } } More than one company finding list can be queried with it's own set of filters. Company 1 shows all available fitlers, while Company 2 shows that empty filters need not be present. To query all companies in your Risk Recon instance, simple remove the \u0026quot;companies\u0026quot; field entirely. If the \u0026quot;companies\u0026quot; field is not present, and filtering is still requested, the \u0026quot;filters\u0026quot; field can be used to filter all findings across all companies. It carries the same behavior as the company filters. The \u0026quot;filters\u0026quot; field is disregarded in the prescense of the \u0026quot;companies\u0026quot; field. Removing both fields will allow retrieval of all findings in the Risk Recon instance. Sample Scan Data Sample Risk Recon API Importer scans can be found here.\n","date":"0001-01-01","id":225,"permalink":"/en/connecting_your_tools/parsers/file/risk_recon/","summary":"Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \u0026#34;url_endpoint\u0026#34;: \u0026#34;https://api.riskrecon.com/v1\u0026#34;, \u0026#34;api_key\u0026#34;: \u0026#34;you-api-key\u0026#34;, \u0026#34;companies\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Company 1\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;domain_name\u0026#34;: [], \u0026#34;ip_address\u0026#34;: [\u0026#34;127.","tags":[],"title":"Risk Recon API Importer"},{"content":"Import Rubocop JSON scan report (with option -f json).\nSample Scan Data Sample Rubocop Scan scans can be found here.\n","date":"0001-01-01","id":226,"permalink":"/en/connecting_your_tools/parsers/file/rubocop/","summary":"Import Rubocop JSON scan report (with option -f json).\nSample Scan Data Sample Rubocop Scan scans can be found here.","tags":[],"title":"Rubocop Scan"},{"content":"From: https://github.com/newrelic/rusty-hog Import the JSON output. Rusty Hog is a secret scanner built in Rust for performance, and based on TruffleHog which is written in Python.\nDefectDojo currently supports the parsing of the following Rusty Hog JSON outputs:\nChoctaw Hog: Scans for secrets in a Git repository. Duroc Hog: Scans for secrets in directories, files, and archives. Gottingen Hog: Scans for secrets in a JIRA issue. Essex Hog: Scans for secrets in a Confluence page. RustyHog scans only one target at a time. This is not efficient if you want to scan all targets (e.g. all JIRA tickets) and upload each single report to DefectDojo. Rusty-Hog-Wrapper deals with this and scans a whole JIRA Project or Confluence Space, merges the findings into a valid file which can be uploaded to DefectDojo. (This is no official recommendation from DefectDojo, but rather a pointer in a direction on how to use this vulnerability scanner in a more efficient way.)\nYou can either select \u0026ldquo;Rusty Hog Scan\u0026rdquo; directly, or specify the sub scanner (e.g. \u0026ldquo;Duroc Hog Scan\u0026rdquo;). If you choose \u0026ldquo;Rusty Hog Scan\u0026rdquo;, we recommend to re-import scans into the same test. For more information look at this issue.\nSample Scan Data Sample Rusty Hog parser scans can be found here.\n","date":"0001-01-01","id":227,"permalink":"/en/connecting_your_tools/parsers/file/rusty_hog/","summary":"From: https://github.com/newrelic/rusty-hog Import the JSON output. Rusty Hog is a secret scanner built in Rust for performance, and based on TruffleHog which is written in Python.","tags":[],"title":"Rusty Hog parser"},{"content":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif\nSARIF parser customizes the Test_Type with data from the report. For example, a report with Dockle as a driver name will produce a Test with a Test_Type named Dockle Scan (SARIF)\nCurrent implementation is limited and will aggregate all the findings in the SARIF file in one single report.\nSupport for de-duplication (fingerprinting) SARIF parser take into account data for fingerprinting. It\u0026rsquo;s base on fingerprints and partialFingerprints properties. It\u0026rsquo;s possible to activate de-duplication based on this data by customizing settings.\n# in your settings.py file DEDUPLICATION_ALGORITHM_PER_PARSER[\u0026#34;SARIF\u0026#34;] = DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE\rSample Scan Data Sample SARIF scans can be found here.\n","date":"0001-01-01","id":228,"permalink":"/en/connecting_your_tools/parsers/file/sarif/","summary":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif","tags":[],"title":"SARIF"},{"content":"Scantist is an open source management platform. Scan and remediate open source security, licensing and compliance risks across your software development lifecycle. Here you can find more information: https://scantist.com/\nSample Scan Data Sample Scantist Scan scans can be found here.\n","date":"0001-01-01","id":229,"permalink":"/en/connecting_your_tools/parsers/file/scantist/","summary":"Scantist is an open source management platform. Scan and remediate open source security, licensing and compliance risks across your software development lifecycle.","tags":[],"title":"Scantist Scan"},{"content":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects. See https://github.com/nccgroup/ScoutSuite\nSample Scan Data Sample ScoutSuite scans can be found here.\n","date":"0001-01-01","id":230,"permalink":"/en/connecting_your_tools/parsers/file/scout_suite/","summary":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects.","tags":[],"title":"ScoutSuite"},{"content":"Import Semgrep output (\u0026ndash;json)\nSample Scan Data Sample Semgrep JSON Report scans can be found here.\n","date":"0001-01-01","id":231,"permalink":"/en/connecting_your_tools/parsers/file/semgrep/","summary":"Import Semgrep output (\u0026ndash;json)\nSample Scan Data Sample Semgrep JSON Report scans can be found here.","tags":[],"title":"Semgrep JSON Report"},{"content":"Configure Personal notifications Personal Notifications are sent in addition to System-Wide Notifications, and will apply to any Product, Product Type or other data type that you have access to. Personal Notification preferences only apply to a single user, and can only be set on the account which is configuring them.\nSystem notifications are set by a DefectDojo Superuser and cannot be opted out of by an individual user.\nStart from the Notifications page (‚öôÔ∏èConfiguration \u0026gt; Notifications in the sidebar). From the Scope drop down menu, you can select which set of notifications you wish to edit. Select Personal Notifications. Check the notification method which you wish to use for each type of notification. You can select more than one. Personal Notifications cannot be sent via Microsoft Teams, as Teams only allows for posting Global notifications in a single channel.\nReceive Personal notifications for a specific Product In addition to standard personal notifications, DefectDojo Users can also receive notifications for activity on a specific Product. This is helpful when there are certain Products which a user needs to monitor more closely.\nThis configuration can be changed from the Notifications section on the Product page: e.g. your-instance.defectdojo.com/product/{id}.\nFrom here, you can set whether you want to receive üîî Alert, Mail or Slack notifications for actions taken on this particular Product. These notifications apply in addition to any system-wide notifications you are already receiving.\nMicrosoft Teams cannot send personal notifications of any kind, so Teams notifications cannot be chosen from this menu.\nPersonal email notifications will always be sent to the email associated with your DefectDojo login. To set up a personal Slack account to receive notifications, see our Guide.\n","date":"0001-01-01","id":232,"permalink":"/en/customize_dojo/notifications/configure_personal_notifs/","summary":"Configure Personal notifications Personal Notifications are sent in addition to System-Wide Notifications, and will apply to any Product, Product Type or other data type that you have access to.","tags":[],"title":"Set Personal Notifications"},{"content":"DefectDojo has two different kinds of notifications: Personal (sent to a single account) and System (which are sent to all users).\nBoth an account‚Äôs Personal Notifications and the global System Notifications can be configured from the same page: ‚öôÔ∏èConfiguration \u0026gt; Notifications in the sidebar.\nConfigure System notifications (Classic UI) You will need Superuser access to change System-wide notifications.\nStart from the Notifications page (‚öôÔ∏è Configuration \u0026gt; Notifications in the sidebar). From the Scope drop down menu, you can select which set of notifications you wish to edit. Select System Notifications. Check the notification delivery method which you wish to use for each type of notification. You can select more than one. To set destinations for system wide email notifications (Email, Slack or MS Teams), see our Guide.\nTemplate Notifications Superusers also have access to a \u0026ldquo;Template\u0026rdquo; form. The Template Form allows you to set the default Personal Notifications that are enabled for any new user.\nWhere System Notifications Are Sent System notifications will be sent to:\nthe single email address specified in System Settings (if enabled) any DefectDojo users with accounts and appropriate RBAC permissions the System-wide Slack or Teams account. As with any notification in DefectDojo, System Notifications will only be sent to users that have access to the relevant data. So even if Product Notifications are set up System-Wide, users will only receive notifications for the Products that they have access to view.\nThis restriction does not apply to System Notifications that are sent to a specific Email or Slack channel.\nSee our guide on Role-Based Access Control for more information on RBAC and setting permissions.\nHowever, the connected System Email, Slack and Teams accounts cannot apply RBAC as they are not associated with a specific DefectDojo user. All selected system-wide notifications will be sent to these locations, so you should ensure that these channels can only be accessed by specific people in your organization.\n","date":"0001-01-01","id":233,"permalink":"/en/customize_dojo/notifications/configure_system_notifs/","summary":"DefectDojo has two different kinds of notifications: Personal (sent to a single account) and System (which are sent to all users).","tags":[],"title":"Set System-Wide Notifications"},{"content":"You will need Superuser access to use the System Settings page, which is required to complete this process.\nNotifications can be pushed to Slack or Teams when certain events trigger in DefectDojo.\nSlack Notifications Setup DefectDojo can post Slack notifications in two different ways:\nSystem-wide notifications, which will be sent to a single Slack channel Personal notifications, which will only be sent to specific users. Here is an example of a Slack Notification sent from DefectDojo:\n‚Äã DefectDojo does not have a dedicated Slack app, but one can be easily created for your workspace by following this guide. A Slack app is required for both System and Personal notifications to be sent correctly.\nCreate a Slack application To set up a Slack connection to DefectDojo, you‚Äôll need to create a custom Slack app.\nBegin this process from the Slack Apps page: https://api.slack.com/apps. Click ‚ÄòCreate New App‚Äô. Select ‚ÄòFrom App Manifest‚Äô. Select your Slack workspace from the menu. Enter your App Manifest - you can copy and paste this JSON file, which includes all the permission settings required to allow the Slack integration to run.\n‚Äã { \u0026#34;_metadata\u0026#34;: { \u0026#34;major_version\u0026#34;: 1, \u0026#34;minor_version\u0026#34;: 1 }, \u0026#34;display_information\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;DefectDojo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Notifications from DefectDojo. See https://docs.defectdojo.com/en/notifications/configure-a-slack-integration/ for configuration steps.\u0026#34;, \u0026#34;background_color\u0026#34;: \u0026#34;#0000AA\u0026#34; }, \u0026#34;features\u0026#34;: { \u0026#34;bot_user\u0026#34;: { \u0026#34;display_name\u0026#34;: \u0026#34;DefectDojo Notifications\u0026#34; } }, \u0026#34;oauth_config\u0026#34;: { \u0026#34;scopes\u0026#34;: { \u0026#34;bot\u0026#34;: [ \u0026#34;chat:write\u0026#34;, \u0026#34;chat:write.customize\u0026#34;, \u0026#34;chat:write.public\u0026#34;, \u0026#34;incoming-webhook\u0026#34;, \u0026#34;users:read\u0026#34;, \u0026#34;users:read.email\u0026#34; ] }, \u0026#34;redirect_urls\u0026#34;: [ \u0026#34;https://slack.com/oauth/v2/authorize\u0026#34; ] } }\rReview the App Summary, and click Create App when you‚Äôre done. Complete the installation by clicking the Install To Workplace button.\nConfigure your Slack integration in DefectDojo You‚Äôll now need to configure the Slack integration on DefectDojo to complete the integration.\nYou will need Superuser access to access DefectDojo\u0026rsquo;s System Settings page.\nNavigate to the App Information page for your Slack App, from https://api.slack.com/apps. This will be the app that was created in the first section - Create a Slack application.\n‚Äã Find your OAuth Access Token. This can be found in the Slack sidebar - Features / OAuth \u0026amp; Permissions. Copy the Bot User OAuth Token.\n‚Äã Open DefectDojo in a new tab, and navigate to Configuration \u0026gt; System Settings from the sidebar. (In the Beta UI, this form is located under Enterprise Settings \u0026gt; System Settings.) Check the Enable Slack notifications box. Paste the Bot User OAuth Token from Step 1 in the Slack token field. The Slack Channel field should correspond to the channel in your workspace where you want your notifications to be written by a DefectDojo bot. If you want to change the name of the DefectDojo bot, you can enter a custom name here. If not, it will use DefectDojo Notifications as determined in the Slack App Manifest. Once this process is complete, DefectDojo can send System-wide notifications to this channel. Select the Notifications which you want to send from the System Notifications page.\nNotes on System-Wide Notifications in Slack: Slack cannot apply any RBAC rules to the Slack channel that you are creating, and will therefore be sharing notifications for the entire DefectDojo system. There is no method in DefectDojo to filter system-wide Slack notifications to a Product Type, Product or Engagement.\nIf you want to apply RBAC-based filtering to your Slack messages, enabling personal notifications from Slack is a better option.\nSend Personal notifications to Slack If your team has a Slack integration enabled (through the above process), individual users can also configure notifications to send directly to your personal Slackbot channel.\nStart by navigating to your personal Profile page on DefectDojo. Find this by clicking the üë§ icon in the top-right corner. Select your DefectDojo Username from the list. (üë§ paul in our example)\n‚Äã Set your Slack Email Address in the menu. This field is nested underneath Additional Contact Information in DefectDojo.\nYou can now set specific notifications to be sent to your personal Slackbot channel. Other users on your Slack channel will not receive these messages.\nMicrosoft Teams Notifications Setup Microsoft Teams can receive notifications to a specific channel. To do this, you will need to set up an incoming webhook on the channel where you wish to receive messages.\nComplete the process listed in the Microsoft Teams Documentation for creating a new Incoming Webhook. Keep your unique webhook.office.com link handy as you will need it in subsequent steps.\n‚Äã In DefectDojo, navigate to Configuration \u0026gt; System Settings from the sidebar. (In the Beta UI, this form is located under Enterprise Settings \u0026gt; System Settings.) Check the Enable Microsoft Teams notifications box. This will open a hidden section of the form, labeled ‚ÄòMsteams url‚Äô.\n‚Äã Paste the webhook.office.com URL (created in Step 1) in the Msteams url box. Your Teams app will now listen to incoming Notifications from DefectDojo and post them to the channel you selected. Notes on the Teams integration Slack cannot apply any RBAC rules to the Teams channel that you are creating, and will therefore be sharing notifications for the entire DefectDojo system. There is no method in DefectDojo to filter system-wide Teams notifications by a Product Type, Product or Engagement. DefectDojo cannot send personal notifications to users on Microsoft Teams. System-Wide Email Notifications Setup Notifications from DefectDojo can also be sent to a specific email address.\nFrom the System Settings page (Configuration \u0026gt; System Settings in the Classic UI, or Enterprise Settings \u0026gt; System Settings in the Beta UI) navigate to Enable Mail (email) Notifications.\nCheck the Enable mail notifications box, and then enter the email address where you want these notifications to be sent (mail notifications to).\nNote that DefectDojo cannot apply RBAC filtering to these emails - they will be sent for all activity in DefectDojo. If you prefer to send a more customized set of email notifications, it is better to set up Personal Notifications with a user or service account that is linked to the appropriate address.\n","date":"0001-01-01","id":234,"permalink":"/en/customize_dojo/notifications/email_slack_teams/","summary":"You will need Superuser access to use the System Settings page, which is required to complete this process.\nNotifications can be pushed to Slack or Teams when certain events trigger in DefectDojo.","tags":[],"title":"Set up Email, Slack or Teams notifications"},{"content":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan scans can be found here.\n","date":"0001-01-01","id":235,"permalink":"/en/connecting_your_tools/parsers/file/skf/","summary":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan scans can be found here.","tags":[],"title":"SKF Scan"},{"content":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk scans can be found here.\n","date":"0001-01-01","id":236,"permalink":"/en/connecting_your_tools/parsers/file/snyk/","summary":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).","tags":[],"title":"Snyk"},{"content":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk Code scans can be found here.\n","date":"0001-01-01","id":237,"permalink":"/en/connecting_your_tools/parsers/file/snyk_code/","summary":"Snyk output file (snyk test --json \u0026gt; snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).","tags":[],"title":"Snyk Code"},{"content":"Solar Appscreener report file can be imported in CSV format from Detailed_Results.csv\nSample Scan Data Sample Solar Appscreener Scan scans can be found here.\n","date":"0001-01-01","id":238,"permalink":"/en/connecting_your_tools/parsers/file/solar_appscreener/","summary":"Solar Appscreener report file can be imported in CSV format from Detailed_Results.csv\nSample Scan Data Sample Solar Appscreener Scan scans can be found here.","tags":[],"title":"Solar Appscreener Scan"},{"content":"SonarQube Scan There are two ways to retrieve findings from SonarQube. You can either use the soprasteria package or the SonarQube REST API directly. Both ways (SonarQube REST API and Soprasteria) are depicted below.\nSample Scan Data Sample SonarQube scans can be found here.\nSonarQube REST API You can retrieve the JSON directly from SonarQube if you use one of the following REST API endpoint:\n\u0026lt;sonarqubeurl\u0026gt;/api/issues/search?projects=\u0026lt;projectkey\u0026gt; \u0026lt;sonarqubeurl\u0026gt;/api/hotspots/search?projectKey=\u0026lt;projectkey\u0026gt; JSON The REST API JSON output can be uploaded to DefectDojo with \u0026ldquo;SonarQube Scan\u0026rdquo;.\nZIP If you have too many findings in one project, you can implement a small script to handle pagination and put all JSON files in a .zip file. This zip file can also be parsed from DefectDojo with \u0026ldquo;SonarQube Scan\u0026rdquo;.\nSoprasteria Soprasteria SonarQube Scan (Aggregates findings per cwe, title, description, file_path.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u0026gt;= 1.1.0 Recommend version for both format \u0026gt;= 3.1.2\nSoprasteria SonarQube Scan Detailed (Import all findings from SonarQube html report.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u0026gt;= 1.1.0. Recommend version for both format \u0026gt;= 3.1.2\n","date":"0001-01-01","id":239,"permalink":"/en/connecting_your_tools/parsers/file/sonarqube/","summary":"SonarQube Scan There are two ways to retrieve findings from SonarQube. You can either use the soprasteria package or the SonarQube REST API directly.","tags":[],"title":"SonarQube"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to \u0026ldquo;SonarQube\u0026rdquo; and Authentication Type \u0026ldquo;API Key\u0026rdquo;. Note the url must be in the format of https://\u0026lt;sonarqube_host\u0026gt;/api Paste your SonarQube API token in the \u0026ldquo;API Key\u0026rdquo; field. By default the tool will import vulnerabilities issues and security hotspots only, but additional filters can be setup using the Extras field separated by commas (e.g. BUG,VULNERABILITY,CODE_SMELL). When using SonarCloud, you must also specify the Organization ID in the Extras field as follows OrgID=sonarcloud-organzation-ID. If also specifying issue type filters, please seperate the items in the Extras field by a vertical bar as follows BUG,VULNERABILITY,CODE_SMELL|OrgID=sonarcloud-organzation-ID\nIn \u0026ldquo;Add API Scan Configuration\u0026rdquo;\nService key 1 must be the SonarQube project key, which can be found by navigating to a specific project and selecting the value from the url https://\u0026lt;sonarqube_host\u0026gt;/dashboard?id=key. When you do not provide a SonarQube project key, DefectDojo will use the name of the Product as the project key in SonarQube. If you would like to import findings from multiple projects, you can specify multiple keys as separated API Scan Configuration in the Product settings. If using SonarCloud, the orginization ID can be used from step 1, but it can be overiden by supplying a different orginization ID in the Service key 2 input field. Multiple SonarQube API Configurations In the import or re-import dialog you can select which API Scan Configuration shall be used. If you do not choose any, DefectDojo will use the API Scan Configuration of the Product if there is only one defined or the SonarQube Tool Configuration if there is only one.\nMulti Branch Scanning If using a version of SonarQube with multi branch scanning, the branch tha be scanned can be supplied in the branch_tag fieild at import/re-import time. If the branch does not exist, a notification will be generated in the alerts table indicating that branch to be imported does not exist. If a branch name is not supplied during import/re-import, the default branch of the SonarQube project will be used.\nNote:: If https is used for the SonarQube, the certificate must be trusted by the DefectDojo instance.\n","date":"0001-01-01","id":240,"permalink":"/en/connecting_your_tools/parsers/api/sonarqube/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"SonarQube API Import"},{"content":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here.\n","date":"0001-01-01","id":241,"permalink":"/en/connecting_your_tools/parsers/file/sonatype/","summary":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here.","tags":[],"title":"Sonatype"},{"content":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can be found here.\n","date":"0001-01-01","id":242,"permalink":"/en/connecting_your_tools/parsers/file/spotbugs/","summary":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can be found here.","tags":[],"title":"SpotBugs"},{"content":"Import JSON output of ssh_audit report. See https://github.com/jtesta/ssh-audit\nSample Scan Data Sample SSH Audit scans can be found here.\n","date":"0001-01-01","id":243,"permalink":"/en/connecting_your_tools/parsers/file/ssh_audit/","summary":"Import JSON output of ssh_audit report. See https://github.com/jtesta/ssh-audit\nSample Scan Data Sample SSH Audit scans can be found here.","tags":[],"title":"SSH Audit"},{"content":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs scans can be found here.\n","date":"0001-01-01","id":244,"permalink":"/en/connecting_your_tools/parsers/file/ssl_labs/","summary":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs scans can be found here.","tags":[],"title":"SSL Labs"},{"content":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan scans can be found here.\n","date":"0001-01-01","id":245,"permalink":"/en/connecting_your_tools/parsers/file/sslscan/","summary":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan scans can be found here.","tags":[],"title":"Sslscan"},{"content":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan\nSample Scan Data Sample Sslyze Scan scans can be found here.\n","date":"0001-01-01","id":246,"permalink":"/en/connecting_your_tools/parsers/file/sslyze/","summary":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan","tags":[],"title":"Sslyze Scan"},{"content":"Users can connect to DefectDojo with a Username and Password, but if you prefer, you can allow users to authenticate using a Single Sign-On or SSO method. You can set up DefectDojo to work with your own SAML Identity Provider, but we also support many OAuth methods for authentication:\nAuth0 Azure Active Directory (Azure AD) GitHub Enterprise GitLab Google KeyCloak Okta All of these methods can only be configured by a Superuser in DefectDojo. DefectDojo Pro users can quickly set up SSO through their system settings, while Open Source users will need to configure these settings on the back-end by setting an environment variable within Docker. This article covers both methods of configuration.\nDisable username / password use You may wish to disable traditional username/password login on your instance.\nDefectDojo Pro users can uncheck the \u0026ldquo;Allow Login via Username and Password\u0026rdquo; box on the Login Settings form: Enterprise Settings \u0026gt; Login Settings.\nOpen-Source users can set environment variables in Docker to disable the Login form:\nDD_SOCIAL_LOGIN_AUTO_REDIRECT: \u0026#34;true\u0026#34; DD_SOCIAL_AUTH_SHOW_LOGIN_FORM: \u0026#34;false\u0026#34;\r‚ö†Ô∏è Login Fallback In case your OAuth or SAML integration stops working, you can always return to the standard login method by adding the following to your DefectDojo URL:\nyour-instance.cloud.defectdojo.com + /login?force_login_form We recommend having at least one DefectDojo admin set up with a username and password as a fallback. ‚Äã\nAuth0 Setup Both DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nInside your Auth0 dashboard, create a new application (Applications / Create Application / Single Page Web Application).\nOn the new application set the following fields:\nName: \u0026ldquo;Defectdojo\u0026rdquo; Allowed Callback URLs: https://your-instance.cloud.defectdojo.com/complete/auth0/ Copy the following info from the application:\nDomain Client ID Client Secret Pro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select Auth0, and use these values from Auth0 to complete the form:\nAuth0 OAuth Key: enter your Client ID Auth0 OAuth Secret: enter your Client Secret Auth0 Domain: enter your Domain. Check the box for \u0026lsquo;Enable Auth0 OAuth\u0026rsquo; to add the \u0026ldquo;Login With Auth0\u0026rdquo; button to the DefectDojo login page.\nOpen-Source Open-Source users will need to map these variables in the local_settings.py file. (see Configuration).\nFill out the variables as follows: DD_SOCIAL_AUTH_AUTH0_OAUTH2_ENABLED=True DD_SOCIAL_AUTH_AUTH0_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_AUTH0_SECRET=(str,\u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_AUTH0_DOMAIN=(str, \u0026#39;**YOUR_AUTH0_DOMAIN_FROM_STEP_ABOVE**\u0026#39;),\nRestart DefectDojo, and you should now see a Login with Auth0 button on the login page.\nAzure Active Directory Setup Users can log in to DefectDojo via Azure AD. DefectDojo can leverage Azure AD Groups to automatically import User Group membership.\nBoth DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nNavigate to the following address and follow instructions to create a new app registration\nhttps://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app Once you register an app, take note of the following information:\nApplication (client) ID Directory (tenant) ID Under Certificates \u0026amp; Secrets, create a new Client Secret Application ID URI Under Authentication \u0026gt; Redirect URIs, add a WEB type of uri where the redirect points to: https://your-instance.cloud.defectdojo.com/complete/azuread-tenant-oauth2/\nPro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select Azure AD, and use these values from Azure to complete the form:\nAzure AD OAuth Key: enter your Application (client) ID Azure AD OAuth Secret: enter the Client Secret which was created in step 2 Azure AD Resource: by default this should be set to https://graph.microsoft.com/. This should be set a the URI which DefectDojo can use to pull additional info (such as Azure AD Group names) from the web API. This field only needs to be changed if your Group Names are stored on a different API resource from the Microsoft Graph Web API. Azure AD Tenant ID: enter the Directory (tenant) ID Azure AD Groups Filter: here, you can enter a regex string to restrict the User Groups you wish to import. Check the Enable Azure AD OAuth box. Submit the form, and Login With Azure AD will be added as an option to the Login menu.\nPro Azure Group Mapping Group synchronization allows you to import User Group membership from Azure AD. DefectDojo\u0026rsquo;s User Groups govern the Products and Product Types a given user can access via RBAC.\nTo import groups from Azure AD users, you can check the Enable Azure AD OAuth Grouping box on the form. All User Groups found in Azure will be matched with an existing User Group in DefectDojo. If an imported Azure User Group is missing from DefectDojo, a new User Group will be created automatically.\nIf you only want to import a subset of Groups from Azure, you can use regex in the Azure AD Groups Filter field. For example, '^team-.*' and 'teamA|teamB|groupC' are regex strings that can be used to restrict the Groups that will be imported to DefectDojo. Regex is used to filter out Group Names.\nSending Groups from Azure AD The Azure AD token need to be configured to include Group IDs. Without this step, the token will not contain any notion of a Group, so users will not be mapped correctly in DefectDojo.\nTo update the format of the token, add a Group Claim that applies to whatever Group type you are using. If unsure of what type that is, select All Groups. Do not activate Emit groups as role claims within the Azure AD \u0026ldquo;Token configuration\u0026rdquo; page.\nApplication API permissions need to be updated with the Group.Read.All permission so that groups can be read on behalf of the user that has successfully signed in.\nGroup Cleaning If Enable Azure AD OAuth Group Cleaning is enabled, groups created by Azure AD in DefectDojo will be automatically removed if they contain no users. Otherwise, Azure-created Groups will be left as-is, even without assigned Users.\nWhen a user is removed from a given group in Azure AD, they will also be removed from the corresponding group in DefectDojo.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_KEY=(str, \u0026#39;YOUR_APPLICATION_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_SECRET=(str, \u0026#39;YOUR_CLIENT_SECRET_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_TENANT_ID=(str, \u0026#39;YOUR_DIRECTORY_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_ENABLED = True Restart DefectDojo, and you should now see a Login with Azure AD button on the login page.\nOpen-Source Azure Group Mapping To import groups from Azure AD users, the following environment variable needs to be set:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS=True This will ensure the user is added to all the groups found in the Azure AD Token. Any missing groups will be created in DefectDojo (unless filtered). This group synchronization allows for product access via groups to limit the products a user can interact with.\nThe Azure AD token returned by Azure will also need to be configured to include group IDs. Without this step, the token will not contain any notion of a group, and the mapping process will report that the current user is not a member of any groups. To update the format of the token, add a group claim that applies to whatever group type you are using.\nIf unsure of what type that is, select All Groups. Do not activate Emit groups as role claims within the Azure AD \u0026ldquo;Token configuration\u0026rdquo; page.\nApplication API permissions need to be updated with the Group.Read.All permission so that groups can be read on behalf of the user that has successfully signed in.\nTo limit the amount of groups imported from Azure AD, a regular expression can be used as the following:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GROUPS_FILTER=\u0026#39;^team-.*\u0026#39; # or \u0026#39;teamA|teamB|groupC\u0026#39; Automatic Cleanup of User-Groups To prevent authorization creep, old Azure AD groups a user is not having anymore can be deleted with the following environment parameter:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS=True When a user is removed from a given group in Azure AD, they will also be removed from the corresponding group in DefectDojo. If there is a group in DefectDojo, that no longer has any members, it will be left as is for record purposes.\nGitHub Enterprise Both DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nNavigate to your GitHub Enterprise Server and follow instructions to create a new OAuth App https://docs.github.com/en/enterprise-server/developers/apps/building-oauth-apps/creating-an-oauth-app\nChoose a name for your application, e.g. \u0026ldquo;DefectDojo\u0026rdquo;.\nFor the Redirect URI, enter the DefectDojo URL with the following format\nhttps://the_hostname_you_have_dojo_deployed:your_server_port/complete/github-enterprise/ Pro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select GitHub Enterprise, and use these values from GitHub to complete the form:\nGitHub Enterprise OAuth Key: enter your GitHub Enterprise OAuth App Client ID GitHub Enterprise OAuth Secret: enter your GitHub Enterprise Client Secret GitHub Enterprise URL: enter the GitHub URL for your organization, likely https://github.\u0026lt;your_company\u0026gt;.com/ GitHub Enterprise API URL: enter the URL for your organization\u0026rsquo;s GitHub API (e.g. https://github.\u0026lt;your_company\u0026gt;.com/api/v3/) Check off the box for \u0026lsquo;Enable GitHub Enterprise OAuth\u0026rsquo;. Submit the form, and \u0026lsquo;Login With GitHub\u0026rsquo; should now be visible on the login page.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_KEY=(str, \u0026#39;GitHub Enterprise OAuth App Client ID\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_SECRET=(str, \u0026#39;GitHub Enterprise OAuth App Client Secret\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_URL=(str, \u0026#39;https://github.\u0026lt;your_company\u0026gt;.com/\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_API_URL=(str, \u0026#39;https://github.\u0026lt;your_company\u0026gt;.com/api/v3/\u0026#39;), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_OAUTH2_ENABLED = True,\nRestart DefectDojo, and you should now see a Login with GitHub Enterprise button on the login page.\nGitLab In a similar fashion to that of Google and Okta, using GitLab as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\nNavigate to your GitLab settings page and got to the Applications section\nhttps://gitlab.com/profile/applications OR https://the_hostname_you_have_gitlab_deployed:your_gitlab_port/profile/applications Choose a name for your application, \u0026ldquo;DefectDojo\u0026rdquo; for example.\nFor the Redirect URI, enter your DefectDojo URL as follows:\nhttps://your-dojo-instance.cloud.defectdojo.com/complete/gitlab/ Pro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select GitLab, and use these values from GitLab to complete the form:\nGitLab OAuth Key: enter your Application ID from GitLab GitLab OAuth Secret: enter the Secret from GitLab GitLab API URL: enter the URL for your GitLab deployment (e.g. https://gitlab.com) Check the \u0026lsquo;Enable GitLab OAuth\u0026rsquo; box, and submit the form. Login With GitLab will be added as an option to the Login menu.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables DD_SOCIAL_AUTH_GITLAB_KEY=(str, \u0026#39;YOUR_APPLICATION_ID_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_GITLAB_SECRET=(str, \u0026#39;YOUR_SECRET_FROM_STEP_ABOVE\u0026#39;), DD_SOCIAL_AUTH_GITLAB_API_URL=(str, \u0026#39;https://gitlab.com\u0026#39;), DD_SOCIAL_AUTH_GITLAB_OAUTH2_ENABLED = True\nAdditionally, if you want to import your Gitlab projects as DefectDojo products, add the following line to your settings:\nDD_SOCIAL_AUTH_GITLAB_PROJECT_AUTO_IMPORT = True Important: if you enable this setting on already working instance with a GitLab integrations, it will require new grant \u0026ldquo;read_repository\u0026rdquo; by user\nRestart DefectDojo, and you should now see a Login with Gitlab button on the login page.\nGoogle Auth Google accounts can be used for user creation and login.\nUpon login with a Google account, a new user will be created if one does not already exist. Existing DefectDojo users will be matched to Google accounts based on their Google username (the name prior to the @ symbol on their Google Account).\nIn order to use Google Authentication, a Google Authentication Server will need to be set up. Both DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nNavigate to the following address and either create a new account, or login with an existing one: Google Developers Console\nOnce logged in, find the key shaped button labeled Credentials on the left side of the screen. Click Create Credentials, and choose OAuth Client ID:\nSelect Web Applications, and provide a descriptive name for the client (such as \u0026ldquo;DefectDojo\u0026rdquo;).\nEnter https://your-instance.cloud.defectdojo.com/complete/google-oauth2/ in the Authorized Redirect URLs section.\nNow with the authentication client created, note the Client ID and Client Secret Key.\nPro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select Google, and use these values to complete the form:\nGoogle OAuth Key should be set to your Client ID. Google OAuth Secret should be set to your Client Secret Key. Whitelisted Domains can be set to the domain name used by your organization. However, this will allow login from any user with this domain name in their Google email address. Alternatively, if you only want to allow specific Google email addresses to log in to DefectDojo, you can enter those in the Whitelisted E-mail Addresses section of the form. (appsecuser1@xyz.com,appsecuser2@xyz.com), etc. Check the Enable Azure AD OAuth box. Submit the form, and Login With Google will be added as an option to the Login menu.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_GOOGLE_OAUTH2_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET=(str, \u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), To authorize users you will need to set the following:\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS = [\u0026#39;example.com\u0026#39;, \u0026#39;example.org\u0026#39;] As an environment variable: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS = example.com,example.org or DD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS = [\u0026#39;\u0026lt;email@example.com\u0026gt;\u0026#39;] As an environment variable: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS = email@example.com,email2@example.com Restart DefectDojo, and Login With Google will be added as an option to the Login menu. KeyCloak Both DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nThis guide assumes you already have a KeyCloak Realm set up. If not, you will need to create one: see KeyCloak Documentation.\nNavigate to your keycloak realm and add a new client of type openid-connect. Choose a name for the client id.\nIn the client settings:\nSet access type to confidential Under valid Redirect URIs, add the URI to your DefectDojo installation, e.g.https://yourorganization.cloud.defectdojo.com or https://\u0026lt;YOUR_DD_HOST\u0026gt;/* Under web origins, add the same (or \u0026lsquo;+\u0026rsquo;) Under Fine grained openID connect configuration -\u0026gt; user info signed response algorithm: set to RS256 Under Fine grained openID connect configuration -\u0026gt; request object signature algorithm: set to RS256 -\u0026gt; save these settings in keycloak (hit save button) Under Scope -\u0026gt; Full Scope Allowed set to off.\nUnder mappers -\u0026gt; add a custom mapper here:\nName: aud Mapper type: audience Included audience: select your client/client-id here Add ID to token: off Add access to token: on Under credentials: copy the value of the secret.\nIn your realm settings -\u0026gt; keys: copy the \u0026ldquo;Public Key\u0026rdquo; (signing key).\nIn your realm settings -\u0026gt; general -\u0026gt; endpoints: look into openId endpoint configuration and copy the values of your Authorization and Token endpoints.\nPro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select KeyCloak, and use these values to complete the form:\nKeyCloak OAuth Key: Enter your client name (from step 1) KeyCloak OAuth Secret: Enter the your client credentials secret (from step 5) KeyCloak Public Key: Enter the Public Key from your realm settings (from step 6) KeyCloak Resource: Enter the Authorization Endpoint URL (from step 7) KeyCloak Group Limiter: Enter the Token Endpoint URL (from step 7) KeyCloak OAuth Login Button Text Choose the text you want to use for the DefectDojo login button. Check the \u0026lsquo;Enable KeyCloak OAuth\u0026rsquo; button, and submit the form. A login button should now be visible on the login page with the text you have set.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables DD_SESSION_COOKIE_SECURE=True, DD_CSRF_COOKIE_SECURE=True, DD_SECURE_SSL_REDIRECT=True, DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY=(str, \u0026#39;\u0026lt;your realm public key\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_KEY=(str, \u0026#39;\u0026lt;your client id\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_SECRET=(str, \u0026#39;\u0026lt;your keycloak client credentials secret\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL=(str, \u0026#39;\u0026lt;your authorization endpoint\u0026gt;\u0026#39;), DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL=(str, \u0026#39;\u0026lt;your token endpoint\u0026gt;\u0026#39;) or, alternatively, for helm configuration, add this to the extraConfig section:\nDD_SESSION_COOKIE_SECURE: \u0026#39;True\u0026#39; DD_CSRF_COOKIE_SECURE: \u0026#39;True\u0026#39; DD_SECURE_SSL_REDIRECT: \u0026#39;True\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED: \u0026#39;True\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY: \u0026#39;\u0026lt;your realm public key\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_KEY: \u0026#39;\u0026lt;your client id\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_SECRET: \u0026#39;\u0026lt;your keycloak client credentials secret\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL: \u0026#39;\u0026lt;your authorization endpoint\u0026gt;\u0026#39; DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL: \u0026#39;\u0026lt;your token endpoint\u0026gt;\u0026#39;\rOptionally, you can set DD_SOCIAL_AUTH_KEYCLOAK_LOGIN_BUTTON_TEXT in order to customize the login button\u0026rsquo;s text caption.\nRestart DefectDojo, and Login With ____ (your login button text) will be added as an option to the Login menu. Okta In a similar fashion to that of Google, using Okta as a OAuth2 provider carries the same attributes and a similar procedure.\nBoth DefectDojo Pro and Open-Source users will need to complete these steps to create an integration:\nNavigate to the following address and either create a new account, or login with an existing one: Okta Account Creation\nOnce logged in, enter the Applications and click Add Application:\nSelect Web Applications.\nAdd the pictured URLs in the Login Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access. Check the Implicit box as well.\nOnce all URLs are added, finish by clicking Done.\nReturn to the Dashboard to find the Org-URL. Note this value as it will be important when configuring DefectDojo.\nNow, with the authentication client created, the Client ID and Client Secret Key need to be copied over to the settings. Click the newly created client and copy the values:\nPro Configuration DefectDojo Pro users can set up this integration from the OAuth Settings page, which is nested under Enterprise Settings.\nIn DefectDojo\u0026rsquo;s OAuth Settings page, select Okta, and use these values to complete the form:\nOkta OAuth Key: set this to your Client ID from step 7 above. Okta OAuth Secret: set this to your Client Secret from step 7 above. Okta Tenant ID: set this to your Okta Org-URL: https://{your-org-url}/oauth2 for example Check the \u0026lsquo;Enable Okta OAuth\u0026rsquo; button, and submit the form. A \u0026lsquo;Login With Okta\u0026rsquo; button should now be visible on the DefectDojo login screen.\nOpen-Source Open-Source users will need to set these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nSet the following environment variables\nDD_SOCIAL_AUTH_OKTA_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_OKTA_OAUTH2_KEY=(str, \u0026#39;**YOUR_CLIENT_ID_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_OKTA_OAUTH2_SECRET=(str, \u0026#39;**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**\u0026#39;), DD_SOCIAL_AUTH_OKTA_OAUTH2_API_URL=(str, \u0026#39;https://{your-org-url}/oauth2\u0026#39;), If during the login process you get the following error: The \u0026lsquo;redirect_uri\u0026rsquo; parameter must be an absolute URI that is whitelisted in the client app settings. and the redirect_uri HTTP GET parameter starts with http:// instead of https:// you need to add SOCIAL_AUTH_REDIRECT_IS_HTTPS = True to Docker environment variables, or to your local_settings.py file.\nRestart DefectDojo, and \u0026lsquo;Login With Okta\u0026rsquo; should appear on the login screen. SAML Configuration DefectDojo Pro users can follow this guide to set up a SAML configuration using the DefectDojo UI. Open-Source users can set up SAML via environment variables, using the following guide.\nOpen the SAML Settings page to view the SAML form. This page is located under the Enterprise Settings option on the sidebar. Complete the SAML form. Start by setting an Entity ID - this is either a label or a URL which your SAML Identity Provider can point to, and use to identify DefectDojo. This is a required field. ‚Äã If you wish, set Login Button Text in DefectDojo. This text will appear on the button or link users click to initiate the login process. ‚Äã You can also set a Logout URL to redirect your users to once they have logged out of DefectDojo. ‚Äã The Name ID Format has four options: Persistent, Transient, Entity and Encrypted. ‚Äã If you would prefer that users have a different SAML ID each time they access DefectDojo, choose Transient. If you want your users to be consistently identified by SAML, use Persistent. If you‚Äôre ok with all of your users sharing a SAML NameID, you can select Entity. If you would like to encrypt each user‚Äôs NameID, you can use Encrypted as your NameID format. ‚Äã Required Attributes are the attributes that DefectDojo requires from the SAML response. ‚Äã Attribute Mapping contains a formula for how you want these attributes to be matched to a user. For example, if your SAML response returns an email, you can associate it with a DefectDojo user with the formula email=email. ‚Äã The left side of the ‚Äò=‚Äô sign represents the attribute you want to map from the SAML response. The right side is a user‚Äôs field in DefectDojo, which you want this attribute to map to. ‚Äã Remote SAML Metadata is the URL where your SAML Identity Provider is located. ‚Äã Finally, check the Enable SAML checkbox at the bottom of this form to confirm that you want to use SAML to log in. Once this is enabled, you will see the Login With SAML button on the DefectDojo Login Page. Additional SAML Options Create Unknown User allows you to decide whether or not to automatically create a new user in DefectDojo if they aren‚Äôt found in the SAML response.\nAllow Unknown Attributes allows you to authorize users who have attributes which are not found in the Attribute Mapping field.\nSign Assertions/Responses will require any incoming SAML responses to be signed.\nSign Logout Requests forces DefectDojo to sign any logout requests.\nForce Authentication determines whether you want to force your users to authenticate using your Identity Provider each time, regardless of existing sessions.\nEnable SAML Debugging will log more detailed SAML output for debugging purposes.\nOpen-Source SAML Navigate to your SAML IdP and find your metadata.\nSet these variables as an environment variable, or without the DD_ prefix in the local_settings.py file. (see Configuration).\nDD_SAML2_ENABLED=(bool, **True**), # SAML Login Button Text DD_SAML2_LOGIN_BUTTON_TEXT=(str, \u0026#39;Login with SAML\u0026#39;), # If the metadata can be accessed from a url, try the DD_SAML2_METADATA_AUTO_CONF_URL=(str, \u0026#39;\u0026lt;https://your_IdP.com/metadata.xml\u0026gt;\u0026#39;), # Otherwise, downlaod a copy of the metadata into an xml file, and # list the path in DD_SAML2_METADATA_LOCAL_FILE_PATH DD_SAML2_METADATA_LOCAL_FILE_PATH=(str, \u0026#39;/path/to/your/metadata.xml\u0026#39;), # Fill in DD_SAML2_ATTRIBUTES_MAP to corresponding SAML2 userprofile attributes provided by your IdP DD_SAML2_ATTRIBUTES_MAP=(dict, { # format: SAML attrib:django_user_model \u0026#39;Email\u0026#39;: \u0026#39;email\u0026#39;, \u0026#39;UserName\u0026#39;: \u0026#39;username\u0026#39;, \u0026#39;Firstname\u0026#39;: \u0026#39;first_name\u0026#39;, \u0026#39;Lastname\u0026#39;: \u0026#39;last_name\u0026#39; }), # May configure the optional fields NOTE: DD_SAML2_ATTRIBUTES_MAP in k8s can be referenced as extraConfig (e.g. DD_SAML2_ATTRIBUTES_MAP: 'Email'='email', 'Username'='username'...)\nNOTE: DD_SITE_URL might also need to be set depending on the choices you make with the metadata.xml provider. (File versus URL).\nCheckout the SAML section in dojo/dojo/settings/settings.dist.py and verfiy if it fits your requirement. If you need help, take a look at the plugin documentation.\nRestart DefectDojo, and you should now see a Login with SAML button (default setting of DD_SAML2_LOGIN_BUTTON_TEXT) on the login page.\nNOTE: In the case when IDP is configured to use self signed (private) certificate, than CA needs to be specified by define environments variable REQUESTS_CA_BUNDLE that points to the path of private CA certificate.\nTroubleshooting The SAML Tracer browser add-on can help troubleshoot SAML problems: Chrome, Firefox.\nAdvanced Configuration The djangosaml2 plugin has a lot of options. For details take a look at the plugin documentation.\nAll default options in DefectDojo can overwritten in the local_settings.py file. If you want to change the organization name, you can add the following lines:\nif SAML2_ENABLED: SAML_CONFIG[\u0026#39;contact_person\u0026#39;] = [{ \u0026#39;given_name\u0026#39;: \u0026#39;Extra\u0026#39;, \u0026#39;sur_name\u0026#39;: \u0026#39;Example\u0026#39;, \u0026#39;company\u0026#39;: \u0026#39;DefectDojo\u0026#39;, \u0026#39;email_address\u0026#39;: \u0026#39;dummy@defectdojo.com\u0026#39;, \u0026#39;contact_type\u0026#39;: \u0026#39;technical\u0026#39; }] SAML_CONFIG[\u0026#39;organization\u0026#39;] = { \u0026#39;name\u0026#39;: [(\u0026#39;DefectDojo\u0026#39;, \u0026#39;en\u0026#39;)], \u0026#39;display_name\u0026#39;: [(\u0026#39;DefectDojo\u0026#39;, \u0026#39;en\u0026#39;)], }, Migration from django-saml2-auth Up to relase 1.15.0 the SAML integration was based on django-saml2-auth. Which the switch to djangosaml2 some parameters has changed:\nDD_SAML2_ASSERTION_URL: not necessary any more - automatically generated DD_SAML2_DEFAULT_NEXT_URL: not necessary any more - default forwarding from defectdojo is used DD_SAML2_NEW_USER_PROFILE: not possible any more - default profile is used, see User Permissions DD_SAML2_ATTRIBUTES_MAP: Syntax has changed DD_SAML2_CREATE_USER: Default value changed to False, to avoid security breaches Other Open-Source Options RemoteUser This implementation is suitable if the DefectDojo instance is placed behind HTTP Authentication Proxy. Dojo expects that the proxy will perform authentication and pass HTTP requests to the Dojo instance with filled HTTP headers. The proxy should check if an attacker is not trying to add a malicious HTTP header and bypass authentication.\nValues which need to be set:\nDD_AUTH_REMOTEUSER_ENABLED - Needs to be set to True DD_AUTH_REMOTEUSER_USERNAME_HEADER - Name of the header which contains the username DD_AUTH_REMOTEUSER_EMAIL_HEADER(optional) - Name of the header which contains the email DD_AUTH_REMOTEUSER_FIRSTNAME_HEADER(optional) - Name of the header which contains the first name DD_AUTH_REMOTEUSER_LASTNAME_HEADER(optional) - Name of the header which contains the last name DD_AUTH_REMOTEUSER_GROUPS_HEADER(optional) - Name of the header which contains the comma-separated list of groups; user will be assigned to these groups (missing groups will be created) DD_AUTH_REMOTEUSER_GROUPS_CLEANUP(optional) - Same as [#automatic-import-of-user-groups](AzureAD implementation) DD_AUTH_REMOTEUSER_TRUSTED_PROXY - Comma separated list of proxies; Simple IP and CIDR formats are supported DD_AUTH_REMOTEUSER_LOGIN_ONLY(optional) - Check Django documentation WARNING: There is possible spoofing of headers (for all DD_AUTH_REMOTEUSER_xxx_HEADER values). Read Warning in Django documentation\nUser Permissions When a new user is created via the social-auth, only the default permissions are active. This means that the newly created user does not have access to add, edit, nor delete anything within DefectDojo. There are two parameters in the System Settings to influence the permissions for newly created users:\nDefault group When both the parameters Default group and Default group role are set, the new user will be a member of the given group with the given role, which will give him the respective permissions.\nGroups from Identity Providers Some Identity Providers are able to send list of groups to which should user belongs. This functionality is implemented only for Identity Providers mentioned below. For all others, we will be more than happy for contribution (hint: functions assign_user_to_groups and cleanup_old_groups_for_user from dojo/pipeline.py might be useful).\nAzure: Check DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS and DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS RemoteUser: Check DD_AUTH_REMOTEUSER_GROUPS_HEADER and DD_AUTH_REMOTEUSER_GROUPS_CLEANUP Other Providers In an effort to accommodate as much generality as possible, it was decided to implement OAuth2 with the social-auth ecosystem as it has a library of compatible providers with documentation of implementation. Conveniently, each provider has an identical procedure of managing the authenticated responses and authorizing access within a given application. The only difficulty is creating a new authentication client with a given OAuth2 provider.\n","date":"0001-01-01","id":247,"permalink":"/en/customize_dojo/user_management/configure_sso/","summary":"Users can connect to DefectDojo with a Username and Password, but if you prefer, you can allow users to authenticate using a Single Sign-On or SSO method.","tags":[],"title":"SSO Configuration (OAuth, SAML)"},{"content":"Import the JSON webhook event from StackHawk. For more information, check out our docs on hooking up StackHawk to Defect Dojo\nSample Scan Data Sample StackHawk HawkScan scans can be found here.\n","date":"0001-01-01","id":248,"permalink":"/en/connecting_your_tools/parsers/file/stackhawk/","summary":"Import the JSON webhook event from StackHawk. For more information, check out our docs on hooking up StackHawk to Defect Dojo","tags":[],"title":"StackHawk HawkScan"},{"content":"Import CSV report files generated by the Sysdig CLI Scanner\nSample Scan Data Sample Sysdig Vulnerability Reports scans can be found here.\n","date":"0001-01-01","id":249,"permalink":"/en/connecting_your_tools/parsers/file/sysdig_cli/","summary":"Import CSV report files generated by the Sysdig CLI Scanner\nSample Scan Data Sample Sysdig Vulnerability Reports scans can be found here.","tags":[],"title":"Sysdig Vulnerability Reports"},{"content":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser will accept Pipeline, Registry and Runtime reports created from the UI More information available at sysdig reporting docs page\nSample Scan Data Sample Sysdig Vulnerability Reports scans can be found here.\n","date":"0001-01-01","id":250,"permalink":"/en/connecting_your_tools/parsers/file/sysdig_reports/","summary":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser will accept Pipeline, Registry and Runtime reports created from the UI More information available at sysdig reporting docs page","tags":[],"title":"Sysdig Vulnerability Reports"},{"content":"Run Talisman in CLI mode and use \u0026ldquo;\u0026ndash;scan\u0026rdquo; argument to scan the git commit history along with \u0026ldquo;\u0026ndash;reportDirectory\u0026rdquo; argument to save the scan reports to a directory. The report will be in JSON format.\nAdditionally, you can set up Git Hooks to automate the scan and then send the generated reports to DefectDojo using its API.\nExample:\n#!/bin/sh # Set DefectDojo API credential and other variables DEFECTDOJO_API_KEY=\u0026#34;your-api-key\u0026#34; DEFECTDOJO_URL=\u0026#34;https://your-defectdojo-url.com\u0026#34; TALISMAN_RESULTS_DIR=\u0026#34;$HOME\u0026#34; # Run talisman in CLI mode and output the result in JSON format CMD=\u0026#34;talisman --scan --ignoreHistory --reportDirectory $TALISMAN_RESULTS_DIR\u0026#34; $CMD # Extract the result result=$(jq \u0026#39;.results[].filename\u0026#39; \u0026#34;${TALISMAN_RESULTS_DIR}/talisman_reports/data/report.json\u0026#34;) # Check if result is not empty if [ -n \u0026#34;$result\u0026#34; ]; then # If talisman found issues, send the JSON output to DefectDojo API endpoint curl -X POST \\ -H \u0026#34;Authorization: Token $DEFECTDOJO_API_KEY\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#34;@$TALISMAN_RESULTS_DIR/talisman_reports/data/report.json\u0026#34; \\ \u0026#34;$DEFECTDOJO_URL/api/v2/import-scan/\u0026#34; # Exit with a non-zero status code to indicate that the commit should be rejected exit 1 else # If talisman did not find any issues, exit with a zero status code exit 0 fi\rSample Scan Data Sample Talisman scans can be found here.\n","date":"0001-01-01","id":251,"permalink":"/en/connecting_your_tools/parsers/file/talisman/","summary":"Run Talisman in CLI mode and use \u0026ldquo;\u0026ndash;scan\u0026rdquo; argument to scan the git commit history along with \u0026ldquo;\u0026ndash;reportDirectory\u0026rdquo; argument to save the scan reports to a directory.","tags":[],"title":"Talisman"},{"content":"Reports can be imported in the CSV, and .nessus (XML) report formats. Legacy Nessus and Nessus WAS reports are supported\nSample Scan Data Sample Tenable scans can be found here.\n","date":"0001-01-01","id":252,"permalink":"/en/connecting_your_tools/parsers/file/tenable/","summary":"Reports can be imported in the CSV, and .nessus (XML) report formats. Legacy Nessus and Nessus WAS reports are supported","tags":[],"title":"Tenable"},{"content":"Import JSON output of terrascan scan report https://github.com/accurics/terrascan\nSample Scan Data Sample Terrascan scans can be found here.\n","date":"0001-01-01","id":253,"permalink":"/en/connecting_your_tools/parsers/file/terrascan/","summary":"Import JSON output of terrascan scan report https://github.com/accurics/terrascan\nSample Scan Data Sample Terrascan scans can be found here.","tags":[],"title":"Terrascan"},{"content":"Import CSV output of testssl scan report.\nSample Scan Data Sample Testssl Scan scans can be found here.\n","date":"0001-01-01","id":254,"permalink":"/en/connecting_your_tools/parsers/file/testssl/","summary":"Import CSV output of testssl scan report.\nSample Scan Data Sample Testssl Scan scans can be found here.","tags":[],"title":"Testssl Scan"},{"content":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan Data Sample TFSec scans can be found here.\n","date":"0001-01-01","id":255,"permalink":"/en/connecting_your_tools/parsers/file/tfsec/","summary":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan Data Sample TFSec scans can be found here.","tags":[],"title":"TFSec"},{"content":"File Types DefectDojo parser accepts a .json file.\nJSON reports are created from the Threagile tool (default name risks.json) using the following command:\ndocker run --rm -it -v \u0026#34;$(pwd)\u0026#34;:/app/work threagile/threagile -verbose -model /app/work/threagile.yaml -output /app/work\rAcceptable JSON Format Parser expects an array of finding. All properties are strings. Required fields are the following\n\u0026ldquo;category\u0026rdquo; \u0026ldquo;title\u0026rdquo; \u0026ldquo;severity\u0026rdquo; \u0026ldquo;synthetic_id\u0026rdquo; \u0026ldquo;exploitation_impact\u0026rdquo; catergory fields is used to set both the title of the Finding as well as the cwe. most_relevant_technical_asset field is used to determine the component.\n[ { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;unchecked\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eEnergon\\u003c/b\\u003e via \\u003cb\\u003eEnergonToPolicyRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@energon-ta\\u003eenergontopolicyregofilestorage@energon-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;energon-ta\\u003eenergontopolicyregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;in-discussion\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIAMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMBachendAPIPoliciesRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage@iam-sidecar-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, { \u0026#34;category\u0026#34;: \u0026#34;unguarded-direct-datastore-access\u0026#34;, \u0026#34;risk_status\u0026#34;: \u0026#34;accepted\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;elevated\u0026#34;, \u0026#34;exploitation_likelihood\u0026#34;: \u0026#34;likely\u0026#34;, \u0026#34;exploitation_impact\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIDMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMSidecarPoliciesRegoFileStorage\\u003c/b\\u003e\u0026#34;, \u0026#34;synthetic_id\u0026#34;: \u0026#34;unguarded-direct-datastore-access@idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage@idm-sidecar-ta@policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_data_asset\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_technical_asset\u0026#34;: \u0026#34;policies-rego-storage-ta\u0026#34;, \u0026#34;most_relevant_trust_boundary\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_shared_runtime\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;most_relevant_communication_link\u0026#34;: \u0026#34;idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage\u0026#34;, \u0026#34;data_breach_probability\u0026#34;: \u0026#34;improbable\u0026#34;, \u0026#34;data_breach_technical_assets\u0026#34;: [ \u0026#34;policies-rego-storage-ta\u0026#34; ] }, ... ]\rSample Scan Data Sample Threagile scans can be found here.\n","date":"0001-01-01","id":256,"permalink":"/en/connecting_your_tools/parsers/file/threagile/","summary":"File Types DefectDojo parser accepts a .json file.\nJSON reports are created from the Threagile tool (default name risks.json) using the following command:","tags":[],"title":"Threagile"},{"content":"File Types This DefectDojo parser accepts JSON files from Threat Composer. The tool supports the export of JSON report out of the browser local storage to a local file.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","date":"0001-01-01","id":257,"permalink":"/en/connecting_your_tools/parsers/file/threat_composer/","summary":"File Types This DefectDojo parser accepts JSON files from Threat Composer. The tool supports the export of JSON report out of the browser local storage to a local file.","tags":[],"title":"Threat Composer"},{"content":"Note: Connectors are a DefectDojo Pro-only feature.\nWhen setting up a Connector for a supported tool, you\u0026rsquo;ll need to give DefectDojo specific information related to the tool\u0026rsquo;s API. At a base level, you\u0026rsquo;ll need:\nLocation -a field whichgenerallyrefers to your tool\u0026rsquo;s URL in your network, Secret - generally an API key. Some tools will require additional API-related fields beyond Location and Secret. They may also require you to make changes on their side to accommodate an incoming Connector from DefectDojo.\nEach tool has a different API configuration, and this guide is intended to help you set up the tool\u0026rsquo;s API so that DefectDojo can connect.\nWhenever possible, we recommend creating a new \u0026lsquo;DefectDojo Bot\u0026rsquo; account within your Security Tool which will only be used by the Connector. This will help you better differentiate between actions manually taken by your team, and automated actions taken by the Connector.\nSupported Connectors AWS Security Hub The AWS Security Hub connector uses an AWS access key to interact with the Security Hub APIs.\nPrerequisites Rather than use the AWS access key from a team member, we recommend creating an IAM User in your AWS account specifically for DefectDojo, with that user\u0026rsquo;s permissions limited to those necessary for interacting with Security Hub.\nAWS\u0026rsquo;s \u0026ldquo;**AWSSecurityHubReadOnlyAccess**policy\u0026rdquo; provides the required level of access for a connector. If you would like to write a custom policy for a Connector, you will need to include the following permissions:\nDescribeHub GetFindingAggregator GetFindings ListFindingAggregators A working policy definition might look like the following:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AWSSecurityHubConnectorPerms\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;securityhub:DescribeHub\u0026#34;, \u0026#34;securityhub:GetFindingAggregator\u0026#34;, \u0026#34;securityhub:GetFindings\u0026#34;, \u0026#34;securityhub:ListFindingAggregators\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }\rPlease note: we may need to use additional API actions in the future to provide the best possible experience, which will require updates to this policy.\nOnce you have created your IAM user and assigned it the necessary permissions using an appropriate policy/role, you will need to generate an access key, which you can then use to create a Connector.\nConnector Mappings Enter the appropriate AWS API Endpoint for your region in the Location field**:** for example, to retrieve results from the us-east-1 region, you would supply https://securityhub.us-east-1.amazonaws.com 2. Enter a valid AWS Access Key in the Access Key field. 3. Enter a matching Secret Key in the Secret Key field.\nDefectDojo can pull Findings from more than one region using Security Hub\u0026rsquo;s cross-region aggregation feature. If cross-region aggregation is enabled, you should supply the API endpoint for your \u0026ldquo;Aggregation Region\u0026rdquo;. Additional linked regions will have ProductRecords created for them in DefectDojo based on your AWS account ID and the region name.\nBurpSuite DefectDojo‚Äôs Burp connector calls Burp‚Äôs GraphQL API to fetch data.\nPrerequisites Before you can set up this connector, you will need an API key from a Burp Service Account. Burp user accounts don‚Äôt have API keys by default, so you may need to create a new user specifically for this purpose.\nSee Burp Documentation for a guide on setting up a Service Account user with an API key.\nConnector Mappings Enter Burp‚Äôs root URL in the Location field: this is the URL where you access the Burp tool. Enter a valid API Key in the Secret field. This is the API key associated with your Burp Service account. See the official Burp documentation for more information on the Burp API.\nCheckmarx ONE DefectDojo\u0026rsquo;s Checkmarx ONE connector calls the Checkmarx API to fetch data.\nConnector Mappings Enter your Tenant Name in the Checkmarx Tenant field. This name should be visible on the Checkmarx ONE login page in the top-right hand corner:\n\u0026quot; Tenant: \u0026lt;your tenant name\u0026gt; \u0026quot;\n‚Äã Enter a valid API key. You may need to generate a new one: see Checkmarx API Documentation for details.\nEnter your tenant location in the Location field. This URL is formatted as follows:\n‚Äãhttps://\u0026lt;your-region\u0026gt;.ast.checkmarx.net/ . Your Region can be found at the beginning of your Checkmarx URL when using the Checkmarx app. https://ast.checkmarx.net is the primary US server (which has no region prefix).\nDependency-Track This connector fetches data from a on-premise Dependency-Track instance, via REST API.\n‚ÄãConnector Mappings\nEnter your local Dependency-Track server URL in the Location field. Enter a valid API key in the Secret field. To generate a Dependency-Track API key:\nAccess Management: Navigate to Administration \u0026gt; Access Management \u0026gt; Teams in the Dependency-Track interface. Teams Setup: You can either create a new team or select an existing one. Teams allow you to manage API access based on group membership. Generate API Key: In the selected team\u0026rsquo;s details page, find the \u0026ldquo;API Keys\u0026rdquo; section. Click the + button to generate a new API key. Assign Permissions: In the \u0026ldquo;Permissions\u0026rdquo; section of the team\u0026rsquo;s page, click the + button to open the permissions selector. Choose VIEW_PORTFOLIO and VIEW_VULNERABILITY permissions to enable API access to project portfolios and vulnerability details. Click \u0026ldquo;Select\u0026rdquo; to confirm and save these permissions. For more information, see Dependency-Track Documentation.\nProbely This connector uses the Probely REST API to fetch data.\n‚ÄãConnector Mappings\nEnter the appropriate API server address in the Location field. (either https://api.us.probely.com/ or https://api.eu.probely.com/ ) Enter a valid API key in the Secret field. You can find an API key under the User \u0026gt; API Keys menu in Probely.\nSee Probely documentation for more info.\nSemGrep This connector uses the SemGrep REST API to fetch data.\nConnector Mappings Enter https://semgrep.dev/api/v1/in the Location field.\nEnter a valid API key in the Secret field. You can find this on the Tokens page:\n‚Äã\n\u0026ldquo;Settings\u0026rdquo; in the left navbar \u0026gt; Tokens \u0026gt; Create new token (https://semgrep.dev/orgs/-/settings/tokens) See SemGrep documentation for more info.\nSonarQube The SonarQube Connector can fetch data from either a SonarCloud account or from a local SonarQube instance.\nFor SonarCloud users:\nEnter https://sonarcloud.io/ in the Location field. Enter a valid API key in the Secret field. For SonarQube (on-premise) users:\nEnter the base url of your SonarQube instance in the Location field: for example https://my.sonarqube.com/ Enter a valid API key in the Secret field. This will need to be a User API Token Type. API tokens can be found and generated via My Account -\u0026gt; Security -\u0026gt; Generate Token in the SonarQube app. For more information, see SonarQube documentation.\nSnyk The Snyk connector uses the Snyk REST API to fetch data.\nConnector Mappings Enter https://api.snyk.io/rest or https://api.eu.snyk.io/rest (for a regional EU deployment) in the Location field. Enter a valid API key in the Secret field. API Tokens are found on a user\u0026rsquo;s Account Settings page in Snyk. See the Snyk API documentation for more info.\nTenable The Tenable connector uses the Tenable.io REST API to fetch data.\nOn-premise Tenable Connectors are not available at this time.\nConnector Mappings Enter https://cloud.tenable.com in the Location field. Enter a valid API key in the Secret field. See Tenable\u0026rsquo;s API Documentation for more info.\nWiz Using the Wiz connector requires you to create a service account: see the Wiz documentation for more info. You will need a Wiz account to access the documentation.\nConnector Mappings Enter your Wiz Client ID in the Client ID field. Enter the Wiz Client Secret in the Secret field. ","date":"0001-01-01","id":258,"permalink":"/en/connecting_your_tools/connectors/connectors_tool_reference/","summary":"Note: Connectors are a DefectDojo Pro-only feature.\nWhen setting up a Connector for a supported tool, you\u0026rsquo;ll need to give DefectDojo specific information related to the tool\u0026rsquo;s API.","tags":[],"title":"Tool-Specific Connector Setup"},{"content":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can be found here.\n","date":"0001-01-01","id":259,"permalink":"/en/connecting_your_tools/parsers/file/trivy/","summary":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can be found here.","tags":[],"title":"Trivy"},{"content":"JSON report of trivy operator scanner.\nTo import the generated Vulnerability Reports, you can also use the trivy-dojo-report-operator.\nSample Scan Data Sample Trivy Operator scans can be found here.\n","date":"0001-01-01","id":260,"permalink":"/en/connecting_your_tools/parsers/file/trivy_operator/","summary":"JSON report of trivy operator scanner.\nTo import the generated Vulnerability Reports, you can also use the trivy-dojo-report-operator.\nSample Scan Data Sample Trivy Operator scans can be found here.","tags":[],"title":"Trivy Operator"},{"content":"JSON Output of Trufflehog. Supports version 2 and 3 of https://github.com/trufflesecurity/trufflehog\nSample Scan Data Sample Trufflehog scans can be found here.\n","date":"0001-01-01","id":261,"permalink":"/en/connecting_your_tools/parsers/file/trufflehog/","summary":"JSON Output of Trufflehog. Supports version 2 and 3 of https://github.com/trufflesecurity/trufflehog\nSample Scan Data Sample Trufflehog scans can be found here.","tags":[],"title":"Trufflehog"},{"content":"JSON Output of Trufflehog3, a fork of TruffleHog located at https://github.com/feeltheajf/truffleHog3\nSample Scan Data Sample Trufflehog3 scans can be found here.\n","date":"0001-01-01","id":262,"permalink":"/en/connecting_your_tools/parsers/file/trufflehog3/","summary":"JSON Output of Trufflehog3, a fork of TruffleHog located at https://github.com/feeltheajf/truffleHog3\nSample Scan Data Sample Trufflehog3 scans can be found here.","tags":[],"title":"Trufflehog3"},{"content":"File Types Trustwave vulnerability scan reports can be exported/imported in CSV format.\nTotal Fields in CSV: 13 Fields in order of appearance:\nStatus (Not mapped) IP - Used for endpoint host if Domain is empty Target Name (Not mapped) Domain - Primary choice for endpoint host Vulnerability Name - Maps to finding title Description - Maps to finding description Remediation - Maps to finding mitigation Protocol - Added to endpoint if present Port - Added to endpoint port if present, converted to integer Severity - Mapped through severity levels: I = Info L = Low M = Medium H = High C = Critical CVE - Added to vulnerability IDs list Service (Not mapped) Evidence - Maps to finding references Field Mapping Details For each finding created, the parser:\nCreates endpoints by combining Domain/IP, Port, and Protocol fields Sets default nb_occurences to 1, incremented for duplicates Uses SHA256 hash of severity + title + description for deduplication Defaults severity to Low if mapping not matched Sample Scan Data Sample Trustwave scans can be found in the unit tests folder.\nLink To Tool Trustwave provides vulnerability scanning services through their SecureConnect platform.\n","date":"0001-01-01","id":263,"permalink":"/en/connecting_your_tools/parsers/file/trustwave/","summary":"File Types Trustwave vulnerability scan reports can be exported/imported in CSV format.\nTotal Fields in CSV: 13 Fields in order of appearance:","tags":[],"title":"Trustwave"},{"content":"Trustwave Fusion API report file can be imported in JSON format\nSample Scan Data Sample Trustwave Fusion API Scan scans can be found here.\n","date":"0001-01-01","id":264,"permalink":"/en/connecting_your_tools/parsers/file/trustwave_fusion_api/","summary":"Trustwave Fusion API report file can be imported in JSON format\nSample Scan Data Sample Trustwave Fusion API Scan scans can be found here.","tags":[],"title":"Trustwave Fusion API Scan"},{"content":"JSON output of the twistcli tool. Example:\n./twistcli images scan \u0026lt;REGISTRY/REPO:TAG\u0026gt; --address https://\u0026lt;SECURE_URL_OF_TWISTLOCK_CONSOLE\u0026gt; --user \u0026lt;USER\u0026gt; --details --output-file=\u0026lt;PATH_TO_SAVE_JSON_FILE\u0026gt; The CSV output from the UI is now also accepted.\nSample Scan Data Sample Twistlock scans can be found here.\n","date":"0001-01-01","id":265,"permalink":"/en/connecting_your_tools/parsers/file/twistlock/","summary":"JSON output of the twistcli tool. Example:\n./twistcli images scan \u0026lt;REGISTRY/REPO:TAG\u0026gt; --address https://\u0026lt;SECURE_URL_OF_TWISTLOCK_CONSOLE\u0026gt; --user \u0026lt;USER\u0026gt; --details --output-file=\u0026lt;PATH_TO_SAVE_JSON_FILE\u0026gt; The CSV output from the UI is now also accepted.","tags":[],"title":"Twistlock"},{"content":"‚ÄòRisk Accepted‚Äô is a special status that can be applied to a Finding in two ways:\nRisk Accepted can be freely applied as a Status if ‚ÄòSimple Risk Acceptance‚Äô is enabled. You can also create Full Risk Acceptances, which are objects stored in DefectDojo to capture a risk acceptance decision made by your team. A Full Risk Acceptance is a special object in DefectDojo, used when Active Findings are ‚Äòbacklogged‚Äô by your team. Often, both security teams and developer teams will decide when a Risk Acceptance is appropriate. In DefectDojo, your team can create Risk Acceptances which capture the internal decision making process and can be used as a source of truth.\nAbout Full Risk Acceptances Each Full Risk Acceptance can store details about the following:\nThe Security team‚Äôs recommendation to a Product owner or other stakeholder Description of the decision made by stakeholders The DefectDojo user involved in the decision making process One or more Findings governed by the Risk Acceptance Findings can be added to a Risk Acceptance regardless of the Product, Test or Engagement they are in.\nAny Findings associated with a Full Risk Acceptance will be set to Inactive, Risk Accepted.\nGenerally, any Risk Acceptances should follow your internal security policy and be re-examined at an appropriate time. As a result, Risk Acceptances also have expiration dates. Once a Risk Acceptance expires, any Findings will be set to Active again.\nAdd a new Full Risk Acceptance Risk Acceptances can be added to a Finding in two ways:\nUsing the Bulk Edit menu, when looking at a list of Findings Using the Add Risk Acceptance button on an individual Finding To create a New Risk Acceptance, complete the Add to New Risk Acceptance form on a Finding you wish to Risk Accept.\nSelect the Owner of the Risk Acceptance - this is generally meant to be the DefectDojo team member responsible for the decision to Risk Accept the Finding. Complete the Optional Fields with any relevant information. If you want to set an Expiration Date or a Warning for that Expiration Date, you can do so here as well. If you don‚Äôt specify a date, the Default Risk Acceptance / Default Risk Acceptance Expiration days will be used from the System Settings page. Select whether you want to Reactivate or Restart SLAs on any associated Findings once the Risk Acceptance expires. Simple Risk Acceptances If you don‚Äôt want to create a Full Risk Acceptance object and would prefer to simply apply a status of ‚ÄòRisk Accepted‚Äô to a Finding, you can do so through the Bulk Edit menu. This method is called Simple Risk Acceptance.\nBefore you can apply a Simple Risk Acceptance to a Finding, Simple Risk Acceptance will need to be enabled at the Product level. This setting can be found on the Edit Product Form.\nApply a Simple Risk Acceptance With one or more Findings selected, open Bulk Update Actions. Navigate to Simple Risk Acceptance Status and select either Accept Risk or Unaccept Risk. Once you have submitted the Bulk Update, ‚ÄòRisk Accepted‚Äô will be applied to any Findings selected without the need to create a Risk Acceptance object (with an expiration date or additional metadata).\nLocating Risk Accepted Findings The sidebar in DefectDojo allows you to quickly find any Risk Accepted Findings by opening Manage \u0026gt; Risk Acceptances. From here you can view the Risk Acceptance objects themselves, or view a list of Risk Accepted Findings.\n","date":"0001-01-01","id":266,"permalink":"/en/working_with_findings/findings_workflows/risk_acceptances/","summary":"‚ÄòRisk Accepted‚Äô is a special status that can be applied to a Finding in two ways:\nRisk Accepted can be freely applied as a Status if ‚ÄòSimple Risk Acceptance‚Äô is enabled.","tags":[],"title":"Using Risk Acceptances"},{"content":"Veracode reports can be ingested in either XML or JSON Format\nDetailed XML Report JSON REST Findings from /appsec/v2/applications/{application_guid}/findings/ Acceptable scan types include STATIC, DYNAMIC, and SCA Findings with a status of CLOSED will not be imported into DefectDojo Acceptable formats are as follows: Findings list Requires slight modification of the response returned from the API Exmample of a request being: url \u0026lt;endpoint\u0026gt; | jq \u0026quot;{findings}\u0026quot; Desired Format: { \u0026#34;findings\u0026#34;: [ { ... }, ... ] }\rEmbedded This response can be saved directly to a file and uploaded Not as ideal for crafting a refined report consisting of multiple requests Desired Format: { \u0026#34;_embedded\u0026#34;: { \u0026#34;findings\u0026#34;: [ { ... }, ... ] }, \u0026#34;_links\u0026#34;: { ... }, \u0026#34;page\u0026#34;: { ... } }\rSample Scan Data Sample Veracode scans can be found here.\n","date":"0001-01-01","id":267,"permalink":"/en/connecting_your_tools/parsers/file/veracode/","summary":"Veracode reports can be ingested in either XML or JSON Format\nDetailed XML Report JSON REST Findings from /appsec/v2/applications/{application_guid}/findings/ Acceptable scan types include STATIC, DYNAMIC, and SCA Findings with a status of CLOSED will not be imported into DefectDojo Acceptable formats are as follows: Findings list Requires slight modification of the response returned from the API Exmample of a request being: url \u0026lt;endpoint\u0026gt; | jq \u0026quot;{findings}\u0026quot; Desired Format: { \u0026#34;findings\u0026#34;: [ { .","tags":[],"title":"Veracode"},{"content":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode SourceClear scans can be found here.\n","date":"0001-01-01","id":268,"permalink":"/en/connecting_your_tools/parsers/file/veracode_sca/","summary":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode SourceClear scans can be found here.","tags":[],"title":"Veracode SourceClear"},{"content":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data Sample Visual Code Grepper (VCG) scans can be found here.\n","date":"0001-01-01","id":269,"permalink":"/en/connecting_your_tools/parsers/file/vcg/","summary":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data Sample Visual Code Grepper (VCG) scans can be found here.","tags":[],"title":"Visual Code Grepper (VCG)"},{"content":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nImport Vulners Audit results, no file required.\nIn Tool Configuration, select Tool Type to \u0026ldquo;Vulners\u0026rdquo; and add the API Key\nIn the Product settings select Add API Scan Configuration and select the previously added Vulners API Tool Configuration.\nAfter this is done, you can import the findings by selecting \u0026ldquo;Vulners\u0026rdquo; as the scan type.\nDetailed installation steps can be found in vulners documentation.\nUse following instructions to generate Vulners API Key.\nMore details about DefectDojo-plugin integration can be found at vulners integrations page.\n","date":"0001-01-01","id":270,"permalink":"/en/connecting_your_tools/parsers/api/vulners/","summary":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.","tags":[],"title":"Vulners"},{"content":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be found here.\n","date":"0001-01-01","id":271,"permalink":"/en/connecting_your_tools/parsers/file/wapiti/","summary":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be found here.","tags":[],"title":"Wapiti Scan"},{"content":"File Types DefectDojo parser accepts a .json file from Wazuh. The export from Wazuh can be done via 2 ways. Choose the one which you prefer.\nexport the Wazuh findings from API and upload them to DefectDojo. This method may be the easiest one but does export all known vulnerabilities at once. It is not possible to sort them after clients or any other categories. You will receive all vulnerabilities in one engagement. It also does not output the endpoint of a finding. export the findings via the script available here. The script fetches the findings by Wazuh client groups and saves them as json, ready for upload. You will receive one file per group allowing you to separate the clients via engagements in Wazuh. It also exports the endpoints hostname and displays them in DefectDojo UI. Independent of your above choice: Have in mind to adjust the max file size via \u0026ldquo;DD_SCAN_FILE_MAX_SIZE\u0026rdquo; if you see files larger than the default value of 100MB. Depending on the amount and category of integrated devices, the file size jumps rapidly.\nAcceptable JSON Format Parser expects a .json file structured as below.\n{ \u0026#34;data\u0026#34;: { \u0026#34;affected_items\u0026#34;: [ { \u0026#34;architecture\u0026#34;: \u0026#34;amd64\u0026#34;, \u0026#34;condition\u0026#34;: \u0026#34;Package less than 4.3.2\u0026#34;, \u0026#34;cve\u0026#34;: \u0026#34;CVE-1234-123123\u0026#34;, \u0026#34;cvss2_score\u0026#34;: 0, \u0026#34;cvss3_score\u0026#34;: 5.5, \u0026#34;detection_time\u0026#34;: \u0026#34;2023-02-08T13:55:10Z\u0026#34;, \u0026#34;external_references\u0026#34;: [ \u0026#34;https://nvd.nist.gov/vuln/detail/CVE-YYYY-XXXXX\u0026#34;, \u0026#34;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-YYYY-XXXXX\u0026#34; ], \u0026#34;name\u0026#34;: \u0026#34;asdf\u0026#34;, \u0026#34;published\u0026#34;: \u0026#34;2022-09-01\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;VALID\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;CVE-YYYY-XXXXX affects asdf\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PACKAGE\u0026#34;, \u0026#34;updated\u0026#34;: \u0026#34;2022-09-07\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;4.3.1\u0026#34; } ], \u0026#34;failed_items\u0026#34;: [], \u0026#34;total_affected_items\u0026#34;: 1, \u0026#34;total_failed_items\u0026#34;: 0 }, \u0026#34;error\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;All selected vulnerabilities were returned\u0026#34; }\rSample Scan Data Sample Wazuh Scanner scans can be found here.\n","date":"0001-01-01","id":272,"permalink":"/en/connecting_your_tools/parsers/file/wazuh/","summary":"File Types DefectDojo parser accepts a .json file from Wazuh. The export from Wazuh can be done via 2 ways. Choose the one which you prefer.","tags":[],"title":"Wazuh Scanner"},{"content":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).\nHTTP Return Code Severity missing Low 200 - 299 High 300 - 399 Low 400 - 499 Medium = 500 | Low\nSample Scan Data Sample Wfuzz JSON importer scans can be found here.\n","date":"0001-01-01","id":273,"permalink":"/en/connecting_your_tools/parsers/file/wfuzz/","summary":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).","tags":[],"title":"Wfuzz JSON importer"},{"content":"Import Whispers JSON results. https://github.com/adeptex/whispers\nSample Scan Data Sample Whispers scans can be found here.\n","date":"0001-01-01","id":274,"permalink":"/en/connecting_your_tools/parsers/file/whispers/","summary":"Import Whispers JSON results. https://github.com/adeptex/whispers\nSample Scan Data Sample Whispers scans can be found here.","tags":[],"title":"Whispers"},{"content":"WhiteHat Sentinel output from api/vuln/query_site can be imported in JSON format.\nSample Scan Data Sample WhiteHat Sentinel scans can be found here.\n","date":"0001-01-01","id":275,"permalink":"/en/connecting_your_tools/parsers/file/whitehat_sentinel/","summary":"WhiteHat Sentinel output from api/vuln/query_site can be imported in JSON format.\nSample Scan Data Sample WhiteHat Sentinel scans can be found here.","tags":[],"title":"WhiteHat Sentinel"},{"content":"This parser imports scan results from wiz. You have to use Report Type Standard when you export the results. The file format will be .csv which is parsable within DefectDojo.\nSample Scan Data Sample Wiz Scanner scans can be found here.\n","date":"0001-01-01","id":276,"permalink":"/en/connecting_your_tools/parsers/file/wiz/","summary":"This parser imports scan results from wiz. You have to use Report Type Standard when you export the results. The file format will be .","tags":[],"title":"Wiz Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli dir scan --path ./ -o scan_dir.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":277,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_dir/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli Dir Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli iac scan --path ./ -o scan_iac.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":278,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_iac/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli IaC Scanner"},{"content":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo. wizcli docker scan --image wizcli-imagescan -o scan_img.json,json\nSample Scan Data Sample Wizcli Scanner scans can be found here.\n","date":"0001-01-01","id":279,"permalink":"/en/connecting_your_tools/parsers/file/wizcli_img/","summary":"This parser imports scan results from wizcli IaC scan. You have to export scan results in JSON format so that it will be parsable within DefectDojo.","tags":[],"title":"Wiz-cli Img Scanner"},{"content":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can be found here.\n","date":"0001-01-01","id":280,"permalink":"/en/connecting_your_tools/parsers/file/wpscan/","summary":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can be found here.","tags":[],"title":"Wpscan Scanner"},{"content":"Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nSample Scan Data Sample Xanitizer scans can be found here.\n","date":"0001-01-01","id":281,"permalink":"/en/connecting_your_tools/parsers/file/xanitizer/","summary":"Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nSample Scan Data Sample Xanitizer scans can be found here.","tags":[],"title":"Xanitizer"},{"content":"Import Yarn Audit scan report in JSON format. Use something like yarn audit --json \u0026gt; yarn_report.json.\nSample Scan Data Sample Yarn Audit scans can be found here.\n","date":"0001-01-01","id":282,"permalink":"/en/connecting_your_tools/parsers/file/yarn_audit/","summary":"Import Yarn Audit scan report in JSON format. Use something like yarn audit --json \u0026gt; yarn_report.json.\nSample Scan Data Sample Yarn Audit scans can be found here.","tags":[],"title":"Yarn Audit"},{"content":"ZAP XML report format (with or without requests and responses).\nSample Scan Data Sample Zed Attack Proxy scans can be found here.\n","date":"0001-01-01","id":283,"permalink":"/en/connecting_your_tools/parsers/file/zap/","summary":"ZAP XML report format (with or without requests and responses).\nSample Scan Data Sample Zed Attack Proxy scans can be found here.","tags":[],"title":"Zed Attack Proxy"}]