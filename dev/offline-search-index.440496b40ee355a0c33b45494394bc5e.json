











































































































































































































































































[{"body":"There are no special instructions for upgrading to 2.37.x. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.37/","tags":"","title":"Upgrading to DefectDojo Version 2.37.x"},{"body":"Previous HELM deployments (HELM chart \u003c=1.6.136, DefectDojo \u003c=2.35.4) used a pinned version of PostgreSQL in versions 11.x. These are incompatible with Django in version 4.2 (used from DefectDojo version 3.36.0; HELM chart 1.6.137). Because of this, it is necessary to upgrade PostgreSQL to version 12.x or higher. DefectDojo in version 3.36.1 (HELM chart 1.6.138) uses this new version of PostgreSQL.\nUnfortunately, an upgrade of PostgreSQL is not enough because PostgreSQL does not support automatic migration of data structures in the filesystem. Because of this, migration is needed. There are different ways (many of them similar to migration between different database backends (e.g. from MySQL to PostgreSQL)). Please find inspiration and the best fitting way for you in:\n https://github.com/DefectDojo/django-DefectDojo/discussions/9480 https://owasp.slack.com/archives/C2P5BA8MN/p1717610931766739?thread_ts=1717587117.831149\u0026cid=C2P5BA8MN https://dev.to/jkostolansky/how-to-upgrade-postgresql-from-11-to-12-2la6  There are no other special instructions for upgrading to 2.36.x. Check the Release Notes for the contents of the release.\n","categories":"","description":"Breaking Change for HELM deployments with PostgreSQL","excerpt":"Breaking Change for HELM deployments with PostgreSQL","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.36/","tags":"","title":"Upgrading to DefectDojo Version 2.36.x"},{"body":"From 2.35.0, DefectDojo will perform an integrity check of the settings.dist.py file to ensure it has not been modified. If the user changed this file (in the past or even now) the DefectDojo instance will not start until those changes have been reverted. Any customization of variables needs to be done via environmental variables or in ‚Äòlocal_settings.py‚Äô. For more information check Configuration documentation page.\nThere are no other special instructions for upgrading to 2.35.x. Check the Release Notes for the contents of the release.\n","categories":"","description":"Integrity checker announced","excerpt":"Integrity checker announced","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.35/","tags":"","title":"Upgrading to DefectDojo Version 2.35.x"},{"body":"Breaking Change\n AWS_Scout2 has been removed. This parser was already disactivated by default in releases \u003e= 2.3.1. and has been replaced with ScoutSuite (https://github.com/nccgroup/ScoutSuite) upstream. Please switch to ScoutSuite now if you haven‚Äôt done it yet.  For all other changes, check the Release Notes for the contents of the release.\n","categories":"","description":"Breaking Change for AWS_Scout2.","excerpt":"Breaking Change for AWS_Scout2.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.34/","tags":"","title":"Upgrading to DefectDojo Version 2.34.x"},{"body":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\n Acunetix and Acunetix360 were merged to Acunetix. There is a migration process built into the upgrade that will automatically convert existing Acunetix360 findings into Acunetix findings.  Breaking Change\n If there is any use of the above mentioned Acunetix360 parser in an automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated accordingly.  For all other changes, check the Release Notes for the contents of the release.\n","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.33/","tags":"","title":"Upgrading to DefectDojo Version 2.33.x"},{"body":"There are no special instructions for upgrading to 2.32.x. Check the Release Notes for the contents of the release.\nRemoval\nThe OpenAPI 2.0 Swagger API documentation was removed in favor of the existing OpenAPI 3.0 API documentation page.\nNote: The API has not changed in any way and behaves the same between OAPI2 and OAPI3\n","categories":"","description":"Breaking change for Removal of OpenAPI 2.0 Swagger","excerpt":"Breaking change for Removal of OpenAPI 2.0 Swagger","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.32/","tags":"","title":"Upgrading to DefectDojo Version 2.32.x"},{"body":"To continue maintaining the most up to date list of parsers, the following actions have been taken:\n OpenVAS XML and OpenVAS CSV were merged to OpenVAS Parser. There is a migration process built into the upgrade that will automatically convert existing OpenVAS XML and OpenVAS CSV findings into OpenVAS Parser findings. Clair Scan and Clair Klar Scan were merged to Clair Scan. There is a migration process built into the upgrade that will automatically convert existing Clair Klar Scan findings to Clair Scan findings. Whitesource has been renamed to Mend. There is a migration process built into the upgrade that will automatically convert existing Whitesource findings and tests into Mend findings and tests  Breaking Change\n If there is any use of the above mentioned parsers in automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated accordingly.  For all other changes, check the Release Notes for the contents of the release.\n","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.31/","tags":"","title":"Upgrading to DefectDojo Version 2.31.x"},{"body":"There are instructions for upgrading to 2.30.0 if you disabled enable_auditlog before (read below). Check the Release Notes for the contents of the release.\nBreaking Change\nParameter enable_auditlog is not possible to set through System settings anymore. If you set this parameter or you need to change it to False (to disable audit logging), set environmental variable DD_ENABLE_AUDITLOG to False.\nIf you are using docker-compose, another EnvVar should be added to the docker-compose.yml file in all the containers ran by the django image. This should do the trick\nDD_ENABLE_AUDITLOG: ${DD_ENABLE_AUDITLOG:-False} Somewhere in the environment blocks for the uwsgi, celerybeat, celeryworker, and init containers.\n","categories":"","description":"Breaking Change for Auditlog.","excerpt":"Breaking Change for Auditlog.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.30/","tags":"","title":"Upgrading to DefectDojo Version 2.30.x"},{"body":"There are no special instructions for upgrading to 2.29.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.29/","tags":"","title":"Upgrading to DefectDojo Version 2.29.x"},{"body":"There are no special instructions for upgrading to 2.28.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.28/","tags":"","title":"Upgrading to DefectDojo Version 2.28.x"},{"body":"There are no special instructions for upgrading to 2.27.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.27/","tags":"","title":"Upgrading to DefectDojo Version 2.27.x"},{"body":"There are no special instructions for upgrading to 2.26.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.26/","tags":"","title":"Upgrading to DefectDojo Version 2.26.x"},{"body":"There are no special instructions for upgrading to 2.25.0. Check the Release Notes for the contents of the release.\nA few query parameters related to filtering object via API related to a products tags have been renamed to be more consistent with the other ‚Äúrelated object tags‚Äù:\nBreaking Change\n Engagement  product__tags__name -\u003e product__tags not_product__tags__name -\u003e not_product__tags   Test  engagement__product__tags__name -\u003e engagement__product__tags not_engagement__product__tags__name -\u003e not_engagement__product__tags   Finding  test__engagement__product__tags__name -\u003e test__engagement__product__tags not_test__engagement__product__tags__name -\u003e not_test__engagement__product__tags    Deprecation\nThe OpenAPI 2.0 Swagger API documentation is being deprecated in favor of the existing OpenAPI 3.0 API documentation page. The OpenAPI 2.0 Swagger API documentation page is slated for removal in version 2.30.0\nNote: The API has not changed in any way and behaves the same between OAPI2 and OAPI3\nFor all other changes, check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.25/","tags":"","title":"Upgrading to DefectDojo Version 2.25.x"},{"body":"There are no special instructions for upgrading to 2.24.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.24/","tags":"","title":"Upgrading to DefectDojo Version 2.24.x"},{"body":"There is a migration from the legacy Nessus and Nessus WAS parsers to a single Tenable parser. The updated Tenable parser simply merges existing support for Nessus and Nessus WAS without introducing new functionality that could create instability\nThere is a migration process built into the upgrade that will automatically convert exiting Nessus and Nessus WAS findings and tests into Tenable findings and tests\nBreaking Change\n If there is any use of the Nessus or Nessus WAS in automated fashion via the import and reimport API endpoints, the scan-type parameter needs to be updated to Tenable Scan The default containerized database will now be PostgreSQL rather than MySQL due to the use of case insensitivity on fields by default  It is recommended to update the database character set and collation to use UTF encoding If your deployment uses the MySQL containerized database, please see the following updates to run DefectDojo:  Use of the helper script ‚Äúdc-up‚Äù: ./dc-up.sh mysql-rabbitmq or ./dc-up.sh mysql-redis Use of the helper script ‚Äúdc-up-d‚Äù: ./dc-up-d.sh mysql-rabbitmq or ./dc-up-d.sh mysql-redis Use of Docker Compose directly: docker-compose --profile mysql-rabbitmq --env-file ./docker/environments/mysql-rabbitmq.env up or docker-compose --profile mysql-redis --env-file ./docker/environments/mysql-redis.env up      For all other changes, check the Release Notes for the contents of the release.\n","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.23/","tags":"","title":"Upgrading to DefectDojo Version 2.23.x"},{"body":"There are no special instructions for upgrading to 2.22.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.22/","tags":"","title":"Upgrading to DefectDojo Version 2.22.x"},{"body":"There are no special instructions for upgrading to 2.21.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.21/","tags":"","title":"Upgrading to DefectDojo Version 2.21.x"},{"body":"There are no special instructions for upgrading to 2.20.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.20/","tags":"","title":"Upgrading to DefectDojo Version 2.20.x"},{"body":"There are new docker images based on alpine with fewer third party dependencies. Related to the new images the current docker files had to be renamed and have a ‚Äú-debian‚Äù or the new images a ‚Äú-alpine‚Äù at the end. Furthermore there are new docker tags [DefectdojoVersion]-[OS]. For example 2.19.0-alpine or 2.19.0-debian. The currend tags (latest and [DefectdojoVersion]) are still based on the ‚Äúold‚Äù images. Be aware that the new alpine images are not heavily tested and may contain bugs.\nBreaking Change\nIn version 2.19.3, the GitHub OAuth integration has been removed to prevent configurations that may allow more access than intended.\nDefectDojo Security Advisory: Severity Medium | Potential GitHub Authentication Misconfiguration\n","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.19/","tags":"","title":"Upgrading to DefectDojo Version 2.19.x"},{"body":"Upgrade instructions for helm chart with rabbitMQ enabled: The rabbitMQ uses a statefulset by default. Before upgrading the helm chart we have to ensure that all queues are empty:\nkubectl exec -i \u003cname_of_the_rabbitmq_pod\u003e -- rabbitmqctl list_queues Next step is to delete rabbitMQ pvc:\nkubectl delete pvc -l app.kubernetes.io/name=rabbitmq Last step is to perform the upgrade.\nFor more information: https://artifacthub.io/packages/helm/bitnami/rabbitmq/11.2.0\n","categories":"","description":"instructions for helm chart","excerpt":"instructions for helm chart","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.18/","tags":"","title":"Upgrading to DefectDojo Version 2.18.x"},{"body":"There are no special instructions for upgrading to 2.17.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.17/","tags":"","title":"Upgrading to DefectDojo Version 2.17.x"},{"body":"There are no special instructions for upgrading to 2.16.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.16/","tags":"","title":"Upgrading to DefectDojo Version 2.16.x"},{"body":"There are no special instructions for upgrading to 2.15.0. Check the Release Notes for the contents of the release.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.15/","tags":"","title":"Upgrading to DefectDojo Version 2.15.x"},{"body":"The last release implemented the search for vulnerability ids, but the search database was not initialized. To populate the database table of the vulnerability ids, execute this django command from the defect dojo installation directory or from a shell of the Docker container or Kubernetes pod:\n./manage.py migrate_cve\nAdditionally this requires a one-time rebuild of the Django-Watson search index. Execute this django command from the defect dojo installation directory or from a shell of the Docker container or Kubernetes pod:\n./manage.py buildwatson\nFurther changes:\nLegacy authorization for changing configurations based on staff users has been removed.\n","categories":"","description":"instructions for helm chart and others","excerpt":"instructions for helm chart and others","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.13/","tags":"","title":"Upgrading to DefectDojo Version 2.13.x"},{"body":"Breaking change for search: The field cve has been removed from the search index for Findings and the Vulnerability Ids have been added to the search index. With this the syntax to search explicitly for vulnerability ids have been changed from cve: to vulnerability_id:, e.g. vulnerability_id:CVE-2020-27619.\nUpgrade instructions for helm chart with postgres enabled: The postgres database uses a statefulset by default. Before upgrading the helm chart we have to delete the statefullset and ensure that the pvc is reused, to keep the data. For more information: https://docs.bitnami.com/kubernetes/infrastructure/postgresql/administration/upgrade/ .\nhelm repo update helm dependency update ./helm/defectdojo # obtain name oft the postgres pvc export POSTGRESQL_PVC=$(kubectl get pvc -l app.kubernetes.io/instance=defectdojo,role=primary -o jsonpath=\"{.items[0].metadata.name}\") # delete postgres statefulset kubectl delete statefulsets.apps defectdojo-postgresql --namespace default --cascade=orphan # upgrade helm upgrade \\  defectdojo \\  ./helm/defectdojo/ \\  --set primary.persistence.existingClaim=$POSTGRESQL_PVC \\  ... # add your custom settings ","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.12/","tags":"","title":"Upgrading to DefectDojo Version 2.12.x"},{"body":"Breaking change for Findings: The field cve will be replaced by a list of Vulnerability Ids, which can store references to security advisories associated with this finding. These can be Common Vulnerabilities and Exposures (CVE) or from other sources, eg. GitHub Security Advisories. Although the field does still exist in the code, the API and the UI have already been changed to use the list of Vulnerability Ids. Other areas like hash code calculation, search and parsers will be migrated step by step in later stages.\nThis change also causes an API change for the endpoint /engagements/{id}/accept_risks/.\n","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.10/","tags":"","title":"Upgrading to DefectDojo Version 2.10.x"},{"body":"Breaking change for APIv2: configuration_url was removed from API endpoint /api/v2/tool_configurations/ due to redundancy.\n","categories":"","description":"breaking change for APIv2","excerpt":"breaking change for APIv2","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.9/","tags":"","title":"Upgrading to DefectDojo Version 2.9.x"},{"body":"Breaking change for Docker Compose: Starting DefectDojo with Docker Compose now supports 2 databases (MySQL and PostgreSQL) and 2 celery brokers (RabbitMQ and Redis). To make this possible, docker-compose needs to be started with the parameters --profile and --env-file. You can get more information in Setup via Docker Compose - Profiles. The profile mysql-rabbitmq provides the same configuration as in previous releases. With this the prerequisites have changed as well: Docker requires at least version 19.03.0 and Docker Compose 1.28.0.\nBreaking change for Helm Chart: In one of the last releases we upgraded the redis dependency in our helm chart without renaming keys in our helm chart. We fixed this bug with this release, but you may want to check if all redis values are correct (Pull Request).\nThe flexible permissions for the configuration of DefectDojo are now active by default. With this, the flag Staff for users is not relevant and not visible anymore. The old behaviour can still be activated by setting the parameter FEATURE_CONFIGURATION_AUTHORIZATION to False. If you haven‚Äôt done so with the previous release, you can still run a migration script with ./manage.py migrate_staff_users. This script:\n creates a group for all staff users, sets all configuration permissions that staff users had and sets the global Owner role, if AUTHORIZATION_STAFF_OVERRIDE is set to True.  ","categories":"","description":"breaking changes","excerpt":"breaking changes","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.8/","tags":"","title":"Upgrading to DefectDojo Version 2.8.x"},{"body":"This release is a breaking change regarding the Choctaw Hog parser. As the maintainers of this project unified multiple parsers under the RustyHog parser, we now support the parsing of Choctaw Hog JSON output files through the Rusty Hog parser. Furthermore, we also support Gottingen Hog and Essex Hog JSON output files with the RustyHog parser.\nThere is another breaking change regarding the import of SSLyze scans. The parser has been renamed from SSLyze 3 Scan (JSON) to SSLyze Scan (JSON). The data in the database is fixed by the initializer, but it may break scripted API calls.\nRelease 2.7.0 contains a beta functionality to make permissions for the configuration of DefectDojo more flexible. When the settings parameter FEATURE_CONFIGURATION_AUTHORIZATION is set to True, many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their Superuser or Staff status, see Configuration Permissions.\nThe functionality using the flag AUTHORIZATION_STAFF_OVERRIDE has been removed. The same result can be achieved with giving the staff users a global Owner role.\nTo support the transition for these 2 changes, you can run a migration script with ./manage.py migrate_staff_users. This script:\n creates a group for all staff users, sets all configuration permissions that staff users had and sets the global Owner role, if AUTHORIZATION_STAFF_OVERRIDE is set to True.  ","categories":"","description":"breaking change","excerpt":"breaking change","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.7/","tags":"","title":"Upgrading to DefectDojo Version 2.7.x"},{"body":"There are no special instructions for upgrading to 2.6.0. Check the Release Notes for the contents of the release.\nPlease consult the security advisories GHSA-f82x-m585-gj24 (moderate) and GHSA-v7fv-g69g-x7p2 (high) to see what security issues were fixed in this release. These will be published and become visible at January 18th, 2022.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.6/","tags":"","title":"Upgrading to DefectDojo Version 2.6.x"},{"body":"Legacy authorization has been completely removed with version 2.5.0. This includes removal of the migration of users to the new authorization as described in https://documentation.defectdojo.com/getting_started/upgrading/#authorization. If you are still using the legacy authorization, you should run the migration with ./manage.py migrate_authorization_v2 before upgrading to version 2.5.0\nThis release introduces the ‚ÄúForgot password‚Äù functionality (DD_FORGOT_PASSWORD: default True). The function allows sending an e-mail with the reset password link. Missing configuration or misconfiguration of SMTP (DD_EMAIL_URL) could raise an error (HTTP-500). Check and test (for example by resetting your own password) if you configured SMTP correctly. If you want to avoid HTTP-500 and you don‚Äôt want to set up SMTP, you can just simply switch off the ‚ÄúForgot password‚Äù functionality (DD_FORGOT_PASSWORD=False).\nRelease renamed system setting mail_notifications_from to email_from. This value will not be used only for sending notifications but also for sending the reset password emails. It is highly recommended to check the content of this value if you are satisfied. If you installed DefectDojo earlier, you can expect \"from@example.com\" there. A fresh installation will use \"no-reply@example.com\"\nThis release updates our helm dependencies. There is a breaking change if you are using the mysql database from the helm chart because we replaced the deprecated chart from the stable repo with a chart from bitnami. If you have persistance enabled, ensure to backup your data before upgrading. All data get lost when replacing the mysql chart during the upgrade. For data migration take a look at the mysql backup and restore process.\nFurthermore we updated our kubernetes version. Current tests run on 1.18.16 and 1.22.0.\n","categories":"","description":"legacy authorization removed","excerpt":"legacy authorization removed","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.5/","tags":"","title":"Upgrading to DefectDojo Version 2.5.x"},{"body":"This releases fixes a High severity vulnerability for which the details will be disclosed on November 16th in GHSA-fwg9-752c-qh8w\nThere is a breaking change in the API for importing and re-importings scans with SonarQube API and Cobalt.io API. The scan configurations have been unified and are set now with the attribute api_scan_configuration. The existing configurations for SonarQube API and Cobalt.io API have been migrated.\nAt the request of pyup.io, we had to remove the parser for Safety scans.\n","categories":"","description":"security Release","excerpt":"security Release","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.4/","tags":"","title":"Upgrading to DefectDojo Version 2.4.x (Security Release)"},{"body":"There are no special instructions for upgrading to 2.3.0. In 2.3.0 we changed the default password hashing algorithm to Argon2 (from PBKDF2). When logging in, exising hashes get replaced by an Argon2 hash. If you want to rehash password without users having to login, please see the Django password management docs. The previous password hashing algorithm (PBKDF2) was not unsafe, but we wanted to follow the OWASP guidelines.\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.3/","tags":"","title":"Upgrading to DefectDojo Version 2.3.x"},{"body":"Upgrade to 2.0.0 contained migration of endpoints. Some parts of migration haven‚Äôt been done properly. This deficiency may manifest as a doubled slash in endpoint URLs (like http://foo.bar:8080//test) or as a problem with deduplication of the same endpoints. The mentioned bug was fixed in 2.2.0 and if you have seen these kinds of problems, just rerun ‚ÄúEndpoint migration‚Äù as it is written in Upgrading to DefectDojo Version 2.0.x..\n","categories":"","description":"No special instructions.","excerpt":"No special instructions.","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.2/","tags":"","title":"Upgrading to DefectDojo Version 2.2.x"},{"body":"Follow the usual steps to upgrade as described above.\nBEFORE UPGRADING\n If you are using SAML2 checkout the new documentaion and update you settings following the migration section. We replaced django-saml2-auth with djangosaml2.  AFTER UPGRADING\n Usual migration process (python manage.py migrate) try to migrate all endpoints to new format and merge duplicates. All broken endpoints (which weren‚Äôt possible to migrate) have red flag üö© in standard list of endpoints. Check if all your endpoints was migrated successfully, go to: https:///endpoint/migrate. Alternatively, this can be run as management command: docker-compose exec uwsgi ./manage.py endpoint_migration --dry-run When all endpoint will be fixed (there is not broken endpoint), press ‚ÄúRun migration‚Äù in https:///endpoint/migrate Or, you can run management command: docker-compose exec uwsgi ./manage.py endpoint_migration Details about endpoint migration / improvements in https://github.com/DefectDojo/django-DefectDojo/pull/4473  We decided to name this version 2.0.0 because we did some big cleanups in this release:\n  Remove API v1 (#4413)\n  Remove setup.bash installation method (#4417)\n  Rename Finding.is_Mitigated field to Finding.is_mitigated (#3854)\n  Remove everything related to the old tagging library (#4419)\n  Remove S0/S1/S2../S5 severity display option (#4415)\n  Refactor EndPoint handling/formatting (#4473)\n  Upgrade to Django 3.x (#3632)\n  PDF Reports removed (#4418)\n  Hashcode calculation logic has changed. To update existing findings run:\n./manage.py dedupe --hash_code_only.\n  If you‚Äôre using docker:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only.\nThis can take a while depending on your instance size.\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/2.0.0  Endpoints  The usual migration process (python manage.py migrate) tries to migrate all endpoints to new format and merge duplicates. All broken endpoints (which weren‚Äôt possible to migrate) have a red flag üö© in the standard list of endpoints. Check if all your endpoints were migrated successfully, go to: https:///endpoint/migrate. Alternatively, this can be run as management command: docker-compose exec uwsgi ./manage.py endpoint_migration --dry-run When all endpoint are fixed (there is not broken endpoint), press ‚ÄúRun migration‚Äù in https:///endpoint/migrate Or, you can run management command: docker-compose exec uwsgi ./manage.py endpoint_migration Details about endpoint migration / improvements in https://github.com/DefectDojo/django-DefectDojo/pull/4473  Authorization The new authorization system for Products and Product Types based on roles is the default now. The fields for authorized users are not available anymore, but you can assign roles as described in Permissions. Users are migrated automatically, so that their permissions are as close as possible to the previous authorization:\n Superusers will still have all permissions on Products and Product Types, so they must not be changed. Staff users have had all permissions for all product types and products, so they will be get a global role as Owner. Product_Members and Product Type_Members will be added for authorized users according to the settings for the previous authorization:  The Reader role is set as the default. If AUTHORIZED_USERS_ALLOW_STAFF is True, the user will get the Owner role for the respective Product or Product Type. If AUTHORIZED_USERS_ALLOW_CHANGE or AUTHORIZED_USERS_ALLOW_DELETE is True, the user will get the Writer role for the respective Product or Product Type.    The new authorization is active for both UI and API. Permissions set via authorized users or via the Django Admin interface are no longer taken into account.\nPlease review the roles for your users after the upgrade to avoid an unintended permissions creep.\n","categories":"","description":"breaking changes","excerpt":"breaking changes","ref":"/django-DefectDojo/dev/getting_started/upgrading/2.0/","tags":"","title":"Upgrading to DefectDojo Version 2.0.x"},{"body":"  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.15.0\n  If you have made changes to JIRA templates or the template config in the JIRA Project config for instances/products/engagements: The jira template settings introduced in 1.13 have been changed. You now have to select a subfolder instead of a sinlge template file. If you have chosen a non-default template here, you have to reapply that to all products / engagements. Also you have to move your custom templates into the correct subfolder in dojo/templates/issue-trackers/.\n  Hashcode calculation logic has changed in #4134, #4308 and #4310 to update existing findings run:\n./manage.py dedupe --hash_code_only\n  If you‚Äôre using docker:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only\nThis can take a while depending on your instance size.\n","categories":"","description":"hashcode calculation logic has changed","excerpt":"hashcode calculation logic has changed","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.15/","tags":"","title":"Upgrading to DefectDojo Version 1.15.x"},{"body":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.14.0  Note that the below fields are now optional without default value. They will not be filled anymore with values such as ‚ÄúNo references given‚Äù when found empty while saving the findings\n mitigation references impact url  ","categories":"","description":"hashcode calculation logic has changed","excerpt":"hashcode calculation logic has changed","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.14/","tags":"","title":"Upgrading to DefectDojo Version 1.14.x"},{"body":"  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.13.0\n  Hashcode settings affecting deduplication have changed, to update existing findings run:\n./manage.py dedupe\n  If you‚Äôre using docker:\ndocker-compose exec uwsgi ./manage.py dedupe  This can take a while depeneding on your instance size. It might possible that new duplicates are detected among existing findings, so make a backup before running!\n","categories":"","description":"hashcode calculation logic has changed","excerpt":"hashcode calculation logic has changed","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.13/","tags":"","title":"Upgrading to DefectDojo Version 1.13.x"},{"body":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.0 1.12.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.1  ","categories":"","description":"security release","excerpt":"security release","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.12/","tags":"","title":"Upgrading to DefectDojo Version 1.12.x"},{"body":" See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.0 1.11.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.1  ","categories":"","description":"security release","excerpt":"security release","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.11/","tags":"","title":"Upgrading to DefectDojo Version 1.11.x"},{"body":"1.10.4 is a security release\n See the security advisory: https://github.com/DefectDojo/django-DefectDojo/security/advisories/GHSA-96vq-gqr9-vf2c See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.10.4 Version 1.10.4 replaces 1.10.3 as the latter contained an incomplete fix  What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases DefectDojo now provides a settings.py file out-of-the-box. Custom settings need to go into local\\_settings.py. See https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.py and https://github.com/DefectDojo/django-DefectDojo/blob/master/docker/extra_settings/README.md A quickfix is to rename your own / customized settings.py or settings.dist.py to local\\_settings.py. Details of that PR: https://github.com/DefectDojo/django-DefectDojo/pull/3136 Major JIRA integration refactoring, for which you should at least use 1.10.1 and not 1.10.0 for many bug fixes.  Breaking changes\nKubernetes/Helm users: we have moved away from the \"stable\" repository to \"bitnami\" in this release. The bitnami postgresql chart required us to add a new key to the postgresql secret, which will give you the error postgresql-postgres-password is missing if you have createPostgresqlSecret: false. In 1.10.1, a fix was also included to allow your existing postgresqlPassword to be reused properly.\nIncluding in 1.10.1 were a couple fixes related to a rabbitMQ upgrade. The path to access password, erlangCookie and existingPasswordSecret changed from rabbitmq to auth. Furthermore, as rabbitMQ is deployed as a StatefulSet, an in-place upgrade is not possible and an error will likely be thrown such as Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden. After ensuring your rabbitMQ celery queue is empty, you will then want to delete your rabbitMQ StatefulSet and PVC to allow them to get re-created, or fully delete and recreate defectdojo.\n","categories":"","description":"security release + breaking changes","excerpt":"security release + breaking changes","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.10/","tags":"","title":"Upgrading to DefectDojo Version 1.10.x"},{"body":"This is a security release\n See the security advisory See release notes  What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases  NOTE:\nWhen upgrading from before 1.9.2, a corrective script may need to be ran\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\n Search index tweaking index rebuild after upgrade:  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson]\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\n","categories":"","description":"security release","excerpt":"security release","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.9.3/","tags":"","title":"Upgrading to DefectDojo Version 1.9.3"},{"body":"What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases Improved search, which requires an index rebuild (https://github.com/DefectDojo/django-DefectDojo/pull/2861)  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\n NOTE:  As a result of a breaking bug revolving around Endpoint_status objects, a corrective script will need to be ran after every dynamic scan imported through either API version.\nThe script can be found here\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\n","categories":"","description":"fix buildwatson create_endpoint_status","excerpt":"fix buildwatson create_endpoint_status","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.8.0/","tags":"","title":"Upgrading to DefectDojo Version 1.8.0"},{"body":"What's New:\n Updated search, you can now search for CVE-XXXX-YYYY Updated search index, fields added to index: 'id', 'title', 'cve', 'url', 'severity', 'description', 'mitigation', 'impact', 'steps_to_reproduce', 'severity_justification', 'references', 'sourcefilepath', 'sourcefile', 'hash_code', 'file_path', 'component_name', 'component_version', 'unique_id_from_tool'  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson dojo.Finding\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson dojo.Finding\nUpgrading to DefectDojo Version 1.5.0 What's New:\n Updated UI with a new DefectDojo logo, default colors and CSS. Updated Product views with tabs for Product Overview, Metrics, Engagements, Endpoints, Benchmarks (ASVS), and Settings to make it easier to navigate and manage your products. New Product Information fields: Regulations, Criticality, Platform, Lifecycle, Origin, User Records, Revenue, External Audience, Internet Accessible Languages pie chart on product overview, only supported through the API and Django admin, integrates with cloc analyzer New Engagement type of CI/CD to support continual testing Engagement shortcuts and ability to import findings and auto-create an engagement Engagement labels for overdue, no tests and findings New Contextual menus throughout DefectDojo and shortcuts to new findings and critical findings Ability to merge a finding into a parent finding and either inactivate or delete the merged findings. Report improvements and styling adjustment with the default option of HTML reports SLA for remediation of severities based on finding criticality, for example critical findings remediated within 7 days. Configurable in System Settings. Engagement Auto-Close Days in System Settings. Automatically close an engagement if open past the end date. Ability to apply remediation advice based on CWE. For example XSS can be configured as a template so that it's consistent across all findings. Enabled in system settings. Finding confidence field supported from scanners. First implementation in the Burp importer. Goast importer for static analysis of Golang products Celery status check on System Settings Beta rules framework release for modifying findings on the fly DefectDojo 2.0 API with Swagger support Created and Modified fields on all major tables Various bug fixes reported on Github  Upgrading to 1.5.0 requirements:\n  Back up your database first, ideally take the backup from production and test the upgrade on a staging server.\n  Edit the settings.py file which can be found in django-DefectDojo/dojo/settings/settings.py. Copy in the rest framework configuration after the CSRF_COOKIE_SECURE = True:\nREST_FRAMEWORK = { 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.TokenAuthentication', 'rest_framework.authentication.BasicAuthentication', ), 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.DjangoModelPermissions', ), 'DEFAULT_RENDERER_CLASSES': ( 'rest_framework.renderers.JSONRenderer', ), 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination', 'PAGE_SIZE': 25 }    Navigate to: LOGIN_EXEMPT_URLS and add the following after r'^%sfinding/image/(?P\u003ctoken\u003e[^/]+)$' % URL_PREFIX:\nr'^%sfinding/image/(?P\u003ctoken\u003e[^/]+)$' % URL_PREFIX, r'^%sapi/v2/' % URL_PREFIX,  Navigate to: INSTALLED_APPS and add the following after: 'multiselectfield',:\n'multiselectfield', 'rest_framework', 'rest_framework.authtoken', 'rest_framework_swagger', 'dbbackup',  Navigate to: CELERY_TASK_IGNORE_RESULT = True and add the following after CELERY_TASK_IGNORE_RESULT line:\nCELERY_RESULT_BACKEND = 'db+sqlite:///dojo.celeryresults.sqlite'  Save your modified settings file. For reference the modified file should look like the new 1.5.0 [settings](https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.dist.py) file, minus the environmental configurations. As an alternative this file can be used and the enviromental configurations from you environment can be copied into this file.\nActivate your virtual environment and then upgrade the requirements:  pip install -r requirements.txt --upgrade\n Upgrade the database:\n./manage.py makemigrations ./manage.py migrate    Collect the static files (Javascript, Images, CSS):\n./manage.py collectstatic --noinput    Complete\n  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.7.0/","tags":"","title":"Upgrading to DefectDojo Version 1.7.0"},{"body":"What's New:\n New importers for Contrast, Nikto and TruffleHog (finding secrets in git repos). Improved merging of findings for dynamic and static importers Markdown support for findings HTML report improvements including support of Markdown. System settings Celery status page to assist in debugging if Celery is functional.  Upgrading to 1.3.1 requires:\n pip install markdown pip install pandas ./manage.py makemigrations ./manage.py migrate ./manage.py collectstatic --noinput Complete  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.3.1/","tags":"","title":"Upgrading to DefectDojo Version 1.3.1"},{"body":"What's New: New feature: Benchmarks (OWASP ASVS)\nUpgrading to 1.2.9 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/benchmark_type.json ./manage.py loaddata dojo/fixtures/benchmark_category.json ./manage.py loaddata dojo/fixtures/benchmark_requirement.json ./manage.py collectstatic --noinput Complete  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.2.9/","tags":"","title":"Upgrading to DefectDojo Version 1.2.9"},{"body":"New feature: Product Grading (Overall Product Health) Upgrading to 1.2.8 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py system_settings ./manage.py collectstatic --noinput pip install asteval pip install --upgrade celery Complete  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.2.8/","tags":"","title":"Upgrading to DefectDojo Version 1.2.8"},{"body":"Upgrading to 1.2.4 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/objects_review.json  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.2.4/","tags":"","title":"Upgrading to DefectDojo Version 1.2.4"},{"body":"Upgrading to 1.2.3 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/language_type.json Currently languages and technologies can be updated via the API or in the admin section of Django.  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.2.3/","tags":"","title":"Upgrading to DefectDojo Version 1.2.3"},{"body":"Upgrading to 1.2.2 requires:\n Copying settings.py to the settings/ folder. If you have supervisor scripts change DJANGO_SETTINGS_MODULE=dojo.settings.settings  ","categories":"","description":"multiple instructions","excerpt":"multiple instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/1.2.2/","tags":"","title":"Upgrading to DefectDojo Version 1.2.2"},{"body":"","categories":"","description":"","excerpt":"","ref":"/django-DefectDojo/dev/link_knowledge-base/","tags":"","title":"Knowledge Base"},{"body":"NGINX The webserver NGINX delivers all static content, e.g. images, JavaScript files or CSS files.\nuWSGI uWSGI is the application server that runs the DefectDojo platform, written in Python/Django, to serve all dynamic content.\nMessage Broker The application server sends tasks to a Message Broker for asynchronous execution. RabbitMQ is a well established choice.\nCelery Worker Tasks like deduplication or the JIRA synchronization are performed asynchronously in the background by the Celery Worker.\nCelery Beat In order to identify and notify users about things like upcoming engagements, DefectDojo runs scheduled tasks. These tasks are scheduled and run using Celery Beat.\nInitializer The Initializer setups / maintains the database and syncs / runs migrations after version upgrades. It shuts itself down after all tasks are performed.\nDatabase The Database stores all the application data of DefectDojo. Currently PostgreSQL and MySQL are supported, with PostgreSQL being the recommended option. Please note the django-watson search engine require one or more MyISAM tables, so you cannot use Azure MySQL or Cloud SQL for MySQL. AWS RDS MySQL supports MyISAM tables.\n","categories":"","description":"The DefectDojo platform consists of several components that work together closely.","excerpt":"The DefectDojo platform consists of several components that work ‚Ä¶","ref":"/django-DefectDojo/dev/getting_started/architecture/","tags":"","title":"Architecture"},{"body":"Product Type Product types represent the top level model, these can be business unit divisions, different offices or locations, development teams, or any other logical way of distinguishing ‚Äútypes‚Äù of products.\n Examples:  IAM Team Internal / 3rd Party Main company / Acquisition San Francisco / New York offices    Product This is the name of any project, program, or product that you are currently testing.\n Examples:  Wordpress Internal wiki Slack    Engagement Engagements are moments in time when testing is taking place. They are associated with a name for easy reference, a time line, a lead (the user account of the main person conducting the testing), a test strategy, and a status. Engagement consists of two types: Interactive and CI/CD. An interactive engagement is typically an engagement conducted by an engineer, where findings are usually uploaded by the engineer. A CI/CD engagement, as it‚Äôs name suggests, is for automated integration with a CI/CD pipeline.\n Examples:  Beta Quarterly PCI Scan Release Version X    Test Tests are a grouping of activities conducted by engineers to attempt to discover flaws in a product. Tests are bundled within engagements, have a start and end date and are defined by a test type.\n Examples:  Burp Scan from Oct. 29, 2015 to Oct. 29, 2015 Nessus Scan from Oct. 31, 2015 to Oct. 31, 2015 API Test from Oct. 15, 2015 to Oct. 20, 2015    Finding A finding represents a flaw discovered while testing. It can be categorized with severities of Critical, High, Medium, Low, and Informational (Info).\n Examples:  OpenSSL ‚ÄòChangeCipherSpec‚Äô MiTM Potential Vulnerability Web Application Potentially Vulnerable to Clickjacking Web Browser XSS Protection Not Enabled    Endpoint Endpoints represent testable systems defined by their IP address or Fully Qualified Domain Name.\n Examples:  https://www.example.com https://www.example.com:8080/products 192.168.0.36    ","categories":"","description":"DefectDojo is made to be flexible to conform to your program, rather than making your team conform to the tool.","excerpt":"DefectDojo is made to be flexible to conform to your program, rather ‚Ä¶","ref":"/django-DefectDojo/dev/usage/models/","tags":"","title":"Core data classes"},{"body":"","categories":"","description":"Report uploaded to DefectDojo as files","excerpt":"Report uploaded to DefectDojo as files","ref":"/django-DefectDojo/dev/integrations/parsers/file/","tags":"","title":"Files"},{"body":"","categories":"","description":"How to install and configure DefectDojo","excerpt":"How to install and configure DefectDojo","ref":"/django-DefectDojo/dev/getting_started/","tags":"","title":"Getting started"},{"body":"Import The importers analyze each report and create new Findings for each item reported. DefectDojo collapses duplicate Findings by capturing the individual hosts vulnerable.\nThis approach will create a new Test for each upload. This can result in a lot of findings. If deduplication is enabled, new Findings that are identical to existing Findings get marked as a duplicate.\nReimport Additionally, DefectDojo allows for re-imports of previously uploaded reports. This greatly reduces the amount of findings as no duplicates are created for findings that already exist.\nDefectDojo will attempt to capture the deltas between the original and new import and automatically add or mitigate findings as appropriate.\nThis behaviour can be controled via the closed_old_findings parameter on the reupload form.\nThe history of a test will be shown with the delta‚Äôs for each reimported scan report. Clicking on a reimport changset will show the affected findings, as well as a status history per finding. Triage-less scanners Some scanners might not include triage information in their reports (e.g. tfsec). They simply scan code or dependencies, flag issues, and return everything. Removing some findings requires you to add comments in your code perhaps, but there is no simple way to filter out findings from the reports.\nThat is why DefectDojo also includes a ‚ÄúDo not reactivate‚Äù checkbox in uploading reports (also in the reimport API), so you can persist the triages that have been done in Defectdojo without reactivating Findings on every upload.\nFor context, see #6892\nAPI This section focuses on Import and Reimport via the API. Please see the full documentation details of all API Endpoints for more details. Reimport is actually the easiest way to get started as it will create any entities on the fly if needed and it will automatically detect if it is a first time upload or a re-upload.\nImport Importing via the API is performed via the import-scan endpoint.\nAs described in the Core Data Classes, a test gets created inside an Engagement, inside a Product, inside a Product Type.\nAn import can be performed by specifying the names of these entities in the API request:\n{ \"minimum_severity\": 'Info', \"active\": True, \"verified\": True, \"scan_type\": 'ZAP Scan', \"test_title\": 'Manual ZAP Scan by John', \"product_type_name\": 'Good Products', \"product_name\": 'My little product', \"engagement_name\": 'Important import', \"auto_create_context\": True, } When auto_create_context is True, the product and engagement will be created if needed. Make sure your user has sufficient permissions to do this.\nA classic way of importing a scan is by specifying the ID of the engagement instead:\n{ \"minimum_severity\": 'Info', \"active\": True, \"verified\": True, \"scan_type\": 'ZAP Scan', \"test_title\": 'Manual ZAP Scan by John', \"engagement\": 123, } Reimport ReImporting via the API is performed via the reimport-scan endpoint.\nA reimport can be performed by specifying the names of these entities in the API request:\n{ \"minimum_severity\": 'Info', \"active\": True, \"verified\": True, \"scan_type\": 'ZAP Scan', \"test_title\": 'Manual ZAP Scan by John', \"product_type_name\": 'Good Products', \"product_name\": 'My little product', \"engagement_name\": 'Important import', \"auto_create_context\": True, \"do_not_reactivate\": False, } When auto_create_context is True, the product and engagement will be created if needed. Make sure your user has sufficient permissions to do this.\nWhen do_not_reactivate is True, the importing/reimporting will ignore uploaded active findings and not reactivate previously closed findings, while still creating new findings if there are new ones. You will get a note on the finding to explain that it was not reactivated for that reason.\nA reimport will automatically select the latest test inside the provided engagement that satisifes the provided scan_type and (optionally) provided test_title.\nIf no existing Test is found, the reimport endpoint will use the import function to import the provided report into a new Test. This means a (CI/CD) script using the API doesn‚Äôt need to know if a Test already exists, or if it is a first time upload for this Product / Engagement.\nA classic way of reimporting a scan is by specifying the ID of the test instead:\n{ \"minimum_severity\": 'Info', \"active\": True, \"verified\": True, \"scan_type\": 'ZAP Scan', \"test\": 123, } Using the Scan Completion Date (API: scan_date) field DefectDojo offers a plethora of supported scanner reports, but not all of them contain the information most important to a user. The scan_date field is a flexible smart feature that allows users to set the completion date of the a given scan report, and have it propagate down to all the findings imported. This field is not mandatory, but the default value for this field is the date of import (whenever the request is processed and a successful response is returned).\nHere are the following use cases for using this field:\n The report does not set the date, and scan_date is not set at import  Finding date will be the default value of scan_date   The report sets the date, and the scan_date is not set at import  Finding date will be whatever the report sets   The report does not set the date, and the scan_date is set at import  Finding date will be whatever the user set for scan_date   The report sets the date, and the scan_date is set at import  Finding date will be whatever the user set for scan_date    ","categories":"","description":"How DefectDojo imports and reimports security tool reports.","excerpt":"How DefectDojo imports and reimports security tool reports.","ref":"/django-DefectDojo/dev/integrations/importing/","tags":"","title":"Importing"},{"body":"Use this template as part of writing a new parser.\n Copy this .md file and add it to docs/integrations/parsers/file in the GitHub repository Update the title to match the name of your new parser Fill out all sections listed below  File Types Specify all file types accepted by your parser. Include a process for creating the acceptable file from the related security tool.\nSample Scan Data / Unit Tests Add a link to the relevant unit tests or sample scan data folder in the GitHub repository.\nLink To Tool A link to the scanner itself - (e.g. GitHub or appropriate vendor link)\n","categories":"","description":"","excerpt":"Use this template as part of writing a new parser.\n Copy this .md file ‚Ä¶","ref":"/django-DefectDojo/dev/contributing/parser-documentation-template/","tags":"","title":"Parser Documentation Template"},{"body":" Information All commands assume that you‚Äôre located at the root of the django-DefectDojo cloned repo.  Pre-requisites  You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally. Checkout dev and make sure you‚Äôre up to date with the latest changes. It‚Äôs advised that you create a dedicated branch for your development, such as git checkout -b parser-name.  It is easiest to use the docker-compose deployment as it has hot-reload capbility for uWSGI. Set up your environment to use the debug environment:\n$ docker/setEnv.sh debug\nPlease have a look at DOCKER.md for more details.\nDocker images You will want to build your docker images locally, and eventually pass in your local user‚Äôs uid to be able to write to the image (handy for database migration files). Assuming your user‚Äôs uid is 1000, then:\n$ docker-compose build --build-arg uid=1000 Which files do you need to modify?    File Purpose     dojo/tools/\u003cparser_dir\u003e/__init__.py Empty file for class initialization   dojo/tools/\u003cparser_dir\u003e/parser.py The meat. This is where you write your actual parser. The class name must be the Python module name without underscores plus Parser. Example: When the name of the Python module is dependency_check, the class name shall be DependencyCheckParser   unittests/scans/\u003cparser_dir\u003e/{many_vulns,no_vuln,one_vuln}.json Sample files containing meaningful data for unit tests. The minimal set.   unittests/tools/test_\u003cparser_name\u003e_parser.py Unit tests of the parser.   dojo/settings/settings.dist.py If you want to use a modern hashcode based deduplication algorithm   doc/content/en/integrations/parsers/\u003cfile/api\u003e/\u003cparser_file\u003e.md Documentation, what kind of file format is required and how it should be obtained    Factory contract Parsers are loaded dynamicaly with a factory pattern. To have your parser loaded and works correctly, you need to implement the contract.\n your parser MUST be in a sub-module of module dojo.tools  ex: dojo.tools.my_tool.parser module   your parser MUST be a class in this sub-module.  ex: dojo.tools.my_tool.parser.MyToolParser   The name of this class MUST be the Python module name without underscores and with Parser suffix.  ex: dojo.tools.my_tool.parser.MyToolParser   This class MUST have an empty constructor or no constructor This class MUST implement 3 methods:  def get_scan_types(self) This function return a list of all the scan_type supported by your parser. This identifiers are used internally. Your parser can support more than one scan_type. For example some parsers use different identifier to modify the behavior of the parser (aggregate, filter, etc‚Ä¶) def get_label_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (short label) def get_description_for_scan_types(self, scan_type): This function return a string used to provide some text in the UI (long description) def get_findings(self, file, test) This function return a list of findings   If your parser have more than 1 scan_type (for detailled mode) you MUST implement def set_mode(self, mode) method  Example:\nclass MyToolParser(object): def get_scan_types(self): return [\"My Tool Scan\", \"My Tool Scan detailed\"] def get_label_for_scan_types(self, scan_type): if scan_type == \"My Tool Scan\": return \"My Tool XML Scan aggregated by ...\" else: return \"My Tool XML Scan\" def get_description_for_scan_types(self, scan_type): return \"Aggregates findings per cwe, title, description, file_path. SonarQube output file can be imported in HTML format. Generate with https://github.com/soprasteria/sonar-report version \u003e= 1.1.0\" def requires_file(self, scan_type): return False # mode: # None (default): aggregates vulnerabilites per sink filename (legacy behavior) # 'detailed' : No aggregation mode = None def set_mode(self, mode): self.mode = mode def get_findings(self, file, test): \u003c...\u003e API Parsers DefectDojo has a limited number of API parsers. While we won‚Äôt remove these connectors, adding API connectors has been problematic and thus we cannot accept new API parsers / connectors from the community at this time for supportability reasonsing. To maintain a high quality API connector, it is necessary to have a license to the tool. To get that license requires partnership with the author or vendor. We‚Äôre close to announcing a new program to help address this and bring API connectors to DefectDojo.\nTemplate Generator Use the template parser to quickly generate the files required. To get started you will need to install cookiecutter.\n$ pip install cookiecutter Then generate your scanner parser from the root of django-DefectDojo:\n$ cookiecutter https://github.com/DefectDojo/cookiecutter-scanner-parser Read more on the template configuration variables.\nThings to pay attention to Here is a list of considerations that will make the parser robust for both common cases and edge cases.\nDo not parse URLs by hand We use 2 modules to handle endpoints:\n hyperlink dojo.models with a specific class to handle processing around URLs to create endpoints Endpoint.  All the existing parser use the same code to parse URL and create endpoints. Using Endpoint.from_uri() is the best way to create endpoints. If you really need to parse an URL, use hyperlink module.\nGood example:\nif \"url\" in item: endpoint = Endpoint.from_uri(item[\"url\"]) finding.unsaved_endpoints = [endpoint] Very bad example:\nu = urlparse(item[\"url\"]) endpoint = Endpoint(host=u.host) finding.unsaved_endpoints = [endpoint] Not all attributes are mandatory Parsers may have many fields, out of which many of them may be optional. It better to not set attribute if you don‚Äôt have data instead of filling with values like NA, No data etc‚Ä¶\nCheck class dojo.models.Finding\nData could be missing in the source report Always make sure you include checks to avoid potential KeyError errors (e.g. field does not exist), for those fields you are not absolutely certain will always be in file that will get uploaded. These translate to 500 error, and do not look good.\nGood example:\nif \"mykey\" in data: finding.cwe = data[\"mykey\"] Do not parse CVSS by hand (vector, score or severity) Data can have CVSS vectors or scores. Don‚Äôt write your own CVSS score algorithm. For parser, we rely on module cvss.\nIt‚Äôs easy to use and will make the parser aligned with the rest of the code.\nExample of use:\nfrom cvss.cvss3 import CVSS3 import cvss.parser vectors = cvss.parser.parse_cvss_from_text(\"CVSS:3.0/S:C/C:H/I:H/A:N/AV:P/AC:H/PR:H/UI:R/E:H/RL:O/RC:R/CR:H/IR:X/AR:X/MAC:H/MPR:X/MUI:X/MC:L/MA:X\") if len(vectors) \u003e 0 and type(vectors[0]) == CVSS3: print(vectors[0].severities()) # this is the 3 severities cvssv3 = vectors[0].clean_vector() severity = vectors[0].severities()[0] vectors[0].compute_base_score() cvssv3_score = vectors[0].scores()[0] print(severity) print(cvssv3_score) Good example:\nvectors = cvss.parser.parse_cvss_from_text(item['cvss_vect']) if len(vectors) \u003e 0 and type(vectors[0]) == CVSS3: finding.cvss = vectors[0].clean_vector() finding.severity = vectors[0].severities()[0] # if your tool does generate severity Bad example (DIY):\ndef get_severity(self, cvss, cvss_version=\"2.0\"): cvss = float(cvss) cvss_version = float(cvss_version[:1]) # If CVSS Version 3 and above if cvss_version \u003e= 3: if cvss \u003e 0 and cvss \u003c 4: return \"Low\" elif cvss \u003e= 4 and cvss \u003c 7: return \"Medium\" elif cvss \u003e= 7 and cvss \u003c 9: return \"High\" elif cvss \u003e= 9: return \"Critical\" else: return \"Informational\" # If CVSS Version prior to 3 else: if cvss \u003e 0 and cvss \u003c 4: return \"Low\" elif cvss \u003e= 4 and cvss \u003c 7: return \"Medium\" elif cvss \u003e= 7 and cvss \u003c= 10: return \"High\" else: return \"Informational\" Deduplication algorithm By default a new parser uses the ‚Äòlegacy‚Äô deduplication algorithm documented at https://documentation.defectdojo.com/usage/features/#deduplication-algorithms\nPlease use a pre-defined deduplication algorithm where applicable.\nUnit tests Each parser must have unit tests, at least to test for 0 vuln, 1 vuln and many vulns. You can take a look at how other parsers have them for starters. The more quality tests, the better.\nIt‚Äôs important to add checks on attributes of findings. For ex:\nwith self.subTest(i=0): finding = findings[0] self.assertEqual(\"test title\", finding.title) self.assertEqual(True, finding.active) self.assertEqual(True, finding.verified) self.assertEqual(False, finding.duplicate) self.assertIn(finding.severity, Finding.SEVERITIES) self.assertEqual(\"CVE-2020-36234\", finding.vulnerability_ids[0]) self.assertEqual(261, finding.cwe) self.assertEqual(\"CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\", finding.cvssv3) self.assertIn(\"security\", finding.tags) self.assertIn(\"network\", finding.tags) self.assertEqual(\"3287f2d0-554f-491b-8516-3c349ead8ee5\", finding.unique_id_from_tool) self.assertEqual(\"TEST1\", finding.vuln_id_from_tool) Use with to open example files In order to make certain that file handles are closed properly, please use the with pattern to open files. Instead of:\ntestfile = open(\"path_to_file.json\") ... testfile.close() use:\nwith open(\"path_to_file.json\") as testfile: ... This ensures the file is closed at the end of the with statement, even if an exception occurs somewhere in the block.\nTest database To test your unit tests locally, you first need to grant some rights. Get your MySQL root password from the docker-compose logs, login as root and issue the following commands:\nMYSQL\u003e grant all privileges on test_defectdojo.* to defectdojo@'%'; MYSQL\u003e flush privileges; Run your tests This local command will launch the unit test for your new parser\n$ docker-compose exec uwsgi bash -c 'python manage.py test unittests.tools.\u003cyour_unittest_py_file\u003e.\u003cmain_class_name\u003e -v2' Example for the blackduck hub parser:\n$ docker-compose exec uwsgi bash -c 'python manage.py test unittests.tools.test_blackduck_csv_parser.TestBlackduckHubParser -v2' Information If you want to run all unit tests, simply run $ docker-compose exec uwsgi bash -c 'python manage.py test unittests -v2'  Endpoint validation Some types of parsers create a list of endpoints that are vulnerable (they are stored in finding.unsaved_endpoints). DefectDojo requires storing endpoints in a specific format (which follow RFCs). Endpoints that do not follow this format can be stored but they will be marked as broken (red flag üö©in UI). To be sure your parse store endpoints in the correct format run the .clean() function for all endpoints in unit tests\nfindings = parser.get_findings(testfile, Test()) for finding in findings: for endpoint in finding.unsaved_endpoints: endpoint.clean() Tests API Parsers Not only parser but also importer should be tested. patch method from unittest.mock is usualy usefull for simulating API responses. It is highly recommeded to use it.\nOther files that could be involved Change to the model In the event where you‚Äôd have to change the model, e.g. to increase a database column size to accomodate a longer string of data to be saved\n  Change what you need in dojo/models.py\n  Create a new migration file in dojo/db_migrations by running and including as part of your PR\n$ docker-compose exec uwsgi bash -c 'python manage.py makemigrations -v2'    Accept a different type of file to upload If you want to be able to accept a new type of file for your parser, take a look at dojo/forms.py around line 436 (at the time of this writing) or locate the 2 places (for import and re-import) where you find the string attrs={\"accept\":.\nFormats currently accepted: .xml, .csv, .nessus, .json, .html, .js, .zip.\nA need for more than just the parser.py Of course, nothing prevents you from having more files than the parser.py file. It‚Äôs python :-)\nPull request examples If you want to take a look at previous parsers that are now part of DefectDojo, take a look at https://github.com/DefectDojo/django-DefectDojo/pulls?q=is%3Apr+sort%3Aupdated-desc+label%3A%22Import+Scans%22+is%3Aclosed\nUpdate the import page documentation Please add a new .md file in [docs/content/en/integrations/parsers] with the details of your new parser. Include the following content headings:\n Acceptable File Type(s) - please include how to generate this type of file from the related tool, as some tools have multiple methods or require specific commands. An example unit test block, if applicable. A link to the relevant unit tests folder so that users can quickly navigate there from Documentation. A link to the scanner itself - (e.g. GitHub or vendor link)  Here is an example of a completed Parser documentation page: https://defectdojo.github.io/django-DefectDojo/integrations/parsers/file/awssecurityhub/\n","categories":"","description":"How to contribute to parsers","excerpt":"How to contribute to parsers","ref":"/django-DefectDojo/dev/contributing/how-to-write-a-parser/","tags":"","title":"Parsers"},{"body":"","categories":"","description":"DefectDojo has the ability to import scan reports from a large number of security tools.","excerpt":"DefectDojo has the ability to import scan reports from a large number ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/","tags":"","title":"Supported reports"},{"body":"All parsers that use API pull have common basic configuration steps, but with different values.\nFollow these steps to set up API importing:\n  Configure the API authentication details by navigating to Configuration -\u003e Tool Configuration -\u003e Add Tool Configuration. Enter a Name, selecting the related Tool Type and Authentication Type ‚ÄúAPI Key‚Äù. Paste your credentials to the proper fields based on definitions below.\n  In the Product settings select Add API Scan Configuration and select the previously added Tool Configuration. Provide values based on definitions below.\n  After this is done, you can import the findings on the Product page through Findings -\u003e Import Scan Results. As the Scan type, select the related type, the API scan configuration from the last step, and click Import.\n  ","categories":"","description":"Report pulled to DefectDojo via API exposed by scanning service","excerpt":"Report pulled to DefectDojo via API exposed by scanning service","ref":"/django-DefectDojo/dev/integrations/parsers/api/","tags":"","title":"API Pull"},{"body":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/doc/ and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.\nThe documentation is generated using drf-spectacular at /api/v2/oa3/swagger-ui/, and is interactive. On the top of API v2 docs is a link that generates an OpenAPI v3 spec.\nTo interact with the documentation, a valid Authorization header value is needed. Visit the /api/key-v2 view to generate your API Key (Token \u003capi_key\u003e) and copy the header value provided.\nEach section allows you to make calls to the API and view the Request URL, Response Body, Response Code and Response Headers.\nIf you‚Äôre logged in to the Defect Dojo web UI, you do not need to provide the authorization token.\nAuthentication The API uses header authentication with API key. The format of the header should be: :\nAuthorization: Token \u003capi.key\u003e  For example: :\nAuthorization: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff  Alternative authentication method If you use an alternative authentication method for users, you may want to disable DefectDojo API tokens because it could bypass your authentication concept.\nUsing of DefectDojo API tokens can be disabled by specifying the environment variable DD_API_TOKENS_ENABLED to False.\nSample Code Here are some simple python examples and their results produced against the /users endpoint: :\nimport requests url = 'http://127.0.0.1:8000/api/v2/users' headers = {'content-type': 'application/json', 'Authorization': 'Token c8572a5adf107a693aa6c72584da31f4d1f1dcff'} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\"'{key}': '{value}'\") print('------------------') This code will return the list of all the users defined in DefectDojo. The json object result looks like : :\n[ { \"first_name\": \"Tyagi\", \"id\": 22, \"last_login\": \"2019-06-18T08:05:51.925743\", \"last_name\": \"Paz\", \"username\": \"dev7958\" }, { \"first_name\": \"saurabh\", \"id\": 31, \"last_login\": \"2019-06-06T11:44:32.533035\", \"last_name\": \"\", \"username\": \"saurabh.paz\" } ] Here is another example against the /users endpoint, this time we will filter the results to include only the users whose user name includes jay:\nimport requests url = 'http://127.0.0.1:8000/api/v2/users/?username__contains=jay' headers = {'content-type': 'application/json', 'Authorization': 'Token c8572a5adf107a693aa6c72584da31f4d1f1dcff'} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.items(): print(f\"'{key}': '{value}'\") print('------------------') The json object result is: :\n[ { \"first_name\": \"Jay\", \"id\": 22, \"last_login\": \"2015-10-28T08:05:51.925743\", \"last_name\": \"Paz\", \"username\": \"jay7958\" }, { \"first_name\": \"\", \"id\": 31, \"last_login\": \"2015-10-13T11:44:32.533035\", \"last_name\": \"\", \"username\": \"jay.paz\" } ] See Django Rest Framework's documentation on interacting with an API for additional examples and tips.\nManually calling the API Tools like Postman can be used for testing the API.\nExample for importing a scan result:\n  Verb: POST\n  URI: http://localhost:8080/api/v2/import-scan/\n  Headers tab:\n add the authentication header  Key: Authorization Value: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff      Body tab\n select \"form-data\", click \"bulk edit\". Example for a ZAP scan:    engagement:3 verified:true active:true lead:1 tags:test scan_type:ZAP Scan minimum_severity:Info skip_duplicates:true close_old_findings:false    Body tab\n Click \"Key-value\" edit Add a \"file\" parameter of type \"file\". This will trigger multi-part form data for sending the file content Browse for the file to upload    Click send\n  Clients / API Wrappers    Wrapper Status Notes     Specific python wrapper working (2021-01-21) API Wrapper including scripts for continous CI/CD uploading. Is lagging behind a bit on latest API features as we plan to revamp the API wrapper   Openapi python wrapper  proof of concept only where we found out the the OpenAPI spec is not perfect yet   Java library working (2021-08-30) Created by the kind people of SecureCodeBox   Image using the Java library working (2021-08-30)    .Net/C# library working (2021-06-08)    dd-import working (2021-08-24) dd-import is not directly an API wrapper. It offers some convenience functions to make it easier to import findings and language data from CI/CD pipelines.    Some of the api wrappers contain quite a bit of logic to ease scanning and importing in CI/CD environments. We are in the process of simplifying this by making the DefectDojo API smarter (so api wrappers / script can be dumber).\n","categories":"","description":"DefectDojo's API lets you automate tasks, e.g. uploading scan reports in CI/CD pipelines.","excerpt":"DefectDojo's API lets you automate tasks, e.g. uploading scan reports ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/api-v2-docs/","tags":"","title":"DefectDojo API v2"},{"body":"The documentation is built with Hugo and uses the theme Docsy. Static files for the webside are build with github actions and are publish in the gh-pages branch.\nHow to run a local preview   Install Hugo. Make sure you have installed the extended version with Sass/SCSS support. Please note there are various Linux packages available on Hugo GitHub\n  Install JavaScript packages\nTo build or update your site‚Äôs CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default, npm installs tools under the directory where you run npm install:\ncd docs npm install    Clone the DefectDojo git repository with the option --recurse-submodules. If you have already cloned the repository, make sure that you have checked out out the Docsy theme or use git submodule to check it out:\ncd docs/themes/docsy git submodule update --init --recursive    Switch to the docs folder and start the hugo server with hot reloading hugo server -D --config config.dev.toml\n  Visit http://localhost:1313/django-DefectDojo/dev.\n  See also the Docsy installation procedures for reference.\n","categories":"","description":"How to amend the documentation","excerpt":"How to amend the documentation","ref":"/django-DefectDojo/dev/contributing/documentation/","tags":"","title":"Documentation"},{"body":"Tags In DefectDojo, tags are a first class citizen and are recognized as the facilitators of organization within each level of the data model. Tags are ideal for grouping objects in a manner that can be filtered out into smaller, more digestible chunks.\nHere is an example with a product with two tags and four findings each with a single tag\nFormat of tag Tags can be formatted in any of the following ways:\n StringWithNoSpaces string-with-hyphens string_with_underscores colons:acceptable ‚Äúquoted string with spaces‚Äù ‚Äúquoted,comma,tag‚Äù ‚Äúquoted with spaces, and also commas!‚Äù  Adding and Removing Tags can be managed in the following ways\n  Creating or Editing new objects\nWhen a new object is created or edited through the UI or API, there is a field for specifying the tags to be set on a given object. This field is a multiselect field that also has auto completion to make searching and adding existing tags a breeze. Here is what the field looks like on the product from the screenshot in the previous section:\n  Import and Reimport\nTags can also be applied to a given test at the time of import or reimport. This is a very handy use case when importing via the API with automation as it provides an opportunity to append automation run details and tool information that may not be captured in the test or finding object directly.\nThe field looks and behaves exactly as it does on a given object\n  Bulk Edit Menu (Findings only)\nWhen needing to update many findings with the same set of tags, the bulk edit menu can be used to ease the burden.\nIn the following example, lets say I want to update the tags of the two findings with the tag ‚Äútag-group-alpha‚Äù to be a new tag list like this [‚Äútag-group-charlie‚Äù, ‚Äútag-group-delta‚Äù]. First I would select the tags to be updated:\nOnce a finding is selected, a new button appears with the name ‚ÄúBulk Edit‚Äù. Clicking this button produces a dropdown menu with many options, but the focus is just on tags for now. Update the field to have the desired tag list as follows, and click submit\nThe tags on the selected Findings will be updated to whatever was specified in the tags field within the bulk edit menu\n  Filtering Tags can be filtered in many ways through both the UI and the API. For example, here is a snippet of the Finding filters:\nThere are ten fields related to tags:\n Tags: filter on any tags that are attached to a given Finding  Examples:  Finding will be returned  Finding Tags: [‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù] Filter Query: ‚ÄúB‚Äù   Finding Will not be returned  Finding Tags: [‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù] Filter Query: ‚ÄúF‚Äù       Not Tags: filter on any tags that are not attached to a given Finding  Examples:  Finding will be returned  Finding Tags: [‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù] Filter Query: ‚ÄúF‚Äù   Finding Will not be returned  Finding Tags: [‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù] Filter Query: ‚ÄúB‚Äù       Tag Name Contains: filter on any tags that contain part or all of the query in the given Finding  Examples:  Finding will be returned  Finding Tags: [‚ÄúAlpha‚Äù, ‚ÄúBeta‚Äù, ‚ÄúCharlie‚Äù] Filter Query: ‚Äúet‚Äù (part of ‚ÄúBeta‚Äù)   Finding Will not be returned  Finding Tags: [‚ÄúAlpha‚Äù, ‚ÄúBeta‚Äù, ‚ÄúCharlie‚Äù] Filter Query: ‚Äúmeg‚Äù (part of ‚ÄúOmega‚Äù)       Not Tags: filter on any tags that do not contain part or all of the query in the given Finding  Examples:  Finding will be returned  Finding Tags: [‚ÄúAlpha‚Äù, ‚ÄúBeta‚Äù, ‚ÄúCharlie‚Äù] Filter Query: ‚Äúmeg‚Äù (part of ‚ÄúOmega‚Äù)   Finding Will not be returned  Finding Tags: [‚ÄúAlpha‚Äù, ‚ÄúBeta‚Äù, ‚ÄúCharlie‚Äù] Filter Query: ‚Äúet‚Äù (part of ‚ÄúBeta‚Äù)        For the other six tag filters, they follow the same rules as ‚ÄúTags‚Äù and ‚ÄúNot Tags‚Äù as above, but at different levels in the data model:\n Tags (Test): filter on any tags that are attached to the Test of a given Finding is part of Not Tags (Test): filter on any tags that are not attached to the Test of a given Finding is part of Tags (Engagement): filter on any tags that are attached to the Engagement of a given Finding is part of Not Tags (Engagement): filter on any tags that are not attached to the Engagement of a given Finding is part of Tags (Product): filter on any tags that are attached to the Product of a given Finding is part of Not Tags (Product): filter on any tags that are not attached to the Product of a given Finding is part of  Tag Inheritance When enabled, tags applied to a given product will automatically be applied to all objects under products in the data model.\nConfiguration Tag Inheritance can be enabled at the following scope levels:\n Global Scope  Every product system wide will begin applying tags to all children objects This is set within the System Settings   Product Scope  Only the selected product will begin applying tags to all children objects This is set at the product creation/edit page    Behaviors Tags can be added and removed to other objects the same as when tag inheritance is disabled. The only exception to that rule being inherited tags as they cannot be removed from an object. See the following example of adding a tag ‚Äútest_only_tag‚Äù to the Test object and a tag ‚Äúengagement_only_tag‚Äù to the Engagement.\nWhen updates are made to the tag list on a product, the same changes are made to all objects within the product asynchronously. The duration of this task directly correlates to the number the objects contained within a finding. If the results are not observed within a reasonable time period, consult the celery worker logs to identify where any problems might have arisen.\nRisk Acceptance Findings cannot always be remediated or addressed for various reasons. A finding 'status' can be change to 'accepted' by doing the following: Findings are accepted in the engagement view. To locate the engagement from the finding click the link to engagement as shown below.\nThen, in the engagement view click the plus icon in the 'Risk Acceptance' box and fill in the details to support the risk acceptance.\nThe engagement view is now updated with the risk.\nThe finding status changes to 'Accepted' with a link to the risk acceptance.\nDeduplication Deduplication is a feature that when enabled will compare findings to automatically identify duplicates. When deduplication is enabled, a list of deduplicated findings is added to the engagement view. The following image illustrates the option deduplication on engagement and deduplication on product level:\nUpon saving a finding, DefectDojo will look at the other findings in the product or the engagement (depending on the configuration) to find duplicates\nWhen a duplicate is found:\n The newly imported finding takes status: inactive, duplicate An \"Original\" link is displayed after the finding status, leading to the original finding  There are two ways to use the deduplication:\n Deduplicate vulnerabilities in the same build/release. The vulnerabilities may be found by the same scanner (same scanner deduplication) or by different scanners (cross-scanner deduplication). this helps analysis and assessment of the technical debt, especially if using many different scanners; although detecting duplicates across scanners is not trivial as it requires a certain standardization. Track unique vulnerabilities across builds/releases so that DefectDojo knows when it finds a vulnerability that has seen it before.  this allows you keep information attached to a given finding in a unique place: all further duplicate findings will point to the original one.\n  Deduplication configuration Global configuration The deduplication can be activated in \"System Settings\" by ticking \"Deduplicate findings\".\nAn option to delete duplicates can be found in the same menu, and the maximum number of duplicates to keep for the same finding can be configured.\nEngagement configuration When creating or editing an engagement, the \"Deduplication within engagement only\" checkbox can be ticked.\n If activated: Findings are only deduplicated within the same engagement. Findings present in different engagements cannot be duplicates Otherwise: Findings are deduplicated across the whole product  Note that currently deduplication does not occur across different products.\nDeduplication algorithms The behavior of the deduplication can be configured for each parser in settings.dist.py (or settings.py after install) by configuring the DEDUPLICATION_ALGORITHM_PER_PARSER variable, or via the env variable (useful for Kubernetes deployments) DD_DEDUPLICATION_ALGORITHM_PER_PARSER with a JSON string like\n{\"ScannerName\":\"algorithm\"} The environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe available algorithms are:\n DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL The deduplication occurs based on finding.unique_id_from_tool which is a unique technical id existing in the source tool. Few scanners populate this field currently. If you want to use this algorithm, you may need to update the scanner code beforehand.  Advantages:  If your source tool has a reliable means of tracking a unique vulnerability across scans, this configuration will allow defectDojo to use this ability.   Drawbacks:  Using this algorithm will not allow cross-scanner deduplication as other tools will have a different technical id. When the tool evolves, it may change the way the unique id is generated. In that case you won't be able to recognise that findings found in previous scans are actually the same as the new findings.     DEDUPE_ALGO_HASH_CODE The deduplication occurs based on finding.hash_code. The hash_code itself is configurable for each scanner in parameter HASHCODE_FIELDS_PER_SCANNER. DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE A finding is a duplicate with another if they have the same unique_id_from_tool OR the same hash_code.  Allows to use both  a technical deduplication (based on unique_id_from_tool) for a reliable same-parser deduplication and a functional one (based on hash_code configured on CWE+severity+file_path for example) for cross-parser deduplication     DEDUPE_ALGO_LEGACY This is algorithm that was in place before the configuration per parser was made possible, and also the default one for backward compatibility reasons.  Legacy algorithm basically deduplicates based on:  For static scanner: ['title', 'cwe', 'line', 'file_path', 'description'] For dynamic scanner: ['title', 'cwe', 'line', 'file_path', 'description', 'endpoints']    Note that there are some subtleties that may give unexpected results. Switch dojo.specific-loggers.deduplication to debug in settings.py to get more info in case of trouble.\n  Hash_code computation configuration The hash_code computation can be configured for each parser using the parameter HASHCODE_FIELDS_PER_SCANNER in settings.dist.py, or via the env variable (useful for Kubernetes deployments) DD_HASHCODE_FIELDS_PER_SCANNER with a JSON string like\n{\"ScannerName\":[\"field1\", \"field2\"]} The environment variable will override the settings in settings.dist.py, replacing by matching the keys.\nThe parameter HASHCODE_ALLOWED_FIELDS list the fields from finding table that were tested and are known to be working when used as a hash_code. Don't hesitate to enrich this list when required (the code is generic and allows adding new fields by configuration only)\nNote that endpoints isn't a field from finding table but rather a meta value that will trigger a computation based on all the endpoints.\nWhen populating HASHCODE_FIELDS_PER_SCANNER, please respect the order of declaration of the fields: use the same order as in HASHCODE_ALLOWED_FIELDS: that will allow cross-scanner deduplication to function because the hash_code is computed as a sha-256 of concatenated values of the configured fields.\nTips:\n  It's advised to use fields that are standardized for a reliable deduplication, especially if aiming at cross-scanner deduplication. For example title and description tend to change when the tools evolve and don't allow cross-scanner deduplication\n Good candidates are  cwe or cve Adding the severity will make sure the deduplication won't be to aggressive (there are several families of XSS and sql injection for example, with various severities but the same cwe). Adding the file_path or endpoints is advised too.      The parameter HASHCODE_ALLOWS_NULL_CWE will allow switching to legacy algorithm when a null cwe is found for a given finding: this is to avoid getting many duplicates when the tool fails to give a cwe while we are expecting it.\n  Hashcode generation / regeneration When you change the hashcode configuration, it is needed to regenerated the hashcodes for all findings, or at least those findings found by scanners for which the configuration was updated.\nThis is sometimes also needed after an upgrade to a new DefectDojo version, for example when we made changes to the hashcode configuration or calculation logic. We will mention this in the upgrade notes.\nTo regenerate the hashcodes, use the dedupe management command:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only This will only regenerated the hashcodes, but will not run any deduplication logic on existing findings. If you want to run deduplication again on existing findings to make sure any duplicates found by the new hashcode config are marked as such, run:\ndocker-compose exec uwsgi ./manage.py dedupe The deduplication part of this command will run the deduplication for each finding in a celery task. If you want to run the deduplication in the foreground process, use:\ndocker-compose exec uwsgi ./manage.py dedupe --dedupe_sync Please note the deduplication process is resource intensive and can take a long time to complete (estimated ~7500 findings per minute when run in the foreground)\nDebugging deduplication There is a specific logger that can be activated in order to have details about the deduplication process : switch dojo.specific-loggers.deduplication to debug in settings.dist.py.\nDeduplication - APIv2 parameters  close_old_findings : if true, findings that are not duplicates and that were in the previous scan of the same type (example ZAP) for the same engagement (or product in case of \"close_old_findings_product_scope\") and that are not present in the new scan are closed (Inactive, Verified, Mitigated). close_old_findings_product_scope : if true, close_old_findings applies to all findings of the same type in the product. Note that \"Deduplication on engagement\" is no longer used to determine the scope of close_old_findings.  Deduplication / Similar findings Similar Findings Visualization:\n Similar Findings While viewing a finding, similar findings within the same product are listed along with buttons to mark one finding a duplicate of the other. Clicking the \"Use as original\" button on a similar finding will mark that finding as the original while marking the viewed finding as a duplicate. Clicking the \"Mark as duplicate\" button on a similar finding will mark that finding as a duplicate of the viewed finding. If a similar finding is already marked as a duplicate, then a \"Reset duplicate status\" button is shown instead which will remove the duplicate status on that finding along with marking it active again.  Service Level Agreement (SLA) DefectDojo allows you to maintain your security SLAs and automatically remind teams whenever a SLA is about to get breached, or is breached.\nTo apply SLAs to Findings, open the System Settings page and check ‚ÄòEnable Finding SLAs‚Äô.\nYou will then need to create one or more SLA Configurations, from the SLA Configuration menu (your-defectdojo.com/sla_config).\nSLA notification configuration There are 3 variables in the system settings that can be set for notifications of SLA breaches. By default notifications are disabled. You can either choose to notify about breaches for findings that are only in ‚ÄòActive‚Äô or for any findings across the instance that are in Active, Verified. Furthermore, it is possible choose to only consider findings that have a JIRA issue linked to them.\nThere are 2 variables in the settings.py file that you can configure, to act on the global behavior.\nSLA_NOTIFY_PRE_BREACH = 3 SLA_NOTIFY_POST_BREACH = 7 The SLA_NOTIFY_PRE_BREACH is expressed in days. Whenever a finding's \"SLA countdown\" (time to remediate) drops to this number, a notification would be sent everyday, as scheduled by the crontab in settings.py, until the day it breaches.\nThe SLA_NOTIFY_POST_BREACH lets you define in days how long you want to be kept notified about findings that have breached the SLA. Passed that number, notifications will cease.\nWarning Be mindful of performance if you choose to have SLA notifications on non-verified findings, especially if you import a lot of findings through CI in 'active' state.  What notification channels for SLA notifications? You will notice that an extra SLA breach option is now present on the Notification page and also in the Product view.\nSLA notification with JIRA You can choose to also send SLA notification as JIRA comments, if your product is configured with JIRA. You can enable this at the Product level in the Product specific JIRA settings.\nThe Product level JIRA notification configuration takes precendence over the global JIRA notification configuration.\nWhen is the SLA notification job run? The default setup will trigger the SLA notification code at 7:30am on a daily basis, as defined in the settings.py file. You can of course modify this schedule to your context.\n'compute-sla-age-and-notify': { 'task': 'dojo.tasks.async_sla_compute_and_notify', 'schedule': crontab(hour=7, minute=30), } Information The celery containers are the ones concerned with this configuration. If you suspect things are not working as expected, make sure they have the latest version of your settings.py file.  You can of course change this default by modifying that stanza.\nLaunching from the CLI You can also invoke the SLA¬†notification function from the CLI. For example, if run from docker-compose:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py sla_notifications' Reports Instant reports Instant reports can be generated for:\n Product types Products Engagements Tests List of Findings Endpoints  Filtering is available on all report generation views to aid in focusing the report for the appropriate need.\nCustom reports Custom reports, generated with the Report Builder, allow you to select specific components to be added to the report. These include:\n Cover Page Table of Contents WYSIWYG Content Findings Vulnerable Endpoints Page Breaks  DefectDojo‚Äôs reports can be generated in HTML.\nMetrics DefectDojo provides a number of metrics visualization in order to help with reporting, awareness and to be able to quickly communicate a products/product type's security stance.\nThe following metric views are provided:\n Product Type Metrics This view provides graphs displaying Open Bug Count by Month, Accepted Bug Count by Month, Open Bug Count by Week, Accepted Bug Count by Week as well as tabular data on Top 10 Products by bug severity, Detail Breakdown of all reported findings, Opened Findings, Accepted Findings, Closed Findings, Trending Open Bug Count, Trending Accepted Bug Count, and Age of Issues.  Product Type Counts This view provides tabular data of Total Current Security Bug Count, Total Security Bugs Opened In Period, Total Security Bugs Closed In Period, Trending Total Bug Count By Month, Top 10 By Bug Severity, and Open Findings. This view works great for communication with stakeholders as it is a snapshot in time of the product.  Product Tag Counts Same as above, but for a group of products sharing a tag. Simple Metrics Provides tabular data for all Product Types. The data displayed in this view is the total number of S0, S1, S2, S3, S4, Opened This Month, and Closed This Month.  Engineer Metrics Provides graphs displaying information about a tester's activity.  Metrics Dashboard Provides a full screen, auto scroll view with many metrics in graph format. This view is great for large displays or \"Dashboards.\"   Users DefectDojo users inherit from django.contrib.auth.models.User.\nA username, first name, last name, and email address can be associated with each user. Additionally the following attributes describe the type of users:\n Active Designates whether this user should be treated as active and can login to DefectDojo. Unselect this instead of deleting accounts. Superuser status Designates that this user can configure the system and has all permissions for objects without explicitly assigning them.  A superuser may force a password reset for any user at any given time. This can be set when creating a new user, or when editing an existing one, requiring the user to change their password upon their next login.\nDefectDojo enforces the following password rules for all users:\n Must meet a length requirement of 9 characters Must be unique (not commonly used) Must contain one of each of the following: a number (0-9), uppercase letter (A-Z), lowercase letter (a-z), and symbol ()[]{}|~!@#$%^\u0026*_-+=;:`'\",\u003c\u003e./?  Calendar The calendar view provides a look at all the engagements and tests occurring during the month d, week or day displayed. Each entry is a direct link to the respective engagement or test view page.\nBenchmarks DefectDojo utilizes the OWASP ASVS Benchmarks to benchmark a product to ensure the product meets your application technical security controls. Benchmarks can be defined per the organizations policy for secure development and multiple benchmarks can be applied to a product.\nBenchmarks are available from the Product view. To view the configured benchmarks select the dropdown menu from the right hand drop down menu. You will find the selection near the bottom of the menu entitled: 'OWASP ASVS v.3.1'.\nIn the Benchmarks view for each product, the default level is ASVS Level\n On the top right hand side the drop down can be changed to the desired ASVS level (Level 1, Level 2 or Level 3). The publish checkbox will display the ASVS score on the product page and in the future this will be applied to reporting.  On the left hand side the ASVS score is displayed with the desired score, the % of benchmarks passed to achieve the score and the total enabled benchmarks for that AVSV level.\nAdditional benchmarks can be added/updated in the Django admin site. In a future release this will be brought out to the UI.\nEndpoint Meta Importer For heavy infrastructure scanning organizations, endpoints need to be as flexible as possible to get the most of DefectDojo. This flexibility comes in the form of Tags and custom fields. Tags allow users to filter, sort, and report objects in ways the base object is not totally proficient in doing.\nEndpoint Meta Importer provides a means to apply arbitrary tags and custom fields to endpoints in mass via a CSV file. Tags and customs fields are stored in the format of column:row.\nHere is a very simple example with only two columns:\nhostname | team | public_facing ------------------------------------------------------------------ sheets.google.com | data analytics | yes docs.google.com | language processing | yes feedback.internal.google.com | human resources | no The three endpoints hosts will be used to find existing endpoints with matching hosts, or create new endpoints, and then apply meta as follows:\nsheets.google.com (endpoint) -\u003e [ team:data analytics, public_facing:yes ] (tags) docs.google.com (endpoint) -\u003e [ team:language processing, public_facing:yes ] (tags) feedback.internal.google.com (endpoint) -\u003e [ team:human resources, public_facing:no ] (tags) Endpoint Meta Importer can be found in the Endpoint tab when viewing a Product\nNote: The field ‚Äúhostname‚Äù is required as it is used to query/create endpoints.\nFindings Image Upload You can add images (.png, .jpeg, .gif) to your findings. In order to achieve this, you have to click on ‚ÄúManage Files‚Äù within the finding: There, you can upload a png file to attach it to a finding: The following picture shows the result: ","categories":"","description":"Various features help manage vulnerabilities.","excerpt":"Various features help manage vulnerabilities.","ref":"/django-DefectDojo/dev/usage/features/","tags":"","title":"Features"},{"body":"Recommended Options  Docker Compose See instructions in DOCKER.md\nSaaS (Includes Support \u0026 Supports the Project) SaaS link\nAWS AMI (Supports the Project) Marketplace link, and complete walkthrough\n Options for the brave (not officially supported)  Kubernetes See instructions in KUBERNETES.md\nLocal install with godojo See instructions in README.md in the godojo repository\n Customizing of settings See Configuration\n","categories":"","description":"DefectDojo supports various installation options.","excerpt":"DefectDojo supports various installation options.","ref":"/django-DefectDojo/dev/getting_started/installation/","tags":"","title":"Installation"},{"body":"Product Health Grading Within DefectDojo‚Äôs system settings, you have the opportunity to enable a grading system for your products. For that you have to enable (‚ÄúEnable Product Grading‚Äù). Then, the products are graded with the following possible grades:\n Grade A Grade B Grade C Grade D Grade F  The best grade is A going down to the worst grade F. By default the grades stick to the achieved percentage mentioned in grade converation here.\nCalculation of the grades The code that performs the grade calculations can be found here.\nThe highest health score is 100 and it decreases based on the number of findings for each severity (critical, high, medium, low) within the product. In the following code snippet you can see the rules. Note that the following abbreviations were used:\n crit: amount of critical findings within the product high: amount of high findings within the product med: amount of medium findings within the product low: amount of low findings within the product  health=100 if crit \u003e 0: health = 40 health = health - ((crit - 1) * 5) if high \u003e 0: if health == 100: health = 60 health = health - ((high - 1) * 3) if med \u003e 0: if health == 100: health = 80 health = health - ((med - 1) * 2) if low \u003e 0: if health == 100: health = 95 health = health - low if health \u003c 5: health = 5 return health ","categories":"","description":"Products are graded based on their health.","excerpt":"Products are graded based on their health.","ref":"/django-DefectDojo/dev/usage/productgrading/","tags":"","title":"Product Health Grading"},{"body":"","categories":"","description":"How to use DefectDojo to manage vulnerabilities","excerpt":"How to use DefectDojo to manage vulnerabilities","ref":"/django-DefectDojo/dev/usage/","tags":"","title":"Usage"},{"body":"Auth0 In the same way as with other identity providers, it‚Äôs now possible to leverage Auth0 to authenticate users on DefectDojo.\n  Inside your Auth0 dashboard create a new application (Applications / Create Application / Single Page Web Application).\n  On the new application set the following fields:\n Name: ‚ÄúDefectdojo‚Äù Allowed Callback URLs: https://the_hostname_you_have_dojo_deployed:your_server_port/complete/auth0/    Copy the following info from the application:\n Domain Client ID Client Secret    Now, edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_AUTH0_OAUTH2_ENABLED=True DD_SOCIAL_AUTH_AUTH0_KEY=(str, '**YOUR_CLIENT_ID_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_AUTH0_SECRET=(str,'**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_AUTH0_DOMAIN=(str, '**YOUR_AUTH0_DOMAIN_FROM_STEP_ABOVE**'),    Restart DefectDojo, and you should now see a Login with Auth0 button on the login page.\n  Google New to DefectDojo, a Google account can now be used for Authentication, Authorization, and a DefectDojo user. Upon login with a Google account, a new user will be created if one does not already exist. The criteria for determining whether a user exists is based on the users username. In the event a new user is created, the username is that of the Google address without the domain. Once created, the user creation process will not happen again as the user is recalled by its username, and logged in. In order to make the magic happen, a Google authentication server needs to be created. Closely follow the steps below to guarantee success.\n  Navigate to the following address and either create a new account, or login with an existing one: Google Developers Console\n  Once logged in, find the key shaped button labeled Credentials on the left side of the screen. Click Create Credentials, and choose OAuth Client ID:\n  Select Web Applications, and provide a descriptive name for the client.\n  Add the pictured URLs in the Authorized Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access.\n  Once all URLs are added, finish by clicking Create\n  Now with the authentication client created, the Client ID and Client Secret Key need to be copied over to the settings. Click the newly created client and copy the values:\n  Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_GOOGLE_OAUTH2_KEY=(str, '**YOUR_CLIENT_ID_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET=(str, '**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**'),  To authorize users you will need to set the following:\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS = ['example.com', 'example.org']  or\nDD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS = ['\u003cemail@example.com\u003e']    OKTA In a similar fashion to that of Google, using OKTA as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\n  Navigate to the following address and either create a new account, or login with an existing one: OKTA Account Creation\n  Once logged in, enter the Applications and click Add Application:\n  Select Web Applications.\n  Add the pictured URLs in the Login Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access. Check the Implicit box as well.\n  Once all URLs are added, finish by clicking Done.\n  Return to the Dashboard to find the Org-URL. Note this value as it will be important in the settings file.\n  Now, with the authentication client created, the Client ID and Client Secret Key need to be copied over to the settings. Click the newly created client and copy the values:\n  Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_OKTA_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_OKTA_OAUTH2_KEY=(str, '**YOUR_CLIENT_ID_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_OKTA_OAUTH2_SECRET=(str, '**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_OKTA_OAUTH2_API_URL=(str, 'https://{your-org-url}/oauth2'),    If during the login process you get the following error: The ‚Äòredirect_uri‚Äô parameter must be an absolute URI that is whitelisted in the client app settings. and the redirect_uri HTTP GET parameter starts with http:// instead of https:// you need to add SOCIAL_AUTH_REDIRECT_IS_HTTPS = True in the settings.\nAzure Active Directory Azure AD Configuration You can now use your corporate Azure Active Directory to authenticate users to Defect Dojo. Users will be using your corporate Azure AD account (A.K.A. Office 365 identity) to authenticate via OAuth, and all the conditional access rules and benefits from Azure Active Directory will also apply to the Defect Dojo Authentication. Once the user signs in, it will try to match the UPN of the user to an existing e-mail from a user in Defect Dojo, and if no match is found, a new user will be created in Defect Dojo, associated with the unique id/value of the user provided by your Azure AD tenant. Then, you can assign roles to this user, such as ‚Äòsuperuser‚Äô.\n  Navigate to the following address and follow instructions to create a new app registration\n https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app    Once you register an app, take note of the following information:\n Application (client) ID Directory (tenant) ID Under Certificates \u0026 Secrets, create a new Client Secret    Under Authentication \u003e Redirect URIs, add a WEB type of uri where the redirect points to\n http://localhost:8080/complete/azuread-tenant-oauth2/ OR https://the_hostname_you_have_dojo_deployed:your_server_port/complete/azuread-tenant-oauth2/    Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_KEY=(str, 'YOUR_APPLICATION_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_SECRET=(str, 'YOUR_CLIENT_SECRET_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_TENANT_ID=(str, 'YOUR_DIRECTORY_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_ENABLED = True    Restart your Dojo, and you should now see a Login with Azure AD button on the login page which should magically work\n  Automatic Import of User-Groups To import groups from Azure AD users, the following environment variable needs to be set:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS=True   This will ensure the user is added to all the groups found in the Azure AD Token. Any missing groups will be created in DefectDojo (unless filtered). This group synchronization allows for product access via groups to limit the products a user can interact with.\nThe Azure AD token returned by Azure will also need to be configured to include group IDs. Without this step, the token will not contain any notion of a group, and the mapping process will report that the current user is not a member of any groups. To update the the format of the token, add a group claim that applies to whatever group type you are using. If unsure of what type that is, select All Groups. Do not activate Emit groups as role claims within the Azure AD ‚ÄúToken configuration‚Äù page.\nApplication API permissions need to be updated with the Group.Read.All permission so that groups can be read on behalf of the user that has successfully signed in.\nTo limit the amount of groups imported from Azure AD, a regular expression can be used as the following:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GROUPS_FILTER='^team-.*' # or 'teamA|teamB|groupC'   Automatic Cleanup of User-Groups To prevent authorization creep, old Azure AD groups a user is not having anymore can be deleted with the following environment parameter:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS=True   When a user is removed from a given group in Azure AD, they will also be removed from the corresponding group in DefectDojo. If there is a group in DefectDojo, that no longer has any members, it will be left as is for record purposes.\nGitlab In a similar fashion to that of Google and OKTA, using Gitlab as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\n  Navigate to your Gitlab settings page and got to the Applications section\n https://gitlab.com/profile/applications OR https://the_hostname_you_have_gitlab_deployed:your_gitlab_port/profile/applications    Choose a name for your application\n  For the Redirect URI, enter the DefectDojo URL with the following format\n https://the_hostname_you_have_dojo_deployed:your_server_port/complete/gitlab/    Edit the settings (see Configuration) with the following information:\nDD_SOCIAL_AUTH_GITLAB_KEY=(str, 'YOUR_APPLICATION_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_GITLAB_SECRET=(str, 'YOUR_SECRET_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_GITLAB_API_URL=(str, 'https://gitlab.com'), DD_SOCIAL_AUTH_GITLAB_OAUTH2_ENABLED = True  Additionally, if you want to import your Gitlab projects as DefectDojo products, add the following line to your settings:\nDD_SOCIAL_AUTH_GITLAB_PROJECT_AUTO_IMPORT = True  Important: if you enable this setting on already working instance with gitlab integrations, it will require new grant ‚Äúread_repository‚Äù by user\n  Restart DefectDojo, and you should now see a Login with Gitlab button on the login page.\n  Keycloak There is also an option to use Keycloak as OAuth2 provider in order to authenticate users to Defect Dojo, also by using the social-auth plugin.\nHere are suggestion on how to configure Keycloak and DefectDojo:\nConfigure Keycloak (assuming you already have an existing realm, otherwise create one)\n Navigate to your keycloak realm and add a new client of type openid-connect. Choose a name for the client id and use this value below for DD_SOCIAL_AUTH_KEYCLOAK_KEY). In the client settings:  Set access type to confidential Under valid Redirect URIs, add the URI to your defect dojo installation, e.g. ‚Äòhttps://\u003cYOUR_DD_HOST\u003e/*‚Äô Under web origins, add the same (or ‚Äò+') Under Fine grained openID connect configuration -\u003e user info signed response algorithm: set to RS256 Under Fine grained openID connect configuration -\u003e request object signature algorithm: set to RS256 -\u003e save these settings in keycloak (hit save button)   Under Scope -\u003e Full Scope Allowed set to off Under mappers -\u003e add a custom mapper here:  Name: aud Mapper type: audience Included audience: select your client/client-id here Add ID to token: off Add access to token: on   Under credentials: copy the secret (and use as DD_SOCIAL_AUTH_KEYCLOAK_SECRET below) In your realm settings -\u003e keys: copy the ‚ÄúPublic key‚Äù (signing key) (use for DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY below) In your realm settings -\u003e general -\u003e endpoints: look into openId endpoint configuration and look up your authorization and token endpoint (use them below)  Configure Defect Dojo Edit the settings (see Configuration) with the following information:\nDD_SESSION_COOKIE_SECURE=True, DD_CSRF_COOKIE_SECURE=True, DD_SECURE_SSL_REDIRECT=True, DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED=True, DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY=(str, '\u003cyour realm public key\u003e'), DD_SOCIAL_AUTH_KEYCLOAK_KEY=(str, '\u003cyour client id\u003e'), DD_SOCIAL_AUTH_KEYCLOAK_SECRET=(str, '\u003cyour keycloak client credentials secret\u003e'), DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL=(str, '\u003cyour authorization endpoint\u003e'), DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL=(str, '\u003cyour token endpoint\u003e')  or, alternatively, for helm configuration, add this to the extraConfig section:\nDD_SESSION_COOKIE_SECURE: 'True' DD_CSRF_COOKIE_SECURE: 'True' DD_SECURE_SSL_REDIRECT: 'True' DD_SOCIAL_AUTH_KEYCLOAK_OAUTH2_ENABLED: 'True' DD_SOCIAL_AUTH_KEYCLOAK_PUBLIC_KEY: '\u003cyour realm public key\u003e' DD_SOCIAL_AUTH_KEYCLOAK_KEY: '\u003cyour client id\u003e' DD_SOCIAL_AUTH_KEYCLOAK_SECRET: '\u003cyour keycloak client credentials secret\u003e' DD_SOCIAL_AUTH_KEYCLOAK_AUTHORIZATION_URL: '\u003cyour authorization endpoint\u003e' DD_SOCIAL_AUTH_KEYCLOAK_ACCESS_TOKEN_URL: '\u003cyour token endpoint\u003e' Optionally, you can set DD_SOCIAL_AUTH_KEYCLOAK_LOGIN_BUTTON_TEXT in order to customize the login button‚Äôs text caption.\nGitHub Enterprise  Navigate to your GitHub Enterprise Server and follow instructions to create a new OAuth App https://docs.github.com/en/enterprise-server/developers/apps/building-oauth-apps/creating-an-oauth-app Choose a name for your application For the Redirect URI, enter the DefectDojo URL with the following format  https://the_hostname_you_have_dojo_deployed:your_server_port/complete/github-enterprise/   Edit the settings (see Configuration) with the following information: DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_KEY=(str, 'GitHub Enterprise OAuth App Client ID'), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_SECRET=(str, 'GitHub Enterprise OAuth App Client Secret'), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_URL=(str, 'https://github.\u003cyour_company\u003e.com/'), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_API_URL=(str, 'https://github.\u003cyour_company\u003e.com/api/v3/'), DD_SOCIAL_AUTH_GITHUB_ENTERPRISE_OAUTH2_ENABLED = True,  Restart DefectDojo, and you should now see a Login with GitHub Enterprise button on the login page.  SAML 2.0 In a similar direction to OAuth, this SAML addition provides a more secure perogative to SSO. For definitions of terms used and more information, see the plugin plugin homepage.\n  Navigate to your SAML IdP and find your metadata\n  Edit the settings (see Configuration) with the following information:\nDD_SAML2_ENABLED=(bool, **True**), # SAML Login Button Text DD_SAML2_LOGIN_BUTTON_TEXT=(str, 'Login with SAML'), # If the metadata can be accessed from a url, try the DD_SAML2_METADATA_AUTO_CONF_URL=(str, '\u003chttps://your_IdP.com/metadata.xml\u003e'), # Otherwise, downlaod a copy of the metadata into an xml file, and # list the path in DD_SAML2_METADATA_LOCAL_FILE_PATH DD_SAML2_METADATA_LOCAL_FILE_PATH=(str, '/path/to/your/metadata.xml'), # Fill in DD_SAML2_ATTRIBUTES_MAP to corresponding SAML2 userprofile attributes provided by your IdP DD_SAML2_ATTRIBUTES_MAP=(dict, { # format: SAML attrib:django_user_model 'Email': 'email', 'UserName': 'username', 'Firstname': 'first_name', 'Lastname': 'last_name' }), # May configure the optional fields    NOTE: DD_SAML2_ATTRIBUTES_MAP in k8s can be referenced as extraConfig (e.g. DD_SAML2_ATTRIBUTES_MAP: 'Email'='email', 'Username'='username'...)\nNOTE: DD_SITE_URL might also need to be set depending on the choices you make with the metadata.xml provider. (File versus URL).\n Checkout the SAML section in dojo/dojo/settings/settings.dist.py and verfiy if it fits your requirement. If you need help, take a look at the plugin documentation.\n  Restart DefectDojo, and you should now see a Login with SAML button (default setting of DD_SAML2_LOGIN_BUTTON_TEXT) on the login page.\n  NOTE: In the case when IDP is configured to use self signed (private) certificate, than CA needs to be specified by define environments variable REQUESTS_CA_BUNDLE that points to the path of private CA certificate.\nAdvanced Configuration The https://github.com/IdentityPython/djangosaml2 plugin has a lot of options. For details take a look at the plugin documentation. All default options in DefectDojo can overwritten in the local_settings.py. If you want to change the organization name, you can add the following lines:\nif SAML2_ENABLED: SAML_CONFIG['contact_person'] = [{ 'given_name': 'Extra', 'sur_name': 'Example', 'company': 'DefectDojo', 'email_address': 'dummy@defectdojo.com', 'contact_type': 'technical' }] SAML_CONFIG['organization'] = { 'name': [('DefectDojo', 'en')], 'display_name': [('DefectDojo', 'en')], }, Migration from django-saml2-auth Up to relase 1.15.0 the SAML integration was based on https://github.com/fangli/django-saml2-auth. Which the switch to djangosaml2 some parameters has changed:\n DD_SAML2_ASSERTION_URL: not necessary any more - automatically generated DD_SAML2_DEFAULT_NEXT_URL: not necessary any more - default forwarding from defectdojo is used DD_SAML2_NEW_USER_PROFILE: not possible any more - default profile is used, see User Permissions DD_SAML2_ATTRIBUTES_MAP: Syntax has changed DD_SAML2_CREATE_USER: Default value changed to False, to avoid security breaches  RemoteUser This implementation is suitable if the DefectDojo instance is placed behind HTTP Authentication Proxy. Dojo expects that the proxy will perform authentication and pass HTTP requests to the Dojo instance with filled HTTP headers. The proxy should check if an attacker is not trying to add a malicious HTTP header and bypass authentication.\nValues which need to be set:\n DD_AUTH_REMOTEUSER_ENABLED - Needs to be set to True DD_AUTH_REMOTEUSER_USERNAME_HEADER - Name of the header which contains the username DD_AUTH_REMOTEUSER_EMAIL_HEADER(optional) - Name of the header which contains the email DD_AUTH_REMOTEUSER_FIRSTNAME_HEADER(optional) - Name of the header which contains the first name DD_AUTH_REMOTEUSER_LASTNAME_HEADER(optional) - Name of the header which contains the last name DD_AUTH_REMOTEUSER_GROUPS_HEADER(optional) - Name of the header which contains the comma-separated list of groups; user will be assigned to these groups (missing groups will be created) DD_AUTH_REMOTEUSER_GROUPS_CLEANUP(optional) - Same as [#automatic-import-of-user-groups](AzureAD implementation) DD_AUTH_REMOTEUSER_TRUSTED_PROXY - Comma separated list of proxies; Simple IP and CIDR formats are supported DD_AUTH_REMOTEUSER_LOGIN_ONLY(optional) - Check Django documentation  WARNING: There is possible spoofing of headers (for all DD_AUTH_REMOTEUSER_xxx_HEADER values). Read Warning in Django documentation\nUser Permissions When a new user is created via the social-auth, only the default permissions are active. This means that the newly created user does not have access to add, edit, nor delete anything within DefectDojo. There are two parameters in the System Settings to influence the permissions for newly created users:\nDefault group When both the parameters Default group and Default group role are set, the new user will be a member of the given group with the given role, which will give him the respective permissions.\nGroups from Identity Providers Some Identity Providers are able to send list of groups to which should user belongs. This functionality is implemented only for Identity Providers mentioned below. For all others, we will be more than happy for contribution (hint: functions assign_user_to_groups and cleanup_old_groups_for_user from dojo/pipeline.py might be useful).\n Azure: Check DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_GET_GROUPS and DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_CLEANUP_GROUPS RemoteUser: Check DD_AUTH_REMOTEUSER_GROUPS_HEADER and DD_AUTH_REMOTEUSER_GROUPS_CLEANUP  Login speed-up You can bypass the login form if you are only using SSO/Social authentication for login in by enabling these two environment variables:\nDD_SOCIAL_LOGIN_AUTO_REDIRECT: \"true\" DD_SOCIAL_AUTH_SHOW_LOGIN_FORM: \"false\" Login form fallback If you are using ‚Äúlogin speed-up‚Äù, it can be useful to be able to login by the standard way, for example when an admin user needs to log in because of a change of some settings or permissions. This feature is accessible by a visiting the URL \u003cDD_HOST\u003e/login?force_login_form.\nOther Providers In an effort to accommodate as much generality as possible, it was decided to implement OAuth2 with the social-auth ecosystem as it has a library of compatible providers with documentation of implementation. Conveniently, each provider has an identical procedure of managing the authenticated responses and authorizing access within a given application. The only difficulty is creating a new authentication client with a given OAuth2 provider.\n","categories":"","description":"OAuth2/SAML2 let users authenticate against enterprise directories.","excerpt":"OAuth2/SAML2 let users authenticate against enterprise directories.","ref":"/django-DefectDojo/dev/integrations/social-authentication/","tags":"","title":"Authentication via OAuth2/SAML2"},{"body":"Regular releases The DefectDojo team aims to maintain the following cadence:\n Minor releases: at least once a month on the first Monday of the month. Patch/Bugfix: releases every week on Monday. Security releases: will be performed outside of our regular cadence depending on severity.  GitHub Actions are the source of truth. The releases are semi-automated. The steps for a regular release are:\n Create the release branch from dev or bugfix and prepare a PR against master (details) ‚Äì\u003e A maintainer verifies and manually merges the PR Tag, issue draft release and docker build+push (details) ‚Äì\u003e A maintainer massages the release-drafter notes and publishes the release A PR to merge master back to dev and bugfix is created to re-align the branches (details)  Security releases PRs that relate to security issues are done through security advisories which provide a way to work privately on code without prematurely disclosing vulnerabilities.\nRelease and hotfix model Diagrams created with plantUML. Find a web-based editor for PlantUML at https://www.planttext.com.\nDocumentation A dev version of the documentation built from the dev branch is available at DefectDojo Documentation - dev branch.\n``` @startuml participant ‚ÄúDev Branch‚Äù as dev #LightBlue participant ‚ÄúBugFix Branch‚Äù as bugfix #LightGreen participant ‚ÄúRelease Branch‚Äù as release #LightGoldenRodYellow participant ‚ÄúMaster Branch‚Äù as master #LightSalmon\n== Minor Release (Monthly) ==\ndev -\u003e release: Create branch ‚Äúrelease/2.x.0‚Äù release -\u003e master: Merge note right: Official Release\\n - Tag 2.x.0\\n - Push 2.x.0 to DockerHub master ‚Äì\u003e bugfix: Merge master into bugfix to realign master ‚Äì\u003e dev: Merge master back into dev\n== Patch/BugFix Release (Weekly) ==\nbugfix -\u003e release: Create branch ‚Äúrelease/2.x.y‚Äù release -\u003e master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master -\u003e bugfix: Merge master back into bugfix to realign master ‚Äì\u003e dev: Merge master into dev to realign\n== Security Release (As Needed) ==\nmaster -\u003e release: Create branch ‚Äúrelease/2.x.y‚Äù release -\u003e master: Merge note right: Official Release\\n - Tag 2.x.y\\n - Push 2.x.y to DockerHub master ‚Äì\u003e bugfix: Merge master into bugfix to realign master ‚Äì\u003e dev: Merge master into dev to realign\n@enduml\n\u003c/div\u003e ","categories":"","description":"How we create releases","excerpt":"How we create releases","ref":"/django-DefectDojo/dev/contributing/branching-model/","tags":"","title":"Branching model"},{"body":"dojo/settings/settings.dist.py The main settings are stored in dojo/settings/settings.dist.py. It is great to use this file as a reference for what can be configured, but it shouldn't be edited directly, because changes will be overwritten when updating DefectDojo. There are several methods to change the default settings:\nEnvironment variables Most parameters can be set by environment variables.\nWhen you deploy DefectDojo via Docker Compose, you can set environment variables in docker-compose.yml. Be aware you have to set the variables for three services: uwsgi, celerybeat and celeryworker.\nWhen you deploy DefectDojo in a Kubernetes cluster, you can set environment variables as extraConfigs and extraSecrets in helm/defectdojo/values.yaml.\nEnvironment file (not with Docker Compose or Kubernetes) settings.dist.py reads environment variables from a file whose name is specified in the environment variable DD_ENV_PATH. If this variable is not set, the default .env.prod is used. The file must be located in the dojo/settings directory.\nAn example can be found in template_env.\nlocal_settings.py (not with Kubernetes) local_settings.py can contain more complex customizations such as adding MIDDLEWARE or INSTALLED_APP entries. This file is processed after settings.dist.py is processed, so you can modify settings delivered by DefectDojo out of the box. The file must be located in the dojo/settings directory. Environment variables in this file must not have the DD_ prefix. If the file is missing feel free to create it. Do not edit settings.dist.py directly.\nAn example can be found in dojo/settings/template-local_settings.\nIn Docker Compose release mode, files in docker/extra_settings/ (relative to the file docker-compose.yml) will be copied into dojo/settings/ in the docker container on startup.\nConfiguration in the UI Users with the superuser status can configure more options via the UI under Configuration / System Settings.\n","categories":"","description":"DefectDojo is highly configurable.","excerpt":"DefectDojo is highly configurable.","ref":"/django-DefectDojo/dev/getting_started/configuration/","tags":"","title":"Configuration"},{"body":"","categories":"","description":"A lot of integrations help to fit DefectDojo in your environment","excerpt":"A lot of integrations help to fit DefectDojo in your environment","ref":"/django-DefectDojo/dev/integrations/","tags":"","title":"Integrations"},{"body":"System-wide permissions  Administrators (aka superusers) have no limitations in the system. They can change all settings, manage users and have read / write access to all data. Staff users can add Product Types, and have access to data according to their role in a Product or Product Type. Regular users have limited functionality available. They cannot add Product Types but have access to data according to their role in a Product or Product Type  Product and Product Type permissions Users can be assigned as members to Products and Product Types, giving them one out of five predefined roles. The role defines what kind of access a user has to functions for interacting with data of that Product or Product Type:\nProduct / Product Type roles:\n    Reader Writer Maintainer Owner API Importer     Add Product Type   1) 1)    View Product Type x x x x x   Remove yourself as a member x x x x    Manage Product Type members   x x    Edit Product Type   x x    Add Product   x x    Add Product Type member as Owner    x    Delete Product Type    x            View Product x x x x x   Remove yourself as a member x x x x    Manage Product members   x x    Edit Product   x x    Add Product member as Owner    x    Delete Product    x            View Engagement x x x x x   Add Engagement  x x x x   Edit Engagement  x x x x   Risk Acceptance  x x x    Delete Engagement   x x            View Test x x x x x   Add Test  x x x    Edit Test  x x x x   Delete Test   x x            View Finding x x x x x   Add Finding  x x x    Edit Finding  x x x    (Re-)Import Scan Result  x x x x   Delete Finding   x x            View Finding Group x x x x x   Add Finding Group  x x x    Edit Finding Group  x x x    Delete Finding Group  x x x            View Endpoint x x x x x   Add Endpoint  x x x    Edit Endpoint  x x x    Delete Endpoint   x x            Edit Benchmark  x x x    Delete Benchmark   x x            View Components x x x x x           View Note History x x x x    Add Note x x x x    Edit Note (x) 2) x x x    Delete Note (x) 2) (x) 2) x x     1) Every superuser can add Product Types. Regular users are not allowed to add Product Types, unless they are a Global Owner or Maintainer.\n2) Every user is allowed to edit and delete his own notes.\nThe role of a user within a Product Type is inherited by all Products of that Product Type, unless the user is explicitly defined as a member of a Product with a different role. In that case, if a user doesn‚Äôt have a certain right for the Product Type, it is then checked if he has the right for the Product.\nA Product Type needs to have at least one owner. The last owner cannot be removed.\nGlobal permissions Users can be assigned a global role in the Edit User dialog. A global role gives a user access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nA use case for a global role could be the Chief Information Security Officer of a company who needs an overview of all systems. If he gets the global role Reader, he can see the findings for all products and also all metrics.\nSince global roles give users access to all data, only superusers are allowed to edit it.\nGroups If you have a number of users who should all have the same permissions for some Products or Product Types, you can put them together in a group. The group defines the roles for Products and Product Types that are applied to all members of the group.\nThe membership of a group itself has a role that determines what permissions the member has to manage the group:\n    Reader Maintainer Owner     Add Group 1)      View Group x x x   Remove yourself as a member x x x   Manage Group members  x x   Edit Group  x x   Add Group member as Owner   x   Delete Group   x    1) Every superuser can add groups. Regular users are not allowed to add groups.\nThe permissions to manage the roles of Products and Product types for a group is defined by the role of the user in the respective Product or Product Type.\nGroups can have a global role too. This global role gives all members of the group access to all Product Types and Products, including the underlying data, with permissions according to the respective role.\nConfiguration permissions Many configuration dialogues and API endpoints can be enabled for users or groups of users, regardless of their superuser status:\n3 configurations can still only be changed by superusers:\n System settings Notifications on system level Configuration permissions for users and groups  Warning These configuration settings are a powerful tool and should be used with great care.  ","categories":"","description":"Users have different functionality available to them, depending on their system-wide permissions and on the role they have as a member of a particular Product or Product Type.","excerpt":"Users have different functionality available to them, depending on ‚Ä¶","ref":"/django-DefectDojo/dev/usage/permissions/","tags":"","title":"Permissions"},{"body":"Questionnaires Questionnaires provide a means for collecting information from developers and respective stakeholders. DefectDojo includes functionality to create new questionnaires with custom questions, open questionnaires to receive responses for certain time periods from insiders or outsiders, and connect questionnaires with new or existing engagements.\nCreating a New Questionnaire To access, create, or modify new/existing questionnaires, navigate to the All Questionnaires dashboard from the sidebar.\nOn the questionnaire dashboard, all existing questionnaires are displayed. To quickly find a questionnaire, the filters may be used to search for snippets within the questionnaire name and/or description, as well as by active/inactive status.\nWhen questionnaires are open for responses, they will be displayed in the General Questionnaires block towards the bottom of the page.\nTo begin the process of creating a new questionnaire, select the Create Questionnaire button located in the top right of the questionnaire dashboard.\nQuestionnaires have a name and description, as well as an activity status, which are initially set on questionnaire creation, but can be modified in the future if necessary. Once these fields are filled in appropriately, the user can create the questionnaire without any questions (by selecting Create Questionnaire), or with questions (by selecting Create Questionnaire and Add Questions).\nTo add questions to a questionnaire, select the dropdown titled Select as many Questions as applicable, which will open all of the existing questions within DefectDojo. Once the desired questions are selected from the list, the dropdown can be closed, and the Update Questionnaire Questions can be selected to save the newly created questionnaire.\nNote: New questions may also be added at the time of questionnaire creation by selecting the plus located next to the questions dropdown.\nCreating New Questions The questions dashboard displays all of the questions that may exist as part of questionnaires within DefectDojo. Similar to questionnaires, to quickly find a question, the filters may be used to search for optional status, or snippets within the question name and/or description. Two types of questions exist within DefectDojo questionnaires: Text Questions and Multiple Choice Questions. To add a new question, select the Create Question button located in the top right of the questions dashboard.\nAdding Text Questions To add a text question (open-ended), fill out the add question form, where:\n Type - The type of question being created, in this case Text. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Question Text - The text that is displayed to prompt a user for their answer (e.g. What is your favorite color?).  Adding Multiple Choice Questions Similar to the process of adding a text question, choice questions (non-open-ended) allow the user to pick from a given list of choices. To add a choice question, fill out the add question form, where:\n Type - The type of question being created, in this case Choice. Order - The order of a question describes its position in a questionnaire relative to other questions (e.g., an order of 1 will put the question higher than a question with order 4). Optional - When the optional box is checked, a question will not be required in a questionnaire. Multichoice - When the multichoice box is checked, multiple choices from the list of choices may be selected by the user. Answer Choices - The possible answer choices that may be selected by a user.  Publishing a Questionnaire Once a questionnaire has been successfully created, it can be published to accept responses. To publish a questionnaire, select the plus located to the right of General Questionnaires.\nThis will prompt for a specific questionnaire to be selected, as well as a date the questionnaire response window should close. The response window sets a due date for recipients. Once these two options have been selected, publish the questionnaire by selecting Add Questionnaire.\nOnce a questionnaire is published, a link to share it can be retrieved by selecting the Share Questionnaire action. To ensure the newly created questionnaire has been constructed as expected, open the share link and view the newly created questionnaire.\nUnassigned Questionnaires When a questionnaire‚Äôs response window has closed, all of the responses will be saved, and the questionnaire will be listed as an Unassigned Answered Engagement Questionnaire on the DefectDojo dashboard.\nThere are three actions that may be taken when a questionnaire‚Äôs response window has closed: View Responses, Create Engagement, and Assign User.\nView Questionnaire Responses To view the questionnaire responses, select the View Responses action. All of the responses from the questionnaire will be displayed.\nCreate an Engagement From a Questionnaire To link the questionnaire to a product via an engagement, select the Create Engagement action. Once a product is selected from the dropdown, select Create Engagement. This will link the questionnaire results with a new engagement under the selected product, which can then be given specific details similar to other engagements in DefectDojo, such as Description, Version, Status, Tags, etc.\nTo view a questionnaire at the engagement level, navigate to the engagement linked with the desired questionnaire. Expand the Additional Features menu to reveal a Questionnaires dropdown, which will contain all of the linked questionnaires.\nAssign a Questionnaire to a User To assign a questionnaire to a user, select the Assign User action. This will prompt for a user to be selected from the dropdown of available users. Once a user is selected, assign the questionnaire to the specified user by selecting Assign Questionnaire.\nCreating Questionnaires From Engagements While questionnaires are commonly created from the questionnaire dashboard, they can also be created at the engagement level. To create a new questionnaire from within an engagement, expand the Additional Features dropdown to reveal the Questionnaires dropdown. In the right side header of the Questionnaires dropdown, select the plus to link a new questionnaire.\nOnce prompted, select a questionnaire from the available surveys list to link it with the engagement. If the user wishes to leave a response at the time of linking the questionnaire with the engagement, the Add Questionnaire and Repond option may be selected. To simply link the questionnaire with the engagement, select Add Questionnaire.\nAnonymous Questionnaires Questionnaires, by default, are only accessible by DefectDojo users. To allow outside responses to DefectDojo questionnaires, ensure the Allow Anonymous Survey Reponses option within the System Settings is selected. To share a questionnaire with anonymous users, use the questionnaire‚Äôs Share Link.\n","categories":"","description":"Collect information from people internal or external to DefectDojo.","excerpt":"Collect information from people internal or external to DefectDojo.","ref":"/django-DefectDojo/dev/usage/questionnaires/","tags":"","title":"Questionnaires"},{"body":"LDAP Authentication Out of the box Defect Dojo does not support LDAP authentication.\nHowever, since Defect Dojo is built using Django, it isn‚Äôt too difficult to add support for LDAP. So long as you don‚Äôt mind building your own Docker images‚Ä¶\nWe will need to modify a grand total of 4-5 files, depending on how you want to pass Dojo your LDAP secrets.\n Dockerfile.django-* Dockerfile.nginx-* requirements.txt settings.dist.py docker-compose.yml (Optional)  Dockerfile modifications In both Dockerfile.django and Dockerfile.nginx, you want to add the following lines to the apt-get install layers:\nlibldap2-dev \\ libsasl2-dev \\ ldap-utils \\ requirements.txt Please check for the latest version of these requirements at the time of implementation on pypi.org and use those if you can.\n https://pypi.org/project/python-ldap/ https://pypi.org/project/django-auth-ldap/  Otherwise add the following to requirements.txt:\npython-ldap==3.4.2 django-auth-ldap==4.1.0 settings.dist.py Find the settings file (hint: /dojo/settings/settings.dist.py) and add the following:\nAt the top of the file:\nimport ldap from django_auth_ldap.config import LDAPSearch, GroupOfNamesType Then further down add LDAP settings to the env dict:\n# LDAP DD_LDAP_SERVER_URI=(str, 'ldap://ldap.example.com'), DD_LDAP_BIND_DN=(str, ''), DD_LDAP_BIND_PASSWORD=(str, ''), Then under the env dict add:\nAUTH_LDAP_SERVER_URI = env('DD_LDAP_SERVER_URI') AUTH_LDAP_BIND_DN = env('DD_LDAP_BIND_DN') AUTH_LDAP_BIND_PASSWORD = env('DD_LDAP_BIND_PASSWORD') AUTH_LDAP_USER_SEARCH = LDAPSearch( \"ou=Groups,dc=example,dc=com\", ldap.SCOPE_SUBTREE, \"(uid=%(user)s)\" ) AUTH_LDAP_USER_ATTR_MAP = { \"first_name\": \"givenName\", \"last_name\": \"sn\", \"email\": \"mail\", } Please make sure to customise all of the LDAP search variables to match your company‚Äôs configuration.\nFor additional group controls you can add:\n# Set up the basic group parameters. AUTH_LDAP_GROUP_SEARCH = LDAPSearch( \"dc=example,dc=com\", ldap.SCOPE_SUBTREE, \"(objectClass=groupOfNames)\", ) AUTH_LDAP_GROUP_TYPE = GroupOfNamesType(name_attr=\"cn\") # Simple group restrictions AUTH_LDAP_REQUIRE_GROUP = \"cn=DD_USER_ACTIVE,ou=Groups,dc=example,dc=com\" AUTH_LDAP_USER_FLAGS_BY_GROUP = { \"is_active\": \"cn=DD_USER_ACTIVE,ou=Groups,dc=example,dc=com\", \"is_staff\": \"cn=DD_USER_STAFF,ou=Groups,dc=example,dc=com\", \"is_superuser\": \"cn=DD_USER_ADMIN,ou=Groups,dc=example,dc=com\", } Then also add 'django_auth_ldap.backend.LDAPBackend' to the AUTHENTICATION_BACKENDS variable, for example:\nAUTHENTICATION_BACKENDS = ( 'django_auth_ldap.backend.LDAPBackend', 'django.contrib.auth.backends.RemoteUserBackend', 'django.contrib.auth.backends.ModelBackend', ) Read the docs for Django Authentication with LDAP here: https://django-auth-ldap.readthedocs.io/en/latest/\ndocker-compose.yml In order to pass the variables to the settings.dist.py file via docker, it‚Äôs a good idea to add these to the docker-compose file.\nYou can do this by adding the following variables to the environment section for the uwsgi image:\nDD_LDAP_SERVER_URI: \"${DD_LDAP_SERVER_URI:-ldap://ldap.example.com}\" DD_LDAP_BIND_DN: \"${DD_LDAP_BIND_DN:-}\" DD_LDAP_BIND_PASSWORD: \"${DD_LDAP_BIND_PASSWORD:-}\" Alternatively you can set these values in a local_settings.py file.\n","categories":"","description":"Authenticate users using LDAP","excerpt":"Authenticate users using LDAP","ref":"/django-DefectDojo/dev/integrations/ldap-authentication/","tags":"","title":"Authentication via LDAP"},{"body":"You can find further information in the contributing guidelines.\n","categories":"","description":"How you can help to make DefectDojo even better","excerpt":"How you can help to make DefectDojo even better","ref":"/django-DefectDojo/dev/contributing/","tags":"","title":"Contributing"},{"body":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.\nWhen he is asked to audit an application, Bill registers a new Product in DefectDojo, and creates a new Engagement. Here he sets some basic information, like how long he expects the Engagement will take, who will be leading the testing (himself), what Product he will be working on, and what tests he will be doing.\nNext, he can add a Test to the Engagement, or upload a Nessus scan and start picking out the real vulnerabilities from the false positives (Nessus scan Findings are imported as inactive by default).\nWithin the Test section, Bill can add Findings for any issues that he has uncovered during his audit. He can assign a severity to the Findings, describe replication steps, mitigation strategies, and impact on the system. This will come in handy when he wants to generate a report to send to the development team responsible for this Product, or his manager.\nOnce Bill has completed his Engagement, he can close the Engagement on the main Engagement page. He can then view the results of his Tests, and generate a report to send to the development team.\nIf Bill hears back from the development team that they won't be able to fix the issue for a while, he can make a note of this on the Engagement page. Bill will also receive Alerts for any bugs that persist longer than they are supposed to based on their severity.\nExample 2 - John the QE manager John wants to keep tabs on what his team members are up to, and find issues that are taking a long time to get fixed. He creates his own DefectDojo account with superuser privileges so that he can view other team members' metrics.\nTo get a better idea of what his team members are currently working on, he can start by checking the Calendar. This will show him any active Engagements that his team is involved in, based on the dates assigned to those Engagements.\nHe can view metrics for a Product Type, such as \"Third Party Apps\" to track his team's activity and follow up with Product teams who have long-lived bugs. He can also look at all the Findings for which there is a Risk Acceptance associated, and ensure that the proper documentation or timeline has been provided for the Findings in question.\nIf he wants to check on a particular team member's progress, he can look at the Engineer Metrics dashboard under \"Additional Metrics\" for that user.\n","categories":"","description":"Two examples how DefectDojo can be used in day-to-day operations.","excerpt":"Two examples how DefectDojo can be used in day-to-day operations.","ref":"/django-DefectDojo/dev/usage/workflows/","tags":"","title":"Example workflows"},{"body":"DefectDojo's JIRA integration is bidirectional. You may push findings to JIRA and share comments. If an issue is closed in JIRA it will automatically be closed in Dojo.\nNOTE: These steps will configure the necessary webhook in JIRA and add JIRA integration into DefectDojo. This isn't sufficient by itself, you will need to configure products and findings to push to JIRA. On a product's settings page you will need to define a:\n Project Key (and this project must exist in JIRA) JIRA Configuration (select the JIRA configuration that you create in the steps below) Component (can be left blank)  Then elect (via tickbox) whether you want to 'Push all issues', 'Enable engagement epic mapping' and/or 'Push notes'. Then click on 'Submit'.\nIf creating a Finding, ensure to tick 'Push to jira' if desired.\nEnabling the Webhook  Visit https://\u003cYOUR JIRA URL\u003e/plugins/servlet/webhooks Click 'Create a Webhook' For the field labeled 'URL' enter: https://\u003cYOUR DOJO DOMAIN\u003e/jira/webhook/\u003cYOUR GENERATED WEBHOOK SECRET\u003e This value can be found under Defect Dojo System settings Under 'Comments' enable 'Created'. Under Issue enable 'Updated'.  Configurations in Dojo  Navigate to the System Settings from the menu on the left side or by directly visiting \u003cyour url\u003e/system_settings. Enable 'Enable JIRA integration' and click submit. For the webhook created in Enabling the Webhook, enable 'Enable JIRA web hook' and click submit.  Adding JIRA to Dojo   Click 'JIRA' from the left hand menu.\n  Select 'Add Configuration' from the drop-down.\n  For JIRA Server:\nEnter the Username \u0026 Password. A Username and JIRA Personal Access Token will not necessarily work.\nFor JIRA Cloud:\nEnter Email Address \u0026 API token for Jira\n  To obtain the 'open status key' and 'closed status key' visit https://\u003cYOUR JIRA URL\u003e/rest/api/latest/issue/\u003cANY VALID ISSUE KEY\u003e/transitions?expand=transitions.fields\n  The 'id' for 'Todo' should be filled in as the 'open status key'\n  The 'id' for 'Done' should be filled in as the 'closed status key'\n  To obtain 'epic name id': If you have admin access to JIRA:\n visit: https://\u003cYOUR JIRA URL\u003e/secure/admin/ViewCustomFields.jspa Click on the cog next to 'Epic Name' and select view. The numeric value for 'epic name id' will be displayed in the URL Note: dojojira uses the same celery functionality as reports. Make sure the celery runner is setup correctly as described: https://documentation.defectdojo.com/basics/features/#reports  Or\n login to JIRA visit https://yourjiraurl/rest/api/2/field and use control+F or grep to search for 'Epic Name' it should look something like this:  { ‚Äúid‚Äù:‚Äúcustomfield_122‚Äù, ‚Äúkey‚Äù:‚Äúcustomfield_122‚Äù, ‚Äúname‚Äù:‚ÄúEpic Name‚Äù, ‚Äúcustom‚Äù:true, ‚Äúorderable‚Äù:true, ‚Äúnavigable‚Äù:true, ‚Äúsearchable‚Äù:true, ‚ÄúclauseNames‚Äù:‚Äúcf[122]‚Äù, ‚ÄúEpic Name‚Äù], ‚Äúschema‚Äù:{‚Äútype‚Äù:‚Äústring‚Äù,‚Äúcustom‚Äù:‚Äúcom.pyxis.greenhopper.jira:gh-epic-label‚Äù,‚ÄúcustomId‚Äù:122} }\nIn the above example 122 is the number needed\nCustomize JIRA issue description By default Defect Dojo uses the dojo/templates/issue-trackers/jira_full/jira-description.tpl template to render the description of the ‚Äòto be‚Äô created JIRA issue. This file can be modified to your needs, rebuild all containers afterwards. There‚Äôs also a more limited template available, which can be chosen when configuring a JIRA Instance or JIRA Project for a Product or Engagement:\nAny folder added to dojo/templates/issue-trackers/ will be added to the dropdown (after rebuilding/restarting the containers).\nEngagement Epic Mapping If creating an Engagement, ensure to tick ‚ÄòEnable engagement epic mapping‚Äô if desired. This can also be done after engagement creation on the edit engagement page. This will create an ‚ÄòEpic‚Äô type issue within Jira. All findings in the engagement pushed to Jira will have a link to this Epic issue. If Epic Mapping was enabled after associated findings have already been pushed to Jira, simply pushing them again will link the Jira issue to the Epic issue.\nPushing findings Findings can be pushed to Jira in a number of ways:\n When importing scanner reports, select ‚ÄòPush to JIRA‚Äô to push every single finding in the report to Jira When creating a new finding, select ‚ÄòPush to JIRA‚Äô and submit. This will create the finding in DefectDojo and Jira simultaneously If a finding already exist, visit the edit finding page and find the ‚ÄòPush to JIRA‚Äô tick box at the bottom When viewing a list of findings, select each relevant tick boxes to the left of the finding, and click the ‚ÄòBulk Edit‚Äô button at the top. find ‚ÄòPush to JIRA‚Äô at the bottom of the menu  Status Sync DefectDojo will try to keep the status in sync with the status in JIRA using the Close and Reopen transition IDs configured for each JIRA instance. This will only work if your workflow in JIRA allows the Close transition to be performed from every status a JIRA issue can be in.\nKnown Issues The Risk Acceptance feature in DefectDojo will (for that reason) not (yet) try to sync statuses. A comment will be pushed to JIRA if a finding is risk accepted or unaccepted. Contributions are welcome to enhance the integration.\nStatus reconciliation Sometimes JIRA is down, or Defect Dojo is down, or there was bug in a webhook. In this case JIRA can become out of sync with Defect Dojo. If this is the case for lots of issues, manual reconciliation might not be feasible. For this scenario there is the management command ‚Äòjira_status_reconciliation‚Äô.\nusage: manage.py jira_status_reconciliation [-h] [--mode MODE] [--product PRODUCT] [--engagement ENGAGEMENT] [--dryrun] [--version] [-v {0,1,2,3}] Reconcile finding status with JIRA issue status, stdout will contain semicolon seperated CSV results. Risk Accepted findings are skipped. Findings created before 1.14.0 are skipped. optional arguments: -h, --help show this help message and exit --mode MODE - reconcile: (default)reconcile any differences in status between Defect Dojo and JIRA, will look at the latest status change timestamp in both systems to determine which one is the correct status - push_status_to_jira: update JIRA status for all JIRA issues connected to a Defect Dojo finding (will not push summary/description, only status) - import_status_from_jira: update Defect Dojo finding status from JIRA --product PRODUCT Only process findings in this product (name) --engagement ENGAGEMENT Only process findings in this product (name) --dryrun Only print actions to be performed, but make no modifications. -v {0,1,2,3}, --verbosity {0,1,2,3} Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output This can be executed from the uwsgi docker container using:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation' DEBUG output can be obtains via -v 3, but only after increasing the logging to DEBUG level in your settings.dist.py or local_settings.py file\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation -v 3' At the end of the command a semicolon seperated CSV summary will be printed. This can be captured by redirecting stdout to a file:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation \u003e jira_reconciliation.csv' Troubleshooting JIRA integration JIRA actions are typically performed in the celery background process. Errors are logged as alerts/notifications to be seen on the top right of the DefectDojo UI and in stdout of the celery workers.\n","categories":"","description":"Bidirectional integration of DefectDojo findings with Jira issues.","excerpt":"Bidirectional integration of DefectDojo findings with Jira issues.","ref":"/django-DefectDojo/dev/integrations/jira/","tags":"","title":"JIRA integration"},{"body":"Filter String Matching Optimization IN the UI, many of the filters for a given object will also query related objects for an easy visual match of an item to filter on. For instances with many objects, this could lead to a considerable performance hit. To alleviate this constriction, enable the ‚ÄúFilter String Matching Optimization‚Äù setting in the System Settings to change many filters to only search on names, rather than the objects themselves. This change will save many large queries, and will improve the performance of UI based interactions.\nAsynchronous Import DefectDojo offers an experimental feature to aynschronously import security reports. This feature works in most use cases, but struggles when doing things such as pushing to Jira during the import process. Because Endpoints are still being processed and created even after the import procedure is completed, pushing Findings to Jira can result in incomplete Jira tickets. It is advised to wait until after import has been completed (reaches 100%).\nTo enable this feature, set ASYNC_FINDING_IMPORT to True in local_settings.py\nAsynchronous Delete For larger instances, deleting an object can take minutes for all related objects to be expanded into memory, rendered on the page, and then removing all objects from the database. To combat this issue, two settings can be set in local_settings.py:\nASYNC_OBJECT_DELETE Deleting an object asynchronously changes the way an object is deleted under the hood. By removing the need to expand into memory, a lot of time (and memory) can be saved by offloading the lookups and removals onto celery processes. This process works by starting at the bottom of a given object, and walking the tree upwards rather than downwards. This way, objects can be seperated into buckets, and then deleted.\nDELETE_PREVIEW Previewing all the objects to be deleted takes almost as much time as deleting the objects itself. This is a safety feature intended to warn users of what they are about to delete, as well as educating users of how the delete functionality works by cascade deleting all related objects. With this feature enabled, the user will only see the following text in the delete preview (without any database lookups)\nPreviewing the relationships has been disabled.\n","categories":"","description":"Settings to configure to enhance performance in DefectDojo","excerpt":"Settings to configure to enhance performance in DefectDojo","ref":"/django-DefectDojo/dev/usage/performance/","tags":"","title":"Performance Enhancements"},{"body":"Production use with docker-compose The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.\nAlthough Docker Compose is one of the supported installation methods to deploy a containerized DefectDojo in a production environment, the docker-compose.yml file is not intended for production use without first customizing it to your particular situation.\nSee Running with Docker Compose for more information how to run DefectDojo with Docker Compose.\nDatabase performance and backup It is recommended to use a dedicated database server and not the preconfigured PostgreSQL database. This will improve the performance of DefectDojo.\nIn both cases (dedicated DB or containerized), if you are self-hosting, it is recommended that you implement and create periodic backups of your data.\nBackup of Media files Media files for uploaded files, including threat models and risk acceptance, are stored in a docker volume. This volume needs to be backed up regularly.\nInstance size Information Please read the paragraphs below about key processes tweaks.  With a separate database, the minimum recommendations are:\n 2 vCPUs 8 GB of RAM 10 GB of disk space (remember, your database is not here -- so what you have for your O/S should do). You could allocate a different disk than your OS's for potential performance improvements.  uWSGI By default (except in ptvsd mode for debug purposes), uWSGI will handle 4 concurrent connections.\nBased on your resource settings, you can tweak:\n DD_UWSGI_NUM_OF_PROCESSES for the number of spawned processes. (default 2) DD_UWSGI_NUM_OF_THREADS for the number of threads in these processes. (default 2)  For example, you may have 4 processes with 6 threads each, yielding 24 concurrent connections.\nCelery worker By default, a single mono-process celery worker is spawned. When storing a large amount of findings, leveraging async functions (like deduplication), or both. Eventually, it is important to adjust these parameters to prevent resource starvation.\nThe following variables can be changed to increase worker performance, while keeping a single celery container.\n DD_CELERY_WORKER_POOL_TYPE will let you switch to prefork. (default solo)  When you enable prefork, the variables below have to be used. see the Dockerfile.django-* for in-file references.\n DD_CELERY_WORKER_AUTOSCALE_MIN defaults to 2. DD_CELERY_WORKER_AUTOSCALE_MAX defaults to 8. DD_CELERY_WORKER_CONCURRENCY defaults to 8. DD_CELERY_WORKER_PREFETCH_MULTIPLIER defaults to 128.  You can execute the following command to see the configuration:\ndocker-compose exec celerybeat bash -c \"celery -A dojo inspect stats\" and see what is in effect.\nAsynchronous Import Please note: Asynchronous Import is currently an experimental feature. Please exercise caution with this method as results may be inconsistent.\nImport and Re-Import can also be configured to handle uploads asynchronously to aid in processing especially large scans. It works by batching Findings and Endpoints by a configurable amount. Each batch will be be processed in separate celery tasks.\nThe following variables impact async imports.\n DD_ASYNC_FINDING_IMPORT defaults to False DD_ASYNC_FINDING_IMPORT_CHUNK_SIZE defaults to 100  When using asynchronous imports with dynamic scanners, Endpoints will continue to ‚Äútrickle‚Äù in even after the import has returned a successful response. This is because processing continues to occur after the Findings have already been imported.\nTo determine if an import has been fully completed, please see the progress bar in the appropriate test.\n","categories":"","description":"For use in Production environments, performance tweaks and backups are recommended.","excerpt":"For use in Production environments, performance tweaks and backups are ‚Ä¶","ref":"/django-DefectDojo/dev/getting_started/running-in-production/","tags":"","title":"Running in production"},{"body":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool. If the repository of the source code is specified in the Engagement, DefectDojo will present the filepath as a link and the user can navigate directly to the location of the vulnerability.\nSetting the repository in the Engagement and Test Engagement While editing the Engagement, users can set the URL of the specific SCM repo. For Interactive Engagement it needs to be the URL including the branch:\n for GitHub - like https://github.com/DefectDojo/django-DefectDojo/tree/dev  for GitLab - like https://gitlab.com/gitlab-org/gitlab/-/tree/master  for public BitBucket - like (like git clone url)  for standalone/onpremise BitBucket https://bb.example.com/scm/some-project/some-repo.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url)   For CI/CD Engagement, where user could set commit hash, branch/tag and code line it should look like examples below:\n for GitHub - like https://github.com/DefectDojo/django-DefectDojo for GitLab - like https://gitlab.com/gitlab-org/gitlab for public BitBucket, Gitea and Codeberg - like https://bitbucket.org/some-user/some-project.git (like git clone url) for standalone/onpremise BitBucket https://bb.example.com/scm/some-project.git or https://bb.example.com/scm/some-user-name/some-repo.git for user public repo (like git clone url)  If user does not set commit hash or branch/tag in appropriate fields of CI/CD Engagement edit form, the URL should look like in Interactive Engagement edit form.\nSCM navigation URL is composed from Repo URL using SCM Type. Github/Gitlab SCM type is default, but user could set certain SCM type in Product custom field ‚Äúscm-type‚Äù.\nProduct custom fields:\nProduct SCM type add:\nPossible SCM types could be ‚Äògithub‚Äô, ‚Äògitlab‚Äô, ‚Äòbitbucket‚Äô, ‚Äòbitbucket-standalone‚Äô, ‚Äògitea‚Äô, ‚Äòcodeberg‚Äô or nothing (for default github).\nLink in Finding When viewing a finding, the location will be presented as a link, if the repository of the source code has been set in the Engagement:\nClicking on this link will open a new tab in the browser, with the source file of the vulnerability at the corresponding line number:\n","categories":"","description":"Integration of repositories to navigate to the locaction of findings in the source code.","excerpt":"Integration of repositories to navigate to the locaction of findings ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/source-code-repositories/","tags":"","title":"Source code repositories"},{"body":"Docker-compose When you deploy a vanilla docker-compose, it will create a persistent volume for your MySQL database. As long as your volume is there, you should not lose any data.\nUsing docker images provided in DockerHub Information If you're using latest, then you need to pre pull the latest from DockerHub to update.  The generic upgrade method for docker-compose are as follows:\n  Pull the latest version\ndocker pull defectdojo/defectdojo-django:latest docker pull defectdojo/defectdojo-nginx:latest   If you would like to use a version other than the latest, specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2 docker pull defectdojo/defectdojo-nginx:1.10.2   If you would like to use alpine based images, you specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2-alpine docker pull defectdojo/defectdojo-nginx:1.10.2-alpine   Go to the directory where your docker-compose.yml file lives\n  Stop DefectDojo: ./dc-stop.sh\n  Re-start DefectDojo, allowing for container recreation: ./dc-up-d.sh\n  Database migrations will be run automatically by the initializer. Check the output via docker-compose logs initializer or relevant k8s command\n  If you have the initializer disabled (or if you want to be on the safe side), run the migration command: docker-compose exec uwsgi /bin/bash -c \"python manage.py migrate\"\n  Building your local images If you build your images locally and do not use the ones from DockerHub, the instructions are the same, with the caveat that you must build your images first.\n  Pull the latest DefectDojo changes\ngit fetch git pull git merge origin/master   Then replace the first step of the above generic upgrade method for docker-compose with: docker-compose build\ngodojo installations If you have installed DefectDojo on ‚Äúiron‚Äù and wish to upgrade the installation, please see the instructions in the repo.\nUpgrade notes for each release ","categories":"","description":"Release specific upgrading instructions","excerpt":"Release specific upgrading instructions","ref":"/django-DefectDojo/dev/getting_started/upgrading/","tags":"","title":"Upgrading"},{"body":"Demo Try out the demo sever at demo.defectdojo.org\nLog in with admin / 1Defectdojo@demo#appsec. Please note that the demo is publicly accessable and regularly reset. Do not put sensitive data in the demo.\n","categories":"","description":"There is DefectDojo demo site running the latest officially released version","excerpt":"There is DefectDojo demo site running the latest officially released ‚Ä¶","ref":"/django-DefectDojo/dev/getting_started/demo/","tags":"","title":"Demo"},{"body":"Notifications DefectDojo can inform you of different events in a variety of ways. You can be notified about things like an upcoming engagement, when someone mentions you in a comment, a scheduled report has finished generating, and more.\nThe following notification methods currently exist:\n Email Slack Microsoft Teams Alerts within DefectDojo (default)  You can set these notifications on a global scope (if you have administrator rights) or on a personal scope. For instance, an administrator might want notifications of all upcoming engagements sent to a certain Slack channel, whereas an individual user wants email notifications to be sent to the user's specified email address when a report has finished generating.\nUsers can define notifications on a product level as well, and these settings will be applied only for selected products.\nIn order to identify and notify you about things like upcoming engagements, DefectDojo runs scheduled tasks for this purpose. These tasks are scheduled and run using Celery beat, so this needs to run for those notifications to work.\nDefectDojo allows template to be used, administrator can use this feature to define which notification should be received by newly created users.\nSlack Basic Integration This method will allow DefectDojo to send Global notifications to a Slack channel. It can also send Personal notifications to an individual user‚Äôs Slackbot.\nTo configure Slack messaging, you will first need to create a new Slack app at https://api.slack.com/apps.\nThis app can be created from scratch, or from a JSON manifest which includes all necessary scopes and bot functionality. This manifest can be copied and pasted into the Slack App wizard when you select ‚ÄòBuild From Manifest‚Äô.\n JSON Manifest { \"_metadata\": { \"major_version\": 1, \"minor_version\": 1 }, \"display_information\": { \"name\": \"DefectDojo\", \"description\": \"Notifications from DefectDojo\", \"background_color\": \"#0000AA\" }, \"features\": { \"bot_user\": { \"display_name\": \"DefectDojo Notifications\" } }, \"oauth_config\": { \"scopes\": { \"bot\": [ \"chat:write\", \"chat:write.customize\", \"chat:write.public\", \"incoming-webhook\", \"users:read\", \"users:read.email\" ] }, \"redirect_urls\": [ \"https://slack.com/oauth/v2/authorize\" ] } }  Choose the channel where you want to post Global notifications during the ‚ÄòCreate From Manifest‚Äô process. Personal notifications will appear in a user‚Äôs Slackbot if they have their Slack Email Address specified on their user profile.\nScopes The following scopes have to be granted to your Slack App. If the App was created from the JSON Manifest above, these permission scopes will already be set correctly.\nToken The Slack Bot Token needs to be pasted in the DefectDojo System Settings, nested underneath the ‚ÄòEnable slack notifications‚Äô checkbox. This token can be found in the Features / OAuth \u0026 Permissions section on the Slack App settings.\nExamples of Slack notifications Microsoft Teams Microsoft Teams does not provide an easy way to send messages to a personal channel. Therefore, DefectDojo can only send system scope notifications to Microsoft Teams.\nTo activate notifications to Microsoft Teams, you have to:\n Configure an Incoming Webhook in a Teams channel and copy the URL of the webhook to the clipboard Activate Enable Microsoft Teams notifications in the System Settings Paste the URL of the Incoming Webhook into the field Msteams url  Specific overrides System notification settings (scope: system) describe the sending of notifications to superadmins. User notification settings (scope: personal) describe sending notifications to the specific user.\nHowever, there is a specific use-case when the user decides to disable notifications (to decrease noise) but the system setting is used to override this behavior. These overrides apply only to user_mentioned and review_requested by default.\nThe scope of this setting is customizable (see environmental variable DD_NOTIFICATIONS_SYSTEM_LEVEL_TRUMP).\nFor more information about this behavior see the related pull request #9699\n","categories":"","description":"DefectDojo can inform you about changes on different channels.","excerpt":"DefectDojo can inform you about changes on different channels.","ref":"/django-DefectDojo/dev/integrations/notifications/","tags":"","title":"Notifications"},{"body":"Please note - the Google Sheets feature has been deprecated as of DefectDojo version 2.21.0 - these documents are for reference only.\nWith the Google Sheets sync feature, DefectDojo allow the users to export all the finding details of each test into a separate Google Spreadsheet. Users can review and edit finding details via Google Spreadsheets. Also, they can add new notes to findings and edit existing notes using the Google Spreadsheet. After reviewing and updating the finding details in the Google Spreadsheet, the user can import (sync) all the changes done via the Google Spreadsheet into DefectDojo database.\nConfiguration Creating a project and a Service Account\n Go to the Service Accounts page. Create a new project for DefectDojo and select it. Click +CREATE SERVICE ACCOUNT, enter a name and description for the service account. You can use the default service account ID, or choose a different, unique one. When done click Create. The Service account permissions (optional) section that follows is not required. Click Continue. On the Grant users access to this service account screen, scroll down to the Create key section. Click +Create key. In the side panel that appears, select the format for your key as JSON Click Create. Your new public/private key pair is generated and downloaded to your machine.  Enabling the required APIs\n Go to the Google API Console. From the projects list, select the project created for DefectDojo. If the APIs \u0026 services page isn't already open, open the console left side menu and select APIs \u0026 services, and then select Library. Google Sheets API and Google Drive API should be enabled. Click the API you want to enable. If you need help finding the API, use the search field. Click ENABLE.  Configurations in DefectDojo\n  Click 'Configuration' from the left hand menu.\n  Click 'Google Sheets Sync'.\n  Fill the form.\n  Upload the downloaded json file into the Upload Credentials file field.\n  Drive Folder Id:\n  Create a folder inside the Google drive of the same Gmail account used to create the service account.\n  Get the client_email from the downloaded json file and share the created drive folder with client_email giving edit access.\n  Extract the folder id from the URL and insert it as the Drive Folder Id:\n    Tick the Enable Service check box. (Optional as this has no impact on the configuration, but you must set it to true inorder to use the feature. Service can be enabled or disabled at any point after the configuration using this check box)\n  For each field in the finding table there are two related entries in the form:\n In the drop down, select Hide if the column needs to be hidden in the Google Sheet, else select any other option based on the length of the entry that goes under the column. If the column needs to be protected in the Google Sheet, tick the check box. Otherwise leave it unchecked.      Click 'Submit'.\n  Admin has the privilege to revoke the access given to DefectDojo to access Google Sheets and Google Drive data by simply clicking the Revoke Access button.\nUsing Google Sheets Sync Feature Before a user can export a test to a Google Spreadsheet, admin must Configure Google Sheets Sync and Enable sync feature.Depending on whether a Google Spreadsheet exists for the test or not, the User interface displayed will be different.\nIf a Google Spreadsheet does not exist for the Test:\nIf a Google Spreadsheet is already created for the Test:\nAfter creating a Google Spreadsheet, users can review and edit Finding details using the Google Sheet. If any change is done in the Google Sheet users can click the Sync Google Sheet button to get those changes into DefectDojo.\n","categories":"","description":"Export finding details to Google Sheets and upload changes from Google Sheets.","excerpt":"Export finding details to Google Sheets and upload changes from Google ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/google-sheets-sync/","tags":"","title":"Google Sheets synchronisation"},{"body":"Please note: The DefectDojo Burp Plugin has been sunset and is no longer a supported feature.\nBurp is still a supported tool, and all the results from it can be imported into DefectDojo. Burp can produce XML reports and these can be uploaded to DefectDojo using the graphical user interface or the API. Our documentation at https://documentation.defectdojo.com/integrations/parsers/file/burp/ describes this usage.\nThis is Burp Plugin to export findings directly to DefectDojo.\nInstallation In order for the plugin to work , you will need to have Jython set up in Burp Suite Pro . To use this plugin before it appears in the BApp Store you will need to do the following :\n Go to Extender and select the Extensions tab Click on Add , select Extension Type: to be Python and select the DefectDojoPlugin.py  Usage ","categories":"","description":"Export findings directly from Burp to DefectDojo.","excerpt":"Export findings directly from Burp to DefectDojo.","ref":"/django-DefectDojo/dev/integrations/burp-plugin/","tags":"","title":"Defect Dojo Burp plugin"},{"body":"Import of languages for a project You can import JSON reports generated by the cloc tool via the API:\nWhen importing a file, all language information for the respective project will be deleted first and then populated with the content of the file. Please make sure to use the --json parameter when invoking the cloc command, to get the correct file format.\nDisplay The results of the import are shown on the left side of the product details page.\nThe colors are defined by entries in the table Language_Type, which has been prepopulated with data from GitHub.\nImport of language types GitHub updates its language colors from time to time, when new languages emerge. The management command\n./manage.py import_github_languages\nreads data from a JSON file hosted in https://github.com/ozh/github-colors to add new languages and update colors.\n","categories":"","description":"You can import an analysis of languages used in a project, including lines of code.","excerpt":"You can import an analysis of languages used in a project, including ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/languages/","tags":"","title":"Languages and lines of code"},{"body":"DefectDojo has protection against brute force attacks through rate limiting\nConfiguration For further information, please visit the package documentation Django Ratelimit\nEnable Rate Limiting To enable and configure rate limiting, edit the settings (see Configuration) and edit/replace the following information:\nDD_RATE_LIMITER_ENABLED=(bool, True), DD_RATE_LIMITER_RATE=(str, '5/m'), DD_RATE_LIMITER_BLOCK=(bool, True), DD_RATE_LIMITER_ACCOUNT_LOCKOUT=(bool, True), Rate Limit The frequency at which the request will be limited can be set to\n seconds - 1s minutes - 5m hours - 100h days - 2400d  Extended configuration can be found here\nBlock Requests By default, rate limiting is set to record offenses, but does not actually block requests and enforce the limit.\nSetting DD_RATE_LIMITER_BLOCK will block all incoming requests at the configured frequncy once that frequency has been exceeded.\nAccount Lockout In the event of a brute force attack, a users credentials could potentially be comprimised.\nIn an attempt to circumvent that event, setting DD_RATE_LIMITER_ACCOUNT_LOCKOUT will force a user to reset their password upon the next attempted login.\nMulti-Process Behavior When using configurations with multiple uwsgi processes, the rate limiting package uses the default cache that is memory based and local to a process.\nExtra Configuation For further information, please visit the package documentation Django Ratelimit\n","categories":"","description":"Configurable rate limiting on the login page to mitigate brute force attacks","excerpt":"Configurable rate limiting on the login page to mitigate brute force ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/rate_limiting/","tags":"","title":"Rate Limiting"},{"body":"Export Findings Pages that show a list of findings or a list of engagements have a CSV and Excel Export functionality in the top right dropdown menu.\nThe list of engagements can be exported as CSV/Excel.\n","categories":"","description":"DefectDojo has the ability to export findings.","excerpt":"DefectDojo has the ability to export findings.","ref":"/django-DefectDojo/dev/integrations/exporting/","tags":"","title":"Exporting"},{"body":"What is DefectDojo? DefectDojo is a DevSecOps platform. DefectDojo streamlines DevSecOps by serving as an aggregator and single pane of glass for your security tools. DefectDojo has smart features to enhance and tune the results from your security tools including the ability to merge findings, remember false positives, and distill duplicates. DefectDojo also integrates with JIRA, provides metrics / reports, and can also be used for traditional pen test management.\nWhat does DefectDojo do? While automation and efficiency are the ultimate end goals, DefectDojo is a bug tracker at its core for vulnerabilities. Taking advantage of DefectDojo‚Äôs Product:Engagement model, enables traceability among multiple projects / test cycles, and allows for fine-grained reporting.\nHow does DefectDojo work?  Getting started covers how to install and configure DefectDojo. Usage covers how to use DefectDojo to manage vulnerabilities. We support a large amount of integrations to help fit DefectDojo in your DevSecOps program.  Where to find DefectDojo? The open-source edition is available on GitHub.\nA running example is available on our demo server, using the credentials admin / defectdojo@demo#appsec. Note: The demo server is refreshed regularly and provisioned with some sample data.\nDefectDojo Pro and Enterprise DefectDojo Inc. hosts a commercial edition of this software, which includes:\n additional features, smart features and UI improvements cloud hosting, with regular backups, updates and maintenance premium support and implementation guidance  For more information, please visit defectdojo.com.\nDefectDojo Inc. also maintains an updated Knowledge Base at https://support.defectdojo.com. The Knowledge Base is written to support DefectDojo‚Äôs Pro and Enterprise releases, but the tutorials and guides may also be applied to the open-source edition.\nFollow DefectDojo Inc. on LinkedIn for updates. To get in touch with us, please reach out to info@defectdojo.com\n","categories":"","description":"","excerpt":"What is DefectDojo? DefectDojo is a DevSecOps platform. DefectDojo ‚Ä¶","ref":"/django-DefectDojo/dev/","tags":"","title":"DefectDojo's Documentation"},{"body":"This parser imports the Acunetix Scanner with xml output or Acunetix 360 Scanner with JSON output.\nSample Scan Data Sample Acunetix Scanner scans can be found here.\n","categories":"","description":"","excerpt":"This parser imports the Acunetix Scanner with xml output or Acunetix ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/acunetix/","tags":"","title":"Acunetix Scanner"},{"body":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample Anchore Enterprise Policy Check scans can be found here.\n","categories":"","description":"","excerpt":"Anchore-CLI JSON policy check report format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/anchore_enterprise/","tags":"","title":"Anchore Enterprise Policy Check"},{"body":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON files are created using the Grype CLI, using the ‚Äò-o json‚Äô option. See: https://github.com/anchore/grype\nExample: grype yourApp/example-page -o json \u003e example_vulns.json\nAcceptable JSON Format All properties are expected as strings and are required by the parser.\n{ \"matches\": [ { \"vulnerability\": { \"id\": \"example-id\", \"dataSource\": \"https://example.org/.../example-id\", \"namespace\": \"exampleName\", \"severity\": \"exampleSeverity\", \"urls\": [ \"https://example.org/.../example-id\", ... ], \"cvss\": [], \"fix\": { \"versions\": [], \"state\": \"not-fixed\" }, \"advisories\": [] }, \"relatedVulnerabilities\": [ { \"id\": \"first-related-example-id\", \"dataSource\": \"https://example.org/.../related-example-id\", \"namespace\": \"first-related-exampleName\", \"severity\": \"first-related-exampleSeverity\", \"urls\": [ \"https://example.org/.../related-example-id\", ... ], \"description\": \"first-example-description\", \"cvss\": [ { \"version\": \"2.0\", \"vector\": \"AV:L/AC:L/Au:N/C:N/I:P/A:N\", \"metrics\": { \"baseScore\": 2.1, \"exploitabilityScore\": 3.9, \"impactScore\": 2.9 }, \"vendorMetadata\": {} } ] }, ... ], \"matchDetails\": [ { \"matcher\": \"example-matcher\", \"searchedBy\": { \"distro\": { \"type\": \"example-distrotype\", \"version\": \"10\" }, \"namespace\": \"exampleName\", \"package\": { \"name\": \"example-package\", \"version\": \"1.17-3+deb10u3\" } }, \"found\": { \"versionConstraint\": \"none (deb)\" } } ], \"artifact\": { \"name\": \"example-artifact\", \"version\": \"example-artifact-version\", \"type\": \"example-type\", \"locations\": [ { \"path\": \".../examplePath/\", \"layerID\": \"exampleLayerID\" }, { \"path\": \".../examplePath-2/\", \"layerID\": \"exampleLayerID\" }, ... ], \"language\": \"\", \"licenses\": [ \"GPL-2\" ], \"cpes\": [ \"example-cpe\", ... ], \"purl\": \"pkg:deb/debian/libgssapi-krb5-2@1.17-3+deb10u3?arch=amd64\", \"metadata\": { \"Source\": \"krb5\" } } }, ... ], \"source\": { \"type\": \"image\", \"target\": { \"userInput\": \"vulnerable-image:latest\", \"imageID\": \"sha256:ce9898fd214aef9c994a42624b09056bdce3ff4a8e3f68dc242d967b80fcbeee\", \"manifestDigest\": \"sha256:9d8825ab20ac86b40eb71495bece1608a302fb180384740697a28c2b0a5a0fc6\", \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"tags\": [ \"vulnerable-image:latest\" ], \"imageSize\": 707381791, \"layers\": [ { \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"digest\": \"sha256:d000633a56813933cb0ac5ee3246cf7a4c0205db6290018a169d7cb096581046\", \"size\": 69238554 }, ... ], \"manifest\": \"exampleManifestString==\", \"config\": \"exampleConfigString\", \"repoDigests\": [] } }, \"distro\": { \"name\": \"debian\", \"version\": \"10\", \"idLike\": \"\" }, \"descriptor\": { \"name\": \"grype\", \"version\": \"0.28.0\", \"configuration\": { \"configPath\": \"\", \"output\": \"json\", \"file\": \"\", \"output-template-file\": \"\", \"quiet\": false, \"check-for-app-update\": true, \"only-fixed\": false, \"scope\": \"Squashed\", \"log\": { \"structured\": false, \"level\": \"\", \"file\": \"\" }, \"db\": { \"cache-dir\": \"/home/user/.cache/grype/db\", \"update-url\": \"https://toolbox-data.anchore.io/grype/databases/listing.json\", \"ca-cert\": \"\", \"auto-update\": true, \"validate-by-hash-on-start\": false }, \"dev\": { \"profile-cpu\": false, \"profile-mem\": false }, \"fail-on-severity\": \"\", \"registry\": { \"insecure-skip-tls-verify\": false, \"insecure-use-http\": false, \"auth\": [] }, \"ignore\": null, \"exclude\": [] }, \"db\": { \"built\": \"2021-12-24T08:14:02Z\", \"schemaVersion\": 3, \"location\": \"/home/user/.cache/grype/db/3\", \"checksum\": \"sha256:6c4777e1acea787e5335ccee6b5e4562cd1767b9cca138c07e0802efb2a74162\", \"error\": null } } } Sample Scan Data Sample Grype scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file.\nAnchore Grype JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/anchore_grype/","tags":"","title":"Anchore Grype"},{"body":"File Types DefectDojo parser accepts a .json file.\nUsing the Anchore CLI is the most reliable way to generate an Anchore report which DefectDojo can parse. When generating a report with the Anchore CLI, please use the following command to ensure complete data: anchore-cli --json image vuln \u003cimage:tag\u003e all\nAcceptable JSON Format All properties are strings and are required by the parser.\n { \"imageDigest\": \"sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\", \"vulnerabilities\": [ { \"feed\": \"example-feed\", \"feed_group\": \"example-feed-group\", \"fix\": \"1.2.4\", \"package\": \"example-package\", \"package_cpe\": \"cpe:2.3:a:*:example:1.2.3:*:*:*:*:*:*:*\", \"package_name\": \"example-package-name\", \"package_path\": \"path/to/package\", \"package_type\": \"dpkg\", \"package_version\": \"1.2.3\", \"severity\": \"Medium\", \"url\": \"https://example.com/cve/CVE-2011-3389\", \"vuln\": \"CVE-2011-3389\" }, ... ], \"vulnerability_type\": \"os\" } Sample Scan Data Sample Anchore-Engine scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file.\nUsing the Anchore ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/anchore_engine/","tags":"","title":"Anchore-Engine"},{"body":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample AnchoreCTL Policies Report scans can be found here.\n","categories":"","description":"","excerpt":"AnchoreCTLs JSON policies report format\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/anchorectl_policies/","tags":"","title":"AnchoreCTL Policies Report"},{"body":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample AnchoreCTL Vuln Report scans can be found here.\n","categories":"","description":"","excerpt":"AnchoreCTLs JSON vulnerability report format\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/anchorectl_vulns/","tags":"","title":"AnchoreCTL Vuln Report"},{"body":"Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nSample Scan Data Sample AppSpider (Rapid7) scans can be found here.\n","categories":"","description":"","excerpt":"Use the VulnerabilitiesSummary.xml file found in the zipped report ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/appspider/","tags":"","title":"AppSpider (Rapid7)"},{"body":"JSON report format.\nSample Scan Data Sample Aqua scans can be found here.\n","categories":"","description":"","excerpt":"JSON report format.\nSample Scan Data Sample Aqua scans can be found ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/aqua/","tags":"","title":"Aqua"},{"body":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter 'json' js.com.afr Sample Scan Data Sample Arachni Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Arachni Web Scanner (https://www.arachni-scanner.com)\nReports are ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/arachni/","tags":"","title":"Arachni Scanner"},{"body":"AuditJS scanning tool using OSSIndex database and generated with --json or -j option (https://www.npmjs.com/package/auditjs).\nauditjs ossi --json \u003e auditjs_report.json Sample Scan Data Sample AuditJS (OSSIndex) scans can be found here.\n","categories":"","description":"","excerpt":"AuditJS scanning tool using OSSIndex database and generated with ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/auditjs/","tags":"","title":"AuditJS (OSSIndex)"},{"body":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file.\nSample Scan Data Sample AWS Prowler Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Prowler file can be imported as a CSV (-M csv) or JSON (-M json) file. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/aws_prowler/","tags":"","title":"AWS Prowler Scanner"},{"body":"File Types DefectDojo parser accepts a native json file produced by prowler v3 with file extension .json or a ocsf-json file produced by prowler v4 with file extension .ocsf.json. Please note: earlier versions of AWS Prowler create output data in a different format. See our other prowler parser documentation if you are using an earlier version of AWS Prowler.\nJSON reports can be created from the AWS Prowler v3 CLI using the following command: prowler \u003cprovider\u003e -M json\nJSON-OCSF reports can be created from the AWS Prowler v4 CLI using the following command: prowler \u003cprovider\u003e -M json-ocsf\nAcceptable Prowler v3 JSON format Parser expects an array of assessments. All properties are strings and are required by the parser.\n [ { \"AssessmentStartTime\": \"example_timestamp\", \"FindingUniqueId\": \"example_uniqueIdFromTool\", \"Provider\": \"example_provider\", \"CheckID\": \"acm_certificates_expiration_check\", \"CheckTitle\": \"Check if ACM Certificates are about to expire in specific days or less\", \"CheckType\": [ \"Example ASFF-Compliant Finding Type\" ], \"ServiceName\": \"example_awsServiceName\", \"SubServiceName\": \"\", \"Status\": \"FAIL\", \"StatusExtended\": \"Example status description\", \"Severity\": \"example_severity\", \"ResourceType\": \"AwsCertificateManagerCertificate\", \"ResourceDetails\": \"\", \"Description\": \"Example general test description.\", \"Risk\": \"Example test impact description.\", \"RelatedUrl\": \"https://docs.aws.amazon.com/config/latest/developerguide/acm-certificate-expiration-check.html\", \"Remediation\": { \"Code\": { \"NativeIaC\": \"\", \"Terraform\": \"\", \"CLI\": \"\", \"Other\": \"\" }, \"Recommendation\": { \"Text\": \"Example recommendation.\", \"Url\": \"https://docs.aws.amazon.com/config/latest/developerguide/example_related_documentation.html\" } }, \"Compliance\": { \"GDPR\": [ \"article_32\" ], ... }, \"Categories\": [], \"DependsOn\": [], \"RelatedTo\": [], \"Notes\": \"\", \"Profile\": null, \"AccountId\": \"example_accountId\", \"OrganizationsInfo\": null, \"Region\": \"example_region\", \"ResourceId\": \"example.resource.id.com\", \"ResourceArn\": \"arn:aws:acm:us-east-1:999999999999:certificate/ffffffff-0000-0000-0000-000000000000\", \"ResourceTags\": {} } ... ] Acceptable Prowler v4 JSON-OCSF format The parser expects an array of assessments. All properties are strings and are required by the parser.\n[{ \"metadata\": { \"event_code\": \"iam_role_administratoraccess_policy_permissive_trust_relationship\", \"product\": { \"name\": \"Prowler\", \"vendor_name\": \"Prowler\", \"version\": \"4.2.1\" }, \"version\": \"1.2.0\" }, \"severity_id\": 4, \"severity\": \"High\", \"status\": \"Suppressed\", \"status_code\": \"FAIL\", \"status_detail\": \"IAM Role myAdministratorExecutionRole has AdministratorAccess policy attached that has too permissive trust relationship.\", \"status_id\": 3, \"unmapped\": { \"check_type\": \"\", \"related_url\": \"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_job-functions.html#jf_administrator\", \"categories\": \"trustboundaries\", \"depends_on\": \"\", \"related_to\": \"\", \"notes\": \"CAF Security Epic: IAM\", \"compliance\": {} }, \"activity_name\": \"Create\", \"activity_id\": 1, \"finding_info\": { \"created_time\": \"2024-06-03T14:15:19.382075\", \"desc\": \"Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\", \"product_uid\": \"prowler\", \"title\": \"Ensure IAM Roles with attached AdministratorAccess policy have a well defined trust relationship\", \"uid\": \"prowler-aws-iam_role_administratoraccess_policy_permissive_trust_relationship-123456789012-us-east-1-myAdministratorExecutionRole\" }, \"resources\": [ { \"cloud_partition\": \"aws\", \"region\": \"us-east-1\", \"data\": { \"details\": \"\" }, \"group\": { \"name\": \"iam\" }, \"labels\": [], \"name\": \"myAdministratorExecutionRole\", \"type\": \"AwsIamRole\", \"uid\": \"arn:aws:iam::123456789012:role/myAdministratorExecutionRole\" } ], \"category_name\": \"Findings\", \"category_uid\": 2, \"class_name\": \"DetectionFinding\", \"class_uid\": 2004, \"cloud\": { \"account\": { \"name\": \"\", \"type\": \"AWS_Account\", \"type_id\": 10, \"uid\": \"123456789012\", \"labels\": [] }, \"org\": { \"name\": \"\", \"uid\": \"\" }, \"provider\": \"aws\", \"region\": \"us-east-1\" }, \"event_time\": \"2024-06-03T14:15:19.382075\", \"remediation\": { \"desc\": \"Apply the principle of least privilege. Instead of AdministratorAccess, assign only the permissions necessary for specific roles and tasks. Create custom IAM policies with minimal permissions based on the principle of least privilege. If a role really needs AdministratorAccess, the trust relationship must be well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\", \"references\": [ \"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\" ] }, \"risk_details\": \"The AWS-managed AdministratorAccess policy grants all actions for all AWS services and for all resources in the account and as such exposes the customer to a significant data leakage threat. It is therefore particularly important that the trust relationship is well defined to restrict it usage only to the Principal, Action, Audience and Subject intended for it.\", \"type_uid\": 200401, \"type_name\": \"Create\" }] Sample Scan Data Unit tests of AWS Prowler v3 JSON and Prowler v4 JSON-OCSF can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/aws_prowler_v3.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a native json file produced by ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/aws_prowler_v3plus/","tags":"","title":"AWS Prowler V3"},{"body":"AWS Security Hub consumes, aggregates, organizes, and prioritizes findings from AWS security services and from the third-party product integrations. Security Hub processes these findings using a standard findings format called the AWS Security Finding Format (ASFF), which eliminates the need for time-consuming data conversion efforts. Then it correlates ingested findings across products to prioritize the most important ones.\nReference: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-findings-format.html\nProwler tool can generate this format with option -M json-asff.\nSample Scan Data Sample AWS Security Finding Format (ASFF) scans can be found here.\n","categories":"","description":"","excerpt":"AWS Security Hub consumes, aggregates, organizes, and prioritizes ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/asff/","tags":"","title":"AWS Security Finding Format (ASFF)"},{"body":"File Types This DefectDojo parser accepts JSON files from AWS Security Hub. The JSON reports can be created from the AWS Security Hub CLI using the following command: aws securityhub get-findings.\nAWS Security Hub integrates with multiple AWS Tools. Thus, you can retrieve findings from various AWS sources through AWS Security Hub. This parser is able to handle the following findings retrieved over AWS Security Hub:\n AWS Security Hub Compliance Checks AWS Security Hub GuardDuty AWS Security Hub Inspector  Example Commands to retrieve JSON output  AWS Security Hub Compliance Checks: aws securityhub get-findings --filters ComplianceStatus=\"[{Comparison=EQUALS,Value=FAILED}]\" | jq \".\" \u003e output.json AWS Security Hub GuardDuty: aws securityhub get-findings --filters ProductName=\"[{Value=GuardDuty,Comparison=EQUALS}]\" | jq \".\" \u003e output.json AWS Security Hub Inspector: aws securityhub get-findings --filters ProductName=\"[{Value=Inspector,Comparison=EQUALS}]\" | jq \".\" \u003e output.json  Sample Scan Data Sample scan data for testing purposes can be found here.\n","categories":"","description":"","excerpt":"File Types This DefectDojo parser accepts JSON files from AWS Security ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/awssecurityhub/","tags":"","title":"AWS Security Hub"},{"body":"Azure Security Center recommendations can be exported from the user interface in CSV format.\nSample Scan Data Sample Azure Security Center Recommendations Scan scans can be found here.\n","categories":"","description":"","excerpt":"Azure Security Center recommendations can be exported from the user ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/azure_security_center_recommendations/","tags":"","title":"Azure Security Center Recommendations Scan"},{"body":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bandit, you will need to install and run the .json report formatter from your Bandit instance.\nSee Bandit documentation: https://bandit.readthedocs.io/en/latest/formatters/index.html\nAcceptable JSON Format All properties are expected as strings, except ‚Äúmetrics‚Äù properties, which are expected as numbers. All properties are required by the parser.\n{ \"errors\": [], \"generated_at\": \"example-timestamp\", \"metrics\": { \"_totals\": { \"CONFIDENCE.HIGH\": 1.0, \"CONFIDENCE.LOW\": 0.0, \"CONFIDENCE.MEDIUM\": 0.0, \"CONFIDENCE.UNDEFINED\": 0.0, \"SEVERITY.HIGH\": 0.0, \"SEVERITY.LOW\": 1.0, \"SEVERITY.MEDIUM\": 0.0, \"SEVERITY.UNDEFINED\": 0.0, \"loc\": 2, \"nosec\": 0 }, \"one/one.py\": { \"CONFIDENCE.HIGH\": 1.0, \"CONFIDENCE.LOW\": 0.0, \"CONFIDENCE.MEDIUM\": 0.0, \"CONFIDENCE.UNDEFINED\": 0.0, \"SEVERITY.HIGH\": 0.0, \"SEVERITY.LOW\": 1.0, \"SEVERITY.MEDIUM\": 0.0, \"SEVERITY.UNDEFINED\": 0.0, \"loc\": 2, \"nosec\": 0 } ... }, \"results\": [ { \"code\": \"1 import os\\n2 assert False\\n\", \"filename\": \"example.filename\", \"issue_confidence\": \"example_confidence\", \"issue_severity\": \"example_severity\", \"issue_text\": \"Example issue description.\", \"line_number\": 2, \"line_range\": [ 2 ], \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\", \"test_id\": \"B101\", \"test_name\": \"assert_used\" } ... ] } Sample Scan Data Sample Bandit scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file.\nTo export a .json ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/bandit/","tags":"","title":"Bandit"},{"body":"File Types DefectDojo parser accepts a .json file.\nTo export a .json file from Bearer CLI, pass ‚Äú-f json‚Äù to your Bearer command\nSee Bearer documentation: https://docs.bearer.com/reference/commands/\nSample Scan Data Sample Bearer scans can be found here\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file.\nTo export a .json ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/bearer_cli/","tags":"","title":"Bearer CLI"},{"body":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to ‚ÄúBlackDuck API‚Äù and Authentication Type ‚ÄúAPI Key‚Äù. Paste your BlackDuck API token in the API Key field.\nIn Add API Scan Configuration provide the ID of the project from which to import findings in the field Service key 1. Provide the version of the project from which to import findings in the field Service key 2.\n","categories":"","description":"","excerpt":"All parsers which using API have common basic configuration step but ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/blackduck/","tags":"","title":"Blackduck API"},{"body":"What Black Duck Binary Analysis gives you visibility into open source and third-party dependencies that have been compiled into executables, libraries, containers, and firmware. You can analyze individual files using an intuitive user interface or Black Duck multifactor open source detection, which automates the scanning of binary artifacts.\nUsing a combination of static and string analysis techniques coupled with fuzzy matching against the Black Duck KnowledgeBase, Black Duck Binary Analysis quickly and reliably identifies components, even if they‚Äôve been modified.\nFor more info, check out Black Duck Binary Analysis here.\nWhy Open source vulnerabilities aren‚Äôt the only security issues that might be lurking in application binaries.\nBlack Duck Binary Analysis can also detect if sensitive information like email addresses, authorization tokens, compiler switches, and passwords are exposed, and it identifies when mobile applications request excessive permissions‚Äîall of which puts your organization and users' personal data at risk.\nHow  Initiate Black Duck Binary Analysis scans using the UI, REST API, or drivers such as pwn_bdba_scan found within the security automation framework, PWN Import a single BDBA vulnerabilty csv results file into DefectDojo leveraging the UI, REST API, or drivers such as pwn_defectdojo_importscan or pwn_defectdojo_reimportscan.  Sample Scan Data Sample Blackduck Binary Analysis scans can be found here.\n","categories":"","description":"","excerpt":"What Black Duck Binary Analysis gives you visibility into open source ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/blackduck_binary_analysis/","tags":"","title":"Blackduck Binary Analysis"},{"body":"Upload the zip file containing the security.csv and files.csv.\nSample Scan Data Sample Blackduck Component Risk scans can be found here.\n","categories":"","description":"","excerpt":"Upload the zip file containing the security.csv and files.csv.\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/blackduck_component_risk/","tags":"","title":"Blackduck Component Risk"},{"body":"2 options:\n Import the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.csv in order to produce findings that bear file locations information. Import a single security.csv file. Findings will not have any file location information.  Sample Scan Data Sample Blackduck Hub scans can be found here.\n","categories":"","description":"","excerpt":"2 options:\n Import the zip file as can be created by Blackduck export. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/blackduck/","tags":"","title":"Blackduck Hub"},{"body":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data Sample Brakeman Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import Brakeman Scanner findings in JSON format.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/brakeman/","tags":"","title":"Brakeman Scan"},{"body":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample Bugcrowd scans can be found here.\n","categories":"","description":"","excerpt":"Import Bugcrowd results in CSV format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/bugcrowd/","tags":"","title":"Bugcrowd"},{"body":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to ‚ÄúBugcrowd API‚Äù and Authentication Type ‚ÄúAPI Key‚Äù. Paste your BlackDuck API token in the API Key field. Set your API key directly in the format username:password in the API Token input, it will be added to the header 'Authorization': 'Token {}'.format(self.api_token),\nFor each product, you can configure 2 things:\n Service key 1: the bugcrowd program code (it‚Äôs the slug name in the url for the program, url safe) Service key 2: the bugcrowd target name (the full name, it will be url-encoded, you can find it in https://tracker.bugcrowd.com//settings/scope/target_groups)  It can be left empty so that all program submissions are imported    That way, per product, you can use the same program but separate by target, which is a fairly common way of filtering/grouping Bugcrowd. Adding support for a 3rd filtering would be possible with Service Key 3, feel free to make a PR.\n","categories":"","description":"","excerpt":"All parsers which using API have common basic configuration step but ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/bugcrowd/","tags":"","title":"Bugcrowd API"},{"body":"Import the text output generated with bundle-audit check\nSample Scan Data Sample Bundler-Audit scans can be found here.\n","categories":"","description":"","excerpt":"Import the text output generated with bundle-audit check\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/bundler_audit/","tags":"","title":"Bundler-Audit"},{"body":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML output.\nDastardly is a free, lightweight web application security scanner for your CI/CD pipeline. It is designed specifically for web developers, and checks your application for seven security issues that are likely to interest you during software development. Dastardly is based on the same scanner as Burp Suite (Burp Scanner).\nSample Scan Data Sample Burp Dastardly scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts Burp Dastardly Scans as an XML ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/burp_dastardly/","tags":"","title":"Burp Dastardly"},{"body":"File Types DefectDojo parser accepts a Standard Report as an HTML file. To parse an XML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp/\nSee also Burp documentation for info on how to export a Standard Report: https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nSample Scan Data Sample Burp Enterprise Scan scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a Standard Report as an HTML ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/burp_enterprise/","tags":"","title":"Burp Enterprise Scan"},{"body":"Import the JSON data returned from the BurpSuite Enterprise GraphQL API. Append all the issues returned to a list and save it as the value for the key ‚ÄúIssues‚Äù. There is no need to filter duplicates, the parser will automatically combine issues with the same name.\nExample:\n{ \"Issues\": [ { \"issue_type\": { \"name\": \"Cross-site scripting (reflected)\", \"description_html\": \"Issue Description\", \"remediation_html\": \"Issue Remediation\", \"vulnerability_classifications_html\": \"\u003cli\u003e\u003ca href=\\\"https://cwe.mitre.org/data/definitions/79.html\\\"\u003eCWE-79: Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')\u003c/a\u003e\u003c/li\u003e\", \"references_html\": \"\u003cli\u003e\u003ca href=\\\"https://portswigger.net/web-security/cross-site-scripting\\\"\u003eCross-site scripting\u003c/a\u003e\u003c/li\u003e\" }, \"description_html\": \"Details\", \"remediation_html\": \"Remediation Details\", \"severity\": \"high\", \"path\": \"/burp\", \"origin\": \"https://portswigger.net\", \"evidence\": [ { \"request_index\": 0, \"request_segments\": [ { \"data_html\": \"GET\" }, { \"highlight_html\": \"data\" }, { \"data_html\": \" HTTP More data\" } ] }, { \"response_index\": 0, \"response_segments\": [ { \"data_html\": \"HTTP/2 200 OK \" }, { \"highlight_html\": \"data\" }, { \"data_html\": \"More data\" } ] } ] } ] } Example GraphQL query to get issue details:\nquery Issue ($id: ID!, $serial_num: ID!) { issue(scan_id: $id, serial_number: $serial_num) { issue_type { name description_html remediation_html vulnerability_classifications_html references_html } description_html remediation_html severity path origin evidence { ... on Request { request_index request_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } ... on Response { response_index response_segments { ... on DataSegment { data_html } ... on HighlightSegment { highlight_html } } } } } } Sample Scan Data Sample Burp GraphQL scans can be found here.\n","categories":"","description":"","excerpt":"Import the JSON data returned from the BurpSuite Enterprise GraphQL ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/burp_graphql/","tags":"","title":"Burp GraphQL"},{"body":"Import Burp REST API scan data in JSON format (/scan/[task_id] endpoint).\nSample Scan Data Sample Burp REST API scans can be found here.\n","categories":"","description":"","excerpt":"Import Burp REST API scan data in JSON format (/scan/[task_id] ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/burp_api/","tags":"","title":"Burp REST API"},{"body":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. To parse an HTML file instead, use this method: https://documentation.defectdojo.com/integrations/parsers/file/burp_enterprise/\nWhen the Burp report is generated, the recommended option is Base64 encoding both the request and response fields - e.g. check the box that says \"Base64-encode requests and responses\". These fields will be processed and made available in the 'Finding View' page.\nSee also: Burp documentation - XML export is described under ‚ÄúExport Issue data‚Äù. https://portswigger.net/burp/documentation/enterprise/work-with-scan-results/generate-reports\nAcceptable XML Format All XML elements are required and will be parsed as strings.\n\u003cissues burpVersion=\"1.6.05\" exportTime=\"Sat Sep 13 22:39:44 CEST 2014\"\u003e \u003cissue\u003e \u003cserialNumber\u003eexampleSerialNumber\u003c/serialNumber\u003e \u003ctype\u003eexampleTypeNumber\u003c/type\u003e \u003cname\u003eExample Issue Name\u003c/name\u003e \u003chost ip=\"192.168.187.137\"\u003ehttp://bwa\u003c/host\u003e \u003cpath\u003e\u003c![CDATA[/bodgeit/basket.jsp]]\u003e\u003c/path\u003e \u003clocation\u003e\u003c![CDATA[/bodgeit/basket.jsp [b_id cookie]]]\u003e\u003c/location\u003e \u003cseverity\u003eExample Severity\u003c/severity\u003e \u003cconfidence\u003eFirm\u003c/confidence\u003e \u003cissueBackground\u003e\u003c![CDATA[Example issue background.]]\u003e\u003c/issueBackground\u003e \u003cremediationBackground\u003e\u003c![CDATA[Example remediation info.]]\u003e\u003c/issueDetail\u003e \u003cremediationDetail\u003e\u003c![CDATA[Example remediation details.]]\u003e\u003c/remediationDetail\u003e \u003crequestresponse\u003e \u003crequest method=\"POST\" base64=\"true\"\u003e\u003c![CDATA[exampleDataString=]]\u003e\u003c/request\u003e \u003cresponse base64=\"true\"\u003e\u003c![CDATA[exampleBase64DataString]]\u003e\u003c/response\u003e \u003cresponseRedirected\u003efalse\u003c/responseRedirected\u003e \u003c/requestresponse\u003e \u003c/issue\u003e ... \u003c/issues\u003e Sample Scan Data Sample Burp scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts Burp Issue data as an .xml file. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/burp/","tags":"","title":"Burp XML"},{"body":"Import JSON output of cargo-audit scan report https://crates.io/crates/cargo-audit\nSample Scan Data Sample CargoAudit Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON output of cargo-audit scan report ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/cargo_audit/","tags":"","title":"CargoAudit Scan"},{"body":" Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis)  To generate the OSA report using Checkmarx CLI: ./runCxConsole.sh OsaScan -v -CxServer \u003c...\u003e -CxToken \u003c..\u003e -projectName \u003c...\u003e -enableOsa -OsaLocationPath \u003clib_folder\u003e -OsaJson \u003coutput_folder\u003e\nThat will generate three files, two of which are needed for defectdojo. Build the file for defectdojo with the jq utility: jq -s . CxOSAVulnerabilities.json CxOSALibraries.json\nData for SAST, SCA and KICS are supported.\nSample Scan Data Sample Checkmarx scans can be found here.\n","categories":"","description":"","excerpt":" Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/checkmarx/","tags":"","title":"Checkmarx"},{"body":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample Checkmarx One scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON Checkmarx One scanner reports\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/checkmarx_one/","tags":"","title":"Checkmarx One Scan"},{"body":"File Types DefectDojo parser accepts Checkov scan data as a .JSON file.\nJSON files can be created from the Checkov CLI: https://www.checkov.io/2.Basics/CLI%20Command%20Reference.html\nAcceptable JSON Format { \"check_type\": \"terraform\", \"results\": { \"passed_checks\": [ ], \"failed_checks\": [ { \"check_id\": \"CKV_AZURE_41\", \"check_name\": \"Ensure the key vault is recoverable\", \"check_result\": { \"result\": \"FAILED\" }, \"code_block\": [ ], \"file_path\": \"file_path\", \"file_line_range\": [ 1, 16 ], \"resource\": \"azurerm_key_vault.main\", \"check_class\": \"checkov.terraform.checks.resource.azure.KeyvaultRecoveryEnabled\", \"guideline\": \"https://docs.bridgecrew.io/docs/ensure-the-key-vault-is-recoverable\" }, ... ], \"skipped_checks\": [], \"parsing_errors\": [] }, \"summary\": { \"passed\": 0, \"failed\": 2, \"skipped\": 0, \"parsing_errors\": 0, \"checkov_version\": \"1.0.467\" } } Sample Scan Data Sample Checkov scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts Checkov scan data as a .JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/checkov/","tags":"","title":"Checkov Report"},{"body":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile Types DefectDojo parser accepts Chef Inspect log scan data as a .log or .txt file.\nSample Scan Data Sample Chef Inspect logs can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/chefinspect\n","categories":"","description":"","excerpt":"Chef Inspect outputs log from https://github.com/inspec/inspec\nFile ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/chefinspect/","tags":"","title":"Chef Inspect Log"},{"body":"You can import JSON reports of Docker image vulnerabilities found by a Clair scan or the Clair Klar client.\nSample Scan Data Sample Clair Scan scans can be found here.\n","categories":"","description":"","excerpt":"You can import JSON reports of Docker image vulnerabilities found by a ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/clair/","tags":"","title":"Clair Scan"},{"body":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON output.\nSample Scan Data Sample Cloudsploit (AquaSecurity) scans can be found here.\n","categories":"","description":"","excerpt":"From: https://github.com/aquasecurity/cloudsploit . Import the JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/cloudsploit/","tags":"","title":"Cloudsploit (AquaSecurity)"},{"body":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to ‚ÄúCobalt.io‚Äù and Authentication Type ‚ÄúAPI Key‚Äù. Paste your Cobalt.io API token in the API Key field and the desired org token in the Extras field.\nIn Add API Scan Configuration provide the ID of the asset from which to import findings in the field Service key 1. The ID can be found at the end of the URL when viewing the asset in your browser.\nIf you have more than one asset configured, you must also select which Cobalt.io API Scan Configuratio to use.\n","categories":"","description":"","excerpt":"All parsers which using API have common basic configuration step but ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/cobalt/","tags":"","title":"Cobalt.io API Import "},{"body":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found here.\n","categories":"","description":"","excerpt":"CSV Report\nSample Scan Data Sample Cobalt.io Scan scans can be found ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/cobalt/","tags":"","title":"Cobalt.io Scan"},{"body":"Import Codechecker static analyzer report in JSON format: https://codechecker.readthedocs.io/en/latest/ Report format described here: https://codechecker.readthedocs.io/en/latest/analyzer/user_guide/#parse\nOne could make Codechecker JSON report using command like this:\nCodeChecker parse /path/to/codechecker/analyzer/output/directory -e json -o /path/to/output/file.json Before this step you should build your project with Codechecker build process interception,\nodeChecker log -b \"make -j8\" -o ./my.project.codechecker.log then analyze it\nCodeChecker analyze ./codechecker.log -o /path/to/codechecker/analyzer/output/directory Sample Scan Data Sample Codechecker Report native scans can be found here.\n","categories":"","description":"","excerpt":"Import Codechecker static analyzer report in JSON format: ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/codechecker/","tags":"","title":"Codechecker Report native"},{"body":"CodeQL can be used to generate a SARIF report, that can be imported into Defect Dojo:\ncodeql database analyze db python-security-and-quality.qls --sarif-add-snippets --format=sarif-latest --output=security-extended.sarif The same can be achieved by running the CodeQL GitHub action with the add-snippet property set to true.\n","categories":"","description":"","excerpt":"CodeQL can be used to generate a SARIF report, that can be imported ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/codeql/","tags":"","title":"CodeQL"},{"body":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found here.\n","categories":"","description":"","excerpt":"CSV Report\nSample Scan Data Sample Contrast Scanner scans can be found ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/contrast/","tags":"","title":"Contrast Scanner"},{"body":"Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\n displayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI)  Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected\nSample Scan Data Sample Coverity API scans can be found here.\n","categories":"","description":"","excerpt":"Export Coverity API view data in JSON format (/api/viewContents/issues ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/coverity_api/","tags":"","title":"Coverity API"},{"body":"File Types This DefectDojo parser accepts JSON files created from the Synopsys Coverity CLI using the following command: coverity scan.\nDocumentation for CLI can be found here.\nExample Commands to retrieve JSON output Run coverity scan --project-dir \u003cproject_dir\u003e --local \u003cresult_file\u003e --local-format json to create the JSON report.\nSample Scan Data Sample Coverity scans can be found here.\n","categories":"","description":"","excerpt":"File Types This DefectDojo parser accepts JSON files created from the ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/coverity_scan/","tags":"","title":"Coverity Scan JSON Report"},{"body":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data Sample Crashtest Security scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON Report Import XML Report in JUnit Format\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/crashtest_security/","tags":"","title":"Crashtest Security"},{"body":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan Report scans can be found here.\n","categories":"","description":"","excerpt":"Import CSV credential scanner reports\nSample Scan Data Sample CredScan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/cred_scan/","tags":"","title":"CredScan Report"},{"body":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample Scan Data Sample Crunch42 Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON findings from Crunch42 vulnerability scan tool.\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/crunch42/","tags":"","title":"Crunch42 Scan"},{"body":"CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.\nFrom: https://www.cyclonedx.org/\nExample with Anchore Grype:\n./grype defectdojo/defectdojo-django:1.13.1 -o cyclonedx \u003e report.xml Example with cyclonedx-bom tool:\npip install cyclonedx-bom cyclonedx-py Usage: cyclonedx-py [OPTIONS] Options: -i \u003cpath\u003e - the alternate filename to a frozen requirements.txt -o \u003cpath\u003e - the bom file to create -j - generate JSON instead of XML Sample Scan Data Sample CycloneDX scans can be found here.\n","categories":"","description":"","excerpt":"CycloneDX is a lightweight software bill of materials (SBOM) standard ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/cyclonedx/","tags":"","title":"CycloneDX"},{"body":"Import report in JSON generated with -j option\nSample Scan Data Sample DawnScanner scans can be found here.\n","categories":"","description":"","excerpt":"Import report in JSON generated with -j option\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dawnscanner/","tags":"","title":"DawnScanner"},{"body":"Import compliance, malware, secret, vulnerability reports from Deepfence Threatmapper in XLSX file format.\nSample Scan Data Sample Threatmapper scans can be found here. In this link are both .xlsx and .csv listed. They contain the same content, but csv can be read in the Browser, but only xlsx is supported by the parser.\n","categories":"","description":"","excerpt":"Import compliance, malware, secret, vulnerability reports from ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/deepfence_threatmapper/","tags":"","title":"Deepfence Threatmapper"},{"body":"OWASP Dependency Check output can be imported in Xml format. This parser ingests the vulnerable dependencies and inherits the suppressions.\n Suppressed vulnerabilities are tagged with the tag: suppressed. Suppressed vulnerabilities are marked as mitigated. If the suppression is missing any \u003cnotes\u003e tag, it tags them as no_suppression_document. Related vulnerable dependencies are tagged with related tag.  Sample Scan Data Sample Dependency Check scans can be found here.\n","categories":"","description":"","excerpt":"OWASP Dependency Check output can be imported in Xml format. This ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dependency_check/","tags":"","title":"Dependency Check"},{"body":"Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format. See here for more info on this JSON format: https://docs.dependencytrack.org/integrations/file-formats/\nSample Scan Data Sample Dependency Track scans can be found here.\n","categories":"","description":"","excerpt":"Dependency Track has implemented a DefectDojo integration. Information ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dependency_track/","tags":"","title":"Dependency Track"},{"body":"Import of JSON report from https://github.com/Yelp/detect-secrets\nSample Scan Data Sample Detect-secrets scans can be found here.\n","categories":"","description":"","excerpt":"Import of JSON report from https://github.com/Yelp/detect-secrets ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/detect_secrets/","tags":"","title":"Detect-secrets"},{"body":"Import JSON reports of OWASP docker-bench-security. docker-bench-security is a script that make tests based on CIS Docker Benchmark.\nSample Scan Data Sample docker-bench-security Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON reports of OWASP docker-bench-security. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dockerbench/","tags":"","title":"docker-bench-security Scanner"},{"body":"Import JSON container image linter reports https://github.com/goodwithtech/dockle\nSample Scan Data Sample Dockle Report scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON container image linter reports ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dockle/","tags":"","title":"Dockle Report"},{"body":"Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nSample Scan Data Sample DrHeader scans can be found here.\n","categories":"","description":"","excerpt":"Import of JSON report from ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/drheader/","tags":"","title":"DrHeader"},{"body":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample Scan Data Sample DSOP Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import XLSX findings from DSOP vulnerability scan pipelines.\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/dsop/","tags":"","title":"DSOP Scan"},{"body":"Import Edgescan vulnerabilities by API or JSON file\nAll parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nStep 1: Add tool configuration\n Select the gear icon from the left hand side of the page. Click on the Tool Configuration option and then + Add Tool Configuration from the dropdown menu. Once presented with a series of fields, set Tool Type to ‚ÄúEdgescan‚Äù and Authentication Type to ‚ÄúAPI Key‚Äù. Paste your Edgescan API key in the API Key field. Click on the Submit button.  Step 2: Add and configure a product\n Select the hamburger menu icon from the left hand side of the page. Click on the All Products option and then + Add Product. Fill in the fields presented. Once the product is added, click on the Settings option then Add API Scan Configuration. Select the previously added Edgescan Tool Configuration. Provide the edgescan asset ID(s) that you wish to import the findings for in the field Service key 1.  Note that multiple asset IDs should be comma separated with no spacing. If you want to import vulnerabilities for all assets, simply leave the Service key 1 field empty.    Step 3: Importing scan results\n After the previous steps are complete, you can import the findings by selecting the Findings option on the product‚Äôs page and then Import Scan Results. Once you are presented with a series of fields, select Edgescan Scan as the scan type.  If you have more than one asset configured, you must also select which Edgescan API Scan Configuration to use.   Click on the Import button.  Important Reminder:\n To ensure you‚Äôre not introducing duplicate vulnerabilities, always use the ‚ÄúRe-Upload Scan‚Äù option when re-importing findings from Edgescan. This can be found within the engagement‚Äôs options by clicking on Engagements , then the active engagement in question, then Edgescan Scan and selecting ‚ÄúRe-Upload Scan‚Äù from the dropdown menu located on the right.  ","categories":"","description":"","excerpt":"Import Edgescan vulnerabilities by API or JSON file\nAll parsers which ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/edgescan/","tags":"","title":"Edgescan"},{"body":"Import Edgescan vulnerabilities by JSON file or API - no file required\n","categories":"","description":"","excerpt":"Import Edgescan vulnerabilities by JSON file or API - no file required ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/edgescan/","tags":"","title":"Edgescan"},{"body":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint scans can be found here.\n","categories":"","description":"","excerpt":"ESLint Json report format (-f json)\nSample Scan Data Sample ESLint ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/eslint/","tags":"","title":"ESLint"},{"body":"You can either import the findings in .xml or in .fpr file format.  If you import a .fpr file, the parser will look for the file ‚Äòaudit.fvdl‚Äô and analyze it. An extracted example can be found here.\nSample Scan Data Sample Fortify scans can be found here.\nGenerate XML Output from Foritfy This section describes how to import XML generated from a Fortify FPR. It assumes you already have, or know how to acquire, an FPR file. Once you have the FPR file you will need use Fortify‚Äôs ReportGenerator tool (located in the bin directory of your fortify install). FORTIFY_INSTALL_ROOT/bin/ReportGenerator\nBy default, the Report Generator tool does not display all issues, it will only display one per category. To get all issues, copy the DefaultReportDefinitionAllIssues.xml to:\nFORTIFY_INSTALL_ROOT/Core/config/reports\nOnce this is complete, you can run the following command on your .fpr file to generate the required XML:\n./path/to/ReportGenerator -format xml -f /path/to/output.xml -source /path/to/downloaded/artifact.fpr -template DefaultReportDefinitionAllIssues.xml ","categories":"","description":"","excerpt":"You can either import the findings in .xml or in .fpr file format.  If ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/fortify/","tags":"","title":"Fortify"},{"body":"Import Generic findings in CSV or JSON format.\nAttributes supported for CSV:\n Date: Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId: Cwe identifier, must be an integer value. Url: Url associated with the finding. Severity: Severity of the finding. Must be one of Info, Low, Medium, High, or Critical. Description: Description of the finding. Can be multiple lines if enclosed in double quotes. Mitigation: Possible Mitigations for the finding. Can be multiple lines if enclosed in double quotes. Impact: Detailed impact of the finding. Can be multiple lines if enclosed in double quotes. References: References associated with the finding. Can be multiple lines if enclosed in double quotes. Active: Indicator if the finding is active. Must be empty, TRUE or FALSE Verified: Indicator if the finding has been verified. Must be empty, TRUE, or FALSE FalsePositive: Indicator if the finding is a false positive. Must be TRUE, or FALSE. Duplicate:Indicator if the finding is a duplicate. Must be TRUE, or FALSE  The CSV expects a header row with the names of the attributes.\nExample of JSON format:\n{ \"findings\": [ { \"title\": \"test title with endpoints as dict\", \"description\": \"Some very long description with\\n\\n some UTF-8 chars √† qu'il est beau\", \"severity\": \"Medium\", \"mitigation\": \"Some mitigation\", \"date\": \"2021-01-06\", \"cve\": \"CVE-2020-36234\", \"cwe\": 261, \"cvssv3\": \"CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\", \"file_path\": \"src/first.cpp\", \"line\": 13, \"endpoints\": [ { \"host\": \"exemple.com\" } ] }, { \"title\": \"test title with endpoints as strings\", \"description\": \"Some very long description with\\n\\n some UTF-8 chars √† qu'il est beau2\", \"severity\": \"Critical\", \"mitigation\": \"Some mitigation\", \"date\": \"2021-01-06\", \"cve\": \"CVE-2020-36235\", \"cwe\": 287, \"cvssv3\": \"CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\", \"file_path\": \"src/two.cpp\", \"line\": 135, \"endpoints\": [ \"http://urlfiltering.paloaltonetworks.com/test-command-and-control\", \"https://urlfiltering.paloaltonetworks.com:2345/test-pest\" ] }, { \"title\": \"test title\", \"description\": \"Some very long description with\\n\\n some UTF-8 chars √† qu'il est beau2\", \"severity\": \"Critical\", \"mitigation\": \"Some mitigation\", \"date\": \"2021-01-06\", \"cve\": \"CVE-2020-36236\", \"cwe\": 287, \"cvssv3\": \"CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:C/C:L/I:L/A:N\", \"file_path\": \"src/threeeeeeeeee.cpp\", \"line\": 1353 } ] } This parser supports an attributes that accept files as Base64 strings. These files are attached to the respective findings.\nExample:\n{ \"name\": \"My wonderful report\", \"findings\": [ { \"title\": \"Vuln with image\", \"description\": \"Some very long description\", \"severity\": \"Medium\", \"files\": [ { \"title\": \"Screenshot from 2017-04-10 16-54-19.png\", \"data\": \"iVBORw0KGgoAAAANSUhEUgAABWgAAAK0CAIAAAARSkPJAAAAA3N\u003c...\u003eTkSuQmCC\" } ] } ] } This parser supports an attribute name and type to be able to define TestType. Based on this, you can define custom HASHCODE_FIELDS or DEDUPLICATION_ALGORITHM in the settings.\nExample:\n{ \"name\": \"My wonderful report\", \"type\": \"My custom Test type\", \"findings\": [ ] } Sample Scan Data Sample Generic Findings Import scans can be found here.\n","categories":"","description":"","excerpt":"Import Generic findings in CSV or JSON format.\nAttributes supported ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/generic/","tags":"","title":"Generic Findings Import"},{"body":"Import Ggshield findings in JSON format.\nSample Scan Data Sample Ggshield scans can be found here.\n","categories":"","description":"","excerpt":"Import Ggshield findings in JSON format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ggshield/","tags":"","title":"Ggshield"},{"body":"Import findings from Github vulnerability scan (GraphQL Query): https://help.github.com/en/github/managing-security-vulnerabilities\nCurrently the parser is able to manage only RepositoryVulnerabilityAlert object. The parser has some kind of search feature which detect the data in the report.\nHere is the mandatory objects and attributes:\nvulnerabilityAlerts (RepositoryVulnerabilityAlert object) + id + createdAt (optional) + vulnerableManifestPath + state (optional) + securityVulnerability (SecurityVulnerability object) + severity (CRITICAL/HIGH/LOW/MODERATE) + package (optional) + name (optional) + advisory (SecurityAdvisory object) + description + summary + description + identifiers + value + references (optional) + url (optional) + cvss (optional) + score (optional) + vectorString (optional) + cwes (optional) References:\n https://docs.github.com/en/graphql/reference/objects#repositoryvulnerabilityalert https://docs.github.com/en/graphql/reference/objects#securityvulnerability  Github v4 graphql query to fetch data, with extended information like the repository name and url, alert number.\nquery getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } Another example of Python script, to have a function that queries any repository, with support for paginated responses and get all findings. Has a filter to only get OPEN dependabot alerts but this can be removed in the GraphQL query\ndef make_query(after_cursor=None): return \"\"\" query getVulnerabilitiesByRepoAndOwner($name: String!, $owner: String!) { repository(name: $name, owner: $owner) { vulnerabilityAlerts(first: 100, after:AFTER, states: OPEN) { nodes { id createdAt vulnerableManifestPath securityVulnerability { severity updatedAt package { name ecosystem } firstPatchedVersion { identifier } vulnerableVersionRange advisory { description summary identifiers { value type } references { url } cvss { vectorString } } } vulnerableManifestPath state vulnerableManifestFilename vulnerableRequirements number dependencyScope dismissComment dismissReason dismissedAt fixedAt } totalCount pageInfo { endCursor hasNextPage hasPreviousPage startCursor } } nameWithOwner url } } \"\"\".replace( \"AFTER\", '\"{}\"'.format(after_cursor) if after_cursor else \"null\" ) # accumulates all pages data into a single object def get_dependabot_alerts_repository(repo, owner): keep_fetching = True after_cursor = None output_result = {\"data\": {\"repository\": {\"vulnerabilityAlerts\": {\"nodes\": []}}}} while keep_fetching: headers = {\"Authorization\": AUTH_TOKEN} request = requests.post( url=\"https://api.github.com/graphql\", json={ \"operationName\": \"getVulnerabilitiesByRepoAndOwner\", \"query\": make_query(after_cursor), \"variables\": {\"name\": repo, \"owner\": owner}, }, headers=headers, ) result = request.json() output_result[\"data\"][\"repository\"][\"name\"] = result[\"data\"][\"repository\"][ \"name\" ] output_result[\"data\"][\"repository\"][\"url\"] = result[\"data\"][\"repository\"][\"url\"] if result[\"data\"][\"repository\"][\"vulnerabilityAlerts\"][\"totalCount\"] == 0: return None output_result[\"data\"][\"repository\"][\"vulnerabilityAlerts\"][\"nodes\"] += result[ \"data\" ][\"repository\"][\"vulnerabilityAlerts\"][\"nodes\"] keep_fetching = result[\"data\"][\"repository\"][\"vulnerabilityAlerts\"][\"pageInfo\"][ \"hasNextPage\" ] after_cursor = result[\"data\"][\"repository\"][\"vulnerabilityAlerts\"][\"pageInfo\"][ \"endCursor\" ] print( \"Fetched {} alerts for repo {}/{}\".format( result[\"data\"][\"repository\"][\"vulnerabilityAlerts\"][\"totalCount\"], owner, repo, ) ) return json.dumps(output_result, indent=2) Sample Scan Data Sample Github Vulnerability scans can be found here.\n","categories":"","description":"","excerpt":"Import findings from Github vulnerability scan (GraphQL Query): ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/github_vulnerability/","tags":"","title":"Github Vulnerability"},{"body":"GitLab API Fuzzing Report report file can be imported in JSON format (option ‚Äìjson)\nSample Scan Data Sample GitLab API Fuzzing Report Scan scans can be found here.\n","categories":"","description":"","excerpt":"GitLab API Fuzzing Report report file can be imported in JSON format ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_api_fuzzing/","tags":"","title":"GitLab API Fuzzing Report Scan"},{"body":"GitLab Container Scan report file can be imported in JSON format (option ‚Äìjson)\nSample Scan Data Sample GitLab Container Scan scans can be found here.\n","categories":"","description":"","excerpt":"GitLab Container Scan report file can be imported in JSON format ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_container_scan/","tags":"","title":"GitLab Container Scan"},{"body":"GitLab DAST Report in JSON format (option ‚Äìjson)\nSample Scan Data Sample GitLab DAST Report scans can be found here.\n","categories":"","description":"","excerpt":"GitLab DAST Report in JSON format (option ‚Äìjson)\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_dast/","tags":"","title":"GitLab DAST Report"},{"body":"Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nSample Scan Data Sample GitLab Dependency Scanning Report scans can be found here.\n","categories":"","description":"","excerpt":"Import Dependency Scanning Report vulnerabilities in JSON format: ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_dep_scan/","tags":"","title":"GitLab Dependency Scanning Report"},{"body":"Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nSample Scan Data Sample GitLab SAST Report scans can be found here.\n","categories":"","description":"","excerpt":"Import SAST Report vulnerabilities in JSON format: ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_sast/","tags":"","title":"GitLab SAST Report"},{"body":"GitLab Secret Detection Report file can be imported in JSON format (option ‚Äìjson).\nSample Scan Data Sample GitLab Secret Detection Report scans can be found here.\n","categories":"","description":"","excerpt":"GitLab Secret Detection Report file can be imported in JSON format ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitlab_secret_detection_report/","tags":"","title":"GitLab Secret Detection Report"},{"body":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample Gitleaks scans can be found here.\n","categories":"","description":"","excerpt":"Import Gitleaks findings in JSON format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gitleaks/","tags":"","title":"Gitleaks"},{"body":"Google Cloud has a Artifact Registry that you can enable security scans https://cloud.google.com/artifact-registry/docs/analysis Once a scan is completed, results can be pulled via API/gcloud https://cloud.google.com/artifact-analysis/docs/metadata-storage and exported to JSON\nFile Types DefectDojo parser accepts Google Cloud Artifact Vulnerability Scan data as a .json file.\nSample Scan Data Sample reports can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/gcloud_artifact_scan\n","categories":"","description":"","excerpt":"Google Cloud has a Artifact Registry that you can enable security ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gcloud_artifact_scan/","tags":"","title":"Google Cloud Artifact Vulnerability Scan"},{"body":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample Gosec Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import Gosec Scanner findings in JSON format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/gosec/","tags":"","title":"Gosec Scanner"},{"body":"JSON vulnerability report generated by govulncheck tool, using a command like govulncheck -json . \u003e\u003e report.json\nSample Scan Data Sample Govulncheck scans can be found here.\n","categories":"","description":"","excerpt":"JSON vulnerability report generated by govulncheck tool, using a ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/govulncheck/","tags":"","title":"Govulncheck"},{"body":"Import HackerOne cases findings in JSON format\nSample Scan Data Sample HackerOne Cases scans can be found here.\n","categories":"","description":"","excerpt":"Import HackerOne cases findings in JSON format\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/h1/","tags":"","title":"HackerOne Cases"},{"body":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample Hadolint scans can be found here.\n","categories":"","description":"","excerpt":"Hadolint Dockerfile scan in json format.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/hadolint/","tags":"","title":"Hadolint"},{"body":"Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nSample Scan Data Sample Harbor Vulnerability scans can be found here.\n","categories":"","description":"","excerpt":"Import findings from Harbor registry container scan: ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/harbor_vulnerability/","tags":"","title":"Harbor Vulnerability"},{"body":"The HCL Appscan has the possibility to export the results in PDF, XML and CSV formats within the portal. However, this parser only supports the import of XML generated from HCL Appscan on cloud.\nSample Scan Data Sample HCL Appscan scans can be found here.\n","categories":"","description":"","excerpt":"The HCL Appscan has the possibility to export the results in PDF, XML ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/hcl_appscan/","tags":"","title":"HCL Appscan"},{"body":"Import findings from Horusec scan.\n./horusec_linux_x64 start -O=report.json -o json -i=\"tests/\" References:\n GitHub repository  Sample Scan Data Sample Horusec scans can be found here.\n","categories":"","description":"","excerpt":"Import findings from Horusec scan.\n./horusec_linux_x64 start ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/horusec/","tags":"","title":"Horusec"},{"body":"Import JSON report of the Humble scanner https://github.com/rfc-st/humble\nSample Scan Data Sample Humble Report scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON report of the Humble scanner ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/humble/","tags":"","title":"Humble Report"},{"body":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI Report scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON reports from HuskyCI\nSample Scan Data Sample HuskyCI ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/huskyci/","tags":"","title":"HuskyCI Report"},{"body":"Import JSON reports from THC Hydra.\nHydra can discover weak login credentials on different types of services (e.g. RDP).\nAs Hydra cannot provide a severity rating (as it doesn‚Äôt know how severe a weak login is at this scanned service), all imported findings will be rated ‚ÄòHigh‚Äô.\nSample JSON report:\n{ \"errormessages\": [ \"[ERROR] Error Message of Something\", \"[ERROR] Another Message\", \"These are very free form\" ], \"generator\": { \"built\": \"2019-03-01 14:44:22\", \"commandline\": \"hydra -b jsonv1 -o results.json ... ...\", \"jsonoutputversion\": \"1.00\", \"server\": \"127.0.0.1\", \"service\": \"http-post-form\", \"software\": \"Hydra\", \"version\": \"v8.5\" }, \"quantityfound\": 1, \"results\": [ { \"host\": \"127.0.0.1\", \"login\": \"bill@example.com\", \"password\": \"bill\", \"port\": 9999, \"service\": \"http-post-form\" } ], \"success\": false } Sample Scan Data Sample Hydra scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON reports from THC Hydra.\nHydra can discover weak login ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/hydra/","tags":"","title":"Hydra"},{"body":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan DAST scans can be found here.\n","categories":"","description":"","excerpt":"XML file from IBM App Scanner.\nSample Scan Data Sample IBM AppScan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ibm_app/","tags":"","title":"IBM AppScan DAST"},{"body":"XML Scan Result File from Immuniweb Scan.\nSample Scan Data Sample Immuniweb Scan scans can be found here.\n","categories":"","description":"","excerpt":"XML Scan Result File from Immuniweb Scan.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/immuniweb/","tags":"","title":"Immuniweb Scan"},{"body":"IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.).\nManual Import Use the Export CSV feature in the IntSights Threat Command GUI to create an IntSights Alerts.csv file. This CSV file can then be imported into Defect Dojo.\nAutomated Import The IntSights get-complete-alert API only returns details for a single alert. To automate the process, individually fetch details for each alert and append to a list. The list is then saved as the value for the key ‚ÄúAlerts‚Äù. This JSON object can then be imported into Defect Dojo.\nExample:\n{ \"Alerts\":[ { \"_id\":\"5c80egf83b4a3900078b6be6\", \"Details\":{ \"Source\":{ \"URL\":\"https://www.htbridge.com/websec/?id=ABCDEF\", \"Date\":\"2018-03-08T00:01:02.622Z\", \"Type\":\"Other\", \"NetworkType\":\"ClearWeb\" }, \"Images\":[ \"5c80egf833963a40007e01e8d\", \"5c80egf833b4a3900078b6bea\", \"5c80egf834626bd0007bd64db\" ], \"Title\":\"HTTP headers weakness in example.com web server\", \"Tags\":[], \"Type\":\"ExploitableData\", \"Severity\":\"Critical\", \"SubType\":\"VulnerabilityInTechnologyInUse\", \"Description\":\"X-XSS-PROTECTION and CONTENT-SECURITY-POLICY headers were not sent by the server, which makes it vulnerable for various attack vectors\" }, \"Assignees\":[ \"5c3c8f99903dfd0006ge5e61\" ], \"FoundDate\":\"2018-03-08T00:01:02.622Z\", \"Assets\":[ { \"Type\":\"Domains\", \"Value\":\"example.com\" } ], \"TakedownStatus\":\"NotSent\", \"IsFlagged\":false, \"UpdateDate\":\"2018-03-08T00:01:02.622Z\", \"RelatedIocs\":[], \"RelatedThreatIDs\":[], \"Closed\":{ \"IsClosed\":false } } ] }  Sample Scan Data Sample IntSights Report scans can be found here.\n","categories":"","description":"","excerpt":"IntSights Threat Command is a commercial Threat Intelligence platform ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/intsights/","tags":"","title":"IntSights Report"},{"body":"File Types Accepts a JSON File, generated from the JFrog Artifact Summary API Call.\nSample Scan Data / Unit Tests Sample JFrog Xray API Summary Artifact Scans can be found here.\nLink To Tool See JFrog Documentation: https://jfrog.com/help/r/jfrog-rest-apis/summary\n","categories":"","description":"","excerpt":"File Types Accepts a JSON File, generated from the JFrog Artifact ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/jfrog_xray_api_summary_artifact/","tags":"","title":"JFrog Xray API Summary Artifact Scan"},{"body":"Import the JSON format for the \"JFrog Xray On Demand Binary Scan\" file. Use this importer for Xray version 3.X\nJFrog file documentation:\nhttps://jfrog.com/help/r/jfrog-cli/on-demand-binary-scan\nSample Scan Data Sample JFrog Xray On Demand Binary Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import the JSON format for the \"JFrog Xray On Demand Binary Scan\" ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/jfrog_xray_on_demand_binary_scan/","tags":"","title":"JFrog Xray On Demand Binary Scan"},{"body":"Import the JSON format for the \"Security \u0026 Compliance | Reports\" export. Jfrog‚Äôs Xray tool is an add-on to their Artifactory repository that does Software Composition Analysis, see https://www.jfrog.com/confluence/display/JFROG/JFrog+Xray for more information. \"Xray Unified\" refers to Xray Version 3.0 and later.\nSample Scan Data Sample JFrog XRay Unified scans can be found here.\n","categories":"","description":"","excerpt":"Import the JSON format for the \"Security \u0026 Compliance | Reports\" ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/jfrog_xray_unified/","tags":"","title":"JFrog XRay Unified"},{"body":"Import the JSON format for the \"Security Export\" file. Use this importer for Xray version 2.X\nSample Scan Data Sample JFrogXRay scans can be found here.\n","categories":"","description":"","excerpt":"Import the JSON format for the \"Security Export\" file. Use this ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/jfrogxray/","tags":"","title":"JFrogXRay"},{"body":"Import of JSON report from https://github.com/Checkmarx/kics\nSample Scan Data Sample KICS Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import of JSON report from https://github.com/Checkmarx/kics\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kics/","tags":"","title":"KICS Scanner"},{"body":"Import Kiuwan Scan in CSV format. Export as CSV Results on Kiuwan.\nSample Scan Data Sample Kiuwan Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import Kiuwan Scan in CSV format. Export as CSV Results on Kiuwan. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kiuwan/","tags":"","title":"Kiuwan Scanner"},{"body":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan Data Sample kube-bench Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON reports of Kubernetes CIS benchmark scans.\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kubebench/","tags":"","title":"kube-bench Scanner"},{"body":"Kubeaudit is a command line tool and a Go package to audit Kubernetes clusters for various different security concerns. The output of of Kubeaudit which is supported within this parser is JSON. The tool can be found here\nSample Scan Data Sample Kubeaudit scans can be found here.\n","categories":"","description":"","excerpt":"Kubeaudit is a command line tool and a Go package to audit Kubernetes ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kubeaudit/","tags":"","title":"Kubeaudit Scan"},{"body":"Import JSON reports of kube-hunter scans. Use ‚Äúkube-hunter ‚Äìreport json‚Äù to produce the report in json format.\nSample Scan Data Sample kubeHunter Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON reports of kube-hunter scans. Use ‚Äúkube-hunter ‚Äìreport ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kubehunter/","tags":"","title":"kubeHunter Scanner"},{"body":"Kubescape is a K8s open-source tool providing a Kubernetes single pane of glass, including risk analysis, security compliance, RBAC visualizer, and image vulnerability scanning. Kubescape scans K8s clusters, YAML files, and HELM charts, detecting misconfigurations according to multiple frameworks (such as the NSA-CISA, MITRE ATT\u0026CK¬Æ), software vulnerabilities, and RBAC (role-based-access-control) violations at early stages of the CI/CD pipeline, calculates risk score instantly and shows risk trends over time.\nThe parser supports json output files\nSample Scan Data Sample Kubescape scans can be found here.\n","categories":"","description":"","excerpt":"Kubescape is a K8s open-source tool providing a Kubernetes single pane ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/kubescape/","tags":"","title":"Kubescape Scanner"},{"body":"File Types Accepts a JSON file, generated from the Mend* Unified Agent.\nSample Scan Data / Unit Tests Unit tests for Mend JSON files can be found at https://github.com/DefectDojo/django-DefectDojo/tree/master/unittests/scans/mend\nLink To Tool See documentation: https://docs.mend.io/bundle/unified_agent/page/example_of_a_unified_agent_json_report.html\nFormerly known as Whitesource.\n","categories":"","description":"","excerpt":"File Types Accepts a JSON file, generated from the Mend* Unified ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/mend/","tags":"","title":"Mend Scan"},{"body":"The Meterian JSON report output file can be imported.\nSample Scan Data Sample Meterian Scanner scans can be found here.\n","categories":"","description":"","excerpt":"The Meterian JSON report output file can be imported.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/meterian/","tags":"","title":"Meterian Scanner"},{"body":"Import XML report\nSample Scan Data Sample Microfocus Webinspect Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import XML report\nSample Scan Data Sample Microfocus Webinspect ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/microfocus_webinspect/","tags":"","title":"Microfocus Webinspect Scanner"},{"body":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data Sample MobSF Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Export a JSON file using the API, api/v1/report_json.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/mobsf/","tags":"","title":"MobSF Scanner"},{"body":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan Data Sample Mobsfscan scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON report from https://github.com/MobSF/mobsfscan\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/mobsfscan/","tags":"","title":"Mobsfscan"},{"body":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON report.\nSample Scan Data Sample Mozilla Observatory ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/mozilla_observatory/","tags":"","title":"Mozilla Observatory Scanner"},{"body":"This parser helps to parse Microsoft Defender Findings and supports two types of imports:\n You can import a JSON output file from the api/vulnerabilities/machinesVulnerabilities endpoint of Microsoft defender. You can upload a custom zip file which include multiple JSON files from two Microsoft Defender Endpoints. For that you have to make your own zip file and include two folders (machines/ and vulnerabilities/) within the zip file. For vulnerabilities/ you can attach multiple JSON files from the api/vulnerabilities/machinesVulnerabilities REST API endpoint of Microsoft Defender. Furthermore, in machines/ you can attach the JSON output from the api/machines REST API endpoint of Microsoft Defender. Then, the parser uses the information in both folders to add more specific information like the affected IP Address to the finding.  Sample Scan Data Sample MS Defender Parser scans can be found here.\n","categories":"","description":"","excerpt":"This parser helps to parse Microsoft Defender Findings and supports ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ms_defender/","tags":"","title":"MS Defender Parser"},{"body":"Nancy output file (go list -json -deps ./‚Ä¶ | nancy sleuth \u003e nancy.json) can be imported in JSON format.\nFile Types This parser expects a JSON file.\nCommand Used To Generate Output  `go list -json -deps ./‚Ä¶ | nancy sleuth \u003e nancy.json`  Sample Scan Data Sample Nancy scans can be found here.\nLink To Tool See Nancy on GitHub: https://github.com/sonatype-nexus-community/nancy\n","categories":"","description":"","excerpt":"Nancy output file (go list -json -deps ./‚Ä¶ | nancy sleuth \u003e ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nancy/","tags":"","title":"Nancy Scan"},{"body":"Vulnerabilities List - JSON report\nSample Scan Data Sample Netsparker scans can be found here.\n","categories":"","description":"","excerpt":"Vulnerabilities List - JSON report\nSample Scan Data Sample Netsparker ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/netsparker/","tags":"","title":"Netsparker"},{"body":"Imports compliance scans returned by REST API.\nSample Scan Data Sample NeuVector (compliance) scans can be found here.\n","categories":"","description":"","excerpt":"Imports compliance scans returned by REST API.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/neuvector/","tags":"","title":"NeuVector (compliance)"},{"body":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample NeuVector (REST) scans can be found here.\n","categories":"","description":"","excerpt":"JSON output of /v1/scan/{entity}/{id} endpoint\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/neuvector_compliance/","tags":"","title":"NeuVector (REST)"},{"body":"Use the full XML export template from Nexpose.\nSample Scan Data Sample Nexpose XML 2.0 (Rapid7) scans can be found here.\n","categories":"","description":"","excerpt":"Use the full XML export template from Nexpose.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nexpose/","tags":"","title":"Nexpose XML 2.0 (Rapid7)"},{"body":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\n XML output (old) new XML output (with nxvmlversion=\"1.2\" type) JSON output  See: https://github.com/sullo/nikto\nSample Scan Data Sample Nikto scans can be found here.\n","categories":"","description":"","excerpt":"Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nikto/","tags":"","title":"Nikto"},{"body":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found here.\n","categories":"","description":"","excerpt":"XML output (use -oX)\nSample Scan Data Sample Nmap scans can be found ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nmap/","tags":"","title":"Nmap"},{"body":"Node Security Platform (NSP) output file can be imported in JSON format.\nSample Scan Data Sample Node Security Platform scans can be found here.\n","categories":"","description":"","excerpt":"Node Security Platform (NSP) output file can be imported in JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nsp/","tags":"","title":"Node Security Platform"},{"body":"Input Type: This parser takes JSON Lines Output from Nosey Parker: https://github.com/praetorian-inc/noseyparkerSupports\nSupports version 0.16.0: https://github.com/praetorian-inc/noseyparker/releases/tag/v0.16.0\nThings to note about the Nosey Parker Parser:  All findings are marked with a severity of ‚ÄòHigh‚Äô The deduplication algorithm marks a unique finding by the secret, filepath, and line number all together The Nosey Parker tool allows for both full history scans of a repo and targeted branch scans   The Parser does NOT differentiate between the 2 scan types (may be future functionality)\n  For full history scans:\n The scan will pick up secrets committed in the past that have since been removed If a secret is removed from source code, it will still show up in the next scan When importing findings via the Dojo API, make sure to use the parameter do_not_reactivate which will keep existing findings closed, without reactivating them    For targeted branch scans:\n Keep in mind there may be active secrets that are either in the git history or not in the current branch      JSON Lines Format: The parser only accepts .jsonl reports. Each line of the JSON Lines file from NoseyParker corresponds to a unique secret found with metadata for every match.\nSample Scan Data Sample scan data for testing purposes can be found here.\n","categories":"","description":"","excerpt":"Input Type: This parser takes JSON Lines Output from Nosey Parker: ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/noseyparker/","tags":"","title":"Nosey Parker"},{"body":"Note: This parser only supports import from NPM Audit v6 or older.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'advisories' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v6 or older due to missing relevant fields, including:\n Finding created / updated dates Relevant CVE number Finding overview (description Field) Recommendation Issue reference CWE Exploitability  See NPM‚Äôs issue on GitHub for more information. https://github.com/npm/npm-audit-report/issues/45\nAttempting to import a file from a later version of NPM Audit will raise an error message.\nSample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","categories":"","description":"","excerpt":"Note: This parser only supports import from NPM Audit v6 or older. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/npm_audit/","tags":"","title":"NPM Audit"},{"body":"Note: This parser only supports import from NPM Audit v7 or newer.\nNode Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'vulnerabilities' subtree.\nFile Types This parser expects a JSON file. Can only import NPM Audit files from NPM Audit v7 or newer. It aims to provide the same information as the non-JSON formatted output.\nAttempting to import a file from a version less than 7 of NPM Audit will raise an error message.\nCommand Used To Generate Output Either of these commands will work:\n `npm audit ‚Äìjson` `npm audit fix ‚Äìdry-run ‚Äìjson`  Sample Scan Data Sample NPM Audit scans can be found here.\nLink To Tool See NPM-Audit-Report on GitHub: https://github.com/npm/npm-audit-report/\n","categories":"","description":"","excerpt":"Note: This parser only supports import from NPM Audit v7 or newer. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/npm_audit_7_plus/","tags":"","title":"NPM Audit Version 7+"},{"body":"Import JSON output of nuclei scan report https://github.com/projectdiscovery/nuclei\nSample Scan Data Sample Nuclei scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON output of nuclei scan report ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/nuclei/","tags":"","title":"Nuclei"},{"body":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data Sample Openscap Vulnerability Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import Openscap Vulnerability Scan in XML formats.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/openscap/","tags":"","title":"Openscap Vulnerability Scan"},{"body":"You can either upload the exported results of an OpenVAS Scan in a .csv or .xml format.\nSample Scan Data Sample OpenVAS scans can be found here.\n","categories":"","description":"","excerpt":"You can either upload the exported results of an OpenVAS Scan in a ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/openvas/","tags":"","title":"OpenVAS Parser"},{"body":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample ORT evaluated model Importer scans can be found here.\n","categories":"","description":"","excerpt":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ort/","tags":"","title":"ORT evaluated model Importer"},{"body":"Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nSample Scan Data Sample OssIndex Devaudit scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON formatted output from [OSSIndex ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ossindex_devaudit/","tags":"","title":"OssIndex Devaudit"},{"body":"Use OSV-Scanner to find existing vulnerabilities affecting your project‚Äôs dependencies.\nSample Scan Data Sample OSV Scanner output can be found here.\n","categories":"","description":"","excerpt":"Use OSV-Scanner to find existing vulnerabilities affecting your ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/osv_scanner/","tags":"","title":"OSV Scanner"},{"body":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample Scan Data Sample Outpost24 Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import Outpost24 endpoint vulnerability scan in XML format.\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/outpost24/","tags":"","title":"Outpost24 Scan"},{"body":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data Sample PHP Security Audit v2 scans can be found here.\n","categories":"","description":"","excerpt":"Import PHP Security Audit v2 Scan in JSON format.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/php_security_audit_v2/","tags":"","title":"PHP Security Audit v2"},{"body":"Import results from the PHP Symfony Security Checker.\nSample Scan Data Sample PHP Symfony Security Checker scans can be found here.\n","categories":"","description":"","excerpt":"Import results from the PHP Symfony Security Checker.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/php_symfony_security_check/","tags":"","title":"PHP Symfony Security Checker"},{"body":"Import pip-audit JSON scan report.\nFile Types This parser expects a JSON file.\nThe parser can handle legacy and current JSON format.\nThe current format has added a dependencies element:\n{ \"dependencies\": [ { \"name\": \"pyopenssl\", \"version\": \"23.1.0\", \"vulns\": [] }, ... ] ... }  The legacy format does not include the dependencies key:\n[ { \"name\": \"adal\", \"version\": \"1.2.2\", \"vulns\": [] }, ... ]  Sample Scan Data Sample pip-audit Scan scans can be found here.\nLink To Tool pip-audit\n","categories":"","description":"","excerpt":"Import pip-audit JSON scan report.\nFile Types This parser expects a ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/pip_audit/","tags":"","title":"pip-audit Scan"},{"body":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.\n","categories":"","description":"","excerpt":"CSV Report\nSample Scan Data Sample PMD Scan scans can be found here.\n","ref":"/django-DefectDojo/dev/integrations/parsers/file/pmd/","tags":"","title":"PMD Scan"},{"body":"Popeye Parser documentation. Popeye is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations. For more information about the tool, please visit the public repository https://github.com/derailed/popeye.\nPopeye reports. Popeye offer different format to export their reports, in this case for the parser we have selected to be done with JSON option for simplicity. Support for other report types planned for future.\nJSON reports have the following structure:\n{ \"popeye\": { \"score\": 100, \"grade\": \"B\", \"sanitizers\": [ { \"sanitizer\": \"cluster\", \"gvr\": \"cluster\", \"tally\": { \"ok\": 1, \"info\": 0, \"warning\": 0, \"error\": 0, \"score\": 100 }, \"issues\": { \"Version\": [ { \"group\": \"__root__\", \"gvr\": \"cluster\", \"level\": 0, \"message\": \"[POP-406] K8s version OK\" } ] } } ] } } They offer a list of ‚Äúsanitizers‚Äù that is the list of scanned resources in the cluster. At the same time, each sanitizer will have a list of issues, in this case the issues names will match to specific resources of the cluster (pods, roles, clusterroles, etc.) where each one will have inside a list of specific findings for that resource (issue in the report).\nThis parser goes through every finding inside the issues of every sanitizer looking for the ones with level 1 (Info), 2 (Warning) or 3 (Error) to be created as findings in DefectDojo.\nFindings severity matching. Popeye scan findings don‚Äôt match to public vulnerabilities, it just looks for possible informational topic, warnings or errors in kubernetes resources definition or configuraiton, so they categorize their findings the following way:\n Severity 0: Ok Severity 1: Info Severity 2: Warning Severity 3: Error  To match it to DefectDojo severity formula, Secerity 0 (Ok) findings from Popeye will be ignored as those are checks that does not need an action to be resolved. For the rest:\n Severity 1 (Info) Popeye findings will be created as Severity ‚ÄúInfo‚Äù findings in DefectDojo. Severity 2 (Warning) Popeye findings will be created as Severity ‚ÄúLow‚Äù findings in DefectDojo. Severity 3 (Errors) Popeye findings will be created as Severity ‚ÄúHigh‚Äù findingsi in DefectDojo.  Sample Scan Data Sample Popeye scans can be found here.\n","categories":"","description":"","excerpt":"Popeye Parser documentation. Popeye is a utility that scans live ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/popeye/","tags":"","title":"Popeye"},{"body":"This parser imports the Progpilot SAST JSON output. The scanner can be found here.\nSample Scan Data Sample Progpilot Parser scans can be found here.\n","categories":"","description":"","excerpt":"This parser imports the Progpilot SAST JSON output. The scanner can be ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/progpilot/","tags":"","title":"Progpilot"},{"body":" (Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON results generated by the pwn_sast Driver. This driver scans source code repositories for security anti-patterns that may result in vulnerability identification. More driver results coming soon‚Ä¶  Sample Scan Data Sample PWN Security Automation Framework scans can be found here.\n","categories":"","description":"","excerpt":" (Main Page)[https://github.com/0dayinc/pwn] pwn_sast: Import the JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/pwn_sast/","tags":"","title":"PWN Security Automation Framework"},{"body":"Qualys WebGUI output files can be imported in XML format.\nSample Scan Data Sample Qualys Infrastructure Scan (WebGUI XML) scans can be found here.\n","categories":"","description":"","excerpt":"Qualys WebGUI output files can be imported in XML format.\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/qualys_infrascan_webgui/","tags":"","title":"Qualys Infrastructure Scan (WebGUI XML)"},{"body":"Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.\nA CSV formatted Qualys Scan Report can also be used. Ensure the following values are checked in the Scan Report Template config:\nCVSS Version = CVSSv3\n Vulnerability Details  Threat Impact   Solution  Patches and Workarounds Virtual Patches and Mitigating Controls   Results  Sample Scan Data Sample Qualys Scan scans can be found here.\n","categories":"","description":"","excerpt":"Qualys output files can be imported in API XML format. Qualys output ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/qualys/","tags":"","title":"Qualys Scan"},{"body":"Qualys WebScan output files can be imported in XML format.\nSample Scan Data Sample Qualys Webapp Scan scans can be found here.\n","categories":"","description":"","excerpt":"Qualys WebScan output files can be imported in XML format.\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/qualys_webapp/","tags":"","title":"Qualys Webapp Scan"},{"body":"You can import a JSON report which was retrieved through the REST API of Red Hat Satellite. The scanner can be found here.\nSample Scan Data Sample Red Hat Satellite scans can be found here.\n","categories":"","description":"","excerpt":"You can import a JSON report which was retrieved through the REST API ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/redhatsatellite/","tags":"","title":"Red Hat Satellite"},{"body":"Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nSample Scan Data Sample Retire.js scans can be found here.\n","categories":"","description":"","excerpt":"Retire.js JavaScript scan (--js) output file can be imported in JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/retirejs/","tags":"","title":"Retire.js"},{"body":"Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \"url_endpoint\": \"https://api.riskrecon.com/v1\", \"api_key\": \"you-api-key\", \"companies\": [ { \"name\": \"Company 1\", \"filters\": { \"domain_name\": [], \"ip_address\": [\"127.0.0.1\"], \"host_name\": [\"localhost\"], \"asset_value\": [], \"severity\": [\"critical\", \"high\"], \"priority\": [], \"hosting_provider\": [], \"country_name\": [] } }, { \"name\": \"Company 2\", \"filters\": { \"ip_address\": [\"0.0.0.0\"] } } ], \"filters\": { \"domain_name\": [], \"ip_address\": [], \"host_name\": [], \"asset_value\": [], \"severity\": [\"critical\"], \"priority\": [], \"hosting_provider\": [], \"country_name\": [] } }  More than one company finding list can be queried with it's own set of filters. Company 1 shows all available fitlers, while Company 2 shows that empty filters need not be present. To query all companies in your Risk Recon instance, simple remove the \"companies\" field entirely. If the \"companies\" field is not present, and filtering is still requested, the \"filters\" field can be used to filter all findings across all companies. It carries the same behavior as the company filters. The \"filters\" field is disregarded in the prescense of the \"companies\" field. Removing both fields will allow retrieval of all findings in the Risk Recon instance.  Sample Scan Data Sample Risk Recon API Importer scans can be found here.\n","categories":"","description":"","excerpt":"Import findings from Risk Recon via the API. Configure your own JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/risk_recon/","tags":"","title":"Risk Recon API Importer"},{"body":"Import Rubocop JSON scan report (with option -f json).\nSample Scan Data Sample Rubocop Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import Rubocop JSON scan report (with option -f json).\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/rubocop/","tags":"","title":"Rubocop Scan"},{"body":"From: https://github.com/newrelic/rusty-hog Import the JSON output. Rusty Hog is a secret scanner built in Rust for performance, and based on TruffleHog which is written in Python.\nDefectDojo currently supports the parsing of the following Rusty Hog JSON outputs:\n Choctaw Hog: Scans for secrets in a Git repository. Duroc Hog: Scans for secrets in directories, files, and archives. Gottingen Hog: Scans for secrets in a JIRA issue. Essex Hog: Scans for secrets in a Confluence page.  RustyHog scans only one target at a time. This is not efficient if you want to scan all targets (e.g. all JIRA tickets) and upload each single report to DefectDojo. Rusty-Hog-Wrapper deals with this and scans a whole JIRA Project or Confluence Space, merges the findings into a valid file which can be uploaded to DefectDojo. (This is no official recommendation from DefectDojo, but rather a pointer in a direction on how to use this vulnerability scanner in a more efficient way.)\nSample Scan Data Sample Rusty Hog parser scans can be found here.\n","categories":"","description":"","excerpt":"From: https://github.com/newrelic/rusty-hog Import the JSON output. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/rusty_hog/","tags":"","title":"Rusty Hog parser"},{"body":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif\nInformation SARIF parser customizes the Test_Type with data from the report. For example, a report with Dockle as a driver name will produce a Test with a Test_Type named Dockle Scan (SARIF)  Warning Current implementation is limited and will aggregate all the findings in the SARIF file in one single report.  Support for de-duplication (fingerprinting) SARIF parser take into account data for fingerprinting. It‚Äôs base on fingerprints and partialFingerprints properties. It‚Äôs possible to activate de-duplication based on this data by customizing settings.\n# in your settings.py file DEDUPLICATION_ALGORITHM_PER_PARSER[\"SARIF\"] = DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE Sample Scan Data Sample SARIF scans can be found here.\n","categories":"","description":"","excerpt":"OASIS Static Analysis Results Interchange Format (SARIF). SARIF is ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sarif/","tags":"","title":"SARIF"},{"body":"Scantist is an open source management platform. Scan and remediate open source security, licensing and compliance risks across your software development lifecycle. Here you can find more information: https://scantist.com/\nSample Scan Data Sample Scantist Scan scans can be found here.\n","categories":"","description":"","excerpt":"Scantist is an open source management platform. Scan and remediate ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/scantist/","tags":"","title":"Scantist Scan"},{"body":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects. See https://github.com/nccgroup/ScoutSuite\nSample Scan Data Sample ScoutSuite scans can be found here.\n","categories":"","description":"","excerpt":"Multi-Cloud security auditing tool. It uses APIs exposed by cloud ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/scout_suite/","tags":"","title":"ScoutSuite"},{"body":"Import Semgrep output (‚Äìjson)\nSample Scan Data Sample Semgrep JSON Report scans can be found here.\n","categories":"","description":"","excerpt":"Import Semgrep output (‚Äìjson)\nSample Scan Data Sample Semgrep JSON ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/semgrep/","tags":"","title":"Semgrep JSON Report"},{"body":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan scans can be found here.\n","categories":"","description":"","excerpt":"Output of SKF Sprint summary export.\nSample Scan Data Sample SKF Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/skf/","tags":"","title":"SKF Scan"},{"body":"Snyk output file (snyk test --json \u003e snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk scans can be found here.\n","categories":"","description":"","excerpt":"Snyk output file (snyk test --json \u003e snyk.json) can be imported in ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/snyk/","tags":"","title":"Snyk"},{"body":"Snyk output file (snyk test --json \u003e snyk.json) can be imported in JSON format. Only SCA (Software Composition Analysis) report is supported (SAST report not supported yet).\nSample Scan Data Sample Snyk Code scans can be found here.\n","categories":"","description":"","excerpt":"Snyk output file (snyk test --json \u003e snyk.json) can be imported in ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/snyk_code/","tags":"","title":"Snyk Code"},{"body":"Solar Appscreener report file can be imported in CSV format from Detailed_Results.csv\nSample Scan Data Sample Solar Appscreener Scan scans can be found here.\n","categories":"","description":"","excerpt":"Solar Appscreener report file can be imported in CSV format from ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/solar_appscreener/","tags":"","title":"Solar Appscreener Scan"},{"body":"SonarQube Scan There are two ways to retrieve findings from SonarQube. You can either use the soprasteria package or the SonarQube REST API directly. Both ways (SonarQube REST API and Soprasteria) are depicted below.\nSample Scan Data Sample SonarQube scans can be found here.\nSonarQube REST API You can retrieve the JSON directly from SonarQube if you use one of the following REST API endpoint:\n \u003csonarqubeurl\u003e/api/issues/search?projects=\u003cprojectkey\u003e \u003csonarqubeurl\u003e/api/hotspots/search?projectKey=\u003cprojectkey\u003e  JSON The REST API JSON output can be uploaded to DefectDojo with ‚ÄúSonarQube Scan‚Äù.\nZIP If you have too many findings in one project, you can implement a small script to handle pagination and put all JSON files in a .zip file. This zip file can also be parsed from DefectDojo with ‚ÄúSonarQube Scan‚Äù.\nSoprasteria Soprasteria SonarQube Scan (Aggregates findings per cwe, title, description, file_path.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u003e= 1.1.0 Recommend version for both format \u003e= 3.1.2\nSoprasteria SonarQube Scan Detailed (Import all findings from SonarQube html report.) SonarQube output file can be imported in HTML format or JSON format. JSON format generated by options --save-report-json and have same behavior with HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u003e= 1.1.0. Recommend version for both format \u003e= 3.1.2\n","categories":"","description":"","excerpt":"SonarQube Scan There are two ways to retrieve findings from SonarQube. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sonarqube/","tags":"","title":"SonarQube"},{"body":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nIn Tool Configuration, select Tool Type to ‚ÄúSonarQube‚Äù and Authentication Type ‚ÄúAPI Key‚Äù. Note the url must be in the format of https://\u003csonarqube_host\u003e/api Paste your SonarQube API token in the ‚ÄúAPI Key‚Äù field. By default the tool will import vulnerabilities issues and security hotspots only, but additional filters can be setup using the Extras field separated by commas (e.g. BUG,VULNERABILITY,CODE_SMELL). When using SonarCloud, you must also specify the Organization ID in the Extras field as follows OrgID=sonarcloud-organzation-ID. If also specifying issue type filters, please seperate the items in the Extras field by a vertical bar as follows BUG,VULNERABILITY,CODE_SMELL|OrgID=sonarcloud-organzation-ID\nIn ‚ÄúAdd API Scan Configuration‚Äù\n Service key 1 must be the SonarQube project key, which can be found by navigating to a specific project and selecting the value from the url https://\u003csonarqube_host\u003e/dashboard?id=key. When you do not provide a SonarQube project key, DefectDojo will use the name of the Product as the project key in SonarQube. If you would like to import findings from multiple projects, you can specify multiple keys as separated API Scan Configuration in the Product settings. If using SonarCloud, the orginization ID can be used from step 1, but it can be overiden by supplying a different orginization ID in the Service key 2 input field.  Multiple SonarQube API Configurations In the import or re-import dialog you can select which API Scan Configuration shall be used. If you do not choose any, DefectDojo will use the API Scan Configuration of the Product if there is only one defined or the SonarQube Tool Configuration if there is only one.\nMulti Branch Scanning If using a version of SonarQube with multi branch scanning, the branch tha be scanned can be supplied in the branch_tag fieild at import/re-import time. If the branch does not exist, a notification will be generated in the alerts table indicating that branch to be imported does not exist. If a branch name is not supplied during import/re-import, the default branch of the SonarQube project will be used.\nNote:: If https is used for the SonarQube, the certificate must be trusted by the DefectDojo instance.\n","categories":"","description":"","excerpt":"All parsers which using API have common basic configuration step but ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/sonarqube/","tags":"","title":"SonarQube API Import"},{"body":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here.\n","categories":"","description":"","excerpt":"JSON output.\nSample Scan Data Sample Sonatype scans can be found here. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sonatype/","tags":"","title":"Sonatype"},{"body":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can be found here.\n","categories":"","description":"","excerpt":"XML report of textui cli.\nSample Scan Data Sample SpotBugs scans can ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/spotbugs/","tags":"","title":"SpotBugs"},{"body":"Import JSON output of ssh_audit report. See https://github.com/jtesta/ssh-audit\nSample Scan Data Sample SSH Audit scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON output of ssh_audit report. See ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ssh_audit/","tags":"","title":"SSH Audit"},{"body":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs scans can be found here.\n","categories":"","description":"","excerpt":"JSON Output of ssllabs-scan cli.\nSample Scan Data Sample SSL Labs ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/ssl_labs/","tags":"","title":"SSL Labs"},{"body":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan scans can be found here.\n","categories":"","description":"","excerpt":"Import XML output of sslscan report.\nSample Scan Data Sample Sslscan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sslscan/","tags":"","title":"Sslscan"},{"body":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan\nSample Scan Data Sample Sslyze Scan scans can be found here.\n","categories":"","description":"","excerpt":"Sslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sslyze/","tags":"","title":"Sslyze Scan"},{"body":"Import the JSON webhook event from StackHawk. For more information, check out our docs on hooking up StackHawk to Defect Dojo\nSample Scan Data Sample StackHawk HawkScan scans can be found here.\n","categories":"","description":"","excerpt":"Import the JSON webhook event from StackHawk. For more information, ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/stackhawk/","tags":"","title":"StackHawk HawkScan"},{"body":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser will accept Pipeline, Registry and Runtime reports created from the UI\nMore information available at our reporting docs page\nSample Scan Data Sample Sysdig Vulnerability Reports scans can be found here.\n","categories":"","description":"","excerpt":"Import CSV report files from Sysdig or a Sysdig UI JSON Report Parser ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/sysdig_reports/","tags":"","title":"Sysdig Vulnerability Reports"},{"body":"Run Talisman in CLI mode and use ‚Äú‚Äìscan‚Äù argument to scan the git commit history along with ‚Äú‚ÄìreportDirectory‚Äù argument to save the scan reports to a directory. The report will be in JSON format.\nAdditionally, you can set up Git Hooks to automate the scan and then send the generated reports to DefectDojo using its API.\nExample:\n#!/bin/sh  # Set DefectDojo API credential and other variables DEFECTDOJO_API_KEY=\"your-api-key\" DEFECTDOJO_URL=\"https://your-defectdojo-url.com\" TALISMAN_RESULTS_DIR=\"$HOME\" # Run talisman in CLI mode and output the result in JSON format CMD=\"talisman --scan --ignoreHistory --reportDirectory $TALISMAN_RESULTS_DIR\" $CMD # Extract the result result=$(jq '.results[].filename' \"${TALISMAN_RESULTS_DIR}/talisman_reports/data/report.json\") # Check if result is not empty if [ -n \"$result\" ]; then # If talisman found issues, send the JSON output to DefectDojo API endpoint curl -X POST \\  -H \"Authorization: Token $DEFECTDOJO_API_KEY\" \\  -H \"Content-Type: application/json\" \\  -d \"@$TALISMAN_RESULTS_DIR/talisman_reports/data/report.json\" \\  \"$DEFECTDOJO_URL/api/v2/import-scan/\" # Exit with a non-zero status code to indicate that the commit should be rejected exit 1 else # If talisman did not find any issues, exit with a zero status code exit 0 fi Sample Scan Data Sample Talisman scans can be found here.\n","categories":"","description":"","excerpt":"Run Talisman in CLI mode and use ‚Äú‚Äìscan‚Äù argument to scan the git ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/talisman/","tags":"","title":"Talisman"},{"body":"Reports can be imported in the CSV, and .nessus (XML) report formats. Legacy Nessus and Nessus WAS reports are supported\nSample Scan Data Sample Tenable scans can be found here.\n","categories":"","description":"","excerpt":"Reports can be imported in the CSV, and .nessus (XML) report formats. ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/tenable/","tags":"","title":"Tenable"},{"body":"Import JSON output of terrascan scan report https://github.com/accurics/terrascan\nSample Scan Data Sample Terrascan scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON output of terrascan scan report ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/terrascan/","tags":"","title":"Terrascan"},{"body":"Import CSV output of testssl scan report.\nSample Scan Data Sample Testssl Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import CSV output of testssl scan report.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/testssl/","tags":"","title":"Testssl Scan"},{"body":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan Data Sample TFSec scans can be found here.\n","categories":"","description":"","excerpt":"Import of JSON report from https://github.com/tfsec/tfsec\nSample Scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/tfsec/","tags":"","title":"TFSec"},{"body":"File Types DefectDojo parser accepts a .json file.\nJSON reports are created from the Threagile tool (default name risks.json) using the following command:\ndocker run --rm -it -v \"$(pwd)\":/app/work threagile/threagile -verbose -model /app/work/threagile.yaml -output /app/work Acceptable JSON Format Parser expects an array of finding. All properties are strings. Required fields are the following\n ‚Äúcategory‚Äù ‚Äútitle‚Äù ‚Äúseverity‚Äù ‚Äúsynthetic_id‚Äù ‚Äúexploitation_impact‚Äù  catergory fields is used to set both the title of the Finding as well as the cwe. most_relevant_technical_asset field is used to determine the component.\n [ { \"category\": \"unguarded-direct-datastore-access\", \"risk_status\": \"unchecked\", \"severity\": \"elevated\", \"exploitation_likelihood\": \"likely\", \"exploitation_impact\": \"medium\", \"title\": \"\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eEnergon\\u003c/b\\u003e via \\u003cb\\u003eEnergonToPolicyRegoFileStorage\\u003c/b\\u003e\", \"synthetic_id\": \"unguarded-direct-datastore-access@energon-ta\\u003eenergontopolicyregofilestorage@energon-ta@policies-rego-storage-ta\", \"most_relevant_data_asset\": \"\", \"most_relevant_technical_asset\": \"policies-rego-storage-ta\", \"most_relevant_trust_boundary\": \"\", \"most_relevant_shared_runtime\": \"\", \"most_relevant_communication_link\": \"energon-ta\\u003eenergontopolicyregofilestorage\", \"data_breach_probability\": \"improbable\", \"data_breach_technical_assets\": [ \"policies-rego-storage-ta\" ] }, { \"category\": \"unguarded-direct-datastore-access\", \"risk_status\": \"in-discussion\", \"severity\": \"elevated\", \"exploitation_likelihood\": \"likely\", \"exploitation_impact\": \"medium\", \"title\": \"\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIAMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMBachendAPIPoliciesRegoFileStorage\\u003c/b\\u003e\", \"synthetic_id\": \"unguarded-direct-datastore-access@iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage@iam-sidecar-ta@policies-rego-storage-ta\", \"most_relevant_data_asset\": \"\", \"most_relevant_technical_asset\": \"policies-rego-storage-ta\", \"most_relevant_trust_boundary\": \"\", \"most_relevant_shared_runtime\": \"\", \"most_relevant_communication_link\": \"iam-sidecar-ta\\u003eiambachendapipoliciesregofilestorage\", \"data_breach_probability\": \"improbable\", \"data_breach_technical_assets\": [ \"policies-rego-storage-ta\" ] }, { \"category\": \"unguarded-direct-datastore-access\", \"risk_status\": \"accepted\", \"severity\": \"elevated\", \"exploitation_likelihood\": \"likely\", \"exploitation_impact\": \"medium\", \"title\": \"\\u003cb\\u003eUnguarded Direct Datastore Access\\u003c/b\\u003e of \\u003cb\\u003ePoliciesRegoStorage\\u003c/b\\u003e by \\u003cb\\u003eIDMSidecar\\u003c/b\\u003e via \\u003cb\\u003eIAMSidecarPoliciesRegoFileStorage\\u003c/b\\u003e\", \"synthetic_id\": \"unguarded-direct-datastore-access@idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage@idm-sidecar-ta@policies-rego-storage-ta\", \"most_relevant_data_asset\": \"\", \"most_relevant_technical_asset\": \"policies-rego-storage-ta\", \"most_relevant_trust_boundary\": \"\", \"most_relevant_shared_runtime\": \"\", \"most_relevant_communication_link\": \"idm-sidecar-ta\\u003eiamsidecarpoliciesregofilestorage\", \"data_breach_probability\": \"improbable\", \"data_breach_technical_assets\": [ \"policies-rego-storage-ta\" ] }, ... ] Sample Scan Data Sample Threagile scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file.\nJSON reports are ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/threagile/","tags":"","title":"Threagile"},{"body":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can be found here.\n","categories":"","description":"","excerpt":"JSON report of trivy scanner.\nSample Scan Data Sample Trivy scans can ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trivy/","tags":"","title":"Trivy"},{"body":"JSON report of trivy operator scanner.\nTo import the generated Vulnerability Reports, you can also use the trivy-dojo-report-operator.\nSample Scan Data Sample Trivy Operator scans can be found here.\n","categories":"","description":"","excerpt":"JSON report of trivy operator scanner.\nTo import the generated ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trivy_operator/","tags":"","title":"Trivy Operator"},{"body":"JSON Output of Trufflehog. Supports version 2 and 3 of https://github.com/trufflesecurity/trufflehog\nSample Scan Data Sample Trufflehog scans can be found here.\n","categories":"","description":"","excerpt":"JSON Output of Trufflehog. Supports version 2 and 3 of ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trufflehog/","tags":"","title":"Trufflehog"},{"body":"JSON Output of Trufflehog3, a fork of TruffleHog located at https://github.com/feeltheajf/truffleHog3\nSample Scan Data Sample Trufflehog3 scans can be found here.\n","categories":"","description":"","excerpt":"JSON Output of Trufflehog3, a fork of TruffleHog located at ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trufflehog3/","tags":"","title":"Trufflehog3"},{"body":"CSV output of Trustwave vulnerability scan.\nSample Scan Data Sample Trustwave scans can be found here.\n","categories":"","description":"","excerpt":"CSV output of Trustwave vulnerability scan.\nSample Scan Data Sample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trustwave/","tags":"","title":"Trustwave"},{"body":"Trustwave Fusion API report file can be imported in JSON format\nSample Scan Data Sample Trustwave Fusion API Scan scans can be found here.\n","categories":"","description":"","excerpt":"Trustwave Fusion API report file can be imported in JSON format\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/trustwave_fusion_api/","tags":"","title":"Trustwave Fusion API Scan"},{"body":"JSON output of the twistcli tool. Example:\n./twistcli images scan \u003cREGISTRY/REPO:TAG\u003e --address https://\u003cSECURE_URL_OF_TWISTLOCK_CONSOLE\u003e --user \u003cUSER\u003e --details --output-file=\u003cPATH_TO_SAVE_JSON_FILE\u003e The CSV output from the UI is now also accepted.\nSample Scan Data Sample Twistlock scans can be found here.\n","categories":"","description":"","excerpt":"JSON output of the twistcli tool. Example:\n./twistcli images scan ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/twistlock/","tags":"","title":"Twistlock"},{"body":"Veracode reports can be ingested in either XML or JSON Format\n Detailed XML Report JSON REST Findings from /appsec/v2/applications/{application_guid}/findings/  Acceptable scan types include STATIC, DYNAMIC, and SCA Findings with a status of CLOSED will not be imported into DefectDojo Acceptable formats are as follows:  Findings list  Requires slight modification of the response returned from the API Exmample of a request being: url \u003cendpoint\u003e | jq \"{findings}\" Desired Format: { \"findings\": [ { ... }, ... ] }    Embedded  This response can be saved directly to a file and uploaded Not as ideal for crafting a refined report consisting of multiple requests Desired Format: { \"_embedded\": { \"findings\": [ { ... }, ... ] }, \"_links\": { ... }, \"page\": { ... } }         Sample Scan Data Sample Veracode scans can be found here.\n","categories":"","description":"","excerpt":"Veracode reports can be ingested in either XML or JSON Format ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/veracode/","tags":"","title":"Veracode"},{"body":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode SourceClear scans can be found here.\n","categories":"","description":"","excerpt":"Import Project CSV or JSON report\nSample Scan Data Sample Veracode ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/veracode_sca/","tags":"","title":"Veracode SourceClear"},{"body":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data Sample Visual Code Grepper (VCG) scans can be found here.\n","categories":"","description":"","excerpt":"VCG output can be imported in CSV or Xml formats.\nSample Scan Data ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/vcg/","tags":"","title":"Visual Code Grepper (VCG)"},{"body":"All parsers which using API have common basic configuration step but with different values. Please, read these steps at first.\nImport Vulners Audit results, no file required.\nIn Tool Configuration, select Tool Type to ‚ÄúVulners‚Äù and add the API Key\nIn the Product settings select Add API Scan Configuration and select the previously added Vulners API Tool Configuration.\nAfter this is done, you can import the findings by selecting ‚ÄúVulners‚Äù as the scan type.\nDetailed installation steps can be found in vulners documentation.\nUse following instructions to generate Vulners API Key.\nMore details about DefectDojo-plugin integration can be found at vulners integrations page.\n","categories":"","description":"","excerpt":"All parsers which using API have common basic configuration step but ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/api/vulners/","tags":"","title":"Vulners"},{"body":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be found here.\n","categories":"","description":"","excerpt":"Import XML report.\nSample Scan Data Sample Wapiti Scan scans can be ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/wapiti/","tags":"","title":"Wapiti Scan"},{"body":"File Types DefectDojo parser accepts a .json file from Wazuh. The export from Wazuh can be done via 2 ways. Choose the one which you prefer.\n export the Wazuh findings from API and upload them to DefectDojo. This method may be the easiest one but does export all known vulnerabilities at once. It is not possible to sort them after clients or any other categories. You will receive all vulnerabilities in one engagement. It also does not output the endpoint of a finding. export the findings via the script available here. The script fetches the findings by Wazuh client groups and saves them as json, ready for upload. You will receive one file per group allowing you to separate the clients via engagements in Wazuh. It also exports the endpoints hostname and displays them in DefectDojo UI.  Independent of your above choice: Have in mind to adjust the max file size via ‚ÄúDD_SCAN_FILE_MAX_SIZE‚Äù if you see files larger than the default value of 100MB. Depending on the amount and category of integrated devices, the file size jumps rapidly.\nAcceptable JSON Format Parser expects a .json file structured as below.\n{ \"data\": { \"affected_items\": [ { \"architecture\": \"amd64\", \"condition\": \"Package less than 4.3.2\", \"cve\": \"CVE-1234-123123\", \"cvss2_score\": 0, \"cvss3_score\": 5.5, \"detection_time\": \"2023-02-08T13:55:10Z\", \"external_references\": [ \"https://nvd.nist.gov/vuln/detail/CVE-YYYY-XXXXX\", \"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-YYYY-XXXXX\" ], \"name\": \"asdf\", \"published\": \"2022-09-01\", \"severity\": \"Medium\", \"status\": \"VALID\", \"title\": \"CVE-YYYY-XXXXX affects asdf\", \"type\": \"PACKAGE\", \"updated\": \"2022-09-07\", \"version\": \"4.3.1\" } ], \"failed_items\": [], \"total_affected_items\": 1, \"total_failed_items\": 0 }, \"error\": 0, \"message\": \"All selected vulnerabilities were returned\" } Sample Scan Data Sample Wazuh Scanner scans can be found here.\n","categories":"","description":"","excerpt":"File Types DefectDojo parser accepts a .json file from Wazuh. The ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/wazuh/","tags":"","title":"Wazuh Scanner"},{"body":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).\n   HTTP Return Code Severity     missing Low   200 - 299 High   300 - 399 Low   400 - 499 Medium     = 500 | Low\n Sample Scan Data Sample Wfuzz JSON importer scans can be found here.\n","categories":"","description":"","excerpt":"Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/wfuzz/","tags":"","title":"Wfuzz JSON importer"},{"body":"Import Whispers JSON results. https://github.com/adeptex/whispers\nSample Scan Data Sample Whispers scans can be found here.\n","categories":"","description":"","excerpt":"Import Whispers JSON results. https://github.com/adeptex/whispers ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/whispers/","tags":"","title":"Whispers"},{"body":"WhiteHat Sentinel output from api/vuln/query_site can be imported in JSON format.\nSample Scan Data Sample WhiteHat Sentinel scans can be found here.\n","categories":"","description":"","excerpt":"WhiteHat Sentinel output from api/vuln/query_site can be imported in ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/whitehat_sentinel/","tags":"","title":"WhiteHat Sentinel"},{"body":"This parser imports scan results from wiz. You have to use Report Type Standard when you export the results. The file format will be .csv which is parsable within DefectDojo.\nSample Scan Data Sample Wiz Scanner scans can be found here.\n","categories":"","description":"","excerpt":"This parser imports scan results from wiz. You have to use Report Type ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/wiz/","tags":"","title":"Wiz Scanner"},{"body":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can be found here.\n","categories":"","description":"","excerpt":"Import JSON report.\nSample Scan Data Sample Wpscan Scanner scans can ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/wpscan/","tags":"","title":"Wpscan Scanner"},{"body":"Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nSample Scan Data Sample Xanitizer scans can be found here.\n","categories":"","description":"","excerpt":"Import XML findings list report, preferably with parameter ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/xanitizer/","tags":"","title":"Xanitizer"},{"body":"Import Yarn Audit scan report in JSON format. Use something like yarn audit --json \u003e yarn_report.json.\nSample Scan Data Sample Yarn Audit scans can be found here.\n","categories":"","description":"","excerpt":"Import Yarn Audit scan report in JSON format. Use something like yarn ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/yarn_audit/","tags":"","title":"Yarn Audit"},{"body":"ZAP XML report format (with or without requests and responses).\nSample Scan Data Sample Zed Attack Proxy scans can be found here.\n","categories":"","description":"","excerpt":"ZAP XML report format (with or without requests and responses).\nSample ‚Ä¶","ref":"/django-DefectDojo/dev/integrations/parsers/file/zap/","tags":"","title":"Zed Attack Proxy"}]